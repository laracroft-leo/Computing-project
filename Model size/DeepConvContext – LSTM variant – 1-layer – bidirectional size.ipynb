{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"L4","authorship_tag":"ABX9TyOZe3MRNHSY6inH7o56XEAP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["# ============ DeepConvContext (A100 80GB high-throughput v2.1) structure & size ============\n","\n","import json\n","from pathlib import Path\n","\n","import torch\n","import torch.nn as nn\n","\n","print(\"\\n[DeepConvContext (A100 80GB high-throughput v2.1) – structure & size]\")\n","\n","# ---------------------------\n","# 1) Determine NUM_CLASSES\n","# ---------------------------\n","BASE = Path(\"/content\")\n","CFG_DIR = BASE / \"configs\"\n","\n","if (CFG_DIR / \"classes.json\").exists():\n","    with open(CFG_DIR / \"classes.json\", \"r\") as f:\n","        classes_cfg = json.load(f)\n","    NUM_CLASSES = int(classes_cfg[\"num_classes\"])\n","    print(f\"Detected NUM_CLASSES from configs: {NUM_CLASSES}\")\n","else:\n","    # Change this default if your experiment uses a different number of classes\n","    NUM_CLASSES = 8\n","    print(\"Warning: /content/configs/classes.json not found. Using default NUM_CLASSES = 8.\")\n","    print(\"Please update NUM_CLASSES manually if this does not match your setup.\")\n","\n","# ---------------------------\n","# 2) Hyperparameters (must match training script)\n","# ---------------------------\n","NUM_CHANNELS      = 6\n","SAMPLES_PER_WIN   = 150\n","STRIDE_SAMPLES    = 75\n","CONTEXT_LEN_WINS  = 100\n","\n","EPOCHS        = 30          # does not affect structure\n","BASE_LR       = 1e-4\n","WEIGHT_DECAY  = 1e-6\n","DROPOUT_P     = 0.5\n","BIDIRECTIONAL = True\n","\n","CONV_CHANNELS    = 64\n","INTRA_LSTM_UNITS = 128\n","INTER_LSTM_UNITS = 128\n","PROJECTION_DIM   = 128\n","KERNEL_SIZE      = 9\n","\n","print(f\"\\nConfig for size check:\")\n","print(f\"  NUM_CLASSES      = {NUM_CLASSES}\")\n","print(f\"  NUM_CHANNELS     = {NUM_CHANNELS}\")\n","print(f\"  SAMPLES_PER_WIN  = {SAMPLES_PER_WIN}\")\n","print(f\"  CONTEXT_LEN_WINS = {CONTEXT_LEN_WINS}\")\n","print(f\"  CONV_CHANNELS    = {CONV_CHANNELS}\")\n","print(f\"  INTRA_LSTM_UNITS = {INTRA_LSTM_UNITS}\")\n","print(f\"  INTER_LSTM_UNITS = {INTER_LSTM_UNITS}\")\n","print(f\"  PROJECTION_DIM   = {PROJECTION_DIM}\")\n","print(f\"  BIDIRECTIONAL    = {BIDIRECTIONAL}\")\n","\n","# ---------------------------\n","# 3) Model definition (must match Step 10 exactly)\n","# ---------------------------\n","class DeepConvLSTM_Intra(nn.Module):\n","    def __init__(self, in_ch=6, conv_ch=64, kernel_size=9, lstm_units=128):\n","        super().__init__()\n","        pad = kernel_size // 2\n","        self.conv1 = nn.Conv1d(in_ch,   conv_ch, kernel_size, padding=pad)\n","        self.conv2 = nn.Conv1d(conv_ch, conv_ch, kernel_size, padding=pad)\n","        self.conv3 = nn.Conv1d(conv_ch, conv_ch, kernel_size, padding=pad)\n","        self.conv4 = nn.Conv1d(conv_ch, conv_ch, kernel_size, padding=pad)\n","        self.relu  = nn.ReLU(inplace=True)\n","        self.lstm  = nn.LSTM(\n","            input_size=conv_ch,\n","            hidden_size=lstm_units,\n","            num_layers=1,\n","            batch_first=True\n","        )\n","\n","    def forward(self, x_win):           # x_win: (N, C, T)\n","        x = self.relu(self.conv1(x_win))\n","        x = self.relu(self.conv2(x))\n","        x = self.relu(self.conv3(x))\n","        x = self.relu(self.conv4(x))\n","        x = x.permute(0, 2, 1)          # (N, T, C)\n","        _, (h_n, _) = self.lstm(x)\n","        return h_n[-1]                  # (N, lstm_units)\n","\n","\n","class DeepConvContext(nn.Module):\n","    def __init__(self, num_channels=6, num_classes=8,\n","                 conv_channels=64, intra_lstm_units=128,\n","                 inter_lstm_units=128, projection_dim=128,\n","                 dropout=0.5, bidirectional=True):\n","        super().__init__()\n","        self.intra = DeepConvLSTM_Intra(\n","            in_ch=num_channels,\n","            conv_ch=conv_channels,\n","            kernel_size=KERNEL_SIZE,\n","            lstm_units=intra_lstm_units\n","        )\n","        self.proj  = nn.Linear(intra_lstm_units, projection_dim)\n","        self.inter = nn.LSTM(\n","            input_size=projection_dim,\n","            hidden_size=inter_lstm_units,\n","            num_layers=1,\n","            batch_first=True,\n","            bidirectional=bidirectional\n","        )\n","        inter_out = inter_lstm_units * (2 if bidirectional else 1)\n","        self.dropout = nn.Dropout(dropout)\n","        self.fc = nn.Linear(inter_out, num_classes)\n","\n","    def forward(self, x):               # x: (B, S, C, T) → (B, S, K)\n","        B, S, C, T = x.shape\n","        x2d = x.reshape(B * S, C, T)\n","        feats = self.intra(x2d).view(B, S, -1)     # (B, S, intra_lstm_units)\n","        proj  = self.proj(feats)                   # (B, S, projection_dim)\n","        inter_out, _ = self.inter(proj)            # (B, S, inter_out)\n","        inter_out = self.dropout(inter_out)\n","        logits = self.fc(inter_out)                # (B, S, num_classes)\n","        return logits\n","\n","# ---------------------------\n","# 4) Instantiate model and compute size\n","# ---------------------------\n","model = DeepConvContext(\n","    num_channels=NUM_CHANNELS,\n","    num_classes=NUM_CLASSES,\n","    conv_channels=CONV_CHANNELS,\n","    intra_lstm_units=INTRA_LSTM_UNITS,\n","    inter_lstm_units=INTER_LSTM_UNITS,\n","    projection_dim=PROJECTION_DIM,\n","    dropout=DROPOUT_P,\n","    bidirectional=BIDIRECTIONAL\n",")\n","\n","print(\"\\n====== nn.Module structure ======\")\n","print(model)\n","\n","# Parameter counts\n","total_params = sum(p.numel() for p in model.parameters())\n","trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","print(\"\\n====== Parameter statistics ======\")\n","print(f\"Total params:      {total_params:,}\")\n","print(f\"Trainable params:  {trainable_params:,}\")\n","\n","print(\"\\n====== Per-layer parameter counts ======\")\n","for name, p in model.named_parameters():\n","    print(f\"{name:40s} shape={tuple(p.shape)}  params={p.numel():,}\")\n","\n","# Size estimation (weights only)\n","def fmt_mb(n_bytes: int) -> str:\n","    return f\"{n_bytes / 1024 / 1024:.2f} MB\"\n","\n","bytes_fp32 = total_params * 4   # float32: 4 bytes per parameter\n","bytes_fp16 = total_params * 2   # float16: 2 bytes per parameter\n","\n","print(\"\\n====== Model size estimate (parameters only) ======\")\n","print(f\"FP32 (float32, 4B/param): {fmt_mb(bytes_fp32)}\")\n","print(f\"FP16 (float16, 2B/param): {fmt_mb(bytes_fp16)}\")\n","\n","# Save a randomly initialised state_dict to check actual .pth size\n","models_dir = BASE / \"models\"\n","models_dir.mkdir(parents=True, exist_ok=True)\n","tmp_path = models_dir / \"deepconvcontext_a100_v21_dummy.pth\"\n","torch.save(model.state_dict(), tmp_path)\n","file_bytes = tmp_path.stat().st_size\n","print(f\"\\nRandom-initialised state_dict saved to {tmp_path.name}\")\n","print(f\"Actual .pth file size: {fmt_mb(file_bytes)}\")\n","tmp_path.unlink(missing_ok=True)\n","\n","print(\"\\n[DeepConvContext (A100 80GB high-throughput v2.1) structure & size – done]\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0eyKlwuQOGTh","executionInfo":{"status":"ok","timestamp":1763406550095,"user_tz":0,"elapsed":4066,"user":{"displayName":"yu Wu","userId":"12692660435918028293"}},"outputId":"f69a2ea2-3202-4ef2-81b4-0d37fcd1101d"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","[DeepConvContext (A100 80GB high-throughput v2.1) – structure & size]\n","Warning: /content/configs/classes.json not found. Using default NUM_CLASSES = 8.\n","Please update NUM_CLASSES manually if this does not match your setup.\n","\n","Config for size check:\n","  NUM_CLASSES      = 8\n","  NUM_CHANNELS     = 6\n","  SAMPLES_PER_WIN  = 150\n","  CONTEXT_LEN_WINS = 100\n","  CONV_CHANNELS    = 64\n","  INTRA_LSTM_UNITS = 128\n","  INTER_LSTM_UNITS = 128\n","  PROJECTION_DIM   = 128\n","  BIDIRECTIONAL    = True\n","\n","====== nn.Module structure ======\n","DeepConvContext(\n","  (intra): DeepConvLSTM_Intra(\n","    (conv1): Conv1d(6, 64, kernel_size=(9,), stride=(1,), padding=(4,))\n","    (conv2): Conv1d(64, 64, kernel_size=(9,), stride=(1,), padding=(4,))\n","    (conv3): Conv1d(64, 64, kernel_size=(9,), stride=(1,), padding=(4,))\n","    (conv4): Conv1d(64, 64, kernel_size=(9,), stride=(1,), padding=(4,))\n","    (relu): ReLU(inplace=True)\n","    (lstm): LSTM(64, 128, batch_first=True)\n","  )\n","  (proj): Linear(in_features=128, out_features=128, bias=True)\n","  (inter): LSTM(128, 128, batch_first=True, bidirectional=True)\n","  (dropout): Dropout(p=0.5, inplace=False)\n","  (fc): Linear(in_features=256, out_features=8, bias=True)\n",")\n","\n","====== Parameter statistics ======\n","Total params:      496,392\n","Trainable params:  496,392\n","\n","====== Per-layer parameter counts ======\n","intra.conv1.weight                       shape=(64, 6, 9)  params=3,456\n","intra.conv1.bias                         shape=(64,)  params=64\n","intra.conv2.weight                       shape=(64, 64, 9)  params=36,864\n","intra.conv2.bias                         shape=(64,)  params=64\n","intra.conv3.weight                       shape=(64, 64, 9)  params=36,864\n","intra.conv3.bias                         shape=(64,)  params=64\n","intra.conv4.weight                       shape=(64, 64, 9)  params=36,864\n","intra.conv4.bias                         shape=(64,)  params=64\n","intra.lstm.weight_ih_l0                  shape=(512, 64)  params=32,768\n","intra.lstm.weight_hh_l0                  shape=(512, 128)  params=65,536\n","intra.lstm.bias_ih_l0                    shape=(512,)  params=512\n","intra.lstm.bias_hh_l0                    shape=(512,)  params=512\n","proj.weight                              shape=(128, 128)  params=16,384\n","proj.bias                                shape=(128,)  params=128\n","inter.weight_ih_l0                       shape=(512, 128)  params=65,536\n","inter.weight_hh_l0                       shape=(512, 128)  params=65,536\n","inter.bias_ih_l0                         shape=(512,)  params=512\n","inter.bias_hh_l0                         shape=(512,)  params=512\n","inter.weight_ih_l0_reverse               shape=(512, 128)  params=65,536\n","inter.weight_hh_l0_reverse               shape=(512, 128)  params=65,536\n","inter.bias_ih_l0_reverse                 shape=(512,)  params=512\n","inter.bias_hh_l0_reverse                 shape=(512,)  params=512\n","fc.weight                                shape=(8, 256)  params=2,048\n","fc.bias                                  shape=(8,)  params=8\n","\n","====== Model size estimate (parameters only) ======\n","FP32 (float32, 4B/param): 1.89 MB\n","FP16 (float16, 2B/param): 0.95 MB\n","\n","Random-initialised state_dict saved to deepconvcontext_a100_v21_dummy.pth\n","Actual .pth file size: 1.90 MB\n","\n","[DeepConvContext (A100 80GB high-throughput v2.1) structure & size – done]\n","\n"]}]}]}