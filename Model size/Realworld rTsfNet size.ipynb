{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"L4","authorship_tag":"ABX9TyPAf3iHu/lu50nGeRFrAi7X"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["# ============ Official rTsfNet (IMWUT 2024, TSF-Mixer + multi-head rotation) – structure & size ============\n","\n","import json\n","import math\n","from pathlib import Path\n","\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras import Input, Model\n","from tensorflow.keras.layers import (\n","    Dense, Dropout, LayerNormalization, LeakyReLU,\n","    Layer, Activation, TimeDistributed, Flatten, Concatenate,\n","    GlobalAveragePooling1D\n",")\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.regularizers import l2\n","\n","print(\"\\n[Official rTsfNet (IMWUT 2024) – structure & size]\")\n","\n","# ---------------------------\n","# 1) Load num_classes and window length if configs exist\n","# ---------------------------\n","BASE = Path(\"/content\")\n","CFG_DIR = BASE / \"configs\"\n","\n","if (CFG_DIR / \"classes.json\").exists():\n","    with open(CFG_DIR / \"classes.json\", \"r\") as f:\n","        classes_cfg = json.load(f)\n","    NUM_CLASSES = int(classes_cfg[\"num_classes\"])\n","    if \"window_config\" in classes_cfg and \"window_samples\" in classes_cfg[\"window_config\"]:\n","        WINDOW_SAMPLES = int(classes_cfg[\"window_config\"][\"window_samples\"])\n","    else:\n","        WINDOW_SAMPLES = 150\n","    print(f\"Detected NUM_CLASSES = {NUM_CLASSES}, WINDOW_SAMPLES = {WINDOW_SAMPLES} from configs.\")\n","else:\n","    NUM_CLASSES = 8\n","    WINDOW_SAMPLES = 150\n","    print(\"Warning: /content/configs/classes.json not found.\")\n","    print(f\"Using defaults: NUM_CLASSES = {NUM_CLASSES}, WINDOW_SAMPLES = {WINDOW_SAMPLES}.\")\n","\n","# ---------------------------\n","# 2) Hyperparameters (must match your official rTsfNet script)\n","# ---------------------------\n","FS                 = 50.0\n","IMU_ROT_HEADS      = 2\n","MLP_BASE           = 128\n","MLP_DEPTH          = 3\n","DROPOUT            = 0.5\n","LR                 = 1e-3\n","WEIGHT_DECAY       = 1e-6\n","USE_ORIG_INPUT     = True\n","USE_BINARY_SELECTION = True\n","LN_EPS             = 1e-7\n","PAD_MODE           = \"SYMMETRIC\"\n","\n","BLOCK_SPECS = [\n","    dict(name=\"short\", num_blocks=4, use_time=True,  use_freq=False),\n","    dict(name=\"long\",  num_blocks=1, use_time=False, use_freq=True),\n","]\n","\n","TIME_FEATS = 12  # mean/std/max/min/ptp/rms/energy/skew/kurt/zcr/ar1/ar2\n","FREQ_FEATS = 7   # centroid/entropy/flatness/soft-peak/bandpowers(3)\n","\n","print(f\"\\nConfig for size check:\")\n","print(f\"  NUM_CLASSES         = {NUM_CLASSES}\")\n","print(f\"  WINDOW_SAMPLES      = {WINDOW_SAMPLES}\")\n","print(f\"  IMU_ROT_HEADS       = {IMU_ROT_HEADS}\")\n","print(f\"  MLP_BASE            = {MLP_BASE}\")\n","print(f\"  MLP_DEPTH           = {MLP_DEPTH}\")\n","print(f\"  DROPOUT             = {DROPOUT}\")\n","print(f\"  WEIGHT_DECAY        = {WEIGHT_DECAY}\")\n","print(f\"  USE_ORIG_INPUT      = {USE_ORIG_INPUT}\")\n","print(f\"  USE_BINARY_SELECTION= {USE_BINARY_SELECTION}\")\n","print(f\"  PAD_MODE            = {PAD_MODE}\")\n","\n","# ---------------------------\n","# 3) Utility MLP stack (shared)\n","# ---------------------------\n","class MLPStack(Layer):\n","    \"\"\"\n","    Dense -> LayerNorm -> LeakyReLU -> Dropout repeated 'depth' times,\n","    hidden width base_kn * (2**k), k: depth-1..0; output dimensionality is base_kn.\n","    \"\"\"\n","    def __init__(self, base_kn=128, depth=3, drop=0.5, wd=0.0, ln_eps=1e-7, name=None):\n","        super().__init__(name=name)\n","        self.base_kn = int(base_kn)\n","        self.depth = int(depth)\n","        self.drop = float(drop)\n","        self.wd = float(wd)\n","        self.ln_eps = float(ln_eps)\n","\n","        self.seq = []\n","        for k in range(self.depth - 1, -1, -1):\n","            self.seq.append(Dense(self.base_kn * (2**k), kernel_regularizer=l2(self.wd)))\n","            self.seq.append(LayerNormalization(epsilon=self.ln_eps))\n","            self.seq.append(LeakyReLU())\n","            self.seq.append(Dropout(self.drop))\n","\n","    @property\n","    def out_dim(self):\n","        return self.base_kn\n","\n","    def call(self, x, training=None):\n","        z = x\n","        for lyr in self.seq:\n","            if isinstance(lyr, Dropout):\n","                z = lyr(z, training=training)\n","            else:\n","                z = lyr(z)\n","        return z\n","\n","    def compute_output_shape(self, input_shape):\n","        return tf.TensorShape([input_shape[0], self.out_dim])\n","\n","# ---------------------------\n","# 4) TSF feature layer (axis-wise)\n","# ---------------------------\n","class TSFFeatureLayer(Layer):\n","    \"\"\"\n","    Compute axis-wise TSF features for a single block [B, L, C];\n","    output shape [B, C, F] where F is the TSF feature dimensionality.\n","    \"\"\"\n","    def __init__(self, fs=50.0, use_time=True, use_freq=True, **kwargs):\n","        super().__init__(**kwargs)\n","        self.fs = float(fs)\n","        self.use_time = bool(use_time)\n","        self.use_freq = bool(use_freq)\n","        self.eps = 1e-8\n","        self._feat_dim = (TIME_FEATS if self.use_time else 0) + (FREQ_FEATS if self.use_freq else 0)\n","\n","    def get_config(self):\n","        cfg = super().get_config()\n","        cfg.update({'fs': self.fs, 'use_time': self.use_time, 'use_freq': self.use_freq})\n","        return cfg\n","\n","    def call(self, x):  # x: [B, L, C]\n","        feats = []\n","        if self.use_time:\n","            mean = tf.reduce_mean(x, axis=1, keepdims=True)\n","            std  = tf.math.reduce_std(x, axis=1, keepdims=True) + self.eps\n","            maxv = tf.reduce_max(x, axis=1, keepdims=True)\n","            minv = tf.reduce_min(x, axis=1, keepdims=True)\n","            ptp  = maxv - minv\n","            rms  = tf.sqrt(tf.reduce_mean(tf.square(x), axis=1, keepdims=True))\n","            energy = tf.reduce_sum(tf.square(x), axis=1, keepdims=True)\n","            skew = tf.reduce_mean(tf.pow((x - mean) / std, 3), axis=1, keepdims=True)\n","            kurt = tf.reduce_mean(tf.pow((x - mean) / std, 4), axis=1, keepdims=True)\n","            signs = tf.sign(x)\n","            sign_changes = tf.abs(signs[:, 1:, :] - signs[:, :-1, :])\n","            zcr = tf.reduce_mean(sign_changes, axis=1, keepdims=True) / 2.0\n","            x_t1 = x[:, :-1, :]; x_tn1 = x[:, 1:, :]\n","            ar1 = tf.reduce_sum(x_t1 * x_tn1, axis=1, keepdims=True) / (\n","                tf.reduce_sum(tf.square(x_t1), axis=1, keepdims=True) + self.eps\n","            )\n","            x_t2 = x[:, :-2, :]; x_tn2 = x[:, 2:, :]\n","            ar2 = tf.reduce_sum(x_t2 * x_tn2, axis=1, keepdims=True) / (\n","                tf.reduce_sum(tf.square(x_t2), axis=1, keepdims=True) + self.eps\n","            )\n","            feats += [mean, std, maxv, minv, ptp, rms, energy, skew, kurt, zcr, ar1, ar2]\n","\n","        if self.use_freq:\n","            mean = tf.reduce_mean(x, axis=1, keepdims=True)\n","            xc = x - mean\n","            x_bc_t = tf.transpose(xc, [0, 2, 1])          # [B, C, L]\n","            fft = tf.signal.rfft(x_bc_t)                  # [B, C, F]\n","            power = tf.square(tf.abs(fft)) + self.eps     # [B, C, F]\n","            power = tf.transpose(power, [0, 2, 1])        # [B, F, C]\n","\n","            F = tf.shape(power)[1]\n","            freqs = tf.linspace(0.0, tf.cast(self.fs, tf.float32) / 2.0, F)\n","            freqs = tf.reshape(freqs, [1, F, 1])          # [1, F, 1]\n","\n","            p = power / (tf.reduce_sum(power, axis=1, keepdims=True) + self.eps)\n","            centroid = tf.reduce_sum(p * freqs, axis=1, keepdims=True)\n","            entropy  = -tf.reduce_sum(p * tf.math.log(p + self.eps), axis=1, keepdims=True) / (\n","                tf.math.log(tf.cast(F, tf.float32) + self.eps)\n","            )\n","            geo = tf.exp(tf.reduce_mean(tf.math.log(power), axis=1, keepdims=True))\n","            ari = tf.reduce_mean(power, axis=1, keepdims=True)\n","            flatness = geo / (ari + self.eps)\n","            temp = 10.0\n","            w = tf.nn.softmax(power * temp, axis=1)\n","            soft_peak = tf.reduce_sum(w * freqs, axis=1, keepdims=True)\n","\n","            def band(low, high):\n","                mask = tf.cast((freqs >= low) & (freqs < high), tf.float32)\n","                bp = tf.reduce_sum(power * mask, axis=1, keepdims=True) / (\n","                    tf.reduce_sum(power, axis=1, keepdims=True) + self.eps\n","                )\n","                return bp\n","\n","            bp1 = band(0.5, 3.0); bp2 = band(3.0, 8.0); bp3 = band(8.0, 15.0)\n","            feats += [centroid, entropy, flatness, soft_peak, bp1, bp2, bp3]\n","\n","        res = tf.concat(feats, axis=1)                    # [B, Fnum, C]\n","        return tf.transpose(res, [0, 2, 1])               # [B, C, Fnum]\n","\n","    def compute_output_shape(self, input_shape):\n","        return tf.TensorShape([input_shape[0], input_shape[2], self._feat_dim])\n","\n","# ---------------------------\n","# 5) L2 channels layers\n","# ---------------------------\n","class AddL2Channels(Layer):\n","    def call(self, x, training=None):\n","        acc = x[:, :, :3]\n","        gyr = x[:, :, 3:6]\n","        l2_acc = tf.sqrt(tf.reduce_sum(tf.square(acc), axis=-1, keepdims=True))\n","        l2_gyr = tf.sqrt(tf.reduce_sum(tf.square(gyr), axis=-1, keepdims=True))\n","        return tf.concat([x, l2_acc, l2_gyr], axis=-1)  # [B, T, 8]\n","\n","    def compute_output_shape(self, input_shape):\n","        return tf.TensorShape([input_shape[0], input_shape[1], 8])\n","\n","\n","class AddL2ChannelsPublic(Layer):\n","    def call(self, x, training=None):\n","        acc = x[:, :, :3]\n","        gyr = x[:, :, 3:6]\n","        l2_acc = tf.sqrt(tf.reduce_sum(tf.square(acc), axis=-1, keepdims=True))\n","        l2_gyr = tf.sqrt(tf.reduce_sum(tf.square(gyr), axis=-1, keepdims=True))\n","        return tf.concat([x, l2_acc, l2_gyr], axis=-1)  # [B, T, 8]\n","\n","# ---------------------------\n","# 6) Block framing (Keras 3 safe)\n","# ---------------------------\n","def _int_ceil_div(a, b):\n","    a = tf.cast(a, tf.int32); b = tf.cast(b, tf.int32)\n","    return tf.math.floordiv(a + b - 1, b)\n","\n","def frame_signal_with_padding(x, num_blocks, pad_mode='SYMMETRIC'):\n","    \"\"\"\n","    x: [B, T, C] -> symmetric padding to length L * num_blocks\n","    and reshape to [B, num_blocks, L, C].\n","    \"\"\"\n","    B = tf.shape(x)[0]; T = tf.shape(x)[1]; C = tf.shape(x)[2]\n","    nb = tf.cast(num_blocks, tf.int32)\n","    L  = _int_ceil_div(T, nb)\n","    total = L * nb\n","    pad_len = total - T\n","    pad_left  = tf.math.floordiv(pad_len, 2)\n","    pad_right = pad_len - pad_left\n","    paddings = tf.stack([\n","        tf.constant([0, 0], dtype=tf.int32),\n","        tf.stack([pad_left, pad_right]),\n","        tf.constant([0, 0], dtype=tf.int32)\n","    ], axis=0)\n","    x_pad = tf.pad(x, paddings, mode=pad_mode)\n","    x_blocks = tf.reshape(x_pad, [B, nb, L, C])\n","    return x_blocks\n","\n","# ---------------------------\n","# 7) TSF block extractor\n","# ---------------------------\n","def _feat_dim_for_spec(use_time, use_freq, tag_dim):\n","    base = (TIME_FEATS if use_time else 0) + (FREQ_FEATS if use_freq else 0)\n","    return base + tag_dim\n","\n","class BlockTSFExtractor(Layer):\n","    \"\"\"\n","    Apply TSF extraction and axis-tag injection for a block set.\n","    Input:  x with shape [B, T, C]\n","    Output: TSF tensor [B, num_blocks, A, F_total] (A = C; F_total includes tags).\n","    \"\"\"\n","    def __init__(self, num_blocks, fs, use_time, use_freq,\n","                 tag_spec=None, pad_mode='SYMMETRIC', name=None, **kwargs):\n","        super().__init__(name=name, **kwargs)\n","        self.num_blocks = int(num_blocks)\n","        self.tsf = TSFFeatureLayer(fs=fs, use_time=use_time, use_freq=use_freq)\n","        self.tag_spec = tag_spec\n","        self.pad_mode = pad_mode\n","        self.tag_dim = 0 if (tag_spec is None or 'axis_tags' not in tag_spec) else int(tag_spec['axis_tags'].shape[1])\n","        self.base_feat_dim = (TIME_FEATS if use_time else 0) + (FREQ_FEATS if use_freq else 0)\n","        self.out_feat_dim = self.base_feat_dim + self.tag_dim\n","\n","    def get_config(self):\n","        cfg = super().get_config()\n","        cfg.update({'num_blocks': self.num_blocks, 'fs': self.tsf.fs,\n","                    'use_time': self.tsf.use_time, 'use_freq': self.tsf.use_freq,\n","                    'pad_mode': self.pad_mode})\n","        return cfg\n","\n","    def call(self, x, training=None):  # x: [B, T, C]\n","        xb = frame_signal_with_padding(x, self.num_blocks, pad_mode=self.pad_mode)  # [B, K, L, C]\n","        B = tf.shape(xb)[0]; K = tf.shape(xb)[1]; L = tf.shape(xb)[2]; C = tf.shape(xb)[3]\n","        xb2 = tf.reshape(xb, [B * K, L, C])                        # [B*K, L, C]\n","        tsf_axis = self.tsf(xb2)                                   # [B*K, C, F]\n","        tsf_axis = tf.reshape(tsf_axis, [B, K, C, self.base_feat_dim])  # [B, K, A, F_base]\n","\n","        if self.tag_dim > 0:\n","            axis_tags = tf.convert_to_tensor(self.tag_spec['axis_tags'], dtype=tsf_axis.dtype)  # [A, tag_dim]\n","            axis_tags = tf.reshape(axis_tags, [1, 1, tf.shape(tsf_axis)[2], -1])               # [1,1,A,tag_dim]\n","            axis_tags = tf.tile(axis_tags, [B, K, 1, 1])                                       # [B,K,A,tag_dim]\n","            tsf_axis = tf.concat([tsf_axis, axis_tags], axis=-1)                               # [B,K,A,F_base+tag_dim]\n","        return tsf_axis\n","\n","    def compute_output_shape(self, input_shape):\n","        return tf.TensorShape([input_shape[0], self.num_blocks, input_shape[2], self.out_feat_dim])\n","\n","# ---------------------------\n","# 8) Binary gate (STE)\n","# ---------------------------\n","class BinaryGate(Layer):\n","    def call(self, p, training=None):\n","        p = tf.clip_by_value(p, 0.0, 1.0)\n","        hard = tf.round(p)\n","        return hard + tf.stop_gradient(p - hard)\n","\n","    def compute_output_shape(self, input_shape):\n","        return tf.TensorShape(input_shape)\n","\n","# ---------------------------\n","# 9) TSF-Mixer sub-block and block\n","# ---------------------------\n","class TSFMixerSubBlock(Layer):\n","    \"\"\"\n","    Input: per-block axis-level TSF features [B', A, F]\n","    Axis-shared MLP -> concat axes -> MLP -> block feature\n","    \"\"\"\n","    def __init__(self, axis_hidden=128, out_hidden=128, base_depth=2,\n","                 drop=0.5, wd=0.0, ln_eps=1e-7, name=None):\n","        super().__init__(name=name)\n","        self.axis_hidden = int(axis_hidden)\n","        self.out_hidden = int(out_hidden)\n","        self.base_depth = int(base_depth)\n","        self.drop = float(drop); self.wd = float(wd); self.ln_eps = float(ln_eps)\n","\n","        self.axis_mlp_layers = []\n","        for k in range(self.base_depth - 1, -1, -1):\n","            self.axis_mlp_layers.append(Dense(self.axis_hidden * (2**k), kernel_regularizer=l2(self.wd)))\n","            self.axis_mlp_layers.append(LayerNormalization(epsilon=self.ln_eps))\n","            self.axis_mlp_layers.append(LeakyReLU())\n","            self.axis_mlp_layers.append(Dropout(self.drop))\n","\n","        self.out_stack = MLPStack(base_kn=self.out_hidden, depth=self.base_depth,\n","                                  drop=self.drop, wd=self.wd, ln_eps=self.ln_eps,\n","                                  name=f'{self.name}_out')\n","\n","    def call(self, x, training=None, **kwargs):  # x: [B', A, F]\n","        Bp = tf.shape(x)[0]; A = tf.shape(x)[1]; F = tf.shape(x)[2]\n","        x2 = tf.reshape(x, [Bp * A, F])\n","        z = x2\n","        for lyr in self.axis_mlp_layers:\n","            if isinstance(lyr, Dropout):\n","                z = lyr(z, training=training)\n","            else:\n","                z = lyr(z)\n","        z = tf.reshape(z, [Bp, A, self.axis_hidden])      # [B', A, H_axis]\n","        z = tf.reshape(z, [Bp, A * self.axis_hidden])     # [B', A*H_axis]\n","        z = self.out_stack(z, training=training)          # [B', H_out]\n","        return z\n","\n","    def compute_output_shape(self, input_shape):\n","        return tf.TensorShape([input_shape[0], self.out_stack.out_dim])\n","\n","\n","class TSFMixerBlock(Layer):\n","    \"\"\"\n","    Extends the sub-Block with:\n","      - channel-wise binary selection over feature dim\n","      - axis-wise binary selection over axis dim\n","    \"\"\"\n","    def __init__(self, feat_dim, axis_hidden=128, out_hidden=128, base_depth=2,\n","                 drop=0.5, wd=0.0, ln_eps=1e-7, use_binary=True, name=None):\n","        super().__init__(name=name)\n","        self.use_binary = bool(use_binary)\n","        self.sub = TSFMixerSubBlock(axis_hidden, out_hidden, base_depth, drop, wd, ln_eps,\n","                                    name=f'{name}_sub')\n","\n","        self.axis_gate_dense = Dense(1, activation='sigmoid', name=f'{name}_axis_gate')\n","        self.chan_gate_dense = Dense(int(feat_dim), activation='sigmoid', name=f'{name}_chan_gate')\n","        self.bin_gate = BinaryGate(name=f'{name}_bin')\n","        self.out_stack = MLPStack(base_kn=out_hidden, depth=base_depth,\n","                                  drop=drop, wd=wd, ln_eps=ln_eps, name=f'{name}_out')\n","\n","    def call(self, x, training=None, **kwargs):  # x: [B', A, F]\n","        Bp = tf.shape(x)[0]; A = tf.shape(x)[1]; F = tf.shape(x)[2]\n","\n","        x_mean_axis = tf.reduce_mean(x, axis=1)         # [B', F]\n","        p_chan = self.chan_gate_dense(x_mean_axis)      # [B', F]\n","        p_chan = tf.reshape(p_chan, [Bp, 1, F])\n","        g_chan = self.bin_gate(p_chan, training=training) if self.use_binary else p_chan\n","        x = x * g_chan\n","\n","        x2 = tf.reshape(x, [Bp * A, F])\n","        z = x2\n","        for lyr in self.sub.axis_mlp_layers:\n","            if isinstance(lyr, Dropout):\n","                z = lyr(z, training=training)\n","            else:\n","                z = lyr(z)\n","        z = tf.reshape(z, [Bp, A, self.sub.axis_hidden])   # [B', A, H_axis]\n","\n","        p_axis = self.axis_gate_dense(z)                   # [B', A, 1]\n","        g_axis = self.bin_gate(p_axis, training=training) if self.use_binary else p_axis\n","        z = z * g_axis\n","\n","        z = tf.reshape(z, [Bp, A * self.sub.axis_hidden])  # [B', A*H_axis]\n","        z = self.out_stack(z, training=training)           # [B', H_out]\n","        return z\n","\n","    def compute_output_shape(self, input_shape):\n","        return tf.TensorShape([input_shape[0], self.out_stack.out_dim])\n","\n","# ---------------------------\n","# 10) Rotation parameter estimator\n","# ---------------------------\n","class RotationParamEstimator(Layer):\n","    \"\"\"\n","    Input: [B, T, 6] raw IMU; internally append L2 channels,\n","    extract TSF (for multiple block sets), TSF-Mixer -> concat -> MLP -> Dense(4, tanh).\n","    \"\"\"\n","    def __init__(self, block_specs, fs, mlp_base=128, mlp_depth=2,\n","                 drop=0.5, wd=0.0, ln_eps=1e-7,\n","                 use_binary=True, pad_mode='SYMMETRIC', name=None):\n","        super().__init__(name=name)\n","        self.block_specs = block_specs\n","        self.fs = fs\n","        self.mlp_base = int(mlp_base)\n","        self.mlp_depth = int(mlp_depth)\n","        self.drop = float(drop)\n","        self.wd = float(wd)\n","        self.ln_eps = float(ln_eps)\n","        self.use_binary = bool(use_binary)\n","        self.pad_mode = pad_mode\n","\n","        axis_tags = []\n","        for i in range(8):\n","            axis_type = i + 1\n","            sensor_type = 1 if (i <= 2 or i == 6) else 2\n","            axis_tags.append([axis_type, sensor_type])\n","        axis_tags = np.array(axis_tags, dtype=np.float32)\n","        self.tag_spec = {'axis_tags': axis_tags}\n","        tag_dim = axis_tags.shape[1]\n","\n","        self.extractors = []\n","        self.td_mixers  = []\n","        self.flatteners = []\n","        for spec in block_specs:\n","            ext = BlockTSFExtractor(num_blocks=spec['num_blocks'], fs=fs,\n","                                    use_time=spec['use_time'], use_freq=spec['use_freq'],\n","                                    tag_spec=self.tag_spec, pad_mode=self.pad_mode,\n","                                    name=f'rot_ext_{spec[\"name\"]}')\n","            self.extractors.append(ext)\n","            feat_dim = _feat_dim_for_spec(spec['use_time'], spec['use_freq'], tag_dim)\n","            mix = TSFMixerBlock(feat_dim=feat_dim, axis_hidden=self.mlp_base,\n","                                out_hidden=self.mlp_base,\n","                                base_depth=max(1, self.mlp_depth - 1),\n","                                drop=self.drop, wd=self.wd,\n","                                ln_eps=self.ln_eps, use_binary=self.use_binary,\n","                                name=f'rot_mix_{spec[\"name\"]}')\n","            self.td_mixers.append(TimeDistributed(mix, name=f'rot_td_{spec[\"name\"]}'))\n","            self.flatteners.append(Flatten(name=f'rot_flat_{spec[\"name\"]}'))\n","\n","        self.concat_sets = Concatenate(name='rot_concat_sets')\n","        self.post_stack = MLPStack(base_kn=self.mlp_base, depth=self.mlp_depth,\n","                                   drop=self.drop, wd=self.wd, ln_eps=self.ln_eps,\n","                                   name='rot_post')\n","        self.out_head = Dense(4, activation='tanh', name='rot4_tanh')\n","        self.add_l2 = AddL2Channels()\n","\n","    def call(self, x, training=None, **kwargs):  # x: [B, T, 6]\n","        x8 = self.add_l2(x)  # [B, T, 8]\n","        feats_all = []\n","        for ext, td, flt in zip(self.extractors, self.td_mixers, self.flatteners):\n","            tsf_blocks = ext(x8, training=training)        # [B, K, A, F]\n","            blk_feat   = td(tsf_blocks, training=training) # [B, K, H]\n","            blk_feat   = flt(blk_feat)                     # [B, K*H]\n","            feats_all.append(blk_feat)\n","        h = self.concat_sets(feats_all)                    # [B, sum(K*H)]\n","        h = self.post_stack(h, training=training)\n","        rot4 = self.out_head(h)                            # [B, 4]\n","        return rot4\n","\n","    def compute_output_shape(self, input_shape):\n","        return tf.TensorShape([input_shape[0], 4])\n","\n","# ---------------------------\n","# 11) Multi-head 3D rotation (official)\n","# ---------------------------\n","class Multihead3DRotationOfficial(Layer):\n","    \"\"\"\n","    Input [B, T, 6]; output: list of rotated streams [B, T, 6].\n","    Rotation parameters estimated by RotationParamEstimator; parameters accumulated across heads.\n","    \"\"\"\n","    def __init__(self, head_nums=2, fs=50.0, mlp_base=128, mlp_depth=2,\n","                 drop=0.5, wd=0.0, ln_eps=1e-7,\n","                 block_specs=None, use_binary=True, pad_mode='SYMMETRIC', name=None):\n","        super().__init__(name=name)\n","        if block_specs is None:\n","            block_specs = BLOCK_SPECS\n","        self.head_nums = int(head_nums)\n","        self.estimator = RotationParamEstimator(block_specs=block_specs, fs=fs,\n","                                                mlp_base=mlp_base, mlp_depth=mlp_depth,\n","                                                drop=drop, wd=wd,\n","                                                ln_eps=ln_eps, use_binary=use_binary,\n","                                                pad_mode=pad_mode,\n","                                                name='rot_estimator')\n","        self.eps = 1e-8\n","\n","    def compute_output_shape(self, input_shape):\n","        return [tf.TensorShape(input_shape) for _ in range(self.head_nums)]\n","\n","    def _axis_angle_to_R(self, axis_raw, angle_raw):\n","        axis = axis_raw / (tf.norm(axis_raw, axis=-1, keepdims=True) + self.eps)\n","        theta = angle_raw * math.pi\n","        B = tf.shape(axis)[0]\n","        ux, uy, uz = axis[:, 0], axis[:, 1], axis[:, 2]\n","        z = tf.zeros_like(ux)\n","        K = tf.stack([z, -uz,  uy,\n","                      uz,  z, -ux,\n","                     -uy,  ux,  z], axis=-1)\n","        K = tf.reshape(K, [B, 3, 3])\n","        I = tf.tile(tf.eye(3, dtype=axis.dtype)[None, ...], [B, 1, 1])\n","        u = tf.expand_dims(axis, -1)\n","        uuT = tf.matmul(u, u, transpose_b=True)\n","        cos = tf.reshape(tf.cos(theta), [-1, 1, 1])\n","        sin = tf.reshape(tf.sin(theta), [-1, 1, 1])\n","        R = cos * I + (1.0 - cos) * uuT + sin * K\n","        return R\n","\n","    def call(self, x, training=None, **kwargs):  # x: [B, T, 6]\n","        acc, gyr = x[:, :, :3], x[:, :, 3:6]\n","        out_list = []\n","        prev_rot4 = None\n","        for _ in range(self.head_nums):\n","            rot4 = self.estimator(x, training=training)  # [B, 4]\n","            if prev_rot4 is not None:\n","                rot4 = rot4 + prev_rot4\n","            prev_rot4 = rot4\n","            axis  = rot4[:, :3]\n","            angle = tf.expand_dims(rot4[:, 3], -1)\n","            R = self._axis_angle_to_R(axis, angle)       # [B, 3, 3]\n","\n","            acc_t = tf.transpose(acc, [0, 2, 1])\n","            acc_rot = tf.transpose(tf.matmul(R, acc_t), [0, 2, 1])\n","            gyr_t = tf.transpose(gyr, [0, 2, 1])\n","            gyr_rot = tf.transpose(tf.matmul(R, gyr_t), [0, 2, 1])\n","\n","            out_list.append(tf.concat([acc_rot, gyr_rot], axis=-1))  # [B, T, 6]\n","        return out_list\n","\n","# ---------------------------\n","# 12) Official rTsfNet body\n","# ---------------------------\n","def r_tsf_net_official(x_shape, n_classes,\n","                       learning_rate=1e-3, base_kn=128, depth=3, dropout_rate=0.5,\n","                       imu_rot_heads=2, fs=50.0, use_orig_input=True,\n","                       use_binary_selection=True, ln_eps=1e-7, pad_mode='SYMMETRIC'):\n","\n","    inputs = Input(shape=x_shape[1:])     # [T, 6]\n","    x = inputs\n","\n","    rot_layer = Multihead3DRotationOfficial(\n","        head_nums=imu_rot_heads, fs=fs,\n","        mlp_base=base_kn, mlp_depth=max(1, depth - 1),\n","        drop=dropout_rate, wd=WEIGHT_DECAY,\n","        ln_eps=ln_eps, block_specs=BLOCK_SPECS,\n","        use_binary=use_binary_selection, pad_mode=pad_mode,\n","        name='multihead_rot_official'\n","    )\n","    rotated_list = rot_layer(x)           # list of [B, T, 6]\n","\n","    streams = []\n","    add_l2 = AddL2ChannelsPublic()\n","    if use_orig_input:\n","        streams.append(add_l2(x))         # [B, T, 8]\n","    for xr in rotated_list:\n","        streams.append(add_l2(xr))\n","    concat_streams = Concatenate(axis=-1, name='concat_streams')(streams)  # [B, T, 8*(1+heads)]\n","\n","    feats_all_sets = []\n","\n","    num_streams = (1 if use_orig_input else 0) + imu_rot_heads\n","    axis_tags_one_stream = []\n","    for i in range(8):\n","        axis_type = i + 1\n","        sensor_type = 1 if (i <= 2 or i == 6) else 2\n","        axis_tags_one_stream.append([axis_type, sensor_type])\n","    axis_tags_one_stream = np.array(axis_tags_one_stream, dtype=np.float32)\n","    axis_tags_all = np.concatenate(\n","        [axis_tags_one_stream for _ in range(num_streams)],\n","        axis=0\n","    )\n","    tag_spec_main = {'axis_tags': axis_tags_all}\n","    tag_dim_main = axis_tags_all.shape[1]\n","\n","    for spec in BLOCK_SPECS:\n","        ext = BlockTSFExtractor(num_blocks=spec['num_blocks'], fs=fs,\n","                                use_time=spec['use_time'], use_freq=spec['use_freq'],\n","                                tag_spec=tag_spec_main, pad_mode=pad_mode,\n","                                name=f'main_ext_{spec[\"name\"]}')\n","        feat_dim = _feat_dim_for_spec(spec['use_time'], spec['use_freq'], tag_dim_main)\n","        mix = TSFMixerBlock(feat_dim=feat_dim, axis_hidden=base_kn, out_hidden=base_kn,\n","                            base_depth=max(1, depth - 1), drop=dropout_rate,\n","                            wd=WEIGHT_DECAY, ln_eps=ln_eps,\n","                            use_binary=use_binary_selection,\n","                            name=f'main_mix_{spec[\"name\"]}')\n","        td  = TimeDistributed(mix, name=f'main_td_{spec[\"name\"]}')\n","        flt = Flatten(name=f'main_flat_{spec[\"name\"]}')\n","\n","        tsf_blocks = ext(concat_streams)  # [B, K, A_all, F]\n","        blk_feat   = td(tsf_blocks)       # [B, K, H]\n","        blk_feat   = flt(blk_feat)        # [B, K*H]\n","        feats_all_sets.append(blk_feat)\n","\n","    z = Concatenate(name='main_concat_sets')(feats_all_sets)\n","    cls_stack = MLPStack(base_kn=base_kn, depth=depth,\n","                         drop=dropout_rate, wd=WEIGHT_DECAY,\n","                         ln_eps=ln_eps, name='cls')\n","    z = cls_stack(z)\n","    logits = Dense(n_classes, kernel_regularizer=l2(WEIGHT_DECAY),\n","                   name='logits')(z)\n","    probs  = Activation('softmax', dtype='float32', name='softmax')(logits)\n","\n","    model = Model(inputs, probs, name='rTsfNet_official_aligned')\n","\n","    opt = Adam(learning_rate=learning_rate, amsgrad=True)\n","    model.compile(\n","        loss='sparse_categorical_crossentropy',\n","        optimizer=opt,\n","        metrics=['accuracy']\n","    )\n","    return model\n","\n","# ---------------------------\n","# 13) Build model and compute size\n","# ---------------------------\n","x_shape = (1, WINDOW_SAMPLES, 6)\n","\n","model = r_tsf_net_official(\n","    x_shape=x_shape,\n","    n_classes=NUM_CLASSES,\n","    learning_rate=LR,\n","    base_kn=MLP_BASE,\n","    depth=MLP_DEPTH,\n","    dropout_rate=DROPOUT,\n","    imu_rot_heads=IMU_ROT_HEADS,\n","    fs=FS,\n","    use_orig_input=USE_ORIG_INPUT,\n","    use_binary_selection=USE_BINARY_SELECTION,\n","    ln_eps=LN_EPS,\n","    pad_mode=PAD_MODE\n",")\n","\n","print(\"\\n====== Keras model.summary() ======\\n\")\n","model.summary(line_length=140)\n","\n","total_params = model.count_params()\n","print(f\"\\nTotal parameters: {total_params:,}\")\n","\n","def fmt_mb(n_bytes: int) -> str:\n","    return f\"{n_bytes / 1024 / 1024:.2f} MB\"\n","\n","bytes_fp32 = total_params * 4\n","bytes_fp16 = total_params * 2\n","\n","print(\"\\n====== Model size estimate (parameters only) ======\")\n","print(f\"FP32 (float32, 4B/param): {fmt_mb(bytes_fp32)}\")\n","print(f\"FP16 (float16, 2B/param): {fmt_mb(bytes_fp16)}\")\n","\n","models_dir = BASE / \"models\"\n","models_dir.mkdir(parents=True, exist_ok=True)\n","tmp_path = models_dir / \"rtsfnet_official_dummy.weights.h5\"\n","model.save_weights(tmp_path)\n","file_bytes = tmp_path.stat().st_size\n","print(f\"\\nRandom-initialised weights saved to: {tmp_path.name}\")\n","print(f\"Actual .weights.h5 file size:       {fmt_mb(file_bytes)}\")\n","\n","print(\"\\n[Official rTsfNet (IMWUT 2024) – structure & size done]\\n\")"],"metadata":{"id":"3NaWdh3JRy7H","executionInfo":{"status":"ok","timestamp":1763407512966,"user_tz":0,"elapsed":2962,"user":{"displayName":"yu Wu","userId":"12692660435918028293"}},"outputId":"cc1f291b-2889-44a9-d8a2-eb2a6ac1a38b","colab":{"base_uri":"https://localhost:8080/","height":1000}},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","[Official rTsfNet (IMWUT 2024) – structure & size]\n","Warning: /content/configs/classes.json not found.\n","Using defaults: NUM_CLASSES = 8, WINDOW_SAMPLES = 150.\n","\n","Config for size check:\n","  NUM_CLASSES         = 8\n","  WINDOW_SAMPLES      = 150\n","  IMU_ROT_HEADS       = 2\n","  MLP_BASE            = 128\n","  MLP_DEPTH           = 3\n","  DROPOUT             = 0.5\n","  WEIGHT_DECAY        = 1e-06\n","  USE_ORIG_INPUT      = True\n","  USE_BINARY_SELECTION= True\n","  PAD_MODE            = SYMMETRIC\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/layers/layer.py:421: UserWarning: `build()` was called on layer 'rot_mix_short', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/keras/src/layers/layer.py:421: UserWarning: `build()` was called on layer 'rot_mix_long', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/keras/src/layers/layer.py:421: UserWarning: `build()` was called on layer 'main_mix_short', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/keras/src/layers/layer.py:421: UserWarning: `build()` was called on layer 'main_mix_long', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","====== Keras model.summary() ======\n","\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"rTsfNet_official_aligned\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"rTsfNet_official_aligned\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                           \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape                     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m              Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected t\u001b[0m\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━\n","│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m6\u001b[0m)                    │                     \u001b[38;5;34m0\u001b[0m │ -          \n","├─────────────────────────────────────────┼───────────────────────────────────┼───────────────────────┼────────────\n","│ multihead_rot_official                  │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m6\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m6\u001b[0m)]  │               \u001b[38;5;34m465,458\u001b[0m │ input_layer\n","│ (\u001b[38;5;33mMultihead3DRotationOfficial\u001b[0m)           │                                   │                       │            \n","├─────────────────────────────────────────┼───────────────────────────────────┼───────────────────────┼────────────\n","│ add_l2_channels_public                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m8\u001b[0m)                    │                     \u001b[38;5;34m0\u001b[0m │ input_layer\n","│ (\u001b[38;5;33mAddL2ChannelsPublic\u001b[0m)                   │                                   │                       │ multihead_r\n","│                                         │                                   │                       │ multihead_r\n","├─────────────────────────────────────────┼───────────────────────────────────┼───────────────────────┼────────────\n","│ concat_streams (\u001b[38;5;33mConcatenate\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m24\u001b[0m)                   │                     \u001b[38;5;34m0\u001b[0m │ add_l2_chan\n","│                                         │                                   │                       │ add_l2_chan\n","│                                         │                                   │                       │ add_l2_chan\n","├─────────────────────────────────────────┼───────────────────────────────────┼───────────────────────┼────────────\n","│ main_ext_short (\u001b[38;5;33mBlockTSFExtractor\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m14\u001b[0m)                 │                     \u001b[38;5;34m0\u001b[0m │ concat_stre\n","├─────────────────────────────────────────┼───────────────────────────────────┼───────────────────────┼────────────\n","│ main_ext_long (\u001b[38;5;33mBlockTSFExtractor\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m9\u001b[0m)                  │                     \u001b[38;5;34m0\u001b[0m │ concat_stre\n","├─────────────────────────────────────────┼───────────────────────────────────┼───────────────────────┼────────────\n","│ main_td_short (\u001b[38;5;33mTimeDistributed\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)                    │                     \u001b[38;5;34m0\u001b[0m │ main_ext_sh\n","├─────────────────────────────────────────┼───────────────────────────────────┼───────────────────────┼────────────\n","│ main_td_long (\u001b[38;5;33mTimeDistributed\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)                    │                     \u001b[38;5;34m0\u001b[0m │ main_ext_lo\n","├─────────────────────────────────────────┼───────────────────────────────────┼───────────────────────┼────────────\n","│ main_flat_short (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                       │                     \u001b[38;5;34m0\u001b[0m │ main_td_sho\n","├─────────────────────────────────────────┼───────────────────────────────────┼───────────────────────┼────────────\n","│ main_flat_long (\u001b[38;5;33mFlatten\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                       │                     \u001b[38;5;34m0\u001b[0m │ main_td_lon\n","├─────────────────────────────────────────┼───────────────────────────────────┼───────────────────────┼────────────\n","│ main_concat_sets (\u001b[38;5;33mConcatenate\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m640\u001b[0m)                       │                     \u001b[38;5;34m0\u001b[0m │ main_flat_s\n","│                                         │                                   │                       │ main_flat_l\n","├─────────────────────────────────────────┼───────────────────────────────────┼───────────────────────┼────────────\n","│ cls (\u001b[38;5;33mMLPStack\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                       │               \u001b[38;5;34m494,208\u001b[0m │ main_concat\n","├─────────────────────────────────────────┼───────────────────────────────────┼───────────────────────┼────────────\n","│ logits (\u001b[38;5;33mDense\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                         │                 \u001b[38;5;34m1,032\u001b[0m │ cls[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n","├─────────────────────────────────────────┼───────────────────────────────────┼───────────────────────┼────────────\n","│ softmax (\u001b[38;5;33mActivation\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                         │                     \u001b[38;5;34m0\u001b[0m │ logits[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m\n","└─────────────────────────────────────────┴───────────────────────────────────┴───────────────────────┴────────────\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━\n","┃<span style=\"font-weight: bold\"> Layer (type)                            </span>┃<span style=\"font-weight: bold\"> Output Shape                      </span>┃<span style=\"font-weight: bold\">               Param # </span>┃<span style=\"font-weight: bold\"> Connected t</span>\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━\n","│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)                    │                     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -          \n","├─────────────────────────────────────────┼───────────────────────────────────┼───────────────────────┼────────────\n","│ multihead_rot_official                  │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)]  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">465,458</span> │ input_layer\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multihead3DRotationOfficial</span>)           │                                   │                       │            \n","├─────────────────────────────────────────┼───────────────────────────────────┼───────────────────────┼────────────\n","│ add_l2_channels_public                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                    │                     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AddL2ChannelsPublic</span>)                   │                                   │                       │ multihead_r\n","│                                         │                                   │                       │ multihead_r\n","├─────────────────────────────────────────┼───────────────────────────────────┼───────────────────────┼────────────\n","│ concat_streams (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                   │                     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_l2_chan\n","│                                         │                                   │                       │ add_l2_chan\n","│                                         │                                   │                       │ add_l2_chan\n","├─────────────────────────────────────────┼───────────────────────────────────┼───────────────────────┼────────────\n","│ main_ext_short (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BlockTSFExtractor</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)                 │                     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concat_stre\n","├─────────────────────────────────────────┼───────────────────────────────────┼───────────────────────┼────────────\n","│ main_ext_long (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BlockTSFExtractor</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)                  │                     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concat_stre\n","├─────────────────────────────────────────┼───────────────────────────────────┼───────────────────────┼────────────\n","│ main_td_short (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                    │                     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ main_ext_sh\n","├─────────────────────────────────────────┼───────────────────────────────────┼───────────────────────┼────────────\n","│ main_td_long (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                    │                     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ main_ext_lo\n","├─────────────────────────────────────────┼───────────────────────────────────┼───────────────────────┼────────────\n","│ main_flat_short (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                       │                     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ main_td_sho\n","├─────────────────────────────────────────┼───────────────────────────────────┼───────────────────────┼────────────\n","│ main_flat_long (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                       │                     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ main_td_lon\n","├─────────────────────────────────────────┼───────────────────────────────────┼───────────────────────┼────────────\n","│ main_concat_sets (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span>)                       │                     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ main_flat_s\n","│                                         │                                   │                       │ main_flat_l\n","├─────────────────────────────────────────┼───────────────────────────────────┼───────────────────────┼────────────\n","│ cls (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MLPStack</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                       │               <span style=\"color: #00af00; text-decoration-color: #00af00\">494,208</span> │ main_concat\n","├─────────────────────────────────────────┼───────────────────────────────────┼───────────────────────┼────────────\n","│ logits (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                         │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">1,032</span> │ cls[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n","├─────────────────────────────────────────┼───────────────────────────────────┼───────────────────────┼────────────\n","│ softmax (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                         │                     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ logits[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>\n","└─────────────────────────────────────────┴───────────────────────────────────┴───────────────────────┴────────────\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m960,698\u001b[0m (3.66 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">960,698</span> (3.66 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m960,698\u001b[0m (3.66 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">960,698</span> (3.66 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Total parameters: 960,698\n","\n","====== Model size estimate (parameters only) ======\n","FP32 (float32, 4B/param): 3.66 MB\n","FP16 (float16, 2B/param): 1.83 MB\n","\n","Random-initialised weights saved to: rtsfnet_official_dummy.weights.h5\n","Actual .weights.h5 file size:       3.98 MB\n","\n","[Official rTsfNet (IMWUT 2024) – structure & size done]\n","\n"]}]}]}