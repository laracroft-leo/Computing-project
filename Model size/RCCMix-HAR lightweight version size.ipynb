{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"L4","authorship_tag":"ABX9TyMX2njouhQ10am0jZxtIqzv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["# ============ RCCMix-HAR (Step 10, GeoContextHAR) – structure & size ============\n","\n","import json\n","from pathlib import Path\n","\n","import torch\n","import torch.nn as nn\n","\n","print(\"\\n[RCCMix-HAR (Step 10, GeoContextHAR) – structure & size]\")\n","\n","# ---------------------------\n","# 1) Determine NUM_CLASSES\n","# ---------------------------\n","BASE = Path(\"/content\")\n","CFG_DIR = BASE / \"configs\"\n","\n","if (CFG_DIR / \"classes.json\").exists():\n","    with open(CFG_DIR / \"classes.json\", \"r\") as f:\n","        classes_cfg = json.load(f)\n","    NUM_CLASSES = int(classes_cfg[\"num_classes\"])\n","    print(f\"Detected NUM_CLASSES from configs: {NUM_CLASSES}\")\n","else:\n","    # Change this if your setup uses a different number of classes\n","    NUM_CLASSES = 8\n","    print(\"Warning: /content/configs/classes.json not found. Using default NUM_CLASSES = 8.\")\n","    print(\"Please update NUM_CLASSES manually if this does not match your setup.\")\n","\n","# ---------------------------\n","# 2) Hyperparameters (must match your RCCMix-HAR Step 10 script)\n","# ---------------------------\n","IN_CHANNELS  = 6         # acc+gyro\n","D_MODEL      = 128\n","N_HEADS      = 4\n","N_LAYERS     = 2\n","D_FF         = 4 * D_MODEL   # 512\n","DROPOUT      = 0.2\n","SEQ_LEN      = 8\n","\n","print(f\"\\nConfig for size check:\")\n","print(f\"  NUM_CLASSES = {NUM_CLASSES}\")\n","print(f\"  IN_CHANNELS = {IN_CHANNELS}\")\n","print(f\"  D_MODEL     = {D_MODEL}\")\n","print(f\"  N_HEADS     = {N_HEADS}\")\n","print(f\"  N_LAYERS    = {N_LAYERS}\")\n","print(f\"  D_FF        = {D_FF}\")\n","print(f\"  DROPOUT     = {DROPOUT}\")\n","print(f\"  SEQ_LEN     = {SEQ_LEN}\")\n","\n","# ---------------------------\n","# 3) Model definition (identical to your script)\n","# ---------------------------\n","class DepthwiseSeparableConv1d(nn.Module):\n","    def __init__(self, in_ch, out_ch, k, dilation=1, dropout=0.0):\n","        super().__init__()\n","        pad = (k // 2) * dilation\n","        self.dw = nn.Conv1d(\n","            in_ch, in_ch, kernel_size=k,\n","            padding=pad, dilation=dilation,\n","            groups=in_ch, bias=False\n","        )\n","        self.pw = nn.Conv1d(in_ch, out_ch, kernel_size=1, bias=False)\n","        self.bn = nn.BatchNorm1d(out_ch)\n","        self.act = nn.GELU()\n","        self.drop = nn.Dropout(dropout)\n","\n","    def forward(self, x):\n","        x = self.dw(x)\n","        x = self.pw(x)\n","        x = self.bn(x)\n","        x = self.act(x)\n","        return self.drop(x)\n","\n","\n","class WindowEncoder(nn.Module):\n","    \"\"\"\n","    rTsfNet-style per-window representation:\n","      - 6D IMU + acc_norm + gyro_norm\n","      - multi-scale depthwise separable conv branches\n","      - global average pooling over time\n","      - geometric conditioning vector g from RMS and energy\n","    \"\"\"\n","    def __init__(self, in_ch=6, d_model=128, dropout=0.2):\n","        super().__init__()\n","        self.in_ch = in_ch\n","        self.aug_ch = in_ch + 2   # + acc_norm + gyro_norm\n","\n","        self.b1 = DepthwiseSeparableConv1d(self.aug_ch, d_model // 2, k=9,  dilation=1, dropout=dropout)\n","        self.b2 = DepthwiseSeparableConv1d(self.aug_ch, d_model // 2, k=19, dilation=2, dropout=dropout)\n","        self.mix = nn.Conv1d(d_model, d_model, kernel_size=1, bias=False)\n","        self.bn  = nn.BatchNorm1d(d_model)\n","        self.act = nn.GELU()\n","        self.drop= nn.Dropout(dropout)\n","\n","        self.g_proj = nn.Sequential(\n","            nn.Linear(4, d_model),\n","            nn.GELU(),\n","            nn.Linear(d_model, d_model)\n","        )\n","\n","    def forward(self, x):\n","        # x: [B*L, C=6, T]\n","        BL, C, T = x.shape\n","\n","        acc_norm = torch.sqrt(\n","            x[:, 0, :]**2 + x[:, 1, :]**2 + x[:, 2, :]**2 + 1e-8\n","        ).unsqueeze(1)  # [B*L,1,T]\n","        gyr_norm = torch.sqrt(\n","            x[:, 3, :]**2 + x[:, 4, :]**2 + x[:, 5, :]**2 + 1e-8\n","        ).unsqueeze(1)  # [B*L,1,T]\n","        x_aug = torch.cat([x, acc_norm, gyr_norm], dim=1)  # [B*L, 8, T]\n","\n","        z = torch.cat([self.b1(x_aug), self.b2(x_aug)], dim=1)  # [B*L, d_model, T]\n","        z = self.mix(z)\n","        z = self.bn(z)\n","        z = self.act(z)\n","        z = self.drop(z)\n","\n","        token = z.mean(dim=-1)  # [B*L, d_model]\n","\n","        acc_rms = acc_norm.squeeze(1).pow(2).mean(dim=-1).sqrt()\n","        gyr_rms = gyr_norm.squeeze(1).pow(2).mean(dim=-1).sqrt()\n","        acc_en  = x[:, 0:3, :].pow(2).mean(dim=(1, 2)).sqrt()\n","        gyr_en  = x[:, 3:6, :].pow(2).mean(dim=(1, 2)).sqrt()\n","        g = torch.stack([acc_rms, gyr_rms, acc_en, gyr_en], dim=-1)  # [B*L, 4]\n","        g = self.g_proj(g)  # [B*L, d_model]\n","\n","        return token, g\n","\n","\n","class CondLayerNorm(nn.Module):\n","    \"\"\"FiLM-style conditional LayerNorm: LN(x) * (1 + gamma(g)) + beta(g).\"\"\"\n","    def __init__(self, d_model):\n","        super().__init__()\n","        self.ln = nn.LayerNorm(d_model)\n","        self.gamma = nn.Linear(d_model, d_model)\n","        self.beta  = nn.Linear(d_model, d_model)\n","\n","    def forward(self, x, g):\n","        y = self.ln(x)\n","        return y * (1 + self.gamma(g)) + self.beta(g)\n","\n","\n","class RCCBlock(nn.Module):\n","    \"\"\"Rotation-conditioned Transformer encoder block.\"\"\"\n","    def __init__(self, d_model=128, n_heads=4, d_ff=512, dropout=0.2):\n","        super().__init__()\n","        self.condln1 = CondLayerNorm(d_model)\n","        self.mha = nn.MultiheadAttention(\n","            d_model, n_heads, dropout=dropout, batch_first=True\n","        )\n","        self.drop1 = nn.Dropout(dropout)\n","\n","        self.condln2 = CondLayerNorm(d_model)\n","        self.ff = nn.Sequential(\n","            nn.Linear(d_model, d_ff),\n","            nn.GELU(),\n","            nn.Dropout(dropout),\n","            nn.Linear(d_ff, d_model)\n","        )\n","        self.drop2 = nn.Dropout(dropout)\n","\n","    def forward(self, x, g):\n","        # x, g: [B, L(+1), d]\n","        y = self.condln1(x, g)\n","        attn, _ = self.mha(y, y, y, need_weights=False)\n","        x = x + self.drop1(attn)\n","\n","        y = self.condln2(x, g)\n","        y = self.ff(y)\n","        x = x + self.drop2(y)\n","        return x\n","\n","\n","class GeoContextHAR(nn.Module):\n","    \"\"\"\n","    RCCMix-HAR main body:\n","      WindowEncoder + rotation-conditioned Transformer + CLS head.\n","    \"\"\"\n","    def __init__(self, in_ch=6, d_model=128, n_layers=2, n_heads=4, d_ff=512,\n","                 dropout=0.2, seq_len=8, num_classes=8):\n","        super().__init__()\n","        self.seq_len = seq_len\n","        self.encoder = WindowEncoder(in_ch=in_ch, d_model=d_model, dropout=dropout)\n","        self.cls_token = nn.Parameter(torch.zeros(1, 1, d_model))\n","        self.pos = nn.Parameter(torch.zeros(1, seq_len + 1, d_model))\n","        self.blocks = nn.ModuleList(\n","            [RCCBlock(d_model, n_heads, d_ff, dropout) for _ in range(n_layers)]\n","        )\n","        self.norm = nn.LayerNorm(d_model)\n","        self.head = nn.Linear(d_model, num_classes)\n","\n","        nn.init.trunc_normal_(self.pos, std=0.02)\n","        nn.init.trunc_normal_(self.cls_token, std=0.02)\n","\n","    def forward(self, x):\n","        # x: [B, L, C, T]\n","        B, L, C, T = x.shape\n","        x = x.reshape(B * L, C, T)\n","        token, g = self.encoder(x)              # [B*L, d_model], [B*L, d_model]\n","        token = token.view(B, L, -1)           # [B, L, d_model]\n","        g     = g.view(B, L, -1)               # [B, L, d_model]\n","\n","        cls = self.cls_token.expand(B, 1, -1)  # [B, 1, d_model]\n","        z = torch.cat([cls, token], dim=1)     # [B, L+1, d_model]\n","        g_cls = g.mean(dim=1, keepdim=True)    # [B, 1, d_model]\n","        g_all = torch.cat([g_cls, g], dim=1)   # [B, L+1, d_model]\n","\n","        z = z + self.pos\n","\n","        for blk in self.blocks:\n","            z = blk(z, g_all)\n","\n","        z = self.norm(z)\n","        cls_rep = z[:, 0, :]                   # [B, d_model]\n","        logits = self.head(cls_rep)            # [B, num_classes]\n","        return logits\n","\n","# ---------------------------\n","# 4) Instantiate model and compute size\n","# ---------------------------\n","model = GeoContextHAR(\n","    in_ch=IN_CHANNELS,\n","    d_model=D_MODEL,\n","    n_layers=N_LAYERS,\n","    n_heads=N_HEADS,\n","    d_ff=D_FF,\n","    dropout=DROPOUT,\n","    seq_len=SEQ_LEN,\n","    num_classes=NUM_CLASSES\n",")\n","\n","print(\"\\n====== nn.Module structure ======\\n\")\n","print(model)\n","\n","# Parameter counts\n","total_params = sum(p.numel() for p in model.parameters())\n","trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","print(\"\\n====== Parameter statistics ======\")\n","print(f\"Total params:      {total_params:,}\")\n","print(f\"Trainable params:  {trainable_params:,}\")\n","\n","print(\"\\n====== Per-layer parameter counts ======\")\n","for name, p in model.named_parameters():\n","    print(f\"{name:45s} shape={tuple(p.shape)}  params={p.numel():,}\")\n","\n","# Size estimation (parameters only)\n","def fmt_mb(n_bytes: int) -> str:\n","    return f\"{n_bytes / 1024 / 1024:.2f} MB\"\n","\n","bytes_fp32 = total_params * 4\n","bytes_fp16 = total_params * 2\n","\n","print(\"\\n====== Model size estimate (parameters only) ======\")\n","print(f\"FP32 (float32, 4B/param): {fmt_mb(bytes_fp32)}\")\n","print(f\"FP16 (float16, 2B/param): {fmt_mb(bytes_fp16)}\")\n","\n","# Save a randomly initialised state_dict to check actual .pt size\n","models_dir = BASE / \"models\"\n","models_dir.mkdir(parents=True, exist_ok=True)\n","tmp_path = models_dir / \"rccmix_har_step10_dummy.pt\"\n","torch.save(model.state_dict(), tmp_path)\n","file_bytes = tmp_path.stat().st_size\n","print(f\"\\nRandom-initialised state_dict saved to: {tmp_path.name}\")\n","print(f\"Actual .pt file size:                 {fmt_mb(file_bytes)}\")\n","\n","print(\"\\n[RCCMix-HAR (Step 10, GeoContextHAR) – structure & size done]\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CgoIuQURSANN","executionInfo":{"status":"ok","timestamp":1763407675356,"user_tz":0,"elapsed":112,"user":{"displayName":"yu Wu","userId":"12692660435918028293"}},"outputId":"d2ff36c1-f58a-4136-e8a5-03849a706bb1"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","[RCCMix-HAR (Step 10, GeoContextHAR) – structure & size]\n","Warning: /content/configs/classes.json not found. Using default NUM_CLASSES = 8.\n","Please update NUM_CLASSES manually if this does not match your setup.\n","\n","Config for size check:\n","  NUM_CLASSES = 8\n","  IN_CHANNELS = 6\n","  D_MODEL     = 128\n","  N_HEADS     = 4\n","  N_LAYERS    = 2\n","  D_FF        = 512\n","  DROPOUT     = 0.2\n","  SEQ_LEN     = 8\n","\n","====== nn.Module structure ======\n","\n","GeoContextHAR(\n","  (encoder): WindowEncoder(\n","    (b1): DepthwiseSeparableConv1d(\n","      (dw): Conv1d(8, 8, kernel_size=(9,), stride=(1,), padding=(4,), groups=8, bias=False)\n","      (pw): Conv1d(8, 64, kernel_size=(1,), stride=(1,), bias=False)\n","      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): GELU(approximate='none')\n","      (drop): Dropout(p=0.2, inplace=False)\n","    )\n","    (b2): DepthwiseSeparableConv1d(\n","      (dw): Conv1d(8, 8, kernel_size=(19,), stride=(1,), padding=(18,), dilation=(2,), groups=8, bias=False)\n","      (pw): Conv1d(8, 64, kernel_size=(1,), stride=(1,), bias=False)\n","      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): GELU(approximate='none')\n","      (drop): Dropout(p=0.2, inplace=False)\n","    )\n","    (mix): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)\n","    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (act): GELU(approximate='none')\n","    (drop): Dropout(p=0.2, inplace=False)\n","    (g_proj): Sequential(\n","      (0): Linear(in_features=4, out_features=128, bias=True)\n","      (1): GELU(approximate='none')\n","      (2): Linear(in_features=128, out_features=128, bias=True)\n","    )\n","  )\n","  (blocks): ModuleList(\n","    (0-1): 2 x RCCBlock(\n","      (condln1): CondLayerNorm(\n","        (ln): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","        (gamma): Linear(in_features=128, out_features=128, bias=True)\n","        (beta): Linear(in_features=128, out_features=128, bias=True)\n","      )\n","      (mha): MultiheadAttention(\n","        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n","      )\n","      (drop1): Dropout(p=0.2, inplace=False)\n","      (condln2): CondLayerNorm(\n","        (ln): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","        (gamma): Linear(in_features=128, out_features=128, bias=True)\n","        (beta): Linear(in_features=128, out_features=128, bias=True)\n","      )\n","      (ff): Sequential(\n","        (0): Linear(in_features=128, out_features=512, bias=True)\n","        (1): GELU(approximate='none')\n","        (2): Dropout(p=0.2, inplace=False)\n","        (3): Linear(in_features=512, out_features=128, bias=True)\n","      )\n","      (drop2): Dropout(p=0.2, inplace=False)\n","    )\n","  )\n","  (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","  (head): Linear(in_features=128, out_features=8, bias=True)\n",")\n","\n","====== Parameter statistics ======\n","Total params:      566,504\n","Trainable params:  566,504\n","\n","====== Per-layer parameter counts ======\n","cls_token                                     shape=(1, 1, 128)  params=128\n","pos                                           shape=(1, 9, 128)  params=1,152\n","encoder.b1.dw.weight                          shape=(8, 1, 9)  params=72\n","encoder.b1.pw.weight                          shape=(64, 8, 1)  params=512\n","encoder.b1.bn.weight                          shape=(64,)  params=64\n","encoder.b1.bn.bias                            shape=(64,)  params=64\n","encoder.b2.dw.weight                          shape=(8, 1, 19)  params=152\n","encoder.b2.pw.weight                          shape=(64, 8, 1)  params=512\n","encoder.b2.bn.weight                          shape=(64,)  params=64\n","encoder.b2.bn.bias                            shape=(64,)  params=64\n","encoder.mix.weight                            shape=(128, 128, 1)  params=16,384\n","encoder.bn.weight                             shape=(128,)  params=128\n","encoder.bn.bias                               shape=(128,)  params=128\n","encoder.g_proj.0.weight                       shape=(128, 4)  params=512\n","encoder.g_proj.0.bias                         shape=(128,)  params=128\n","encoder.g_proj.2.weight                       shape=(128, 128)  params=16,384\n","encoder.g_proj.2.bias                         shape=(128,)  params=128\n","blocks.0.condln1.ln.weight                    shape=(128,)  params=128\n","blocks.0.condln1.ln.bias                      shape=(128,)  params=128\n","blocks.0.condln1.gamma.weight                 shape=(128, 128)  params=16,384\n","blocks.0.condln1.gamma.bias                   shape=(128,)  params=128\n","blocks.0.condln1.beta.weight                  shape=(128, 128)  params=16,384\n","blocks.0.condln1.beta.bias                    shape=(128,)  params=128\n","blocks.0.mha.in_proj_weight                   shape=(384, 128)  params=49,152\n","blocks.0.mha.in_proj_bias                     shape=(384,)  params=384\n","blocks.0.mha.out_proj.weight                  shape=(128, 128)  params=16,384\n","blocks.0.mha.out_proj.bias                    shape=(128,)  params=128\n","blocks.0.condln2.ln.weight                    shape=(128,)  params=128\n","blocks.0.condln2.ln.bias                      shape=(128,)  params=128\n","blocks.0.condln2.gamma.weight                 shape=(128, 128)  params=16,384\n","blocks.0.condln2.gamma.bias                   shape=(128,)  params=128\n","blocks.0.condln2.beta.weight                  shape=(128, 128)  params=16,384\n","blocks.0.condln2.beta.bias                    shape=(128,)  params=128\n","blocks.0.ff.0.weight                          shape=(512, 128)  params=65,536\n","blocks.0.ff.0.bias                            shape=(512,)  params=512\n","blocks.0.ff.3.weight                          shape=(128, 512)  params=65,536\n","blocks.0.ff.3.bias                            shape=(128,)  params=128\n","blocks.1.condln1.ln.weight                    shape=(128,)  params=128\n","blocks.1.condln1.ln.bias                      shape=(128,)  params=128\n","blocks.1.condln1.gamma.weight                 shape=(128, 128)  params=16,384\n","blocks.1.condln1.gamma.bias                   shape=(128,)  params=128\n","blocks.1.condln1.beta.weight                  shape=(128, 128)  params=16,384\n","blocks.1.condln1.beta.bias                    shape=(128,)  params=128\n","blocks.1.mha.in_proj_weight                   shape=(384, 128)  params=49,152\n","blocks.1.mha.in_proj_bias                     shape=(384,)  params=384\n","blocks.1.mha.out_proj.weight                  shape=(128, 128)  params=16,384\n","blocks.1.mha.out_proj.bias                    shape=(128,)  params=128\n","blocks.1.condln2.ln.weight                    shape=(128,)  params=128\n","blocks.1.condln2.ln.bias                      shape=(128,)  params=128\n","blocks.1.condln2.gamma.weight                 shape=(128, 128)  params=16,384\n","blocks.1.condln2.gamma.bias                   shape=(128,)  params=128\n","blocks.1.condln2.beta.weight                  shape=(128, 128)  params=16,384\n","blocks.1.condln2.beta.bias                    shape=(128,)  params=128\n","blocks.1.ff.0.weight                          shape=(512, 128)  params=65,536\n","blocks.1.ff.0.bias                            shape=(512,)  params=512\n","blocks.1.ff.3.weight                          shape=(128, 512)  params=65,536\n","blocks.1.ff.3.bias                            shape=(128,)  params=128\n","norm.weight                                   shape=(128,)  params=128\n","norm.bias                                     shape=(128,)  params=128\n","head.weight                                   shape=(8, 128)  params=1,024\n","head.bias                                     shape=(8,)  params=8\n","\n","====== Model size estimate (parameters only) ======\n","FP32 (float32, 4B/param): 2.16 MB\n","FP16 (float16, 2B/param): 1.08 MB\n","\n","Random-initialised state_dict saved to: rccmix_har_step10_dummy.pt\n","Actual .pt file size:                 2.19 MB\n","\n","[RCCMix-HAR (Step 10, GeoContextHAR) – structure & size done]\n","\n"]}]}]}