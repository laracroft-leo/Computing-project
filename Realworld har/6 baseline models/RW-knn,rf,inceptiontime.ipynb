{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"L4","authorship_tag":"ABX9TyMVzSjAFkTvJxzJ/Xif5iyS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fmMTFOunwlg9","executionInfo":{"status":"ok","timestamp":1762688248570,"user_tz":0,"elapsed":249167,"user":{"displayName":"yu Wu","userId":"12692660435918028293"}},"outputId":"ffd9480f-49db-4bfe-856b-07c69df0f8f7"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/data/rwhar\n","--2025-11-09 11:33:20--  https://wifo5-14.informatik.uni-mannheim.de/sensor/dataset/realworld2016/realworld2016_dataset.zip\n","Resolving wifo5-14.informatik.uni-mannheim.de (wifo5-14.informatik.uni-mannheim.de)... 134.155.98.56\n","Connecting to wifo5-14.informatik.uni-mannheim.de (wifo5-14.informatik.uni-mannheim.de)|134.155.98.56|:443... connected.\n","WARNING: no certificate subject alternative name matches\n","\trequested host name ‘wifo5-14.informatik.uni-mannheim.de’.\n","HTTP request sent, awaiting response... 403 Forbidden\n","2025-11-09 11:33:21 ERROR 403: Forbidden.\n","\n","--2025-11-09 11:33:21--  http://wifo5-14.informatik.uni-mannheim.de/sensor/dataset/realworld2016/realworld2016_dataset.zip\n","Resolving wifo5-14.informatik.uni-mannheim.de (wifo5-14.informatik.uni-mannheim.de)... 134.155.98.56\n","Connecting to wifo5-14.informatik.uni-mannheim.de (wifo5-14.informatik.uni-mannheim.de)|134.155.98.56|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 3721016476 (3.5G) [application/zip]\n","Saving to: ‘realworld2016_dataset.zip’\n","\n","realworld2016_datas 100%[===================>]   3.46G  14.5MB/s    in 3m 29s  \n","\n","2025-11-09 11:36:50 (17.0 MB/s) - ‘realworld2016_dataset.zip’ saved [3721016476/3721016476]\n","\n","=== top-level ===\n","total 3.5G\n","drwxr-xr-x 17 root root 4.0K Nov  9 11:37 .\n","drwxr-xr-x  3 root root 4.0K Nov  9 11:33 ..\n","drwxr-xr-x  5 root root 4.0K Apr 27  2016 proband1\n","drwxr-xr-x  5 root root 4.0K Jul 21  2015 proband10\n","drwxr-xr-x  5 root root 4.0K Jul 22  2015 proband11\n","drwxr-xr-x  5 root root 4.0K Jul 28  2015 proband12\n","drwxr-xr-x  5 root root 4.0K Jul 27  2015 proband13\n","drwxr-xr-x  5 root root 4.0K Jul 29  2015 proband14\n","drwxr-xr-x  5 root root 4.0K Jul 28  2015 proband15\n","drwxr-xr-x  5 root root 4.0K Sep 22  2015 proband2\n","drwxr-xr-x  5 root root 4.0K Jul 27  2015 proband3\n","drwxr-xr-x  5 root root 4.0K Jul 28  2015 proband4\n","drwxr-xr-x  5 root root 4.0K Jul 27  2015 proband5\n","drwxr-xr-x  5 root root 4.0K Jul 27  2015 proband6\n","drwxr-xr-x  5 root root 4.0K Jul 27  2015 proband7\n","drwxr-xr-x  5 root root 4.0K Jul 28  2015 proband8\n","drwxr-xr-x  5 root root 4.0K Jul 27  2015 proband9\n","-rw-r--r--  1 root root 3.5G Jan 18  2022 realworld2016_dataset.zip\n","=== dirs (depth<=2) ===\n",".\n","./proband1\n","./proband10\n","./proband10/data\n","./proband10/images\n","./proband10/videos\n","./proband11\n","./proband11/data\n","./proband11/images\n","./proband11/videos\n","./proband12\n","./proband12/data\n","./proband12/images\n","./proband12/videos\n","./proband13\n","./proband13/data\n","./proband13/images\n","./proband13/videos\n","./proband14\n","./proband14/data\n"]}],"source":["# RealWorld-HAR (RealWorld2016, University of Mannheim)\n","!mkdir -p /content/data/rwhar\n","%cd /content/data/rwhar\n","\n","# Attempt HTTPS first (disabling certificate verification due to an SNI mismatch on the host); on failure, fall back to HTTP\n","!wget -c --no-check-certificate \"https://wifo5-14.informatik.uni-mannheim.de/sensor/dataset/realworld2016/realworld2016_dataset.zip\" -O realworld2016_dataset.zip || wget -c \"http://wifo5-14.informatik.uni-mannheim.de/sensor/dataset/realworld2016/realworld2016_dataset.zip\" -O realworld2016_dataset.zip\n","\n","# Decompress and perform a brief inspection\n","!unzip -q -o realworld2016_dataset.zip\n","!echo \"=== top-level ===\"\n","!ls -lah\n","!echo \"=== dirs (depth<=2) ===\"\n","!find . -maxdepth 2 -type d | sort | head -n 20"]},{"cell_type":"code","source":["# ================ Step 0: Project Initialization ================\n","import os\n","from datetime import datetime\n","\n","# Create directory structure\n","dirs = ['data/raw', 'interim', 'proc', 'features', 'models', 'logs', 'figures', 'configs']\n","for d in dirs:\n","    os.makedirs(f'/content/{d}', exist_ok=True)\n","print(\"✓ Directory structure created\")\n","\n","# Git Initialization\n","%cd /content\n","!git init\n","!git config user.name \"HAR-Project\"\n","!git config user.email \"har@project.local\"\n","print(\"✓ Git repository initialized\")\n","\n","# Persist environment information\n","!pip freeze > logs/env.txt\n","print(\"✓ Environment dependencies saved to logs/env.txt\")\n","\n","# Persist random seed list and hardware information\n","import json\n","import subprocess\n","\n","meta = {\n","    \"timestamp\": datetime.now().isoformat(),\n","    \"random_seeds\": [42, 123, 456, 789, 2024],  # predefined seeds\n","    \"hardware\": {\n","        \"gpu\": subprocess.getoutput(\"nvidia-smi --query-gpu=name --format=csv,noheader\"),\n","        \"cpu\": subprocess.getoutput(\"cat /proc/cpuinfo | grep 'model name' | head -1\").split(':')[1].strip(),\n","    }\n","}\n","\n","with open('logs/init_meta.json', 'w') as f:\n","    json.dump(meta, f, indent=2)\n","print(\"✓ Metadata saved to logs/init_meta.json\")\n","\n","# Initial commit\n","!git add .\n","!git commit -m \"init: project structure and environment\"\n","git_hash = subprocess.getoutput(\"git rev-parse HEAD\")\n","print(f\"✓ Git commit hash: {git_hash[:8]}\")\n","\n","\n","# ================ Step 1: Data Acquisition (Compliance) ================\n","# Move raw data to data/raw/ and retain structure\n","!mv /content/data/rwhar/* /content/data/raw/ 2>/dev/null || true\n","!rm -rf /content/data/rwhar\n","print(\"✓ Raw data moved to data/raw/\")\n","\n","# Compute checksums\n","import hashlib\n","\n","def calc_checksum(filepath):\n","    h = hashlib.sha256()\n","    with open(filepath, 'rb') as f:\n","        for chunk in iter(lambda: f.read(8192), b\"\"):\n","            h.update(chunk)\n","    return h.hexdigest()\n","\n","checksums = {}\n","for root, _, files in os.walk('/content/data/raw'):\n","    for f in files:\n","        path = os.path.join(root, f)\n","        rel_path = os.path.relpath(path, '/content/data/raw')\n","        checksums[rel_path] = calc_checksum(path)\n","\n","with open('/content/logs/checksums.txt', 'w') as f:\n","    f.write(f\"# RealWorld2016 dataset checksums (SHA256)\\n\")\n","    f.write(f\"# Generated at: {datetime.now().isoformat()}\\n\\n\")\n","    for path, sha in sorted(checksums.items()):\n","        f.write(f\"{sha}  {path}\\n\")\n","\n","print(f\"✓ Computed checksums for {len(checksums)} files → logs/checksums.txt\")\n","\n","# Record data source\n","with open('/content/logs/data_source.txt', 'w') as f:\n","    f.write(\"RealWorld2016 Human Activity Recognition Dataset\\n\")\n","    f.write(\"=\" * 50 + \"\\n\")\n","    f.write(\"Source: University of Mannheim\\n\")\n","    f.write(\"URL: https://wifo5-14.informatik.uni-mannheim.de/sensor/dataset/realworld2016/\\n\")\n","    f.write(\"Citation: Sztyler, T., & Stuckenschmidt, H. (2016). On-body localization of wearable devices.\\n\")\n","    f.write(f\"Downloaded: {datetime.now().isoformat()}\\n\")\n","\n","print(\"✓ Data source recorded to logs/data_source.txt\")\n","\n","# Commit data acquisition records\n","!git add logs/\n","!git commit -m \"data: add RealWorld2016 checksums and source\"\n","print(f\"\\n{'='*60}\\nProject initialization and data acquisition completed\\n{'='*60}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AJjI365kxre0","executionInfo":{"status":"ok","timestamp":1762688634963,"user_tz":0,"elapsed":386382,"user":{"displayName":"yu Wu","userId":"12692660435918028293"}},"outputId":"88960c82-8059-466d-fe2a-80a01bd1872c"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["✓ Directory structure created\n","/content\n","\u001b[33mhint: Using 'master' as the name for the initial branch. This default branch name\u001b[m\n","\u001b[33mhint: is subject to change. To configure the initial branch name to use in all\u001b[m\n","\u001b[33mhint: of your new repositories, which will suppress this warning, call:\u001b[m\n","\u001b[33mhint: \u001b[m\n","\u001b[33mhint: \tgit config --global init.defaultBranch <name>\u001b[m\n","\u001b[33mhint: \u001b[m\n","\u001b[33mhint: Names commonly chosen instead of 'master' are 'main', 'trunk' and\u001b[m\n","\u001b[33mhint: 'development'. The just-created branch can be renamed via this command:\u001b[m\n","\u001b[33mhint: \u001b[m\n","\u001b[33mhint: \tgit branch -m <name>\u001b[m\n","Initialized empty Git repository in /content/.git/\n","✓ Git repository initialized\n","✓ Environment dependencies saved to logs/env.txt\n","✓ Metadata saved to logs/init_meta.json\n","[master (root-commit) a5c34cf] init: project structure and environment\n"," 1837 files changed, 51721 insertions(+)\n"," create mode 100644 .config/.last_opt_in_prompt.yaml\n"," create mode 100644 .config/.last_survey_prompt.yaml\n"," create mode 100644 .config/.last_update_check.json\n"," create mode 100644 .config/active_config\n"," create mode 100644 .config/config_sentinel\n"," create mode 100644 .config/configurations/config_default\n"," create mode 100644 .config/default_configs.db\n"," create mode 100644 .config/gce\n"," create mode 100644 .config/hidden_gcloud_config_universe_descriptor_data_cache_configs.db\n"," create mode 100644 .config/logs/2025.11.05/14.33.13.470069.log\n"," create mode 100644 .config/logs/2025.11.05/14.33.36.385956.log\n"," create mode 100644 .config/logs/2025.11.05/14.33.44.287731.log\n"," create mode 100644 .config/logs/2025.11.05/14.33.45.559498.log\n"," create mode 100644 .config/logs/2025.11.05/14.33.53.434728.log\n"," create mode 100644 .config/logs/2025.11.05/14.33.54.129583.log\n"," create mode 100644 data/rwhar/proband1/data/acc_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband1/data/acc_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband1/data/acc_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband1/data/acc_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband1/data/acc_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband1/data/acc_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband1/data/acc_lying_csv.zip\n"," create mode 100644 data/rwhar/proband1/data/acc_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband1/data/acc_running_csv.zip\n"," create mode 100644 data/rwhar/proband1/data/acc_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband1/data/acc_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband1/data/acc_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband1/data/acc_standing_csv.zip\n"," create mode 100644 data/rwhar/proband1/data/acc_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband1/data/acc_walking_csv.zip\n"," create mode 100644 data/rwhar/proband1/data/acc_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband1/data/gps_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband1/data/gps_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband1/data/gps_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband1/data/gps_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband1/data/gps_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband1/data/gps_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband1/data/gps_lying_csv.zip\n"," create mode 100644 data/rwhar/proband1/data/gps_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband1/data/gps_running_csv.zip\n"," create mode 100644 data/rwhar/proband1/data/gps_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband1/data/gps_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband1/data/gps_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband1/data/gps_standing_csv.zip\n"," create mode 100644 data/rwhar/proband1/data/gps_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband1/data/gps_walking_csv.zip\n"," create mode 100644 data/rwhar/proband1/data/gps_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband1/data/gyr_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband1/data/gyr_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband1/data/gyr_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband1/data/gyr_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband1/data/gyr_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband1/data/gyr_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband1/data/gyr_lying_csv.zip\n"," create mode 100644 data/rwhar/proband1/data/gyr_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband1/data/gyr_running_csv.zip\n"," create mode 100644 data/rwhar/proband1/data/gyr_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband1/data/gyr_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband1/data/gyr_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband1/data/gyr_standing_csv.zip\n"," create mode 100644 data/rwhar/proband1/data/gyr_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband1/data/gyr_walking_csv.zip\n"," create mode 100644 data/rwhar/proband1/data/gyr_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband1/data/lig_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband1/data/lig_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband1/data/lig_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband1/data/lig_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband1/data/lig_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband1/data/lig_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband1/data/lig_lying_csv.zip\n"," create mode 100644 data/rwhar/proband1/data/lig_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband1/data/lig_running_csv.zip\n"," create mode 100644 data/rwhar/proband1/data/lig_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband1/data/lig_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband1/data/lig_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband1/data/lig_standing_csv.zip\n"," create mode 100644 data/rwhar/proband1/data/lig_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband1/data/lig_walking_csv.zip\n"," create mode 100644 data/rwhar/proband1/data/lig_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband1/data/mag_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband1/data/mag_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband1/data/mag_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband1/data/mag_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband1/data/mag_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband1/data/mag_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband1/data/mag_lying_csv.zip\n"," create mode 100644 data/rwhar/proband1/data/mag_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband1/data/mag_running_csv.zip\n"," create mode 100644 data/rwhar/proband1/data/mag_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband1/data/mag_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband1/data/mag_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband1/data/mag_standing_csv.zip\n"," create mode 100644 data/rwhar/proband1/data/mag_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband1/data/mag_walking_csv.zip\n"," create mode 100644 data/rwhar/proband1/data/mag_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband1/data/mic_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband1/data/mic_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband1/data/mic_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband1/data/mic_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband1/data/mic_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband1/data/mic_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband1/data/mic_lying_csv.zip\n"," create mode 100644 data/rwhar/proband1/data/mic_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband1/data/mic_running_csv.zip\n"," create mode 100644 data/rwhar/proband1/data/mic_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband1/data/mic_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband1/data/mic_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband1/data/mic_standing_csv.zip\n"," create mode 100644 data/rwhar/proband1/data/mic_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband1/data/mic_walking_csv.zip\n"," create mode 100644 data/rwhar/proband1/data/mic_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband1/images/chest.png\n"," create mode 100644 data/rwhar/proband1/images/chest_thumb.png\n"," create mode 100644 data/rwhar/proband1/images/forearm.png\n"," create mode 100644 data/rwhar/proband1/images/forearm_thumb.png\n"," create mode 100644 data/rwhar/proband1/images/head.png\n"," create mode 100644 data/rwhar/proband1/images/head_thumb.png\n"," create mode 100644 data/rwhar/proband1/images/overview.png\n"," create mode 100644 data/rwhar/proband1/images/overview_thumb.png\n"," create mode 100644 data/rwhar/proband1/images/preview.png\n"," create mode 100644 data/rwhar/proband1/images/shin.png\n"," create mode 100644 data/rwhar/proband1/images/shin_thumb.png\n"," create mode 100644 data/rwhar/proband1/images/thigh.png\n"," create mode 100644 data/rwhar/proband1/images/thigh_thumb.png\n"," create mode 100644 data/rwhar/proband1/images/upperarm.png\n"," create mode 100644 data/rwhar/proband1/images/upperarm_thumb.png\n"," create mode 100644 data/rwhar/proband1/images/waist.png\n"," create mode 100644 data/rwhar/proband1/images/waist_thumb.png\n"," create mode 100644 data/rwhar/proband1/videos/video_climbing down_thumb.png\n"," create mode 100644 data/rwhar/proband1/videos/video_climbing up_thumb.png\n"," create mode 100644 data/rwhar/proband1/videos/video_jumping_thumb.png\n"," create mode 100644 data/rwhar/proband1/videos/video_lying_thumb.png\n"," create mode 100644 data/rwhar/proband1/videos/video_running_thumb.png\n"," create mode 100644 data/rwhar/proband1/videos/video_sitting_thumb.png\n"," create mode 100644 data/rwhar/proband1/videos/video_standing_thumb.png\n"," create mode 100644 data/rwhar/proband1/videos/video_walking_thumb.png\n"," create mode 100644 data/rwhar/proband10/data/acc_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband10/data/acc_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband10/data/acc_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband10/data/acc_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband10/data/acc_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband10/data/acc_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband10/data/acc_lying_csv.zip\n"," create mode 100644 data/rwhar/proband10/data/acc_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband10/data/acc_running_csv.zip\n"," create mode 100644 data/rwhar/proband10/data/acc_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband10/data/acc_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband10/data/acc_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband10/data/acc_standing_csv.zip\n"," create mode 100644 data/rwhar/proband10/data/acc_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband10/data/acc_walking_csv.zip\n"," create mode 100644 data/rwhar/proband10/data/acc_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband10/data/gps_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband10/data/gps_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband10/data/gps_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband10/data/gps_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband10/data/gps_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband10/data/gps_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband10/data/gps_lying_csv.zip\n"," create mode 100644 data/rwhar/proband10/data/gps_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband10/data/gps_running_csv.zip\n"," create mode 100644 data/rwhar/proband10/data/gps_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband10/data/gps_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband10/data/gps_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband10/data/gps_standing_csv.zip\n"," create mode 100644 data/rwhar/proband10/data/gps_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband10/data/gps_walking_csv.zip\n"," create mode 100644 data/rwhar/proband10/data/gps_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband10/data/gyr_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband10/data/gyr_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband10/data/gyr_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband10/data/gyr_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband10/data/gyr_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband10/data/gyr_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband10/data/gyr_lying_csv.zip\n"," create mode 100644 data/rwhar/proband10/data/gyr_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband10/data/gyr_running_csv.zip\n"," create mode 100644 data/rwhar/proband10/data/gyr_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband10/data/gyr_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband10/data/gyr_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband10/data/gyr_standing_csv.zip\n"," create mode 100644 data/rwhar/proband10/data/gyr_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband10/data/gyr_walking_csv.zip\n"," create mode 100644 data/rwhar/proband10/data/gyr_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband10/data/lig_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband10/data/lig_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband10/data/lig_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband10/data/lig_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband10/data/lig_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband10/data/lig_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband10/data/lig_lying_csv.zip\n"," create mode 100644 data/rwhar/proband10/data/lig_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband10/data/lig_running_csv.zip\n"," create mode 100644 data/rwhar/proband10/data/lig_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband10/data/lig_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband10/data/lig_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband10/data/lig_standing_csv.zip\n"," create mode 100644 data/rwhar/proband10/data/lig_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband10/data/lig_walking_csv.zip\n"," create mode 100644 data/rwhar/proband10/data/lig_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband10/data/mag_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband10/data/mag_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband10/data/mag_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband10/data/mag_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband10/data/mag_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband10/data/mag_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband10/data/mag_lying_csv.zip\n"," create mode 100644 data/rwhar/proband10/data/mag_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband10/data/mag_running_csv.zip\n"," create mode 100644 data/rwhar/proband10/data/mag_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband10/data/mag_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband10/data/mag_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband10/data/mag_standing_csv.zip\n"," create mode 100644 data/rwhar/proband10/data/mag_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband10/data/mag_walking_csv.zip\n"," create mode 100644 data/rwhar/proband10/data/mag_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband10/data/mic_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband10/data/mic_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband10/data/mic_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband10/data/mic_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband10/data/mic_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband10/data/mic_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband10/data/mic_lying_csv.zip\n"," create mode 100644 data/rwhar/proband10/data/mic_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband10/data/mic_running_csv.zip\n"," create mode 100644 data/rwhar/proband10/data/mic_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband10/data/mic_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband10/data/mic_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband10/data/mic_standing_csv.zip\n"," create mode 100644 data/rwhar/proband10/data/mic_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband10/data/mic_walking_csv.zip\n"," create mode 100644 data/rwhar/proband10/data/mic_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband10/images/chest.png\n"," create mode 100644 data/rwhar/proband10/images/chest_thumb.png\n"," create mode 100644 data/rwhar/proband10/images/forearm.png\n"," create mode 100644 data/rwhar/proband10/images/forearm_thumb.png\n"," create mode 100644 data/rwhar/proband10/images/head.png\n"," create mode 100644 data/rwhar/proband10/images/head_thumb.png\n"," create mode 100644 data/rwhar/proband10/images/overview.png\n"," create mode 100644 data/rwhar/proband10/images/overview_thumb.png\n"," create mode 100644 data/rwhar/proband10/images/preview.png\n"," create mode 100644 data/rwhar/proband10/images/shin.png\n"," create mode 100644 data/rwhar/proband10/images/shin_thumb.png\n"," create mode 100644 data/rwhar/proband10/images/thigh.png\n"," create mode 100644 data/rwhar/proband10/images/thigh_thumb.png\n"," create mode 100644 data/rwhar/proband10/images/upperarm.png\n"," create mode 100644 data/rwhar/proband10/images/upperarm_thumb.png\n"," create mode 100644 data/rwhar/proband10/images/waist.png\n"," create mode 100644 data/rwhar/proband10/images/waist_thumb.png\n"," create mode 100644 data/rwhar/proband10/videos/video_climbing down_thumb.png\n"," create mode 100644 data/rwhar/proband10/videos/video_climbing up_thumb.png\n"," create mode 100644 data/rwhar/proband10/videos/video_jumping_thumb.png\n"," create mode 100644 data/rwhar/proband10/videos/video_lying_thumb.png\n"," create mode 100644 data/rwhar/proband10/videos/video_running_thumb.png\n"," create mode 100644 data/rwhar/proband10/videos/video_sitting_thumb.png\n"," create mode 100644 data/rwhar/proband10/videos/video_standing_thumb.png\n"," create mode 100644 data/rwhar/proband10/videos/video_walking_thumb.png\n"," create mode 100644 data/rwhar/proband11/data/acc_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband11/data/acc_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband11/data/acc_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband11/data/acc_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband11/data/acc_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband11/data/acc_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband11/data/acc_lying_csv.zip\n"," create mode 100644 data/rwhar/proband11/data/acc_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband11/data/acc_running_csv.zip\n"," create mode 100644 data/rwhar/proband11/data/acc_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband11/data/acc_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband11/data/acc_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband11/data/acc_standing_csv.zip\n"," create mode 100644 data/rwhar/proband11/data/acc_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband11/data/acc_walking_csv.zip\n"," create mode 100644 data/rwhar/proband11/data/acc_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband11/data/gps_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband11/data/gps_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband11/data/gps_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband11/data/gps_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband11/data/gps_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband11/data/gps_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband11/data/gps_lying_csv.zip\n"," create mode 100644 data/rwhar/proband11/data/gps_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband11/data/gps_running_csv.zip\n"," create mode 100644 data/rwhar/proband11/data/gps_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband11/data/gps_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband11/data/gps_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband11/data/gps_standing_csv.zip\n"," create mode 100644 data/rwhar/proband11/data/gps_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband11/data/gps_walking_csv.zip\n"," create mode 100644 data/rwhar/proband11/data/gps_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband11/data/gyr_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband11/data/gyr_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband11/data/gyr_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband11/data/gyr_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband11/data/gyr_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband11/data/gyr_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband11/data/gyr_lying_csv.zip\n"," create mode 100644 data/rwhar/proband11/data/gyr_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband11/data/gyr_running_csv.zip\n"," create mode 100644 data/rwhar/proband11/data/gyr_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband11/data/gyr_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband11/data/gyr_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband11/data/gyr_standing_csv.zip\n"," create mode 100644 data/rwhar/proband11/data/gyr_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband11/data/gyr_walking_csv.zip\n"," create mode 100644 data/rwhar/proband11/data/gyr_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband11/data/lig_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband11/data/lig_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband11/data/lig_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband11/data/lig_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband11/data/lig_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband11/data/lig_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband11/data/lig_lying_csv.zip\n"," create mode 100644 data/rwhar/proband11/data/lig_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband11/data/lig_running_csv.zip\n"," create mode 100644 data/rwhar/proband11/data/lig_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband11/data/lig_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband11/data/lig_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband11/data/lig_standing_csv.zip\n"," create mode 100644 data/rwhar/proband11/data/lig_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband11/data/lig_walking_csv.zip\n"," create mode 100644 data/rwhar/proband11/data/lig_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband11/data/mag_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband11/data/mag_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband11/data/mag_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband11/data/mag_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband11/data/mag_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband11/data/mag_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband11/data/mag_lying_csv.zip\n"," create mode 100644 data/rwhar/proband11/data/mag_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband11/data/mag_running_csv.zip\n"," create mode 100644 data/rwhar/proband11/data/mag_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband11/data/mag_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband11/data/mag_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband11/data/mag_standing_csv.zip\n"," create mode 100644 data/rwhar/proband11/data/mag_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband11/data/mag_walking_csv.zip\n"," create mode 100644 data/rwhar/proband11/data/mag_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband11/data/mic_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband11/data/mic_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband11/data/mic_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband11/data/mic_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband11/data/mic_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband11/data/mic_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband11/data/mic_lying_csv.zip\n"," create mode 100644 data/rwhar/proband11/data/mic_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband11/data/mic_running_csv.zip\n"," create mode 100644 data/rwhar/proband11/data/mic_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband11/data/mic_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband11/data/mic_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband11/data/mic_standing_csv.zip\n"," create mode 100644 data/rwhar/proband11/data/mic_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband11/data/mic_walking_csv.zip\n"," create mode 100644 data/rwhar/proband11/data/mic_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband11/images/chest.png\n"," create mode 100644 data/rwhar/proband11/images/chest_thumb.png\n"," create mode 100644 data/rwhar/proband11/images/forearm.png\n"," create mode 100644 data/rwhar/proband11/images/forearm_thumb.png\n"," create mode 100644 data/rwhar/proband11/images/head.png\n"," create mode 100644 data/rwhar/proband11/images/head_thumb.png\n"," create mode 100644 data/rwhar/proband11/images/overview.png\n"," create mode 100644 data/rwhar/proband11/images/overview_thumb.png\n"," create mode 100644 data/rwhar/proband11/images/preview.png\n"," create mode 100644 data/rwhar/proband11/images/shin.png\n"," create mode 100644 data/rwhar/proband11/images/shin_thumb.png\n"," create mode 100644 data/rwhar/proband11/images/thigh.png\n"," create mode 100644 data/rwhar/proband11/images/thigh_thumb.png\n"," create mode 100644 data/rwhar/proband11/images/upperarm.png\n"," create mode 100644 data/rwhar/proband11/images/upperarm_thumb.png\n"," create mode 100644 data/rwhar/proband11/images/waist.png\n"," create mode 100644 data/rwhar/proband11/images/waist_thumb.png\n"," create mode 100644 data/rwhar/proband11/videos/video_climbing down_thumb.png\n"," create mode 100644 data/rwhar/proband11/videos/video_climbing up_thumb.png\n"," create mode 100644 data/rwhar/proband11/videos/video_jumping_thumb.png\n"," create mode 100644 data/rwhar/proband11/videos/video_lying_thumb.png\n"," create mode 100644 data/rwhar/proband11/videos/video_running_thumb.png\n"," create mode 100644 data/rwhar/proband11/videos/video_sitting_thumb.png\n"," create mode 100644 data/rwhar/proband11/videos/video_standing_thumb.png\n"," create mode 100644 data/rwhar/proband11/videos/video_walking_thumb.png\n"," create mode 100644 data/rwhar/proband12/data/acc_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband12/data/acc_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband12/data/acc_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband12/data/acc_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband12/data/acc_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband12/data/acc_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband12/data/acc_lying_csv.zip\n"," create mode 100644 data/rwhar/proband12/data/acc_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband12/data/acc_running_csv.zip\n"," create mode 100644 data/rwhar/proband12/data/acc_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband12/data/acc_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband12/data/acc_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband12/data/acc_standing_csv.zip\n"," create mode 100644 data/rwhar/proband12/data/acc_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband12/data/acc_walking_csv.zip\n"," create mode 100644 data/rwhar/proband12/data/acc_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband12/data/gps_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband12/data/gps_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband12/data/gps_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband12/data/gps_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband12/data/gps_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband12/data/gps_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband12/data/gps_lying_csv.zip\n"," create mode 100644 data/rwhar/proband12/data/gps_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband12/data/gps_running_csv.zip\n"," create mode 100644 data/rwhar/proband12/data/gps_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband12/data/gps_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband12/data/gps_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband12/data/gps_standing_csv.zip\n"," create mode 100644 data/rwhar/proband12/data/gps_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband12/data/gps_walking_csv.zip\n"," create mode 100644 data/rwhar/proband12/data/gps_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband12/data/gyr_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband12/data/gyr_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband12/data/gyr_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband12/data/gyr_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband12/data/gyr_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband12/data/gyr_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband12/data/gyr_lying_csv.zip\n"," create mode 100644 data/rwhar/proband12/data/gyr_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband12/data/gyr_running_csv.zip\n"," create mode 100644 data/rwhar/proband12/data/gyr_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband12/data/gyr_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband12/data/gyr_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband12/data/gyr_standing_csv.zip\n"," create mode 100644 data/rwhar/proband12/data/gyr_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband12/data/gyr_walking_csv.zip\n"," create mode 100644 data/rwhar/proband12/data/gyr_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband12/data/lig_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband12/data/lig_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband12/data/lig_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband12/data/lig_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband12/data/lig_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband12/data/lig_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband12/data/lig_lying_csv.zip\n"," create mode 100644 data/rwhar/proband12/data/lig_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband12/data/lig_running_csv.zip\n"," create mode 100644 data/rwhar/proband12/data/lig_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband12/data/lig_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband12/data/lig_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband12/data/lig_standing_csv.zip\n"," create mode 100644 data/rwhar/proband12/data/lig_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband12/data/lig_walking_csv.zip\n"," create mode 100644 data/rwhar/proband12/data/lig_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband12/data/mag_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband12/data/mag_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband12/data/mag_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband12/data/mag_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband12/data/mag_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband12/data/mag_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband12/data/mag_lying_csv.zip\n"," create mode 100644 data/rwhar/proband12/data/mag_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband12/data/mag_running_csv.zip\n"," create mode 100644 data/rwhar/proband12/data/mag_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband12/data/mag_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband12/data/mag_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband12/data/mag_standing_csv.zip\n"," create mode 100644 data/rwhar/proband12/data/mag_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband12/data/mag_walking_csv.zip\n"," create mode 100644 data/rwhar/proband12/data/mag_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband12/data/mic_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband12/data/mic_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband12/data/mic_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband12/data/mic_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband12/data/mic_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband12/data/mic_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband12/data/mic_lying_csv.zip\n"," create mode 100644 data/rwhar/proband12/data/mic_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband12/data/mic_running_csv.zip\n"," create mode 100644 data/rwhar/proband12/data/mic_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband12/data/mic_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband12/data/mic_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband12/data/mic_standing_csv.zip\n"," create mode 100644 data/rwhar/proband12/data/mic_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband12/data/mic_walking_csv.zip\n"," create mode 100644 data/rwhar/proband12/data/mic_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband12/images/chest.png\n"," create mode 100644 data/rwhar/proband12/images/chest_thumb.png\n"," create mode 100644 data/rwhar/proband12/images/forearm.png\n"," create mode 100644 data/rwhar/proband12/images/forearm_thumb.png\n"," create mode 100644 data/rwhar/proband12/images/head.png\n"," create mode 100644 data/rwhar/proband12/images/head_thumb.png\n"," create mode 100644 data/rwhar/proband12/images/overview.png\n"," create mode 100644 data/rwhar/proband12/images/overview_thumb.png\n"," create mode 100644 data/rwhar/proband12/images/preview.png\n"," create mode 100644 data/rwhar/proband12/images/shin.png\n"," create mode 100644 data/rwhar/proband12/images/shin_thumb.png\n"," create mode 100644 data/rwhar/proband12/images/thigh.png\n"," create mode 100644 data/rwhar/proband12/images/thigh_thumb.png\n"," create mode 100644 data/rwhar/proband12/images/upperarm.png\n"," create mode 100644 data/rwhar/proband12/images/upperarm_thumb.png\n"," create mode 100644 data/rwhar/proband12/images/waist.png\n"," create mode 100644 data/rwhar/proband12/images/waist_thumb.png\n"," create mode 100644 data/rwhar/proband12/videos/video_climbing down_thumb.png\n"," create mode 100644 data/rwhar/proband12/videos/video_climbing up_thumb.png\n"," create mode 100644 data/rwhar/proband12/videos/video_jumping_thumb.png\n"," create mode 100644 data/rwhar/proband12/videos/video_lying_thumb.png\n"," create mode 100644 data/rwhar/proband12/videos/video_running_thumb.png\n"," create mode 100644 data/rwhar/proband12/videos/video_sitting_thumb.png\n"," create mode 100644 data/rwhar/proband12/videos/video_standing_thumb.png\n"," create mode 100644 data/rwhar/proband12/videos/video_walking_thumb.png\n"," create mode 100644 data/rwhar/proband13/data/acc_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband13/data/acc_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband13/data/acc_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband13/data/acc_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband13/data/acc_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband13/data/acc_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband13/data/acc_lying_csv.zip\n"," create mode 100644 data/rwhar/proband13/data/acc_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband13/data/acc_running_csv.zip\n"," create mode 100644 data/rwhar/proband13/data/acc_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband13/data/acc_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband13/data/acc_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband13/data/acc_standing_csv.zip\n"," create mode 100644 data/rwhar/proband13/data/acc_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband13/data/acc_walking_csv.zip\n"," create mode 100644 data/rwhar/proband13/data/acc_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband13/data/gps_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband13/data/gps_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband13/data/gps_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband13/data/gps_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband13/data/gps_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband13/data/gps_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband13/data/gps_lying_csv.zip\n"," create mode 100644 data/rwhar/proband13/data/gps_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband13/data/gps_running_csv.zip\n"," create mode 100644 data/rwhar/proband13/data/gps_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband13/data/gps_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband13/data/gps_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband13/data/gps_standing_csv.zip\n"," create mode 100644 data/rwhar/proband13/data/gps_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband13/data/gps_walking_csv.zip\n"," create mode 100644 data/rwhar/proband13/data/gps_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband13/data/gyr_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband13/data/gyr_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband13/data/gyr_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband13/data/gyr_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband13/data/gyr_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband13/data/gyr_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband13/data/gyr_lying_csv.zip\n"," create mode 100644 data/rwhar/proband13/data/gyr_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband13/data/gyr_running_csv.zip\n"," create mode 100644 data/rwhar/proband13/data/gyr_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband13/data/gyr_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband13/data/gyr_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband13/data/gyr_standing_csv.zip\n"," create mode 100644 data/rwhar/proband13/data/gyr_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband13/data/gyr_walking_csv.zip\n"," create mode 100644 data/rwhar/proband13/data/gyr_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband13/data/lig_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband13/data/lig_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband13/data/lig_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband13/data/lig_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband13/data/lig_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband13/data/lig_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband13/data/lig_lying_csv.zip\n"," create mode 100644 data/rwhar/proband13/data/lig_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband13/data/lig_running_csv.zip\n"," create mode 100644 data/rwhar/proband13/data/lig_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband13/data/lig_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband13/data/lig_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband13/data/lig_standing_csv.zip\n"," create mode 100644 data/rwhar/proband13/data/lig_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband13/data/lig_walking_csv.zip\n"," create mode 100644 data/rwhar/proband13/data/lig_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband13/data/mag_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband13/data/mag_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband13/data/mag_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband13/data/mag_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband13/data/mag_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband13/data/mag_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband13/data/mag_lying_csv.zip\n"," create mode 100644 data/rwhar/proband13/data/mag_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband13/data/mag_running_csv.zip\n"," create mode 100644 data/rwhar/proband13/data/mag_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband13/data/mag_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband13/data/mag_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband13/data/mag_standing_csv.zip\n"," create mode 100644 data/rwhar/proband13/data/mag_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband13/data/mag_walking_csv.zip\n"," create mode 100644 data/rwhar/proband13/data/mag_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband13/data/mic_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband13/data/mic_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband13/data/mic_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband13/data/mic_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband13/data/mic_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband13/data/mic_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband13/data/mic_lying_csv.zip\n"," create mode 100644 data/rwhar/proband13/data/mic_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband13/data/mic_running_csv.zip\n"," create mode 100644 data/rwhar/proband13/data/mic_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband13/data/mic_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband13/data/mic_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband13/data/mic_standing_csv.zip\n"," create mode 100644 data/rwhar/proband13/data/mic_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband13/data/mic_walking_csv.zip\n"," create mode 100644 data/rwhar/proband13/data/mic_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband13/images/chest.png\n"," create mode 100644 data/rwhar/proband13/images/chest_thumb.png\n"," create mode 100644 data/rwhar/proband13/images/forearm.png\n"," create mode 100644 data/rwhar/proband13/images/forearm_thumb.png\n"," create mode 100644 data/rwhar/proband13/images/head.png\n"," create mode 100644 data/rwhar/proband13/images/head_thumb.png\n"," create mode 100644 data/rwhar/proband13/images/overview.png\n"," create mode 100644 data/rwhar/proband13/images/overview_thumb.png\n"," create mode 100644 data/rwhar/proband13/images/preview.png\n"," create mode 100644 data/rwhar/proband13/images/shin.png\n"," create mode 100644 data/rwhar/proband13/images/shin_thumb.png\n"," create mode 100644 data/rwhar/proband13/images/thigh.png\n"," create mode 100644 data/rwhar/proband13/images/thigh_thumb.png\n"," create mode 100644 data/rwhar/proband13/images/upperarm.png\n"," create mode 100644 data/rwhar/proband13/images/upperarm_thumb.png\n"," create mode 100644 data/rwhar/proband13/images/waist.png\n"," create mode 100644 data/rwhar/proband13/images/waist_thumb.png\n"," create mode 100644 data/rwhar/proband13/videos/video_climbing down_thumb.png\n"," create mode 100644 data/rwhar/proband13/videos/video_climbing up_thumb.png\n"," create mode 100644 data/rwhar/proband13/videos/video_jumping_thumb.png\n"," create mode 100644 data/rwhar/proband13/videos/video_lying_thumb.png\n"," create mode 100644 data/rwhar/proband13/videos/video_running_thumb.png\n"," create mode 100644 data/rwhar/proband13/videos/video_sitting_thumb.png\n"," create mode 100644 data/rwhar/proband13/videos/video_standing_thumb.png\n"," create mode 100644 data/rwhar/proband13/videos/video_walking_thumb.png\n"," create mode 100644 data/rwhar/proband14/data/acc_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband14/data/acc_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband14/data/acc_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband14/data/acc_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband14/data/acc_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband14/data/acc_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband14/data/acc_lying_csv.zip\n"," create mode 100644 data/rwhar/proband14/data/acc_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband14/data/acc_running_csv.zip\n"," create mode 100644 data/rwhar/proband14/data/acc_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband14/data/acc_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband14/data/acc_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband14/data/acc_standing_csv.zip\n"," create mode 100644 data/rwhar/proband14/data/acc_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband14/data/acc_walking_csv.zip\n"," create mode 100644 data/rwhar/proband14/data/acc_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband14/data/gps_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband14/data/gps_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband14/data/gps_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband14/data/gps_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband14/data/gps_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband14/data/gps_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband14/data/gps_lying_csv.zip\n"," create mode 100644 data/rwhar/proband14/data/gps_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband14/data/gps_running_csv.zip\n"," create mode 100644 data/rwhar/proband14/data/gps_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband14/data/gps_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband14/data/gps_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband14/data/gps_standing_csv.zip\n"," create mode 100644 data/rwhar/proband14/data/gps_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband14/data/gps_walking_csv.zip\n"," create mode 100644 data/rwhar/proband14/data/gps_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband14/data/gyr_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband14/data/gyr_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband14/data/gyr_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband14/data/gyr_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband14/data/gyr_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband14/data/gyr_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband14/data/gyr_lying_csv.zip\n"," create mode 100644 data/rwhar/proband14/data/gyr_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband14/data/gyr_running_csv.zip\n"," create mode 100644 data/rwhar/proband14/data/gyr_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband14/data/gyr_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband14/data/gyr_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband14/data/gyr_standing_csv.zip\n"," create mode 100644 data/rwhar/proband14/data/gyr_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband14/data/gyr_walking_csv.zip\n"," create mode 100644 data/rwhar/proband14/data/gyr_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband14/data/lig_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband14/data/lig_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband14/data/lig_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband14/data/lig_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband14/data/lig_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband14/data/lig_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband14/data/lig_lying_csv.zip\n"," create mode 100644 data/rwhar/proband14/data/lig_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband14/data/lig_running_csv.zip\n"," create mode 100644 data/rwhar/proband14/data/lig_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband14/data/lig_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband14/data/lig_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband14/data/lig_standing_csv.zip\n"," create mode 100644 data/rwhar/proband14/data/lig_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband14/data/lig_walking_csv.zip\n"," create mode 100644 data/rwhar/proband14/data/lig_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband14/data/mag_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband14/data/mag_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband14/data/mag_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband14/data/mag_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband14/data/mag_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband14/data/mag_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband14/data/mag_lying_csv.zip\n"," create mode 100644 data/rwhar/proband14/data/mag_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband14/data/mag_running_csv.zip\n"," create mode 100644 data/rwhar/proband14/data/mag_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband14/data/mag_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband14/data/mag_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband14/data/mag_standing_csv.zip\n"," create mode 100644 data/rwhar/proband14/data/mag_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband14/data/mag_walking_csv.zip\n"," create mode 100644 data/rwhar/proband14/data/mag_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband14/data/mic_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband14/data/mic_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband14/data/mic_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband14/data/mic_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband14/data/mic_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband14/data/mic_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband14/data/mic_lying_csv.zip\n"," create mode 100644 data/rwhar/proband14/data/mic_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband14/data/mic_running_csv.zip\n"," create mode 100644 data/rwhar/proband14/data/mic_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband14/data/mic_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband14/data/mic_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband14/data/mic_standing_csv.zip\n"," create mode 100644 data/rwhar/proband14/data/mic_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband14/data/mic_walking_csv.zip\n"," create mode 100644 data/rwhar/proband14/data/mic_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband14/images/.directory\n"," create mode 100644 data/rwhar/proband14/images/chest.png\n"," create mode 100644 data/rwhar/proband14/images/chest_thumb.png\n"," create mode 100644 data/rwhar/proband14/images/forearm.png\n"," create mode 100644 data/rwhar/proband14/images/forearm_thumb.png\n"," create mode 100644 data/rwhar/proband14/images/head.png\n"," create mode 100644 data/rwhar/proband14/images/head_thumb.png\n"," create mode 100644 data/rwhar/proband14/images/overview.png\n"," create mode 100644 data/rwhar/proband14/images/overview_thumb.png\n"," create mode 100644 data/rwhar/proband14/images/preview.png\n"," create mode 100644 data/rwhar/proband14/images/shin.png\n"," create mode 100644 data/rwhar/proband14/images/shin_thumb.png\n"," create mode 100644 data/rwhar/proband14/images/thigh.png\n"," create mode 100644 data/rwhar/proband14/images/thigh_thumb.png\n"," create mode 100644 data/rwhar/proband14/images/upperarm.png\n"," create mode 100644 data/rwhar/proband14/images/upperarm_thumb.png\n"," create mode 100644 data/rwhar/proband14/images/waist.png\n"," create mode 100644 data/rwhar/proband14/images/waist_thumb.png\n"," create mode 100644 data/rwhar/proband14/videos/video_climbing down_thumb.png\n"," create mode 100644 data/rwhar/proband14/videos/video_climbing up_thumb.png\n"," create mode 100644 data/rwhar/proband14/videos/video_jumping_thumb.png\n"," create mode 100644 data/rwhar/proband14/videos/video_lying_thumb.png\n"," create mode 100644 data/rwhar/proband14/videos/video_running_thumb.png\n"," create mode 100644 data/rwhar/proband14/videos/video_sitting_thumb.png\n"," create mode 100644 data/rwhar/proband14/videos/video_standing_thumb.png\n"," create mode 100644 data/rwhar/proband14/videos/video_walking_thumb.png\n"," create mode 100644 data/rwhar/proband15/data/acc_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband15/data/acc_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband15/data/acc_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband15/data/acc_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband15/data/acc_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband15/data/acc_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband15/data/acc_lying_csv.zip\n"," create mode 100644 data/rwhar/proband15/data/acc_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband15/data/acc_running_csv.zip\n"," create mode 100644 data/rwhar/proband15/data/acc_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband15/data/acc_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband15/data/acc_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband15/data/acc_standing_csv.zip\n"," create mode 100644 data/rwhar/proband15/data/acc_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband15/data/acc_walking_csv.zip\n"," create mode 100644 data/rwhar/proband15/data/acc_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband15/data/gps_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband15/data/gps_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband15/data/gps_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband15/data/gps_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband15/data/gps_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband15/data/gps_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband15/data/gps_lying_csv.zip\n"," create mode 100644 data/rwhar/proband15/data/gps_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband15/data/gps_running_csv.zip\n"," create mode 100644 data/rwhar/proband15/data/gps_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband15/data/gps_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband15/data/gps_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband15/data/gps_standing_csv.zip\n"," create mode 100644 data/rwhar/proband15/data/gps_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband15/data/gps_walking_csv.zip\n"," create mode 100644 data/rwhar/proband15/data/gps_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband15/data/gyr_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband15/data/gyr_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband15/data/gyr_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband15/data/gyr_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband15/data/gyr_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband15/data/gyr_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband15/data/gyr_lying_csv.zip\n"," create mode 100644 data/rwhar/proband15/data/gyr_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband15/data/gyr_running_csv.zip\n"," create mode 100644 data/rwhar/proband15/data/gyr_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband15/data/gyr_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband15/data/gyr_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband15/data/gyr_standing_csv.zip\n"," create mode 100644 data/rwhar/proband15/data/gyr_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband15/data/gyr_walking_csv.zip\n"," create mode 100644 data/rwhar/proband15/data/gyr_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband15/data/lig_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband15/data/lig_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband15/data/lig_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband15/data/lig_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband15/data/lig_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband15/data/lig_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband15/data/lig_lying_csv.zip\n"," create mode 100644 data/rwhar/proband15/data/lig_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband15/data/lig_running_csv.zip\n"," create mode 100644 data/rwhar/proband15/data/lig_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband15/data/lig_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband15/data/lig_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband15/data/lig_standing_csv.zip\n"," create mode 100644 data/rwhar/proband15/data/lig_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband15/data/lig_walking_csv.zip\n"," create mode 100644 data/rwhar/proband15/data/lig_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband15/data/mag_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband15/data/mag_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband15/data/mag_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband15/data/mag_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband15/data/mag_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband15/data/mag_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband15/data/mag_lying_csv.zip\n"," create mode 100644 data/rwhar/proband15/data/mag_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband15/data/mag_running_csv.zip\n"," create mode 100644 data/rwhar/proband15/data/mag_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband15/data/mag_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband15/data/mag_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband15/data/mag_standing_csv.zip\n"," create mode 100644 data/rwhar/proband15/data/mag_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband15/data/mag_walking_csv.zip\n"," create mode 100644 data/rwhar/proband15/data/mag_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband15/data/mic_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband15/data/mic_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband15/data/mic_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband15/data/mic_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband15/data/mic_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband15/data/mic_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband15/data/mic_lying_csv.zip\n"," create mode 100644 data/rwhar/proband15/data/mic_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband15/data/mic_running_csv.zip\n"," create mode 100644 data/rwhar/proband15/data/mic_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband15/data/mic_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband15/data/mic_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband15/data/mic_standing_csv.zip\n"," create mode 100644 data/rwhar/proband15/data/mic_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband15/data/mic_walking_csv.zip\n"," create mode 100644 data/rwhar/proband15/data/mic_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband15/images/chest.png\n"," create mode 100644 data/rwhar/proband15/images/chest_thumb.png\n"," create mode 100644 data/rwhar/proband15/images/forearm.png\n"," create mode 100644 data/rwhar/proband15/images/forearm_thumb.png\n"," create mode 100644 data/rwhar/proband15/images/head.png\n"," create mode 100644 data/rwhar/proband15/images/head_thumb.png\n"," create mode 100644 data/rwhar/proband15/images/overview.png\n"," create mode 100644 data/rwhar/proband15/images/overview_thumb.png\n"," create mode 100644 data/rwhar/proband15/images/preview.png\n"," create mode 100644 data/rwhar/proband15/images/shin.png\n"," create mode 100644 data/rwhar/proband15/images/shin_thumb.png\n"," create mode 100644 data/rwhar/proband15/images/thigh.png\n"," create mode 100644 data/rwhar/proband15/images/thigh_thumb.png\n"," create mode 100644 data/rwhar/proband15/images/upperarm.png\n"," create mode 100644 data/rwhar/proband15/images/upperarm_thumb.png\n"," create mode 100644 data/rwhar/proband15/images/waist.png\n"," create mode 100644 data/rwhar/proband15/images/waist_thumb.png\n"," create mode 100644 data/rwhar/proband15/videos/video_climbing down_thumb.png\n"," create mode 100644 data/rwhar/proband15/videos/video_climbing up_thumb.png\n"," create mode 100644 data/rwhar/proband15/videos/video_jumping_thumb.png\n"," create mode 100644 data/rwhar/proband15/videos/video_lying_thumb.png\n"," create mode 100644 data/rwhar/proband15/videos/video_running_thumb.png\n"," create mode 100644 data/rwhar/proband15/videos/video_sitting_thumb.png\n"," create mode 100644 data/rwhar/proband15/videos/video_standing_thumb.png\n"," create mode 100644 data/rwhar/proband15/videos/video_walking_thumb.png\n"," create mode 100644 data/rwhar/proband2/data/acc_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband2/data/acc_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband2/data/acc_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband2/data/acc_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband2/data/acc_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband2/data/acc_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband2/data/acc_lying_csv.zip\n"," create mode 100644 data/rwhar/proband2/data/acc_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband2/data/acc_running_csv.zip\n"," create mode 100644 data/rwhar/proband2/data/acc_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband2/data/acc_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband2/data/acc_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband2/data/acc_standing_csv.zip\n"," create mode 100644 data/rwhar/proband2/data/acc_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband2/data/acc_walking_csv.zip\n"," create mode 100644 data/rwhar/proband2/data/acc_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband2/data/gps_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband2/data/gps_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband2/data/gps_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband2/data/gps_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband2/data/gps_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband2/data/gps_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband2/data/gps_lying_csv.zip\n"," create mode 100644 data/rwhar/proband2/data/gps_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband2/data/gps_running_csv.zip\n"," create mode 100644 data/rwhar/proband2/data/gps_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband2/data/gps_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband2/data/gps_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband2/data/gps_standing_csv.zip\n"," create mode 100644 data/rwhar/proband2/data/gps_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband2/data/gps_walking_csv.zip\n"," create mode 100644 data/rwhar/proband2/data/gps_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband2/data/gyr_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband2/data/gyr_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband2/data/gyr_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband2/data/gyr_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband2/data/gyr_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband2/data/gyr_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband2/data/gyr_lying_csv.zip\n"," create mode 100644 data/rwhar/proband2/data/gyr_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband2/data/gyr_running_csv.zip\n"," create mode 100644 data/rwhar/proband2/data/gyr_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband2/data/gyr_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband2/data/gyr_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband2/data/gyr_standing_csv.zip\n"," create mode 100644 data/rwhar/proband2/data/gyr_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband2/data/gyr_walking_csv.zip\n"," create mode 100644 data/rwhar/proband2/data/gyr_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband2/data/lig_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband2/data/lig_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband2/data/lig_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband2/data/lig_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband2/data/lig_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband2/data/lig_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband2/data/lig_lying_csv.zip\n"," create mode 100644 data/rwhar/proband2/data/lig_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband2/data/lig_running_csv.zip\n"," create mode 100644 data/rwhar/proband2/data/lig_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband2/data/lig_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband2/data/lig_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband2/data/lig_standing_csv.zip\n"," create mode 100644 data/rwhar/proband2/data/lig_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband2/data/lig_walking_csv.zip\n"," create mode 100644 data/rwhar/proband2/data/lig_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband2/data/mag_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband2/data/mag_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband2/data/mag_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband2/data/mag_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband2/data/mag_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband2/data/mag_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband2/data/mag_lying_csv.zip\n"," create mode 100644 data/rwhar/proband2/data/mag_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband2/data/mag_running_csv.zip\n"," create mode 100644 data/rwhar/proband2/data/mag_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband2/data/mag_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband2/data/mag_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband2/data/mag_standing_csv.zip\n"," create mode 100644 data/rwhar/proband2/data/mag_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband2/data/mag_walking_csv.zip\n"," create mode 100644 data/rwhar/proband2/data/mag_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband2/data/mic_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband2/data/mic_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband2/data/mic_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband2/data/mic_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband2/data/mic_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband2/data/mic_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband2/data/mic_lying_csv.zip\n"," create mode 100644 data/rwhar/proband2/data/mic_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband2/data/mic_running_csv.zip\n"," create mode 100644 data/rwhar/proband2/data/mic_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband2/data/mic_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband2/data/mic_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband2/data/mic_standing_csv.zip\n"," create mode 100644 data/rwhar/proband2/data/mic_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband2/data/mic_walking_csv.zip\n"," create mode 100644 data/rwhar/proband2/data/mic_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband2/images/chest.png\n"," create mode 100644 data/rwhar/proband2/images/chest_thumb.png\n"," create mode 100644 data/rwhar/proband2/images/forearm.png\n"," create mode 100644 data/rwhar/proband2/images/forearm_thumb.png\n"," create mode 100644 data/rwhar/proband2/images/head.png\n"," create mode 100644 data/rwhar/proband2/images/head_thumb.png\n"," create mode 100644 data/rwhar/proband2/images/overview.png\n"," create mode 100644 data/rwhar/proband2/images/overview_thumb.png\n"," create mode 100644 data/rwhar/proband2/images/preview.png\n"," create mode 100644 data/rwhar/proband2/images/shin.png\n"," create mode 100644 data/rwhar/proband2/images/shin_thumb.png\n"," create mode 100644 data/rwhar/proband2/images/thigh.png\n"," create mode 100644 data/rwhar/proband2/images/thigh_thumb.png\n"," create mode 100644 data/rwhar/proband2/images/upperarm.png\n"," create mode 100644 data/rwhar/proband2/images/upperarm_thumb.png\n"," create mode 100644 data/rwhar/proband2/images/waist.png\n"," create mode 100644 data/rwhar/proband2/images/waist_thumb.png\n"," create mode 100644 data/rwhar/proband2/videos/video_climbing down_thumb.png\n"," create mode 100644 data/rwhar/proband2/videos/video_climbing up_thumb.png\n"," create mode 100644 data/rwhar/proband2/videos/video_jumping_thumb.png\n"," create mode 100644 data/rwhar/proband2/videos/video_lying_thumb.png\n"," create mode 100644 data/rwhar/proband2/videos/video_running_thumb.png\n"," create mode 100644 data/rwhar/proband2/videos/video_sitting_thumb.png\n"," create mode 100644 data/rwhar/proband2/videos/video_standing_thumb.png\n"," create mode 100644 data/rwhar/proband2/videos/video_walking_thumb.png\n"," create mode 100644 data/rwhar/proband3/data/acc_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband3/data/acc_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband3/data/acc_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband3/data/acc_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband3/data/acc_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband3/data/acc_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband3/data/acc_lying_csv.zip\n"," create mode 100644 data/rwhar/proband3/data/acc_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband3/data/acc_running_csv.zip\n"," create mode 100644 data/rwhar/proband3/data/acc_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband3/data/acc_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband3/data/acc_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband3/data/acc_standing_csv.zip\n"," create mode 100644 data/rwhar/proband3/data/acc_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband3/data/acc_walking_csv.zip\n"," create mode 100644 data/rwhar/proband3/data/acc_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband3/data/gps_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband3/data/gps_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband3/data/gps_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband3/data/gps_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband3/data/gps_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband3/data/gps_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband3/data/gps_lying_csv.zip\n"," create mode 100644 data/rwhar/proband3/data/gps_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband3/data/gps_running_csv.zip\n"," create mode 100644 data/rwhar/proband3/data/gps_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband3/data/gps_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband3/data/gps_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband3/data/gps_standing_csv.zip\n"," create mode 100644 data/rwhar/proband3/data/gps_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband3/data/gps_walking_csv.zip\n"," create mode 100644 data/rwhar/proband3/data/gps_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband3/data/gyr_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband3/data/gyr_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband3/data/gyr_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband3/data/gyr_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband3/data/gyr_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband3/data/gyr_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband3/data/gyr_lying_csv.zip\n"," create mode 100644 data/rwhar/proband3/data/gyr_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband3/data/gyr_running_csv.zip\n"," create mode 100644 data/rwhar/proband3/data/gyr_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband3/data/gyr_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband3/data/gyr_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband3/data/gyr_standing_csv.zip\n"," create mode 100644 data/rwhar/proband3/data/gyr_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband3/data/gyr_walking_csv.zip\n"," create mode 100644 data/rwhar/proband3/data/gyr_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband3/data/lig_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband3/data/lig_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband3/data/lig_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband3/data/lig_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband3/data/lig_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband3/data/lig_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband3/data/lig_lying_csv.zip\n"," create mode 100644 data/rwhar/proband3/data/lig_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband3/data/lig_running_csv.zip\n"," create mode 100644 data/rwhar/proband3/data/lig_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband3/data/lig_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband3/data/lig_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband3/data/lig_standing_csv.zip\n"," create mode 100644 data/rwhar/proband3/data/lig_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband3/data/lig_walking_csv.zip\n"," create mode 100644 data/rwhar/proband3/data/lig_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband3/data/mag_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband3/data/mag_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband3/data/mag_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband3/data/mag_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband3/data/mag_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband3/data/mag_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband3/data/mag_lying_csv.zip\n"," create mode 100644 data/rwhar/proband3/data/mag_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband3/data/mag_running_csv.zip\n"," create mode 100644 data/rwhar/proband3/data/mag_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband3/data/mag_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband3/data/mag_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband3/data/mag_standing_csv.zip\n"," create mode 100644 data/rwhar/proband3/data/mag_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband3/data/mag_walking_csv.zip\n"," create mode 100644 data/rwhar/proband3/data/mag_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband3/data/mic_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband3/data/mic_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband3/data/mic_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband3/data/mic_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband3/data/mic_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband3/data/mic_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband3/data/mic_lying_csv.zip\n"," create mode 100644 data/rwhar/proband3/data/mic_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband3/data/mic_running_csv.zip\n"," create mode 100644 data/rwhar/proband3/data/mic_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband3/data/mic_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband3/data/mic_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband3/data/mic_standing_csv.zip\n"," create mode 100644 data/rwhar/proband3/data/mic_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband3/data/mic_walking_csv.zip\n"," create mode 100644 data/rwhar/proband3/data/mic_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband3/images/chest.png\n"," create mode 100644 data/rwhar/proband3/images/chest_thumb.png\n"," create mode 100644 data/rwhar/proband3/images/forearm.png\n"," create mode 100644 data/rwhar/proband3/images/forearm_thumb.png\n"," create mode 100644 data/rwhar/proband3/images/head.png\n"," create mode 100644 data/rwhar/proband3/images/head_thumb.png\n"," create mode 100644 data/rwhar/proband3/images/overview.png\n"," create mode 100644 data/rwhar/proband3/images/overview_thumb.png\n"," create mode 100644 data/rwhar/proband3/images/preview.png\n"," create mode 100644 data/rwhar/proband3/images/shin.png\n"," create mode 100644 data/rwhar/proband3/images/shin_thumb.png\n"," create mode 100644 data/rwhar/proband3/images/thigh.png\n"," create mode 100644 data/rwhar/proband3/images/thigh_thumb.png\n"," create mode 100644 data/rwhar/proband3/images/upperarm.png\n"," create mode 100644 data/rwhar/proband3/images/upperarm_thumb.png\n"," create mode 100644 data/rwhar/proband3/images/waist.png\n"," create mode 100644 data/rwhar/proband3/images/waist_thumb.png\n"," create mode 100644 data/rwhar/proband3/videos/video_climbing down_thumb.png\n"," create mode 100644 data/rwhar/proband3/videos/video_climbing up_thumb.png\n"," create mode 100644 data/rwhar/proband3/videos/video_jumping_thumb.png\n"," create mode 100644 data/rwhar/proband3/videos/video_lying_thumb.png\n"," create mode 100644 data/rwhar/proband3/videos/video_running_thumb.png\n"," create mode 100644 data/rwhar/proband3/videos/video_sitting_thumb.png\n"," create mode 100644 data/rwhar/proband3/videos/video_standing_thumb.png\n"," create mode 100644 data/rwhar/proband3/videos/video_walking_thumb.png\n"," create mode 100644 data/rwhar/proband4/data/acc_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband4/data/acc_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband4/data/acc_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband4/data/acc_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband4/data/acc_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband4/data/acc_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband4/data/acc_lying_csv.zip\n"," create mode 100644 data/rwhar/proband4/data/acc_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband4/data/acc_running_csv.zip\n"," create mode 100644 data/rwhar/proband4/data/acc_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband4/data/acc_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband4/data/acc_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband4/data/acc_standing_csv.zip\n"," create mode 100644 data/rwhar/proband4/data/acc_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband4/data/acc_walking_csv.zip\n"," create mode 100644 data/rwhar/proband4/data/acc_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband4/data/gps_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband4/data/gps_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband4/data/gps_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband4/data/gps_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband4/data/gps_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband4/data/gps_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband4/data/gps_lying_csv.zip\n"," create mode 100644 data/rwhar/proband4/data/gps_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband4/data/gps_running_csv.zip\n"," create mode 100644 data/rwhar/proband4/data/gps_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband4/data/gps_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband4/data/gps_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband4/data/gps_standing_csv.zip\n"," create mode 100644 data/rwhar/proband4/data/gps_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband4/data/gps_walking_csv.zip\n"," create mode 100644 data/rwhar/proband4/data/gps_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband4/data/gyr_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband4/data/gyr_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband4/data/gyr_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband4/data/gyr_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband4/data/gyr_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband4/data/gyr_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband4/data/gyr_lying_csv.zip\n"," create mode 100644 data/rwhar/proband4/data/gyr_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband4/data/gyr_running_csv.zip\n"," create mode 100644 data/rwhar/proband4/data/gyr_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband4/data/gyr_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband4/data/gyr_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband4/data/gyr_standing_csv.zip\n"," create mode 100644 data/rwhar/proband4/data/gyr_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband4/data/gyr_walking_csv.zip\n"," create mode 100644 data/rwhar/proband4/data/gyr_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband4/data/lig_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband4/data/lig_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband4/data/lig_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband4/data/lig_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband4/data/lig_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband4/data/lig_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband4/data/lig_lying_csv.zip\n"," create mode 100644 data/rwhar/proband4/data/lig_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband4/data/lig_running_csv.zip\n"," create mode 100644 data/rwhar/proband4/data/lig_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband4/data/lig_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband4/data/lig_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband4/data/lig_standing_csv.zip\n"," create mode 100644 data/rwhar/proband4/data/lig_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband4/data/lig_walking_csv.zip\n"," create mode 100644 data/rwhar/proband4/data/lig_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband4/data/mag_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband4/data/mag_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband4/data/mag_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband4/data/mag_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband4/data/mag_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband4/data/mag_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband4/data/mag_lying_csv.zip\n"," create mode 100644 data/rwhar/proband4/data/mag_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband4/data/mag_running_csv.zip\n"," create mode 100644 data/rwhar/proband4/data/mag_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband4/data/mag_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband4/data/mag_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband4/data/mag_standing_csv.zip\n"," create mode 100644 data/rwhar/proband4/data/mag_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband4/data/mag_walking_csv.zip\n"," create mode 100644 data/rwhar/proband4/data/mag_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband4/data/mic_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband4/data/mic_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband4/data/mic_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband4/data/mic_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband4/data/mic_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband4/data/mic_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband4/data/mic_lying_csv.zip\n"," create mode 100644 data/rwhar/proband4/data/mic_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband4/data/mic_running_csv.zip\n"," create mode 100644 data/rwhar/proband4/data/mic_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband4/data/mic_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband4/data/mic_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband4/data/mic_standing_csv.zip\n"," create mode 100644 data/rwhar/proband4/data/mic_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband4/data/mic_walking_csv.zip\n"," create mode 100644 data/rwhar/proband4/data/mic_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband4/images/DSC_0342.JPG\n"," create mode 100644 data/rwhar/proband4/images/chest.png\n"," create mode 100644 data/rwhar/proband4/images/chest_thumb.png\n"," create mode 100644 data/rwhar/proband4/images/forearm.png\n"," create mode 100644 data/rwhar/proband4/images/forearm_thumb.png\n"," create mode 100644 data/rwhar/proband4/images/head.png\n"," create mode 100644 data/rwhar/proband4/images/head_thumb.png\n"," create mode 100644 data/rwhar/proband4/images/overview.png\n"," create mode 100644 data/rwhar/proband4/images/overview_thumb.png\n"," create mode 100644 data/rwhar/proband4/images/preview.png\n"," create mode 100644 data/rwhar/proband4/images/shin.png\n"," create mode 100644 data/rwhar/proband4/images/shin_thumb.png\n"," create mode 100644 data/rwhar/proband4/images/thigh.png\n"," create mode 100644 data/rwhar/proband4/images/thigh_thumb.png\n"," create mode 100644 data/rwhar/proband4/images/upperarm.png\n"," create mode 100644 data/rwhar/proband4/images/upperarm_thumb.png\n"," create mode 100644 data/rwhar/proband4/images/waist.png\n"," create mode 100644 data/rwhar/proband4/images/waist_thumb.png\n"," create mode 100644 data/rwhar/proband4/videos/video_climbing down_thumb.png\n"," create mode 100644 data/rwhar/proband4/videos/video_climbing up_thumb.png\n"," create mode 100644 data/rwhar/proband4/videos/video_jumping_thumb.png\n"," create mode 100644 data/rwhar/proband4/videos/video_lying_thumb.png\n"," create mode 100644 data/rwhar/proband4/videos/video_running_thumb.png\n"," create mode 100644 data/rwhar/proband4/videos/video_sitting_thumb.png\n"," create mode 100644 data/rwhar/proband4/videos/video_standing_thumb.png\n"," create mode 100644 data/rwhar/proband4/videos/video_walking_thumb.png\n"," create mode 100644 data/rwhar/proband5/data/acc_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband5/data/acc_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband5/data/acc_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband5/data/acc_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband5/data/acc_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband5/data/acc_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband5/data/acc_lying_csv.zip\n"," create mode 100644 data/rwhar/proband5/data/acc_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband5/data/acc_running_csv.zip\n"," create mode 100644 data/rwhar/proband5/data/acc_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband5/data/acc_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband5/data/acc_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband5/data/acc_standing_csv.zip\n"," create mode 100644 data/rwhar/proband5/data/acc_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband5/data/acc_walking_csv.zip\n"," create mode 100644 data/rwhar/proband5/data/acc_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband5/data/gps_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband5/data/gps_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband5/data/gps_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband5/data/gps_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband5/data/gps_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband5/data/gps_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband5/data/gps_lying_csv.zip\n"," create mode 100644 data/rwhar/proband5/data/gps_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband5/data/gps_running_csv.zip\n"," create mode 100644 data/rwhar/proband5/data/gps_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband5/data/gps_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband5/data/gps_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband5/data/gps_standing_csv.zip\n"," create mode 100644 data/rwhar/proband5/data/gps_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband5/data/gps_walking_csv.zip\n"," create mode 100644 data/rwhar/proband5/data/gps_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband5/data/gyr_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband5/data/gyr_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband5/data/gyr_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband5/data/gyr_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband5/data/gyr_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband5/data/gyr_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband5/data/gyr_lying_csv.zip\n"," create mode 100644 data/rwhar/proband5/data/gyr_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband5/data/gyr_running_csv.zip\n"," create mode 100644 data/rwhar/proband5/data/gyr_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband5/data/gyr_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband5/data/gyr_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband5/data/gyr_standing_csv.zip\n"," create mode 100644 data/rwhar/proband5/data/gyr_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband5/data/gyr_walking_csv.zip\n"," create mode 100644 data/rwhar/proband5/data/gyr_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband5/data/lig_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband5/data/lig_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband5/data/lig_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband5/data/lig_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband5/data/lig_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband5/data/lig_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband5/data/lig_lying_csv.zip\n"," create mode 100644 data/rwhar/proband5/data/lig_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband5/data/lig_running_csv.zip\n"," create mode 100644 data/rwhar/proband5/data/lig_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband5/data/lig_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband5/data/lig_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband5/data/lig_standing_csv.zip\n"," create mode 100644 data/rwhar/proband5/data/lig_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband5/data/lig_walking_csv.zip\n"," create mode 100644 data/rwhar/proband5/data/lig_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband5/data/mag_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband5/data/mag_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband5/data/mag_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband5/data/mag_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband5/data/mag_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband5/data/mag_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband5/data/mag_lying_csv.zip\n"," create mode 100644 data/rwhar/proband5/data/mag_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband5/data/mag_running_csv.zip\n"," create mode 100644 data/rwhar/proband5/data/mag_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband5/data/mag_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband5/data/mag_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband5/data/mag_standing_csv.zip\n"," create mode 100644 data/rwhar/proband5/data/mag_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband5/data/mag_walking_csv.zip\n"," create mode 100644 data/rwhar/proband5/data/mag_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband5/data/mic_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband5/data/mic_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband5/data/mic_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband5/data/mic_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband5/data/mic_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband5/data/mic_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband5/data/mic_lying_csv.zip\n"," create mode 100644 data/rwhar/proband5/data/mic_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband5/data/mic_running_csv.zip\n"," create mode 100644 data/rwhar/proband5/data/mic_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband5/data/mic_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband5/data/mic_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband5/data/mic_standing_csv.zip\n"," create mode 100644 data/rwhar/proband5/data/mic_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband5/data/mic_walking_csv.zip\n"," create mode 100644 data/rwhar/proband5/data/mic_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband5/images/chest.png\n"," create mode 100644 data/rwhar/proband5/images/chest_thumb.png\n"," create mode 100644 data/rwhar/proband5/images/forearm.png\n"," create mode 100644 data/rwhar/proband5/images/forearm_thumb.png\n"," create mode 100644 data/rwhar/proband5/images/head.png\n"," create mode 100644 data/rwhar/proband5/images/head_thumb.png\n"," create mode 100644 data/rwhar/proband5/images/overview.png\n"," create mode 100644 data/rwhar/proband5/images/overview_thumb.png\n"," create mode 100644 data/rwhar/proband5/images/preview.png\n"," create mode 100644 data/rwhar/proband5/images/shin.png\n"," create mode 100644 data/rwhar/proband5/images/shin_thumb.png\n"," create mode 100644 data/rwhar/proband5/images/upperarm.png\n"," create mode 100644 data/rwhar/proband5/images/upperarm_thumb.png\n"," create mode 100644 data/rwhar/proband5/images/waist.png\n"," create mode 100644 data/rwhar/proband5/images/waist_thumb.png\n"," create mode 100644 data/rwhar/proband5/videos/video_climbing down_thumb.png\n"," create mode 100644 data/rwhar/proband5/videos/video_climbing up_thumb.png\n"," create mode 100644 data/rwhar/proband5/videos/video_jumping_thumb.png\n"," create mode 100644 data/rwhar/proband5/videos/video_lying_thumb.png\n"," create mode 100644 data/rwhar/proband5/videos/video_running_thumb.png\n"," create mode 100644 data/rwhar/proband5/videos/video_sitting_thumb.png\n"," create mode 100644 data/rwhar/proband5/videos/video_standing_thumb.png\n"," create mode 100644 data/rwhar/proband5/videos/video_walking_thumb.png\n"," create mode 100644 data/rwhar/proband6/data/acc_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband6/data/acc_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband6/data/acc_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband6/data/acc_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband6/data/acc_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband6/data/acc_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband6/data/acc_lying_csv.zip\n"," create mode 100644 data/rwhar/proband6/data/acc_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband6/data/acc_running_csv.zip\n"," create mode 100644 data/rwhar/proband6/data/acc_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband6/data/acc_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband6/data/acc_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband6/data/acc_standing_csv.zip\n"," create mode 100644 data/rwhar/proband6/data/acc_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband6/data/acc_walking_csv.zip\n"," create mode 100644 data/rwhar/proband6/data/acc_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband6/data/gps_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband6/data/gps_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband6/data/gps_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband6/data/gps_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband6/data/gps_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband6/data/gps_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband6/data/gps_lying_csv.zip\n"," create mode 100644 data/rwhar/proband6/data/gps_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband6/data/gps_running_csv.zip\n"," create mode 100644 data/rwhar/proband6/data/gps_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband6/data/gps_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband6/data/gps_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband6/data/gps_standing_csv.zip\n"," create mode 100644 data/rwhar/proband6/data/gps_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband6/data/gps_walking_csv.zip\n"," create mode 100644 data/rwhar/proband6/data/gps_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband6/data/gyr_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband6/data/gyr_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband6/data/gyr_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband6/data/gyr_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband6/data/gyr_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband6/data/gyr_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband6/data/gyr_lying_csv.zip\n"," create mode 100644 data/rwhar/proband6/data/gyr_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband6/data/gyr_running_csv.zip\n"," create mode 100644 data/rwhar/proband6/data/gyr_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband6/data/gyr_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband6/data/gyr_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband6/data/gyr_standing_csv.zip\n"," create mode 100644 data/rwhar/proband6/data/gyr_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband6/data/gyr_walking_csv.zip\n"," create mode 100644 data/rwhar/proband6/data/gyr_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband6/data/lig_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband6/data/lig_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband6/data/lig_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband6/data/lig_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband6/data/lig_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband6/data/lig_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband6/data/lig_lying_csv.zip\n"," create mode 100644 data/rwhar/proband6/data/lig_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband6/data/lig_running_csv.zip\n"," create mode 100644 data/rwhar/proband6/data/lig_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband6/data/lig_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband6/data/lig_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband6/data/lig_standing_csv.zip\n"," create mode 100644 data/rwhar/proband6/data/lig_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband6/data/lig_walking_csv.zip\n"," create mode 100644 data/rwhar/proband6/data/lig_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband6/data/mag_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband6/data/mag_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband6/data/mag_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband6/data/mag_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband6/data/mag_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband6/data/mag_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband6/data/mag_lying_csv.zip\n"," create mode 100644 data/rwhar/proband6/data/mag_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband6/data/mag_running_csv.zip\n"," create mode 100644 data/rwhar/proband6/data/mag_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband6/data/mag_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband6/data/mag_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband6/data/mag_standing_csv.zip\n"," create mode 100644 data/rwhar/proband6/data/mag_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband6/data/mag_walking_csv.zip\n"," create mode 100644 data/rwhar/proband6/data/mag_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband6/data/mic_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband6/data/mic_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband6/data/mic_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband6/data/mic_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband6/data/mic_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband6/data/mic_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband6/data/mic_lying_csv.zip\n"," create mode 100644 data/rwhar/proband6/data/mic_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband6/data/mic_running_csv.zip\n"," create mode 100644 data/rwhar/proband6/data/mic_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband6/data/mic_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband6/data/mic_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband6/data/mic_standing_csv.zip\n"," create mode 100644 data/rwhar/proband6/data/mic_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband6/data/mic_walking_csv.zip\n"," create mode 100644 data/rwhar/proband6/data/mic_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband6/images/chest.png\n"," create mode 100644 data/rwhar/proband6/images/chest_thumb.png\n"," create mode 100644 data/rwhar/proband6/images/forearm.png\n"," create mode 100644 data/rwhar/proband6/images/forearm_thumb.png\n"," create mode 100644 data/rwhar/proband6/images/head.png\n"," create mode 100644 data/rwhar/proband6/images/head_thumb.png\n"," create mode 100644 data/rwhar/proband6/images/overview.png\n"," create mode 100644 data/rwhar/proband6/images/overview_thumb.png\n"," create mode 100644 data/rwhar/proband6/images/preview.png\n"," create mode 100644 data/rwhar/proband6/images/shin.png\n"," create mode 100644 data/rwhar/proband6/images/shin_thumb.png\n"," create mode 100644 data/rwhar/proband6/images/upperarm.png\n"," create mode 100644 data/rwhar/proband6/images/upperarm_thumb.png\n"," create mode 100644 data/rwhar/proband6/images/waist.png\n"," create mode 100644 data/rwhar/proband6/images/waist_thumb.png\n"," create mode 100644 data/rwhar/proband6/videos/video_climbing down_thumb.png\n"," create mode 100644 data/rwhar/proband6/videos/video_climbing up_thumb.png\n"," create mode 100644 data/rwhar/proband6/videos/video_jumping_thumb.png\n"," create mode 100644 data/rwhar/proband6/videos/video_lying_thumb.png\n"," create mode 100644 data/rwhar/proband6/videos/video_running_thumb.png\n"," create mode 100644 data/rwhar/proband6/videos/video_sitting_thumb.png\n"," create mode 100644 data/rwhar/proband6/videos/video_standing_thumb.png\n"," create mode 100644 data/rwhar/proband6/videos/video_walking_thumb.png\n"," create mode 100644 data/rwhar/proband7/data/acc_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband7/data/acc_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband7/data/acc_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband7/data/acc_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband7/data/acc_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband7/data/acc_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband7/data/acc_lying_csv.zip\n"," create mode 100644 data/rwhar/proband7/data/acc_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband7/data/acc_running_csv.zip\n"," create mode 100644 data/rwhar/proband7/data/acc_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband7/data/acc_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband7/data/acc_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband7/data/acc_standing_csv.zip\n"," create mode 100644 data/rwhar/proband7/data/acc_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband7/data/acc_walking_csv.zip\n"," create mode 100644 data/rwhar/proband7/data/acc_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband7/data/gps_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband7/data/gps_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband7/data/gps_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband7/data/gps_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband7/data/gps_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband7/data/gps_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband7/data/gps_lying_csv.zip\n"," create mode 100644 data/rwhar/proband7/data/gps_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband7/data/gps_running_csv.zip\n"," create mode 100644 data/rwhar/proband7/data/gps_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband7/data/gps_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband7/data/gps_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband7/data/gps_standing_csv.zip\n"," create mode 100644 data/rwhar/proband7/data/gps_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband7/data/gps_walking_csv.zip\n"," create mode 100644 data/rwhar/proband7/data/gps_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband7/data/gyr_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband7/data/gyr_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband7/data/gyr_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband7/data/gyr_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband7/data/gyr_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband7/data/gyr_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband7/data/gyr_lying_csv.zip\n"," create mode 100644 data/rwhar/proband7/data/gyr_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband7/data/gyr_running_csv.zip\n"," create mode 100644 data/rwhar/proband7/data/gyr_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband7/data/gyr_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband7/data/gyr_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband7/data/gyr_standing_csv.zip\n"," create mode 100644 data/rwhar/proband7/data/gyr_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband7/data/gyr_walking_csv.zip\n"," create mode 100644 data/rwhar/proband7/data/gyr_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband7/data/lig_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband7/data/lig_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband7/data/lig_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband7/data/lig_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband7/data/lig_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband7/data/lig_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband7/data/lig_lying_csv.zip\n"," create mode 100644 data/rwhar/proband7/data/lig_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband7/data/lig_running_csv.zip\n"," create mode 100644 data/rwhar/proband7/data/lig_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband7/data/lig_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband7/data/lig_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband7/data/lig_standing_csv.zip\n"," create mode 100644 data/rwhar/proband7/data/lig_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband7/data/lig_walking_csv.zip\n"," create mode 100644 data/rwhar/proband7/data/lig_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband7/data/mag_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband7/data/mag_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband7/data/mag_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband7/data/mag_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband7/data/mag_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband7/data/mag_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband7/data/mag_lying_csv.zip\n"," create mode 100644 data/rwhar/proband7/data/mag_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband7/data/mag_running_csv.zip\n"," create mode 100644 data/rwhar/proband7/data/mag_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband7/data/mag_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband7/data/mag_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband7/data/mag_standing_csv.zip\n"," create mode 100644 data/rwhar/proband7/data/mag_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband7/data/mag_walking_csv.zip\n"," create mode 100644 data/rwhar/proband7/data/mag_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband7/data/mic_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband7/data/mic_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband7/data/mic_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband7/data/mic_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband7/data/mic_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband7/data/mic_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband7/data/mic_lying_csv.zip\n"," create mode 100644 data/rwhar/proband7/data/mic_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband7/data/mic_running_csv.zip\n"," create mode 100644 data/rwhar/proband7/data/mic_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband7/data/mic_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband7/data/mic_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband7/data/mic_standing_csv.zip\n"," create mode 100644 data/rwhar/proband7/data/mic_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband7/data/mic_walking_csv.zip\n"," create mode 100644 data/rwhar/proband7/data/mic_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband7/images/chest.png\n"," create mode 100644 data/rwhar/proband7/images/chest_thumb.png\n"," create mode 100644 data/rwhar/proband7/images/forearm.png\n"," create mode 100644 data/rwhar/proband7/images/forearm_thumb.png\n"," create mode 100644 data/rwhar/proband7/images/head.png\n"," create mode 100644 data/rwhar/proband7/images/head_thumb.png\n"," create mode 100644 data/rwhar/proband7/images/overview.png\n"," create mode 100644 data/rwhar/proband7/images/overview_thumb.png\n"," create mode 100644 data/rwhar/proband7/images/preview.png\n"," create mode 100644 data/rwhar/proband7/images/shin.png\n"," create mode 100644 data/rwhar/proband7/images/shin_thumb.png\n"," create mode 100644 data/rwhar/proband7/images/thigh.png\n"," create mode 100644 data/rwhar/proband7/images/thigh_thumb.png\n"," create mode 100644 data/rwhar/proband7/images/upperarm.png\n"," create mode 100644 data/rwhar/proband7/images/upperarm_thumb.png\n"," create mode 100644 data/rwhar/proband7/images/waist.png\n"," create mode 100644 data/rwhar/proband7/images/waist_thumb.png\n"," create mode 100644 data/rwhar/proband7/videos/video_climbing down_thumb.png\n"," create mode 100644 data/rwhar/proband7/videos/video_climbing up_thumb.png\n"," create mode 100644 data/rwhar/proband7/videos/video_jumping_thumb.png\n"," create mode 100644 data/rwhar/proband7/videos/video_lying_thumb.png\n"," create mode 100644 data/rwhar/proband7/videos/video_running_thumb.png\n"," create mode 100644 data/rwhar/proband7/videos/video_sitting_thumb.png\n"," create mode 100644 data/rwhar/proband7/videos/video_standing_thumb.png\n"," create mode 100644 data/rwhar/proband7/videos/video_walking_thumb.png\n"," create mode 100644 data/rwhar/proband8/data/acc_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband8/data/acc_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband8/data/acc_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband8/data/acc_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband8/data/acc_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband8/data/acc_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband8/data/acc_lying_csv.zip\n"," create mode 100644 data/rwhar/proband8/data/acc_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband8/data/acc_running_csv.zip\n"," create mode 100644 data/rwhar/proband8/data/acc_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband8/data/acc_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband8/data/acc_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband8/data/acc_standing_csv.zip\n"," create mode 100644 data/rwhar/proband8/data/acc_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband8/data/acc_walking_csv.zip\n"," create mode 100644 data/rwhar/proband8/data/acc_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband8/data/gps_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband8/data/gps_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband8/data/gps_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband8/data/gps_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband8/data/gps_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband8/data/gps_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband8/data/gps_lying_csv.zip\n"," create mode 100644 data/rwhar/proband8/data/gps_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband8/data/gps_running_csv.zip\n"," create mode 100644 data/rwhar/proband8/data/gps_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband8/data/gps_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband8/data/gps_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband8/data/gps_standing_csv.zip\n"," create mode 100644 data/rwhar/proband8/data/gps_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband8/data/gps_walking_csv.zip\n"," create mode 100644 data/rwhar/proband8/data/gps_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband8/data/gyr_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband8/data/gyr_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband8/data/gyr_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband8/data/gyr_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband8/data/gyr_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband8/data/gyr_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband8/data/gyr_lying_csv.zip\n"," create mode 100644 data/rwhar/proband8/data/gyr_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband8/data/gyr_running_csv.zip\n"," create mode 100644 data/rwhar/proband8/data/gyr_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband8/data/gyr_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband8/data/gyr_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband8/data/gyr_standing_csv.zip\n"," create mode 100644 data/rwhar/proband8/data/gyr_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband8/data/gyr_walking_csv.zip\n"," create mode 100644 data/rwhar/proband8/data/gyr_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband8/data/lig_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband8/data/lig_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband8/data/lig_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband8/data/lig_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband8/data/lig_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband8/data/lig_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband8/data/lig_lying_csv.zip\n"," create mode 100644 data/rwhar/proband8/data/lig_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband8/data/lig_running_csv.zip\n"," create mode 100644 data/rwhar/proband8/data/lig_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband8/data/lig_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband8/data/lig_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband8/data/lig_standing_csv.zip\n"," create mode 100644 data/rwhar/proband8/data/lig_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband8/data/lig_walking_csv.zip\n"," create mode 100644 data/rwhar/proband8/data/lig_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband8/data/mag_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband8/data/mag_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband8/data/mag_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband8/data/mag_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband8/data/mag_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband8/data/mag_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband8/data/mag_lying_csv.zip\n"," create mode 100644 data/rwhar/proband8/data/mag_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband8/data/mag_running_csv.zip\n"," create mode 100644 data/rwhar/proband8/data/mag_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband8/data/mag_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband8/data/mag_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband8/data/mag_standing_csv.zip\n"," create mode 100644 data/rwhar/proband8/data/mag_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband8/data/mag_walking_csv.zip\n"," create mode 100644 data/rwhar/proband8/data/mag_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband8/data/mic_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband8/data/mic_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband8/data/mic_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband8/data/mic_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband8/data/mic_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband8/data/mic_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband8/data/mic_lying_csv.zip\n"," create mode 100644 data/rwhar/proband8/data/mic_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband8/data/mic_running_csv.zip\n"," create mode 100644 data/rwhar/proband8/data/mic_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband8/data/mic_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband8/data/mic_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband8/data/mic_standing_csv.zip\n"," create mode 100644 data/rwhar/proband8/data/mic_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband8/data/mic_walking_csv.zip\n"," create mode 100644 data/rwhar/proband8/data/mic_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband8/images/chest.png\n"," create mode 100644 data/rwhar/proband8/images/chest_thumb.png\n"," create mode 100644 data/rwhar/proband8/images/forearm.png\n"," create mode 100644 data/rwhar/proband8/images/forearm_thumb.png\n"," create mode 100644 data/rwhar/proband8/images/head.png\n"," create mode 100644 data/rwhar/proband8/images/head_thumb.png\n"," create mode 100644 data/rwhar/proband8/images/overview.png\n"," create mode 100644 data/rwhar/proband8/images/overview_thumb.png\n"," create mode 100644 data/rwhar/proband8/images/preview.png\n"," create mode 100644 data/rwhar/proband8/images/shin.png\n"," create mode 100644 data/rwhar/proband8/images/shin_thumb.png\n"," create mode 100644 data/rwhar/proband8/images/thigh.png\n"," create mode 100644 data/rwhar/proband8/images/thigh_thumb.png\n"," create mode 100644 data/rwhar/proband8/images/upperarm.png\n"," create mode 100644 data/rwhar/proband8/images/upperarm_thumb.png\n"," create mode 100644 data/rwhar/proband8/images/waist.png\n"," create mode 100644 data/rwhar/proband8/images/waist_thumb.png\n"," create mode 100644 data/rwhar/proband8/videos/video_climbing down_thumb.png\n"," create mode 100644 data/rwhar/proband8/videos/video_climbing up_thumb.png\n"," create mode 100644 data/rwhar/proband8/videos/video_jumping_thumb.png\n"," create mode 100644 data/rwhar/proband8/videos/video_lying_thumb.png\n"," create mode 100644 data/rwhar/proband8/videos/video_running_thumb.png\n"," create mode 100644 data/rwhar/proband8/videos/video_sitting_thumb.png\n"," create mode 100644 data/rwhar/proband8/videos/video_standing_thumb.png\n"," create mode 100644 data/rwhar/proband8/videos/video_walking_thumb.png\n"," create mode 100644 data/rwhar/proband9/data/acc_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband9/data/acc_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband9/data/acc_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband9/data/acc_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband9/data/acc_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband9/data/acc_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband9/data/acc_lying_csv.zip\n"," create mode 100644 data/rwhar/proband9/data/acc_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband9/data/acc_running_csv.zip\n"," create mode 100644 data/rwhar/proband9/data/acc_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband9/data/acc_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband9/data/acc_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband9/data/acc_standing_csv.zip\n"," create mode 100644 data/rwhar/proband9/data/acc_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband9/data/acc_walking_csv.zip\n"," create mode 100644 data/rwhar/proband9/data/acc_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband9/data/gps_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband9/data/gps_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband9/data/gps_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband9/data/gps_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband9/data/gps_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband9/data/gps_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband9/data/gps_lying_csv.zip\n"," create mode 100644 data/rwhar/proband9/data/gps_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband9/data/gps_running_csv.zip\n"," create mode 100644 data/rwhar/proband9/data/gps_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband9/data/gps_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband9/data/gps_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband9/data/gps_standing_csv.zip\n"," create mode 100644 data/rwhar/proband9/data/gps_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband9/data/gps_walking_csv.zip\n"," create mode 100644 data/rwhar/proband9/data/gps_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband9/data/gyr_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband9/data/gyr_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband9/data/gyr_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband9/data/gyr_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband9/data/gyr_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband9/data/gyr_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband9/data/gyr_lying_csv.zip\n"," create mode 100644 data/rwhar/proband9/data/gyr_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband9/data/gyr_running_csv.zip\n"," create mode 100644 data/rwhar/proband9/data/gyr_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband9/data/gyr_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband9/data/gyr_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband9/data/gyr_standing_csv.zip\n"," create mode 100644 data/rwhar/proband9/data/gyr_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband9/data/gyr_walking_csv.zip\n"," create mode 100644 data/rwhar/proband9/data/gyr_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband9/data/lig_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband9/data/lig_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband9/data/lig_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband9/data/lig_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband9/data/lig_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband9/data/lig_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband9/data/lig_lying_csv.zip\n"," create mode 100644 data/rwhar/proband9/data/lig_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband9/data/lig_running_csv.zip\n"," create mode 100644 data/rwhar/proband9/data/lig_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband9/data/lig_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband9/data/lig_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband9/data/lig_standing_csv.zip\n"," create mode 100644 data/rwhar/proband9/data/lig_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband9/data/lig_walking_csv.zip\n"," create mode 100644 data/rwhar/proband9/data/lig_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband9/data/mag_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband9/data/mag_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband9/data/mag_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband9/data/mag_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband9/data/mag_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband9/data/mag_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband9/data/mag_lying_csv.zip\n"," create mode 100644 data/rwhar/proband9/data/mag_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband9/data/mag_running_csv.zip\n"," create mode 100644 data/rwhar/proband9/data/mag_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband9/data/mag_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband9/data/mag_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband9/data/mag_standing_csv.zip\n"," create mode 100644 data/rwhar/proband9/data/mag_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband9/data/mag_walking_csv.zip\n"," create mode 100644 data/rwhar/proband9/data/mag_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband9/data/mic_climbingdown_csv.zip\n"," create mode 100644 data/rwhar/proband9/data/mic_climbingdown_sqlite.zip\n"," create mode 100644 data/rwhar/proband9/data/mic_climbingup_csv.zip\n"," create mode 100644 data/rwhar/proband9/data/mic_climbingup_sqlite.zip\n"," create mode 100644 data/rwhar/proband9/data/mic_jumping_csv.zip\n"," create mode 100644 data/rwhar/proband9/data/mic_jumping_sqlite.zip\n"," create mode 100644 data/rwhar/proband9/data/mic_lying_csv.zip\n"," create mode 100644 data/rwhar/proband9/data/mic_lying_sqlite.zip\n"," create mode 100644 data/rwhar/proband9/data/mic_running_csv.zip\n"," create mode 100644 data/rwhar/proband9/data/mic_running_sqlite.zip\n"," create mode 100644 data/rwhar/proband9/data/mic_sitting_csv.zip\n"," create mode 100644 data/rwhar/proband9/data/mic_sitting_sqlite.zip\n"," create mode 100644 data/rwhar/proband9/data/mic_standing_csv.zip\n"," create mode 100644 data/rwhar/proband9/data/mic_standing_sqlite.zip\n"," create mode 100644 data/rwhar/proband9/data/mic_walking_csv.zip\n"," create mode 100644 data/rwhar/proband9/data/mic_walking_sqlite.zip\n"," create mode 100644 data/rwhar/proband9/images/chest.png\n"," create mode 100644 data/rwhar/proband9/images/chest_thumb.png\n"," create mode 100644 data/rwhar/proband9/images/forearm.png\n"," create mode 100644 data/rwhar/proband9/images/forearm_thumb.png\n"," create mode 100644 data/rwhar/proband9/images/head.png\n"," create mode 100644 data/rwhar/proband9/images/head_thumb.png\n"," create mode 100644 data/rwhar/proband9/images/overview.png\n"," create mode 100644 data/rwhar/proband9/images/overview_thumb.png\n"," create mode 100644 data/rwhar/proband9/images/preview.png\n"," create mode 100644 data/rwhar/proband9/images/shin.png\n"," create mode 100644 data/rwhar/proband9/images/shin_thumb.png\n"," create mode 100644 data/rwhar/proband9/images/thigh.png\n"," create mode 100644 data/rwhar/proband9/images/thigh_thumb.png\n"," create mode 100644 data/rwhar/proband9/images/upperarm.png\n"," create mode 100644 data/rwhar/proband9/images/upperarm_thumb.png\n"," create mode 100644 data/rwhar/proband9/images/waist.png\n"," create mode 100644 data/rwhar/proband9/images/waist_thumb.png\n"," create mode 100644 data/rwhar/proband9/videos/video_climbing down_thumb.png\n"," create mode 100644 data/rwhar/proband9/videos/video_climbing up_thumb.png\n"," create mode 100644 data/rwhar/proband9/videos/video_jumping_thumb.png\n"," create mode 100644 data/rwhar/proband9/videos/video_lying_thumb.png\n"," create mode 100644 data/rwhar/proband9/videos/video_running_thumb.png\n"," create mode 100644 data/rwhar/proband9/videos/video_sitting_thumb.png\n"," create mode 100644 data/rwhar/proband9/videos/video_standing_thumb.png\n"," create mode 100644 data/rwhar/proband9/videos/video_walking_thumb.png\n"," create mode 100644 data/rwhar/realworld2016_dataset.zip\n"," create mode 100644 logs/env.txt\n"," create mode 100644 logs/init_meta.json\n"," create mode 100755 sample_data/README.md\n"," create mode 100755 sample_data/anscombe.json\n"," create mode 100644 sample_data/california_housing_test.csv\n"," create mode 100644 sample_data/california_housing_train.csv\n"," create mode 100644 sample_data/mnist_test.csv\n"," create mode 100644 sample_data/mnist_train_small.csv\n","✓ Git commit hash: a5c34cfe\n","✓ Raw data moved to data/raw/\n","✓ Computed checksums for 1814 files → logs/checksums.txt\n","✓ Data source recorded to logs/data_source.txt\n","[master 37271f2] data: add RealWorld2016 checksums and source\n"," 2 files changed, 1823 insertions(+)\n"," create mode 100644 logs/checksums.txt\n"," create mode 100644 logs/data_source.txt\n","\n","============================================================\n","Project initialization and data acquisition completed\n","============================================================\n"]}]},{"cell_type":"code","source":["# ================ Step 2: Sensor/Location Selection (Revised) ================\n","import pandas as pd\n","from pathlib import Path\n","import json\n","import zipfile\n","\n","print(\"Step 2: Sensor/Location Selection\")\n","print(\"=\" * 60)\n","\n","raw_dir = Path('/content/data/raw')\n","\n","# Decompress all zip files first\n","print(\"Extracting sensor data...\")\n","zip_files = list(raw_dir.rglob('*.zip'))\n","print(f\"Found {len(zip_files)} zip files\")\n","\n","for zip_path in zip_files:\n","    if 'csv.zip' in zip_path.name:\n","        extract_dir = zip_path.parent / zip_path.stem\n","        if not extract_dir.exists():\n","            with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n","                zip_ref.extractall(extract_dir)\n","\n","print(\"✓ Extraction complete\")\n","\n","# Search for CSV files under acc and gyr directories\n","print(\"\\nSearching for sensor directories...\")\n","acc_dirs = list(raw_dir.rglob('acc_*_csv'))\n","gyr_dirs = list(raw_dir.rglob('gyr_*_csv'))\n","\n","print(f\"✓ Found {len(acc_dirs)} ACC directories\")\n","print(f\"✓ Found {len(gyr_dirs)} GYR directories\")\n","\n","if acc_dirs:\n","    print(f\"\\nExample ACC directory: {acc_dirs[0].relative_to(raw_dir)}\")\n","    sample_files = list(acc_dirs[0].glob('*.csv'))\n","    print(f\"Number of files under {acc_dirs[0].name}: {len(sample_files)}\")\n","    if sample_files:\n","        print(f\"Example file: {sample_files[0].name}\")\n","\n","# Find all files containing \"waist\"\n","waist_files = {'acc': [], 'gyr': []}\n","\n","for acc_dir in acc_dirs:\n","    for f in acc_dir.glob('*waist*.csv'):\n","        waist_files['acc'].append(f)\n","\n","for gyr_dir in gyr_dirs:\n","    for f in gyr_dir.glob('*waist*.csv'):\n","        waist_files['gyr'].append(f)\n","\n","print(f\"\\n✓ Found Waist-ACC files: {len(waist_files['acc'])}\")\n","print(f\"✓ Found Waist-GYR files: {len(waist_files['gyr'])}\")\n","\n","# Display example files\n","if waist_files['acc']:\n","    print(f\"\\nExample ACC file: {waist_files['acc'][0].relative_to(raw_dir)}\")\n","    sample_acc = pd.read_csv(waist_files['acc'][0])\n","    print(f\"Columns: {list(sample_acc.columns)}\")\n","    print(f\"Shape: {sample_acc.shape}\")\n","    print(sample_acc.head(3))\n","\n","if waist_files['gyr']:\n","    print(f\"\\nExample GYR file: {waist_files['gyr'][0].relative_to(raw_dir)}\")\n","    sample_gyr = pd.read_csv(waist_files['gyr'][0])\n","    print(f\"Columns: {list(sample_gyr.columns)}\")\n","    print(f\"Shape: {sample_gyr.shape}\")\n","    print(sample_gyr.head(3))\n","\n","# Collect metadata\n","waist_metadata = []\n","for sensor_type in ['acc', 'gyr']:\n","    for filepath in waist_files[sensor_type]:\n","        parts = filepath.parts\n","        subject = [p for p in parts if p.startswith('proband')][0]\n","        activity = filepath.parent.name.split('_')[1]\n","\n","        df = pd.read_csv(filepath)\n","        waist_metadata.append({\n","            'subject': subject,\n","            'activity': activity,\n","            'sensor': sensor_type,\n","            'original_path': str(filepath.relative_to(raw_dir)),\n","            'shape': list(df.shape),\n","            'columns': list(df.columns)\n","        })\n","\n","# Persist selection report\n","with open('/content/logs/sensor_selection.json', 'w') as f:\n","    json.dump({\n","        'selection': {\n","            'position': 'waist',\n","            'sensors': ['acc', 'gyr'],\n","            'channels': 6,\n","            'rationale': 'Single position to avoid domain shift; ACC+GYRO is the standard configuration for HAR'\n","        },\n","        'files_found': {\n","            'acc': len(waist_files['acc']),\n","            'gyr': len(waist_files['gyr'])\n","        },\n","        'metadata': waist_metadata[:10]\n","    }, f, indent=2)\n","\n","print(f\"\\n✓ Selection report saved: logs/sensor_selection.json\")\n","\n","!git add logs/sensor_selection.json\n","!git commit -m \"data: select waist position with acc+gyr sensors\"\n","\n","\n","# ================ Step 3: Column Alignment and Naming ================\n","print(\"\\n\\nStep 3: Column Alignment and Naming\")\n","print(\"=\" * 60)\n","\n","# Analyze column names\n","acc_cols = set()\n","gyr_cols = set()\n","\n","for filepath in waist_files['acc'][:3]:\n","    df = pd.read_csv(filepath)\n","    acc_cols.update(df.columns)\n","\n","for filepath in waist_files['gyr'][:3]:\n","    df = pd.read_csv(filepath)\n","    gyr_cols.update(df.columns)\n","\n","print(f\"ACC column names: {sorted(acc_cols)}\")\n","print(f\"GYR column names: {sorted(gyr_cols)}\")\n","\n","# Define standard mapping\n","standard_mapping = {\n","    'acc': {\n","        'attr_x': 'acc_x',\n","        'attr_y': 'acc_y',\n","        'attr_z': 'acc_z',\n","        'attr_time': 'timestamp'\n","    },\n","    'gyr': {\n","        'attr_x': 'gyro_x',\n","        'attr_y': 'gyro_y',\n","        'attr_z': 'gyro_z',\n","        'attr_time': 'timestamp'\n","    }\n","}\n","\n","cols_config = {\n","    'standard_columns': ['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_y', 'gyro_z'],\n","    'units': {\n","        'acc_x': 'm/s²', 'acc_y': 'm/s²', 'acc_z': 'm/s²',\n","        'gyro_x': 'rad/s', 'gyro_y': 'rad/s', 'gyro_z': 'rad/s'\n","    },\n","    'mapping': standard_mapping,\n","    'timestamp_col': 'timestamp'\n","}\n","\n","with open('/content/configs/cols.json', 'w') as f:\n","    json.dump(cols_config, f, indent=2)\n","\n","print(\"\\n✓ Column mapping configuration saved: configs/cols.json\")\n","\n","# Generate schema report\n","report = [\n","    \"# RealWorld2016 Data Schema Report\\n\\n\",\n","    f\"Generated at: {datetime.now().isoformat()}\\n\\n\",\n","    \"## Standard column definitions\\n\\n\",\n","    \"| Column | Unit | Description |\\n|------|------|------|\\n\"\n","]\n","\n","for col in cols_config['standard_columns']:\n","    unit = cols_config['units'][col]\n","    sensor = 'Accelerometer' if 'acc' in col else 'Gyroscope'\n","    axis = col.split('_')[1].upper()\n","    report.append(f\"| {col} | {unit} | {sensor} {axis}-axis |\\n\")\n","\n","report.append(\"\\n## Original column mapping\\n\\n### Accelerometer\\n\")\n","for orig, std in standard_mapping['acc'].items():\n","    report.append(f\"- `{orig}` → `{std}`\\n\")\n","\n","report.append(\"\\n### Gyroscope\\n\")\n","for orig, std in standard_mapping['gyr'].items():\n","    report.append(f\"- `{orig}` → `{std}`\\n\")\n","\n","# Missing-value statistics\n","report.append(\"\\n## Data quality checks\\n\\n\")\n","for sensor in ['acc', 'gyr']:\n","    report.append(f\"### {sensor.upper()} Missing values (sample of 5 files)\\n\\n\")\n","    has_missing = False\n","    for fp in waist_files[sensor][:5]:\n","        df = pd.read_csv(fp)\n","        missing = df.isnull().sum()\n","        if missing.sum() > 0:\n","            report.append(f\"- {fp.name}: {missing[missing > 0].to_dict()}\\n\")\n","            has_missing = True\n","    if not has_missing:\n","        report.append(\"- No missing values ✓\\n\")\n","    report.append(\"\\n\")\n","\n","with open('/content/logs/schema_report.md', 'w') as f:\n","    f.writelines(report)\n","\n","print(\"✓ Schema report saved: logs/schema_report.md\")\n","print(\"\\n\" + \"\".join(report))\n","\n","!git add configs/cols.json logs/schema_report.md\n","!git commit -m \"data: standardize column names and units\"\n","\n","print(f\"\\n{'='*60}\")\n","print(\"Steps 2–3 completed\")\n","print(f\"{'='*60}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B5Tf06GpzMyx","executionInfo":{"status":"ok","timestamp":1762688662566,"user_tz":0,"elapsed":27595,"user":{"displayName":"yu Wu","userId":"12692660435918028293"}},"outputId":"79a6bece-ac77-46e3-b1a9-b374c25d1f6b"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Step 2: Sensor/Location Selection\n","============================================================\n","Extracting sensor data...\n","Found 1441 zip files\n","✓ Extraction complete\n","\n","Searching for sensor directories...\n","✓ Found 120 ACC directories\n","✓ Found 120 GYR directories\n","\n","Example ACC directory: proband4/data/acc_climbingdown_csv\n","Number of files under acc_climbingdown_csv: 0\n","\n","✓ Found Waist-ACC files: 114\n","✓ Found Waist-GYR files: 114\n","\n","Example ACC file: proband4/data/acc_jumping_csv/acc_jumping_waist.csv\n","Columns: ['id', 'attr_time', 'attr_x', 'attr_y', 'attr_z']\n","Shape: (4296, 5)\n","   id      attr_time    attr_x    attr_y    attr_z\n","0   1  1436295094003  9.890448 -0.516549  0.517148\n","1   2  1436295094022  9.922171 -0.441132  0.587178\n","2   3  1436295094041  9.961675 -0.413598  0.519542\n","\n","Example GYR file: proband4/data/gyr_jumping_csv/Gyroscope_jumping_waist.csv\n","Columns: ['id', 'attr_time', 'attr_x', 'attr_y', 'attr_z']\n","Shape: (4292, 5)\n","   id      attr_time    attr_x    attr_y    attr_z\n","0   1  1436295094022 -0.002988 -0.022363 -0.004502\n","1   2  1436295094041  0.003121 -0.036413 -0.002364\n","2   3  1436295094062  0.016865 -0.037329 -0.006945\n","\n","✓ Selection report saved: logs/sensor_selection.json\n","[master 4ef6c9c] data: select waist position with acc+gyr sensors\n"," 1 file changed, 187 insertions(+)\n"," create mode 100644 logs/sensor_selection.json\n","\n","\n","Step 3: Column Alignment and Naming\n","============================================================\n","ACC column names: ['attr_time', 'attr_x', 'attr_y', 'attr_z', 'id']\n","GYR column names: ['attr_time', 'attr_x', 'attr_y', 'attr_z', 'id']\n","\n","✓ Column mapping configuration saved: configs/cols.json\n","✓ Schema report saved: logs/schema_report.md\n","\n","# RealWorld2016 Data Schema Report\n","\n","Generated at: 2025-11-09T11:44:22.798790\n","\n","## Standard column definitions\n","\n","| Column | Unit | Description |\n","|------|------|------|\n","| acc_x | m/s² | Accelerometer X-axis |\n","| acc_y | m/s² | Accelerometer Y-axis |\n","| acc_z | m/s² | Accelerometer Z-axis |\n","| gyro_x | rad/s | Gyroscope X-axis |\n","| gyro_y | rad/s | Gyroscope Y-axis |\n","| gyro_z | rad/s | Gyroscope Z-axis |\n","\n","## Original column mapping\n","\n","### Accelerometer\n","- `attr_x` → `acc_x`\n","- `attr_y` → `acc_y`\n","- `attr_z` → `acc_z`\n","- `attr_time` → `timestamp`\n","\n","### Gyroscope\n","- `attr_x` → `gyro_x`\n","- `attr_y` → `gyro_y`\n","- `attr_z` → `gyro_z`\n","- `attr_time` → `timestamp`\n","\n","## Data quality checks\n","\n","### ACC Missing values (sample of 5 files)\n","\n","- No missing values ✓\n","\n","### GYR Missing values (sample of 5 files)\n","\n","- No missing values ✓\n","\n","\n","[master 201d6ee] data: standardize column names and units\n"," 2 files changed, 72 insertions(+)\n"," create mode 100644 configs/cols.json\n"," create mode 100644 logs/schema_report.md\n","\n","============================================================\n","Steps 2–3 completed\n","============================================================\n"]}]},{"cell_type":"code","source":["# ================ Step 4: Timeline Normalization (Final) ================\n","import numpy as np\n","import pandas as pd\n","from scipy import interpolate\n","import matplotlib.pyplot as plt\n","from pathlib import Path\n","import json\n","import zipfile\n","\n","print(\"\\n\\nStep 4: Timeline Normalization\")\n","print(\"=\" * 60)\n","\n","raw_dir = Path('/content/data/raw')\n","\n","# Decompression\n","print(\"Extracting waist data...\")\n","for proband_dir in raw_dir.glob('proband*'):\n","    data_dir = proband_dir / 'data'\n","    if data_dir.exists():\n","        for zip_file in data_dir.glob('*_csv.zip'):\n","            if zip_file.stem.startswith(('acc_', 'gyr_')):\n","                extract_dir = zip_file.parent / zip_file.stem\n","                if not extract_dir.exists():\n","                    with zipfile.ZipFile(zip_file, 'r') as zf:\n","                        if any('waist' in f.lower() for f in zf.namelist()):\n","                            zf.extractall(extract_dir)\n","\n","# Scan\n","waist_files = {'acc': [], 'gyr': []}\n","for csv_file in raw_dir.rglob('*.csv'):\n","    if 'waist' in csv_file.name.lower():\n","        if csv_file.parent.name.startswith('acc_'):\n","            waist_files['acc'].append(csv_file)\n","        elif csv_file.parent.name.startswith('gyr_'):\n","            waist_files['gyr'].append(csv_file)\n","\n","print(f\"✓ ACC: {len(waist_files['acc'])}, GYR: {len(waist_files['gyr'])}\")\n","\n","# Improved pairing: directory mapping + same-name preference\n","def find_gyr_for_acc(acc_path):\n","    gyr_dir = acc_path.parent.parent / acc_path.parent.name.replace('acc_', 'gyr_')\n","    if not gyr_dir.exists():\n","        return None\n","    cand = gyr_dir / acc_path.name.replace('acc_', 'gyr_')\n","    if cand.exists():\n","        return cand\n","    cands = sorted(gyr_dir.glob('*waist*.csv'))\n","    return cands[0] if cands else None\n","\n","file_pairs = []\n","for acc_path in waist_files['acc']:\n","    gyr_path = find_gyr_for_acc(acc_path)\n","    if not gyr_path:\n","        continue\n","    proband = next(p for p in acc_path.parts if p.startswith('proband'))\n","    activity = acc_path.parent.name.split('_')[1]\n","    file_pairs.append((acc_path, gyr_path, proband, activity))\n","\n","print(f\"✓ File pairs: {len(file_pairs)}\")\n","\n","with open('/content/configs/cols.json', 'r') as f:\n","    cols_config = json.load(f)\n","\n","TARGET_FS = 50\n","MAX_GAP_MS = 200\n","MIN_DURATION_S = 1.0\n","interim_dir = Path('/content/interim')\n","interim_dir.mkdir(exist_ok=True)\n","\n","def detect_time_unit(df, col='timestamp'):\n","    ts = df[col].sort_values().iloc[:200].values\n","    diffs = np.diff(ts)\n","    diffs = diffs[diffs > 0]\n","    if len(diffs) == 0:\n","        return None, None\n","    dt = np.median(diffs)\n","\n","    if 0.01 < dt < 5:\n","        return df[col] * 1e9, 's'\n","    elif 10 < dt < 100:\n","        return df[col] * 1e6, 'ms'\n","    elif 10000 < dt < 100000:\n","        return df[col] * 1e3, 'us'\n","    elif 1e7 < dt < 1e8:\n","        return df[col], 'ns'\n","    else:\n","        return None, None\n","\n","all_stats = []\n","skipped = []\n","\n","for idx, (acc_path, gyr_path, proband, activity) in enumerate(file_pairs):\n","    print(f\"\\n[{idx+1}/{len(file_pairs)}] {proband}/{activity}\")\n","\n","    acc_df = pd.read_csv(acc_path).rename(columns=cols_config['mapping']['acc'])\n","    gyr_df = pd.read_csv(gyr_path).rename(columns=cols_config['mapping']['gyr'])\n","\n","    acc_ts_ns, acc_unit = detect_time_unit(acc_df)\n","    gyr_ts_ns, gyr_unit = detect_time_unit(gyr_df)\n","\n","    if acc_ts_ns is None or gyr_ts_ns is None:\n","        print(f\"  ⚠️ Skipped: unable to determine timestamp unit\")\n","        skipped.append(f\"{proband}_{activity}\")\n","        continue\n","\n","    acc_df['timestamp_ns'] = acc_ts_ns\n","    gyr_df['timestamp_ns'] = gyr_ts_ns\n","    acc_df = acc_df[['timestamp_ns', 'acc_x', 'acc_y', 'acc_z']].sort_values('timestamp_ns').drop_duplicates('timestamp_ns')\n","    gyr_df = gyr_df[['timestamp_ns', 'gyro_x', 'gyro_y', 'gyro_z']].sort_values('timestamp_ns').drop_duplicates('timestamp_ns')\n","\n","    df = None\n","    merge_mode = 'absolute'\n","    merge_tol = None\n","    offset_ns = 0\n","\n","    # Adaptive tolerance\n","    for tol_ms in [10, 30, 50, 100]:\n","        tol_ns = int(tol_ms * 1e6)\n","        df_try = pd.merge_asof(acc_df, gyr_df, on='timestamp_ns', direction='nearest', tolerance=tol_ns).dropna()\n","        if len(df_try) >= TARGET_FS:\n","            df = df_try\n","            merge_tol = tol_ms\n","            break\n","\n","    # Fallback 1: relative time (relaxed thresholds)\n","    if df is None:\n","        for tol_ms in [10, 30, 50]:\n","            acc_tmp = acc_df.copy()\n","            gyr_tmp = gyr_df.copy()\n","            acc_tmp['t_rel'] = acc_tmp['timestamp_ns'] - acc_tmp['timestamp_ns'].iloc[0]\n","            gyr_tmp['t_rel'] = gyr_tmp['timestamp_ns'] - gyr_tmp['timestamp_ns'].iloc[0]\n","\n","            df_try = pd.merge_asof(acc_tmp.sort_values('t_rel'), gyr_tmp.sort_values('t_rel'),\n","                                   on='t_rel', direction='nearest', tolerance=int(tol_ms*1e6)).dropna()\n","\n","            if len(df_try) > 1:\n","                p99 = (df_try['t_rel'].diff() / 1e6).quantile(0.99)\n","                match_rate = len(df_try) / max(1, min(len(acc_df), len(gyr_df)))\n","\n","                if len(df_try) >= TARGET_FS and p99 <= 40 and match_rate >= 0.5:\n","                    df = df_try.rename(columns={'t_rel': 'timestamp_ns'})\n","                    merge_mode = 'relative'\n","                    merge_tol = tol_ms\n","                    break\n","\n","    # Fallback 2: offset search (broaden range and thresholds)\n","    if df is None:\n","        best_df, best_matches, best_offset = None, -1, 0\n","        for offset_ms in range(-3000, 3001, 50):\n","            gyr_shift = gyr_df.copy()\n","            gyr_shift['timestamp_ns'] = gyr_shift['timestamp_ns'] + int(offset_ms * 1e6)\n","            df_try = pd.merge_asof(acc_df, gyr_shift, on='timestamp_ns',\n","                                   direction='nearest', tolerance=int(30*1e6)).dropna()\n","            if len(df_try) > best_matches:\n","                best_df, best_matches, best_offset = df_try, len(df_try), offset_ms\n","\n","        if best_matches >= TARGET_FS and best_df is not None and len(best_df) > 1:\n","            p99 = (best_df['timestamp_ns'].diff() / 1e6).quantile(0.99)\n","            match_rate = best_matches / max(1, min(len(acc_df), len(gyr_df)))\n","\n","            if p99 <= 40 and match_rate >= 0.5:\n","                df = best_df\n","                merge_mode = 'offset_search'\n","                merge_tol = 30\n","                offset_ns = int(best_offset * 1e6)\n","\n","    # Fallback 3: intersection window resampling\n","    if df is None:\n","        t0 = max(acc_df['timestamp_ns'].iloc[0], gyr_df['timestamp_ns'].iloc[0])\n","        t1 = min(acc_df['timestamp_ns'].iloc[-1], gyr_df['timestamp_ns'].iloc[-1])\n","\n","        if t1 - t0 >= 1e9:\n","            STEP_NS = int(1e9 / TARGET_FS)\n","            t_grid = np.arange(t0, t1, STEP_NS, dtype=np.int64)\n","\n","            acc_interp = interpolate.interp1d(acc_df['timestamp_ns'].values,\n","                                              acc_df[['acc_x', 'acc_y', 'acc_z']].values,\n","                                              axis=0, kind='linear', bounds_error=True)\n","            gyr_interp = interpolate.interp1d(gyr_df['timestamp_ns'].values,\n","                                              gyr_df[['gyro_x', 'gyro_y', 'gyro_z']].values,\n","                                              axis=0, kind='linear', bounds_error=True)\n","\n","            acc_vals = acc_interp(t_grid)\n","            gyr_vals = gyr_interp(t_grid)\n","\n","            df = pd.DataFrame({\n","                'timestamp': t_grid,\n","                'segment_id': 0,\n","                'proband': proband,\n","                'activity': activity,\n","                'acc_x': acc_vals[:, 0], 'acc_y': acc_vals[:, 1], 'acc_z': acc_vals[:, 2],\n","                'gyro_x': gyr_vals[:, 0], 'gyro_y': gyr_vals[:, 1], 'gyro_z': gyr_vals[:, 2]\n","            })\n","\n","            out_name = f\"{proband}_{activity}_waist.csv\"\n","            df.to_csv(interim_dir / out_name, index=False)\n","\n","            all_stats.append({\n","                'file': out_name,\n","                'proband': proband,\n","                'activity': activity,\n","                'acc_unit': acc_unit,\n","                'gyr_unit': gyr_unit,\n","                'merge_mode': 'intersection',\n","                'segments': 1,\n","                'samples': len(df)\n","            })\n","\n","            print(f\"  {acc_unit}/{gyr_unit}, intersection, 1 segment, {len(df)} samples\")\n","            continue\n","\n","    if df is None or len(df) < TARGET_FS:\n","        print(f\"  ⚠️ Skipped: merge failed\")\n","        skipped.append(f\"{proband}_{activity}\")\n","        continue\n","\n","    df = df.reset_index(drop=True)\n","    df['dt_ms'] = df['timestamp_ns'].diff() / 1e6\n","\n","    # Segmentation\n","    gaps = df['dt_ms'].values\n","    large_gap_idx = np.where(gaps > MAX_GAP_MS)[0]\n","    split_points = [0] + large_gap_idx.tolist() + [len(df)]\n","\n","    segments = []\n","    for i in range(len(split_points) - 1):\n","        seg = df.iloc[split_points[i]:split_points[i + 1]].copy()\n","        if len(seg) > 1:\n","            duration_s = (seg['timestamp_ns'].iloc[-1] - seg['timestamp_ns'].iloc[0]) / 1e9\n","            if duration_s >= MIN_DURATION_S:\n","                segments.append(seg)\n","\n","    if len(segments) == 0:\n","        print(f\"  ⚠️ Skipped: no valid segments\")\n","        skipped.append(f\"{proband}_{activity}\")\n","        continue\n","\n","    # Resampling\n","    STEP_NS = int(1e9 / TARGET_FS)\n","    all_resampled = []\n","    for seg_id, seg in enumerate(segments):\n","        t_start = seg['timestamp_ns'].iloc[0]\n","        t_end = seg['timestamp_ns'].iloc[-1]\n","        t_grid = np.arange(t_start, t_end + 1, STEP_NS, dtype=np.int64)\n","\n","        df_seg = pd.DataFrame({\n","            'timestamp': t_grid,\n","            'segment_id': seg_id,\n","            'proband': proband,\n","            'activity': activity\n","        })\n","        for col in ['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_y', 'gyro_z']:\n","            f = interpolate.interp1d(seg['timestamp_ns'], seg[col], kind='linear', bounds_error=True)\n","            df_seg[col] = f(t_grid)\n","\n","        all_resampled.append(df_seg)\n","\n","    df_final = pd.concat(all_resampled, ignore_index=True)\n","\n","    out_name = f\"{proband}_{activity}_waist.csv\"\n","    df_final.to_csv(interim_dir / out_name, index=False)\n","\n","    stat = {\n","        'file': out_name,\n","        'proband': proband,\n","        'activity': activity,\n","        'acc_unit': acc_unit,\n","        'gyr_unit': gyr_unit,\n","        'merge_mode': merge_mode,\n","        'merge_tolerance_ms': merge_tol,\n","        'segments': len(segments),\n","        'samples': len(df_final)\n","    }\n","    if merge_mode == 'offset_search':\n","        stat['offset_ns'] = offset_ns\n","\n","    all_stats.append(stat)\n","\n","    mode_str = f\"{merge_mode}\" + (f\"(Δ={offset_ns/1e6:.0f}ms)\" if merge_mode=='offset_search' else '')\n","    print(f\"  {acc_unit}/{gyr_unit}, {mode_str}, {len(segments)} segments, {len(df_final)} samples\")\n","\n","print(f\"\\n✓ Completed {len(all_stats)} files\")\n","if skipped:\n","    print(f\"⚠️ Skipped {len(skipped)}: {skipped}\")\n","\n","# Plotting\n","if all_stats:\n","    first_file = all_stats[0]\n","    first_pair = [(p[0], p[1], p[2], p[3]) for p in file_pairs if p[2] == first_file['proband'] and p[3] == first_file['activity']][0]\n","\n","    acc_df = pd.read_csv(first_pair[0]).rename(columns=cols_config['mapping']['acc'])\n","    gyr_df = pd.read_csv(first_pair[1]).rename(columns=cols_config['mapping']['gyr'])\n","    acc_ts_ns, _ = detect_time_unit(acc_df)\n","    gyr_ts_ns, _ = detect_time_unit(gyr_df)\n","    acc_df['timestamp_ns'] = acc_ts_ns\n","    gyr_df['timestamp_ns'] = gyr_ts_ns\n","    acc_df = acc_df[['timestamp_ns', 'acc_x', 'acc_y', 'acc_z']].sort_values('timestamp_ns').drop_duplicates('timestamp_ns')\n","    gyr_df = gyr_df[['timestamp_ns', 'gyro_x', 'gyro_y', 'gyro_z']].sort_values('timestamp_ns').drop_duplicates('timestamp_ns')\n","\n","    df = pd.merge_asof(acc_df, gyr_df, on='timestamp_ns', direction='nearest', tolerance=int(100*1e6)).dropna()\n","    intervals = df['timestamp_ns'].diff() / 1e6\n","\n","    fig, ax = plt.subplots(figsize=(10, 4))\n","    ax.hist(intervals[intervals < 100], bins=100, edgecolor='black', linewidth=0.5)\n","    ax.axvline(20, color='red', linestyle='--', label='Ideal (50Hz=20ms)')\n","    ax.axvline(MAX_GAP_MS, color='orange', linestyle='--', label=f'Threshold ({MAX_GAP_MS}ms)')\n","    ax.set_xlabel('Sampling Interval (ms)')\n","    ax.set_ylabel('Count')\n","    ax.set_title(f'Sampling Interval Distribution - {first_pair[2]}/{first_pair[3]}')\n","    ax.legend()\n","    ax.grid(alpha=0.3)\n","    plt.tight_layout()\n","    plt.savefig('/content/figures/step4_interval_hist.png', dpi=150)\n","    plt.close()\n","\n","with open('/content/logs/step4_summary.json', 'w') as f:\n","    json.dump({'files': all_stats, 'skipped': skipped}, f, indent=2)\n","\n","!git add figures/ logs/step4_*.json interim/\n","!git commit -m \"preproc: final time normalization with all fallbacks\"\n","\n","print(f\"\\n{'='*60}\\nStep 4 completed\\n{'='*60}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2rdB7hREzZJK","executionInfo":{"status":"ok","timestamp":1762688722562,"user_tz":0,"elapsed":59915,"user":{"displayName":"yu Wu","userId":"12692660435918028293"}},"outputId":"97a5074c-f076-41cd-b1fa-b84275632229"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","Step 4: Timeline Normalization\n","============================================================\n","Extracting waist data...\n","✓ ACC: 114, GYR: 114\n","✓ File pairs: 114\n","\n","[1/114] proband4/jumping\n","  ms/ms, absolute, 3 segments, 4148 samples\n","\n","[2/114] proband4/sitting\n","  ms/ms, absolute, 14 segments, 31248 samples\n","\n","[3/114] proband4/standing\n","  ms/ms, absolute, 12 segments, 29741 samples\n","\n","[4/114] proband4/lying\n","  ms/ms, absolute, 16 segments, 33106 samples\n","\n","[5/114] proband4/running\n","  ms/ms, absolute, 40 segments, 50541 samples\n","\n","[6/114] proband4/walking\n","  ms/ms, absolute, 13 segments, 30482 samples\n","\n","[7/114] proband9/climbingdown\n","  ms/ms, absolute, 18 segments, 24302 samples\n","\n","[8/114] proband9/jumping\n","  ms/ms, absolute, 4 segments, 4976 samples\n","\n","[9/114] proband9/sitting\n","  ms/ms, absolute, 24 segments, 31473 samples\n","\n","[10/114] proband9/standing\n","  ms/ms, absolute, 18 segments, 31296 samples\n","\n","[11/114] proband9/lying\n","  ms/ms, absolute, 15 segments, 30587 samples\n","\n","[12/114] proband9/running\n","  ms/ms, absolute, 41 segments, 39416 samples\n","\n","[13/114] proband9/climbingup\n","  ms/ms, absolute, 21 segments, 26388 samples\n","\n","[14/114] proband9/walking\n","  ms/ms, absolute, 25 segments, 30358 samples\n","\n","[15/114] proband15/climbingdown\n","  ms/ms, absolute, 23 segments, 24728 samples\n","\n","[16/114] proband15/jumping\n","  ms/ms, absolute, 6 segments, 4568 samples\n","\n","[17/114] proband15/sitting\n","  ms/ms, absolute, 29 segments, 31196 samples\n","\n","[18/114] proband15/standing\n","  ms/ms, absolute, 21 segments, 30457 samples\n","\n","[19/114] proband15/lying\n","  ms/ms, absolute, 23 segments, 32001 samples\n","\n","[20/114] proband15/running\n","  ms/ms, absolute, 27 segments, 32719 samples\n","\n","[21/114] proband15/climbingup\n","  ms/ms, absolute, 22 segments, 28145 samples\n","\n","[22/114] proband15/walking\n","  ms/ms, absolute, 27 segments, 32152 samples\n","\n","[23/114] proband11/climbingdown\n","  ms/ms, absolute, 19 segments, 24032 samples\n","\n","[24/114] proband11/jumping\n","  ms/ms, absolute, 7 segments, 4796 samples\n","\n","[25/114] proband11/sitting\n","  ms/ms, absolute, 26 segments, 30245 samples\n","\n","[26/114] proband11/standing\n","  ms/ms, absolute, 20 segments, 30514 samples\n","\n","[27/114] proband11/lying\n","  ms/ms, absolute, 19 segments, 31836 samples\n","\n","[28/114] proband11/running\n","  ms/ms, absolute, 34 segments, 29843 samples\n","\n","[29/114] proband11/climbingup\n","  ms/ms, absolute, 25 segments, 30391 samples\n","\n","[30/114] proband11/walking\n","  ms/ms, absolute, 30 segments, 32123 samples\n","\n","[31/114] proband2/climbingdown\n","  ms/ms, absolute, 24 segments, 23939 samples\n","\n","[32/114] proband2/jumping\n","  ms/ms, absolute, 3 segments, 4512 samples\n","\n","[33/114] proband2/sitting\n","  ms/ms, absolute, 17 segments, 29887 samples\n","\n","[34/114] proband2/standing\n","  ms/ms, absolute, 49 segments, 28717 samples\n","\n","[35/114] proband2/lying\n","  ms/ms, absolute, 28 segments, 30002 samples\n","\n","[36/114] proband2/running\n","  ms/ms, absolute, 42 segments, 28701 samples\n","\n","[37/114] proband2/climbingup\n","  ms/ms, absolute, 37 segments, 23484 samples\n","\n","[38/114] proband2/walking\n","  ms/ms, absolute, 38 segments, 28946 samples\n","\n","[39/114] proband12/climbingdown\n","  ms/ms, absolute, 17 segments, 23499 samples\n","\n","[40/114] proband12/jumping\n","  ms/ms, absolute, 12 segments, 4279 samples\n","\n","[41/114] proband12/sitting\n","  ms/ms, absolute, 62 segments, 29317 samples\n","\n","[42/114] proband12/standing\n","  ms/ms, absolute, 28 segments, 29789 samples\n","\n","[43/114] proband12/lying\n","  ms/ms, absolute, 22 segments, 30306 samples\n","\n","[44/114] proband12/running\n","  ms/ms, absolute, 23 segments, 28742 samples\n","\n","[45/114] proband12/climbingup\n","  ms/ms, absolute, 13 segments, 27393 samples\n","\n","[46/114] proband12/walking\n","  ms/ms, absolute, 50 segments, 29476 samples\n","\n","[47/114] proband8/climbingdown\n","  ms/ms, absolute, 26 segments, 21304 samples\n","\n","[48/114] proband8/jumping\n","  ms/ms, absolute, 5 segments, 4694 samples\n","\n","[49/114] proband8/sitting\n","  ms/ms, absolute, 15 segments, 31855 samples\n","\n","[50/114] proband8/standing\n","  ms/ms, absolute, 13 segments, 31386 samples\n","\n","[51/114] proband8/lying\n","  ms/ms, absolute, 20 segments, 30683 samples\n","\n","[52/114] proband8/running\n","  ms/ms, absolute, 20 segments, 29937 samples\n","\n","[53/114] proband8/climbingup\n","  ms/ms, absolute, 47 segments, 55851 samples\n","\n","[54/114] proband8/walking\n","  ms/ms, absolute, 31 segments, 31652 samples\n","\n","[55/114] proband13/climbingdown\n","  ms/ms, absolute, 20 segments, 21127 samples\n","\n","[56/114] proband13/jumping\n","  ms/ms, absolute, 2 segments, 5370 samples\n","\n","[57/114] proband13/sitting\n","  ms/ms, absolute, 24 segments, 31261 samples\n","\n","[58/114] proband13/standing\n","  ms/ms, absolute, 35 segments, 32877 samples\n","\n","[59/114] proband13/lying\n","  ms/ms, absolute, 23 segments, 31336 samples\n","\n","[60/114] proband13/running\n","  ms/ms, absolute, 21 segments, 29961 samples\n","\n","[61/114] proband13/climbingup\n","  ms/ms, absolute, 23 segments, 29031 samples\n","\n","[62/114] proband13/walking\n","  ms/ms, absolute, 20 segments, 31882 samples\n","\n","[63/114] proband14/jumping\n","  ms/ms, absolute, 5 segments, 4642 samples\n","\n","[64/114] proband14/sitting\n","  ms/ms, absolute, 31 segments, 30562 samples\n","\n","[65/114] proband14/standing\n","  ms/ms, absolute, 34 segments, 30114 samples\n","\n","[66/114] proband14/lying\n","  ms/ms, absolute, 27 segments, 30563 samples\n","\n","[67/114] proband14/running\n","  ms/ms, absolute, 33 segments, 29786 samples\n","\n","[68/114] proband14/walking\n","  ms/ms, absolute, 50 segments, 32007 samples\n","\n","[69/114] proband7/jumping\n","  ms/ms, absolute, 6 segments, 4853 samples\n","\n","[70/114] proband7/sitting\n","  ms/ms, absolute, 23 segments, 31417 samples\n","\n","[71/114] proband7/standing\n","  ms/ms, absolute, 24 segments, 32005 samples\n","\n","[72/114] proband7/lying\n","  ms/ms, absolute, 29 segments, 31520 samples\n","\n","[73/114] proband7/running\n","  ms/ms, absolute, 27 segments, 35636 samples\n","\n","[74/114] proband7/walking\n","  ms/ms, absolute, 27 segments, 29987 samples\n","\n","[75/114] proband1/climbingdown\n","  ms/ms, absolute, 17 segments, 24607 samples\n","\n","[76/114] proband1/jumping\n","  ms/ms, absolute, 4 segments, 4214 samples\n","\n","[77/114] proband1/sitting\n","  ⚠️ Skipped: merge failed\n","\n","[78/114] proband1/standing\n","  ms/ms, absolute, 22 segments, 30988 samples\n","\n","[79/114] proband1/lying\n","  ⚠️ Skipped: unable to determine timestamp unit\n","\n","[80/114] proband1/running\n","  ms/ms, absolute, 14 segments, 30013 samples\n","\n","[81/114] proband1/climbingup\n","  ms/ms, absolute, 25 segments, 31752 samples\n","\n","[82/114] proband1/walking\n","  ms/ms, absolute, 14 segments, 31332 samples\n","\n","[83/114] proband5/climbingdown\n","  ms/ms, absolute, 19 segments, 24376 samples\n","\n","[84/114] proband5/jumping\n","  ms/ms, absolute, 3 segments, 4715 samples\n","\n","[85/114] proband5/sitting\n","  ms/ms, absolute, 16 segments, 31973 samples\n","\n","[86/114] proband5/standing\n","  ms/ms, absolute, 21 segments, 29060 samples\n","\n","[87/114] proband5/lying\n","  ms/ms, absolute, 29 segments, 31975 samples\n","\n","[88/114] proband5/running\n","  ms/ms, absolute, 41 segments, 53805 samples\n","\n","[89/114] proband5/climbingup\n","  ms/ms, absolute, 19 segments, 29417 samples\n","\n","[90/114] proband5/walking\n","  ms/ms, absolute, 24 segments, 33814 samples\n","\n","[91/114] proband10/climbingdown\n","  ms/ms, absolute, 20 segments, 21216 samples\n","\n","[92/114] proband10/jumping\n","  ms/ms, absolute, 1 segments, 5193 samples\n","\n","[93/114] proband10/sitting\n","  ms/ms, absolute, 32 segments, 30836 samples\n","\n","[94/114] proband10/standing\n","  ms/ms, absolute, 27 segments, 31946 samples\n","\n","[95/114] proband10/lying\n","  ms/ms, absolute, 22 segments, 31164 samples\n","\n","[96/114] proband10/running\n","  ms/ms, absolute, 31 segments, 31071 samples\n","\n","[97/114] proband10/climbingup\n","  ms/ms, absolute, 21 segments, 22201 samples\n","\n","[98/114] proband10/walking\n","  ms/ms, absolute, 26 segments, 30684 samples\n","\n","[99/114] proband3/climbingdown\n","  ms/ms, absolute, 18 segments, 26974 samples\n","\n","[100/114] proband3/jumping\n","  ms/ms, absolute, 6 segments, 4966 samples\n","\n","[101/114] proband3/sitting\n","  ms/ms, absolute, 24 segments, 30493 samples\n","\n","[102/114] proband3/standing\n","  ms/ms, absolute, 25 segments, 30327 samples\n","\n","[103/114] proband3/lying\n","  ms/ms, absolute, 23 segments, 30629 samples\n","\n","[104/114] proband3/running\n","  ms/ms, absolute, 33 segments, 36762 samples\n","\n","[105/114] proband3/climbingup\n","  ms/ms, absolute, 22 segments, 28553 samples\n","\n","[106/114] proband3/walking\n","  ms/ms, absolute, 21 segments, 33355 samples\n","\n","[107/114] proband6/climbingdown\n","  ms/ms, absolute, 19 segments, 24014 samples\n","\n","[108/114] proband6/jumping\n","  ms/ms, absolute, 2 segments, 4737 samples\n","\n","[109/114] proband6/sitting\n","  ms/ms, absolute, 20 segments, 32055 samples\n","\n","[110/114] proband6/standing\n","  ms/ms, absolute, 32 segments, 30664 samples\n","\n","[111/114] proband6/lying\n","  ms/ms, absolute, 26 segments, 31199 samples\n","\n","[112/114] proband6/running\n","  ms/ms, absolute, 38 segments, 31910 samples\n","\n","[113/114] proband6/climbingup\n","  ms/ms, absolute, 16 segments, 24999 samples\n","\n","[114/114] proband6/walking\n","  ms/ms, absolute, 30 segments, 30436 samples\n","\n","✓ Completed 112 files\n","⚠️ Skipped 2: ['proband1_sitting', 'proband1_lying']\n","[master 400ef05] preproc: final time normalization with all fallbacks\n"," 114 files changed, 3031873 insertions(+)\n"," create mode 100644 figures/step4_interval_hist.png\n"," create mode 100644 interim/proband10_climbingdown_waist.csv\n"," create mode 100644 interim/proband10_climbingup_waist.csv\n"," create mode 100644 interim/proband10_jumping_waist.csv\n"," create mode 100644 interim/proband10_lying_waist.csv\n"," create mode 100644 interim/proband10_running_waist.csv\n"," create mode 100644 interim/proband10_sitting_waist.csv\n"," create mode 100644 interim/proband10_standing_waist.csv\n"," create mode 100644 interim/proband10_walking_waist.csv\n"," create mode 100644 interim/proband11_climbingdown_waist.csv\n"," create mode 100644 interim/proband11_climbingup_waist.csv\n"," create mode 100644 interim/proband11_jumping_waist.csv\n"," create mode 100644 interim/proband11_lying_waist.csv\n"," create mode 100644 interim/proband11_running_waist.csv\n"," create mode 100644 interim/proband11_sitting_waist.csv\n"," create mode 100644 interim/proband11_standing_waist.csv\n"," create mode 100644 interim/proband11_walking_waist.csv\n"," create mode 100644 interim/proband12_climbingdown_waist.csv\n"," create mode 100644 interim/proband12_climbingup_waist.csv\n"," create mode 100644 interim/proband12_jumping_waist.csv\n"," create mode 100644 interim/proband12_lying_waist.csv\n"," create mode 100644 interim/proband12_running_waist.csv\n"," create mode 100644 interim/proband12_sitting_waist.csv\n"," create mode 100644 interim/proband12_standing_waist.csv\n"," create mode 100644 interim/proband12_walking_waist.csv\n"," create mode 100644 interim/proband13_climbingdown_waist.csv\n"," create mode 100644 interim/proband13_climbingup_waist.csv\n"," create mode 100644 interim/proband13_jumping_waist.csv\n"," create mode 100644 interim/proband13_lying_waist.csv\n"," create mode 100644 interim/proband13_running_waist.csv\n"," create mode 100644 interim/proband13_sitting_waist.csv\n"," create mode 100644 interim/proband13_standing_waist.csv\n"," create mode 100644 interim/proband13_walking_waist.csv\n"," create mode 100644 interim/proband14_jumping_waist.csv\n"," create mode 100644 interim/proband14_lying_waist.csv\n"," create mode 100644 interim/proband14_running_waist.csv\n"," create mode 100644 interim/proband14_sitting_waist.csv\n"," create mode 100644 interim/proband14_standing_waist.csv\n"," create mode 100644 interim/proband14_walking_waist.csv\n"," create mode 100644 interim/proband15_climbingdown_waist.csv\n"," create mode 100644 interim/proband15_climbingup_waist.csv\n"," create mode 100644 interim/proband15_jumping_waist.csv\n"," create mode 100644 interim/proband15_lying_waist.csv\n"," create mode 100644 interim/proband15_running_waist.csv\n"," create mode 100644 interim/proband15_sitting_waist.csv\n"," create mode 100644 interim/proband15_standing_waist.csv\n"," create mode 100644 interim/proband15_walking_waist.csv\n"," create mode 100644 interim/proband1_climbingdown_waist.csv\n"," create mode 100644 interim/proband1_climbingup_waist.csv\n"," create mode 100644 interim/proband1_jumping_waist.csv\n"," create mode 100644 interim/proband1_running_waist.csv\n"," create mode 100644 interim/proband1_standing_waist.csv\n"," create mode 100644 interim/proband1_walking_waist.csv\n"," create mode 100644 interim/proband2_climbingdown_waist.csv\n"," create mode 100644 interim/proband2_climbingup_waist.csv\n"," create mode 100644 interim/proband2_jumping_waist.csv\n"," create mode 100644 interim/proband2_lying_waist.csv\n"," create mode 100644 interim/proband2_running_waist.csv\n"," create mode 100644 interim/proband2_sitting_waist.csv\n"," create mode 100644 interim/proband2_standing_waist.csv\n"," create mode 100644 interim/proband2_walking_waist.csv\n"," create mode 100644 interim/proband3_climbingdown_waist.csv\n"," create mode 100644 interim/proband3_climbingup_waist.csv\n"," create mode 100644 interim/proband3_jumping_waist.csv\n"," create mode 100644 interim/proband3_lying_waist.csv\n"," create mode 100644 interim/proband3_running_waist.csv\n"," create mode 100644 interim/proband3_sitting_waist.csv\n"," create mode 100644 interim/proband3_standing_waist.csv\n"," create mode 100644 interim/proband3_walking_waist.csv\n"," create mode 100644 interim/proband4_jumping_waist.csv\n"," create mode 100644 interim/proband4_lying_waist.csv\n"," create mode 100644 interim/proband4_running_waist.csv\n"," create mode 100644 interim/proband4_sitting_waist.csv\n"," create mode 100644 interim/proband4_standing_waist.csv\n"," create mode 100644 interim/proband4_walking_waist.csv\n"," create mode 100644 interim/proband5_climbingdown_waist.csv\n"," create mode 100644 interim/proband5_climbingup_waist.csv\n"," create mode 100644 interim/proband5_jumping_waist.csv\n"," create mode 100644 interim/proband5_lying_waist.csv\n"," create mode 100644 interim/proband5_running_waist.csv\n"," create mode 100644 interim/proband5_sitting_waist.csv\n"," create mode 100644 interim/proband5_standing_waist.csv\n"," create mode 100644 interim/proband5_walking_waist.csv\n"," create mode 100644 interim/proband6_climbingdown_waist.csv\n"," create mode 100644 interim/proband6_climbingup_waist.csv\n"," create mode 100644 interim/proband6_jumping_waist.csv\n"," create mode 100644 interim/proband6_lying_waist.csv\n"," create mode 100644 interim/proband6_running_waist.csv\n"," create mode 100644 interim/proband6_sitting_waist.csv\n"," create mode 100644 interim/proband6_standing_waist.csv\n"," create mode 100644 interim/proband6_walking_waist.csv\n"," create mode 100644 interim/proband7_jumping_waist.csv\n"," create mode 100644 interim/proband7_lying_waist.csv\n"," create mode 100644 interim/proband7_running_waist.csv\n"," create mode 100644 interim/proband7_sitting_waist.csv\n"," create mode 100644 interim/proband7_standing_waist.csv\n"," create mode 100644 interim/proband7_walking_waist.csv\n"," create mode 100644 interim/proband8_climbingdown_waist.csv\n"," create mode 100644 interim/proband8_climbingup_waist.csv\n"," create mode 100644 interim/proband8_jumping_waist.csv\n"," create mode 100644 interim/proband8_lying_waist.csv\n"," create mode 100644 interim/proband8_running_waist.csv\n"," create mode 100644 interim/proband8_sitting_waist.csv\n"," create mode 100644 interim/proband8_standing_waist.csv\n"," create mode 100644 interim/proband8_walking_waist.csv\n"," create mode 100644 interim/proband9_climbingdown_waist.csv\n"," create mode 100644 interim/proband9_climbingup_waist.csv\n"," create mode 100644 interim/proband9_jumping_waist.csv\n"," create mode 100644 interim/proband9_lying_waist.csv\n"," create mode 100644 interim/proband9_running_waist.csv\n"," create mode 100644 interim/proband9_sitting_waist.csv\n"," create mode 100644 interim/proband9_standing_waist.csv\n"," create mode 100644 interim/proband9_walking_waist.csv\n"," create mode 100644 logs/step4_summary.json\n","\n","============================================================\n","Step 4 completed\n","============================================================\n"]}]},{"cell_type":"code","source":["# ================ Step 5: Gravity Removal / Detrending (Batch Processing) ================\n","import numpy as np\n","import pandas as pd\n","from scipy.signal import butter, filtfilt\n","import matplotlib.pyplot as plt\n","from pathlib import Path\n","import json\n","\n","print(\"\\n\\nStep 5: Gravity Removal / Detrending\")\n","print(\"=\" * 60)\n","\n","interim_dir = Path('/content/interim')\n","proc_dir = Path('/content/proc')\n","proc_dir.mkdir(exist_ok=True)\n","\n","TARGET_FS = 50\n","CUTOFF_HZ = 0.3\n","\n","def highpass_filter(data, cutoff, fs, order=3):\n","    \"\"\"Third-order Butterworth high-pass filter\"\"\"\n","    nyq = 0.5 * fs\n","    normal_cutoff = cutoff / nyq\n","    b, a = butter(order, normal_cutoff, btype='high', analog=False)\n","    return filtfilt(b, a, data)\n","\n","# Process all files\n","interim_files = sorted(interim_dir.glob('*.csv'))\n","print(f\"Found {len(interim_files)} files\")\n","\n","all_static_means = []\n","\n","for idx, filepath in enumerate(interim_files):\n","    print(f\"\\n[{idx+1}/{len(interim_files)}] {filepath.name}\")\n","\n","    df = pd.read_csv(filepath)\n","    print(f\"  Original: {df.shape}, {df['segment_id'].nunique()} segments\")\n","\n","    processed_segments = []\n","\n","    # Filter per segment\n","    for seg_id, seg_df in df.groupby('segment_id'):\n","        seg_df = seg_df.copy()\n","\n","        # Accelerometer high-pass filtering\n","        for axis in ['x', 'y', 'z']:\n","            col = f'acc_{axis}'\n","            seg_df[col] = highpass_filter(seg_df[col].values, CUTOFF_HZ, TARGET_FS, order=3)\n","\n","        # Gyroscope mean removal\n","        for axis in ['x', 'y', 'z']:\n","            col = f'gyro_{axis}'\n","            seg_df[col] = seg_df[col] - seg_df[col].mean()\n","\n","        processed_segments.append(seg_df)\n","\n","    df_filtered = pd.concat(processed_segments, ignore_index=True)\n","\n","    # Validate static segment (from the longest segment)\n","    longest_seg = df_filtered.groupby('segment_id').size().idxmax()\n","    seg_for_verify = df_filtered[df_filtered['segment_id'] == longest_seg].reset_index(drop=True)\n","\n","    window_size = TARGET_FS * 2\n","    acc_mag = np.sqrt(seg_for_verify['acc_x']**2 + seg_for_verify['acc_y']**2 + seg_for_verify['acc_z']**2)\n","    static_idx = acc_mag.rolling(window_size).std().idxmin()\n","    static_seg = seg_for_verify.iloc[static_idx:static_idx+window_size]\n","\n","    static_means = {f'acc_{ax}': static_seg[f'acc_{ax}'].mean() for ax in ['x', 'y', 'z']}\n","    all_static_means.append({'file': filepath.name, **static_means})\n","\n","    # Save\n","    df_filtered.to_csv(proc_dir / filepath.name, index=False)\n","    print(f\"  ✓ {len(df_filtered)} samples → proc/{filepath.name}\")\n","\n","print(f\"\\n✓ Completed {len(interim_files)} files\")\n","\n","# Plot verification figure for the first file\n","if interim_files:\n","    first_file = interim_files[0]\n","    df = pd.read_csv(proc_dir / first_file.name)\n","    longest_seg = df.groupby('segment_id').size().idxmax()\n","    seg = df[df['segment_id'] == longest_seg].reset_index(drop=True)\n","\n","    window_size = TARGET_FS * 2\n","    acc_mag = np.sqrt(seg['acc_x']**2 + seg['acc_y']**2 + seg['acc_z']**2)\n","    static_idx = acc_mag.rolling(window_size).std().idxmin()\n","    static_seg = seg.iloc[static_idx:static_idx+window_size]\n","\n","    fig, axes = plt.subplots(3, 1, figsize=(12, 8), sharex=True)\n","    time_sec = np.arange(len(seg)) / TARGET_FS\n","\n","    for i, axis in enumerate(['x', 'y', 'z']):\n","        ax = axes[i]\n","        col = f'acc_{axis}'\n","        ax.plot(time_sec, seg[col], linewidth=0.5, alpha=0.7)\n","        ax.axhline(0, color='red', linestyle='--', linewidth=1, alpha=0.5)\n","\n","        static_t = static_idx / TARGET_FS\n","        static_mean = static_seg[col].mean()\n","        ax.axvspan(static_t, static_t + 2, color='green', alpha=0.2,\n","                   label=f'Static (mean={static_mean:.4f})')\n","\n","        ax.set_ylabel(f'ACC {axis.upper()} (m/s²)')\n","        ax.grid(alpha=0.3)\n","        ax.legend(loc='upper right')\n","\n","    axes[-1].set_xlabel('Time (s)')\n","    axes[0].set_title(f'Detrended Signal - {first_file.name} (segment {longest_seg})')\n","    plt.tight_layout()\n","    plt.savefig('/content/figures/step5_detrend_verify.png', dpi=150)\n","    plt.close()\n","    print(f\"\\n✓ Verification figure: figures/step5_detrend_verify.png\")\n","\n","# Save parameters\n","filter_params = {\n","    'acc_highpass': {'cutoff_hz': CUTOFF_HZ, 'order': 3, 'filter_type': 'Butterworth'},\n","    'gyro_detrend': 'mean_removal',\n","    'sampling_rate': TARGET_FS,\n","    'filtering_method': 'per_segment',\n","    'files_processed': len(interim_files),\n","    'static_means_samples': all_static_means[:5]\n","}\n","\n","with open('/content/logs/step5_filter_params.json', 'w') as f:\n","    json.dump(filter_params, f, indent=2)\n","\n","get_ipython().system('git add figures/step5_detrend_verify.png logs/step5_filter_params.json proc/')\n","get_ipython().system('git commit -m \"preproc: batch filtering for all files\"')\n","\n","print(f\"\\n{'='*60}\\nStep 5 completed\\n{'='*60}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9voMJk_0z3Gq","executionInfo":{"status":"ok","timestamp":1762688784080,"user_tz":0,"elapsed":61513,"user":{"displayName":"yu Wu","userId":"12692660435918028293"}},"outputId":"6ab04675-ed7f-424e-9536-e1630cf82789"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","Step 5: Gravity Removal / Detrending\n","============================================================\n","Found 112 files\n","\n","[1/112] proband10_climbingdown_waist.csv\n","  Original: (21216, 10), 20 segments\n","  ✓ 21216 samples → proc/proband10_climbingdown_waist.csv\n","\n","[2/112] proband10_climbingup_waist.csv\n","  Original: (22201, 10), 21 segments\n","  ✓ 22201 samples → proc/proband10_climbingup_waist.csv\n","\n","[3/112] proband10_jumping_waist.csv\n","  Original: (5193, 10), 1 segments\n","  ✓ 5193 samples → proc/proband10_jumping_waist.csv\n","\n","[4/112] proband10_lying_waist.csv\n","  Original: (31164, 10), 22 segments\n","  ✓ 31164 samples → proc/proband10_lying_waist.csv\n","\n","[5/112] proband10_running_waist.csv\n","  Original: (31071, 10), 31 segments\n","  ✓ 31071 samples → proc/proband10_running_waist.csv\n","\n","[6/112] proband10_sitting_waist.csv\n","  Original: (30836, 10), 32 segments\n","  ✓ 30836 samples → proc/proband10_sitting_waist.csv\n","\n","[7/112] proband10_standing_waist.csv\n","  Original: (31946, 10), 27 segments\n","  ✓ 31946 samples → proc/proband10_standing_waist.csv\n","\n","[8/112] proband10_walking_waist.csv\n","  Original: (30684, 10), 26 segments\n","  ✓ 30684 samples → proc/proband10_walking_waist.csv\n","\n","[9/112] proband11_climbingdown_waist.csv\n","  Original: (24032, 10), 19 segments\n","  ✓ 24032 samples → proc/proband11_climbingdown_waist.csv\n","\n","[10/112] proband11_climbingup_waist.csv\n","  Original: (30391, 10), 25 segments\n","  ✓ 30391 samples → proc/proband11_climbingup_waist.csv\n","\n","[11/112] proband11_jumping_waist.csv\n","  Original: (4796, 10), 7 segments\n","  ✓ 4796 samples → proc/proband11_jumping_waist.csv\n","\n","[12/112] proband11_lying_waist.csv\n","  Original: (31836, 10), 19 segments\n","  ✓ 31836 samples → proc/proband11_lying_waist.csv\n","\n","[13/112] proband11_running_waist.csv\n","  Original: (29843, 10), 34 segments\n","  ✓ 29843 samples → proc/proband11_running_waist.csv\n","\n","[14/112] proband11_sitting_waist.csv\n","  Original: (30245, 10), 26 segments\n","  ✓ 30245 samples → proc/proband11_sitting_waist.csv\n","\n","[15/112] proband11_standing_waist.csv\n","  Original: (30514, 10), 20 segments\n","  ✓ 30514 samples → proc/proband11_standing_waist.csv\n","\n","[16/112] proband11_walking_waist.csv\n","  Original: (32123, 10), 30 segments\n","  ✓ 32123 samples → proc/proband11_walking_waist.csv\n","\n","[17/112] proband12_climbingdown_waist.csv\n","  Original: (23499, 10), 17 segments\n","  ✓ 23499 samples → proc/proband12_climbingdown_waist.csv\n","\n","[18/112] proband12_climbingup_waist.csv\n","  Original: (27393, 10), 13 segments\n","  ✓ 27393 samples → proc/proband12_climbingup_waist.csv\n","\n","[19/112] proband12_jumping_waist.csv\n","  Original: (4279, 10), 12 segments\n","  ✓ 4279 samples → proc/proband12_jumping_waist.csv\n","\n","[20/112] proband12_lying_waist.csv\n","  Original: (30306, 10), 22 segments\n","  ✓ 30306 samples → proc/proband12_lying_waist.csv\n","\n","[21/112] proband12_running_waist.csv\n","  Original: (28742, 10), 23 segments\n","  ✓ 28742 samples → proc/proband12_running_waist.csv\n","\n","[22/112] proband12_sitting_waist.csv\n","  Original: (29317, 10), 62 segments\n","  ✓ 29317 samples → proc/proband12_sitting_waist.csv\n","\n","[23/112] proband12_standing_waist.csv\n","  Original: (29789, 10), 28 segments\n","  ✓ 29789 samples → proc/proband12_standing_waist.csv\n","\n","[24/112] proband12_walking_waist.csv\n","  Original: (29476, 10), 50 segments\n","  ✓ 29476 samples → proc/proband12_walking_waist.csv\n","\n","[25/112] proband13_climbingdown_waist.csv\n","  Original: (21127, 10), 20 segments\n","  ✓ 21127 samples → proc/proband13_climbingdown_waist.csv\n","\n","[26/112] proband13_climbingup_waist.csv\n","  Original: (29031, 10), 23 segments\n","  ✓ 29031 samples → proc/proband13_climbingup_waist.csv\n","\n","[27/112] proband13_jumping_waist.csv\n","  Original: (5370, 10), 2 segments\n","  ✓ 5370 samples → proc/proband13_jumping_waist.csv\n","\n","[28/112] proband13_lying_waist.csv\n","  Original: (31336, 10), 23 segments\n","  ✓ 31336 samples → proc/proband13_lying_waist.csv\n","\n","[29/112] proband13_running_waist.csv\n","  Original: (29961, 10), 21 segments\n","  ✓ 29961 samples → proc/proband13_running_waist.csv\n","\n","[30/112] proband13_sitting_waist.csv\n","  Original: (31261, 10), 24 segments\n","  ✓ 31261 samples → proc/proband13_sitting_waist.csv\n","\n","[31/112] proband13_standing_waist.csv\n","  Original: (32877, 10), 35 segments\n","  ✓ 32877 samples → proc/proband13_standing_waist.csv\n","\n","[32/112] proband13_walking_waist.csv\n","  Original: (31882, 10), 20 segments\n","  ✓ 31882 samples → proc/proband13_walking_waist.csv\n","\n","[33/112] proband14_jumping_waist.csv\n","  Original: (4642, 10), 5 segments\n","  ✓ 4642 samples → proc/proband14_jumping_waist.csv\n","\n","[34/112] proband14_lying_waist.csv\n","  Original: (30563, 10), 27 segments\n","  ✓ 30563 samples → proc/proband14_lying_waist.csv\n","\n","[35/112] proband14_running_waist.csv\n","  Original: (29786, 10), 33 segments\n","  ✓ 29786 samples → proc/proband14_running_waist.csv\n","\n","[36/112] proband14_sitting_waist.csv\n","  Original: (30562, 10), 31 segments\n","  ✓ 30562 samples → proc/proband14_sitting_waist.csv\n","\n","[37/112] proband14_standing_waist.csv\n","  Original: (30114, 10), 34 segments\n","  ✓ 30114 samples → proc/proband14_standing_waist.csv\n","\n","[38/112] proband14_walking_waist.csv\n","  Original: (32007, 10), 50 segments\n","  ✓ 32007 samples → proc/proband14_walking_waist.csv\n","\n","[39/112] proband15_climbingdown_waist.csv\n","  Original: (24728, 10), 23 segments\n","  ✓ 24728 samples → proc/proband15_climbingdown_waist.csv\n","\n","[40/112] proband15_climbingup_waist.csv\n","  Original: (28145, 10), 22 segments\n","  ✓ 28145 samples → proc/proband15_climbingup_waist.csv\n","\n","[41/112] proband15_jumping_waist.csv\n","  Original: (4568, 10), 6 segments\n","  ✓ 4568 samples → proc/proband15_jumping_waist.csv\n","\n","[42/112] proband15_lying_waist.csv\n","  Original: (32001, 10), 23 segments\n","  ✓ 32001 samples → proc/proband15_lying_waist.csv\n","\n","[43/112] proband15_running_waist.csv\n","  Original: (32719, 10), 27 segments\n","  ✓ 32719 samples → proc/proband15_running_waist.csv\n","\n","[44/112] proband15_sitting_waist.csv\n","  Original: (31196, 10), 29 segments\n","  ✓ 31196 samples → proc/proband15_sitting_waist.csv\n","\n","[45/112] proband15_standing_waist.csv\n","  Original: (30457, 10), 21 segments\n","  ✓ 30457 samples → proc/proband15_standing_waist.csv\n","\n","[46/112] proband15_walking_waist.csv\n","  Original: (32152, 10), 27 segments\n","  ✓ 32152 samples → proc/proband15_walking_waist.csv\n","\n","[47/112] proband1_climbingdown_waist.csv\n","  Original: (24607, 10), 17 segments\n","  ✓ 24607 samples → proc/proband1_climbingdown_waist.csv\n","\n","[48/112] proband1_climbingup_waist.csv\n","  Original: (31752, 10), 25 segments\n","  ✓ 31752 samples → proc/proband1_climbingup_waist.csv\n","\n","[49/112] proband1_jumping_waist.csv\n","  Original: (4214, 10), 4 segments\n","  ✓ 4214 samples → proc/proband1_jumping_waist.csv\n","\n","[50/112] proband1_running_waist.csv\n","  Original: (30013, 10), 14 segments\n","  ✓ 30013 samples → proc/proband1_running_waist.csv\n","\n","[51/112] proband1_standing_waist.csv\n","  Original: (30988, 10), 22 segments\n","  ✓ 30988 samples → proc/proband1_standing_waist.csv\n","\n","[52/112] proband1_walking_waist.csv\n","  Original: (31332, 10), 14 segments\n","  ✓ 31332 samples → proc/proband1_walking_waist.csv\n","\n","[53/112] proband2_climbingdown_waist.csv\n","  Original: (23939, 10), 24 segments\n","  ✓ 23939 samples → proc/proband2_climbingdown_waist.csv\n","\n","[54/112] proband2_climbingup_waist.csv\n","  Original: (23484, 10), 37 segments\n","  ✓ 23484 samples → proc/proband2_climbingup_waist.csv\n","\n","[55/112] proband2_jumping_waist.csv\n","  Original: (4512, 10), 3 segments\n","  ✓ 4512 samples → proc/proband2_jumping_waist.csv\n","\n","[56/112] proband2_lying_waist.csv\n","  Original: (30002, 10), 28 segments\n","  ✓ 30002 samples → proc/proband2_lying_waist.csv\n","\n","[57/112] proband2_running_waist.csv\n","  Original: (28701, 10), 42 segments\n","  ✓ 28701 samples → proc/proband2_running_waist.csv\n","\n","[58/112] proband2_sitting_waist.csv\n","  Original: (29887, 10), 17 segments\n","  ✓ 29887 samples → proc/proband2_sitting_waist.csv\n","\n","[59/112] proband2_standing_waist.csv\n","  Original: (28717, 10), 49 segments\n","  ✓ 28717 samples → proc/proband2_standing_waist.csv\n","\n","[60/112] proband2_walking_waist.csv\n","  Original: (28946, 10), 38 segments\n","  ✓ 28946 samples → proc/proband2_walking_waist.csv\n","\n","[61/112] proband3_climbingdown_waist.csv\n","  Original: (26974, 10), 18 segments\n","  ✓ 26974 samples → proc/proband3_climbingdown_waist.csv\n","\n","[62/112] proband3_climbingup_waist.csv\n","  Original: (28553, 10), 22 segments\n","  ✓ 28553 samples → proc/proband3_climbingup_waist.csv\n","\n","[63/112] proband3_jumping_waist.csv\n","  Original: (4966, 10), 6 segments\n","  ✓ 4966 samples → proc/proband3_jumping_waist.csv\n","\n","[64/112] proband3_lying_waist.csv\n","  Original: (30629, 10), 23 segments\n","  ✓ 30629 samples → proc/proband3_lying_waist.csv\n","\n","[65/112] proband3_running_waist.csv\n","  Original: (36762, 10), 33 segments\n","  ✓ 36762 samples → proc/proband3_running_waist.csv\n","\n","[66/112] proband3_sitting_waist.csv\n","  Original: (30493, 10), 24 segments\n","  ✓ 30493 samples → proc/proband3_sitting_waist.csv\n","\n","[67/112] proband3_standing_waist.csv\n","  Original: (30327, 10), 25 segments\n","  ✓ 30327 samples → proc/proband3_standing_waist.csv\n","\n","[68/112] proband3_walking_waist.csv\n","  Original: (33355, 10), 21 segments\n","  ✓ 33355 samples → proc/proband3_walking_waist.csv\n","\n","[69/112] proband4_jumping_waist.csv\n","  Original: (4148, 10), 3 segments\n","  ✓ 4148 samples → proc/proband4_jumping_waist.csv\n","\n","[70/112] proband4_lying_waist.csv\n","  Original: (33106, 10), 16 segments\n","  ✓ 33106 samples → proc/proband4_lying_waist.csv\n","\n","[71/112] proband4_running_waist.csv\n","  Original: (50541, 10), 40 segments\n","  ✓ 50541 samples → proc/proband4_running_waist.csv\n","\n","[72/112] proband4_sitting_waist.csv\n","  Original: (31248, 10), 14 segments\n","  ✓ 31248 samples → proc/proband4_sitting_waist.csv\n","\n","[73/112] proband4_standing_waist.csv\n","  Original: (29741, 10), 12 segments\n","  ✓ 29741 samples → proc/proband4_standing_waist.csv\n","\n","[74/112] proband4_walking_waist.csv\n","  Original: (30482, 10), 13 segments\n","  ✓ 30482 samples → proc/proband4_walking_waist.csv\n","\n","[75/112] proband5_climbingdown_waist.csv\n","  Original: (24376, 10), 19 segments\n","  ✓ 24376 samples → proc/proband5_climbingdown_waist.csv\n","\n","[76/112] proband5_climbingup_waist.csv\n","  Original: (29417, 10), 19 segments\n","  ✓ 29417 samples → proc/proband5_climbingup_waist.csv\n","\n","[77/112] proband5_jumping_waist.csv\n","  Original: (4715, 10), 3 segments\n","  ✓ 4715 samples → proc/proband5_jumping_waist.csv\n","\n","[78/112] proband5_lying_waist.csv\n","  Original: (31975, 10), 29 segments\n","  ✓ 31975 samples → proc/proband5_lying_waist.csv\n","\n","[79/112] proband5_running_waist.csv\n","  Original: (53805, 10), 41 segments\n","  ✓ 53805 samples → proc/proband5_running_waist.csv\n","\n","[80/112] proband5_sitting_waist.csv\n","  Original: (31973, 10), 16 segments\n","  ✓ 31973 samples → proc/proband5_sitting_waist.csv\n","\n","[81/112] proband5_standing_waist.csv\n","  Original: (29060, 10), 21 segments\n","  ✓ 29060 samples → proc/proband5_standing_waist.csv\n","\n","[82/112] proband5_walking_waist.csv\n","  Original: (33814, 10), 24 segments\n","  ✓ 33814 samples → proc/proband5_walking_waist.csv\n","\n","[83/112] proband6_climbingdown_waist.csv\n","  Original: (24014, 10), 19 segments\n","  ✓ 24014 samples → proc/proband6_climbingdown_waist.csv\n","\n","[84/112] proband6_climbingup_waist.csv\n","  Original: (24999, 10), 16 segments\n","  ✓ 24999 samples → proc/proband6_climbingup_waist.csv\n","\n","[85/112] proband6_jumping_waist.csv\n","  Original: (4737, 10), 2 segments\n","  ✓ 4737 samples → proc/proband6_jumping_waist.csv\n","\n","[86/112] proband6_lying_waist.csv\n","  Original: (31199, 10), 26 segments\n","  ✓ 31199 samples → proc/proband6_lying_waist.csv\n","\n","[87/112] proband6_running_waist.csv\n","  Original: (31910, 10), 38 segments\n","  ✓ 31910 samples → proc/proband6_running_waist.csv\n","\n","[88/112] proband6_sitting_waist.csv\n","  Original: (32055, 10), 20 segments\n","  ✓ 32055 samples → proc/proband6_sitting_waist.csv\n","\n","[89/112] proband6_standing_waist.csv\n","  Original: (30664, 10), 32 segments\n","  ✓ 30664 samples → proc/proband6_standing_waist.csv\n","\n","[90/112] proband6_walking_waist.csv\n","  Original: (30436, 10), 30 segments\n","  ✓ 30436 samples → proc/proband6_walking_waist.csv\n","\n","[91/112] proband7_jumping_waist.csv\n","  Original: (4853, 10), 6 segments\n","  ✓ 4853 samples → proc/proband7_jumping_waist.csv\n","\n","[92/112] proband7_lying_waist.csv\n","  Original: (31520, 10), 29 segments\n","  ✓ 31520 samples → proc/proband7_lying_waist.csv\n","\n","[93/112] proband7_running_waist.csv\n","  Original: (35636, 10), 27 segments\n","  ✓ 35636 samples → proc/proband7_running_waist.csv\n","\n","[94/112] proband7_sitting_waist.csv\n","  Original: (31417, 10), 23 segments\n","  ✓ 31417 samples → proc/proband7_sitting_waist.csv\n","\n","[95/112] proband7_standing_waist.csv\n","  Original: (32005, 10), 24 segments\n","  ✓ 32005 samples → proc/proband7_standing_waist.csv\n","\n","[96/112] proband7_walking_waist.csv\n","  Original: (29987, 10), 27 segments\n","  ✓ 29987 samples → proc/proband7_walking_waist.csv\n","\n","[97/112] proband8_climbingdown_waist.csv\n","  Original: (21304, 10), 26 segments\n","  ✓ 21304 samples → proc/proband8_climbingdown_waist.csv\n","\n","[98/112] proband8_climbingup_waist.csv\n","  Original: (55851, 10), 47 segments\n","  ✓ 55851 samples → proc/proband8_climbingup_waist.csv\n","\n","[99/112] proband8_jumping_waist.csv\n","  Original: (4694, 10), 5 segments\n","  ✓ 4694 samples → proc/proband8_jumping_waist.csv\n","\n","[100/112] proband8_lying_waist.csv\n","  Original: (30683, 10), 20 segments\n","  ✓ 30683 samples → proc/proband8_lying_waist.csv\n","\n","[101/112] proband8_running_waist.csv\n","  Original: (29937, 10), 20 segments\n","  ✓ 29937 samples → proc/proband8_running_waist.csv\n","\n","[102/112] proband8_sitting_waist.csv\n","  Original: (31855, 10), 15 segments\n","  ✓ 31855 samples → proc/proband8_sitting_waist.csv\n","\n","[103/112] proband8_standing_waist.csv\n","  Original: (31386, 10), 13 segments\n","  ✓ 31386 samples → proc/proband8_standing_waist.csv\n","\n","[104/112] proband8_walking_waist.csv\n","  Original: (31652, 10), 31 segments\n","  ✓ 31652 samples → proc/proband8_walking_waist.csv\n","\n","[105/112] proband9_climbingdown_waist.csv\n","  Original: (24302, 10), 18 segments\n","  ✓ 24302 samples → proc/proband9_climbingdown_waist.csv\n","\n","[106/112] proband9_climbingup_waist.csv\n","  Original: (26388, 10), 21 segments\n","  ✓ 26388 samples → proc/proband9_climbingup_waist.csv\n","\n","[107/112] proband9_jumping_waist.csv\n","  Original: (4976, 10), 4 segments\n","  ✓ 4976 samples → proc/proband9_jumping_waist.csv\n","\n","[108/112] proband9_lying_waist.csv\n","  Original: (30587, 10), 15 segments\n","  ✓ 30587 samples → proc/proband9_lying_waist.csv\n","\n","[109/112] proband9_running_waist.csv\n","  Original: (39416, 10), 41 segments\n","  ✓ 39416 samples → proc/proband9_running_waist.csv\n","\n","[110/112] proband9_sitting_waist.csv\n","  Original: (31473, 10), 24 segments\n","  ✓ 31473 samples → proc/proband9_sitting_waist.csv\n","\n","[111/112] proband9_standing_waist.csv\n","  Original: (31296, 10), 18 segments\n","  ✓ 31296 samples → proc/proband9_standing_waist.csv\n","\n","[112/112] proband9_walking_waist.csv\n","  Original: (30358, 10), 25 segments\n","  ✓ 30358 samples → proc/proband9_walking_waist.csv\n","\n","✓ Completed 112 files\n","\n","✓ Verification figure: figures/step5_detrend_verify.png\n","[master eaeea69] preproc: batch filtering for all files\n"," 114 files changed, 3030676 insertions(+)\n"," create mode 100644 figures/step5_detrend_verify.png\n"," create mode 100644 logs/step5_filter_params.json\n"," create mode 100644 proc/proband10_climbingdown_waist.csv\n"," create mode 100644 proc/proband10_climbingup_waist.csv\n"," create mode 100644 proc/proband10_jumping_waist.csv\n"," create mode 100644 proc/proband10_lying_waist.csv\n"," create mode 100644 proc/proband10_running_waist.csv\n"," create mode 100644 proc/proband10_sitting_waist.csv\n"," create mode 100644 proc/proband10_standing_waist.csv\n"," create mode 100644 proc/proband10_walking_waist.csv\n"," create mode 100644 proc/proband11_climbingdown_waist.csv\n"," create mode 100644 proc/proband11_climbingup_waist.csv\n"," create mode 100644 proc/proband11_jumping_waist.csv\n"," create mode 100644 proc/proband11_lying_waist.csv\n"," create mode 100644 proc/proband11_running_waist.csv\n"," create mode 100644 proc/proband11_sitting_waist.csv\n"," create mode 100644 proc/proband11_standing_waist.csv\n"," create mode 100644 proc/proband11_walking_waist.csv\n"," create mode 100644 proc/proband12_climbingdown_waist.csv\n"," create mode 100644 proc/proband12_climbingup_waist.csv\n"," create mode 100644 proc/proband12_jumping_waist.csv\n"," create mode 100644 proc/proband12_lying_waist.csv\n"," create mode 100644 proc/proband12_running_waist.csv\n"," create mode 100644 proc/proband12_sitting_waist.csv\n"," create mode 100644 proc/proband12_standing_waist.csv\n"," create mode 100644 proc/proband12_walking_waist.csv\n"," create mode 100644 proc/proband13_climbingdown_waist.csv\n"," create mode 100644 proc/proband13_climbingup_waist.csv\n"," create mode 100644 proc/proband13_jumping_waist.csv\n"," create mode 100644 proc/proband13_lying_waist.csv\n"," create mode 100644 proc/proband13_running_waist.csv\n"," create mode 100644 proc/proband13_sitting_waist.csv\n"," create mode 100644 proc/proband13_standing_waist.csv\n"," create mode 100644 proc/proband13_walking_waist.csv\n"," create mode 100644 proc/proband14_jumping_waist.csv\n"," create mode 100644 proc/proband14_lying_waist.csv\n"," create mode 100644 proc/proband14_running_waist.csv\n"," create mode 100644 proc/proband14_sitting_waist.csv\n"," create mode 100644 proc/proband14_standing_waist.csv\n"," create mode 100644 proc/proband14_walking_waist.csv\n"," create mode 100644 proc/proband15_climbingdown_waist.csv\n"," create mode 100644 proc/proband15_climbingup_waist.csv\n"," create mode 100644 proc/proband15_jumping_waist.csv\n"," create mode 100644 proc/proband15_lying_waist.csv\n"," create mode 100644 proc/proband15_running_waist.csv\n"," create mode 100644 proc/proband15_sitting_waist.csv\n"," create mode 100644 proc/proband15_standing_waist.csv\n"," create mode 100644 proc/proband15_walking_waist.csv\n"," create mode 100644 proc/proband1_climbingdown_waist.csv\n"," create mode 100644 proc/proband1_climbingup_waist.csv\n"," create mode 100644 proc/proband1_jumping_waist.csv\n"," create mode 100644 proc/proband1_running_waist.csv\n"," create mode 100644 proc/proband1_standing_waist.csv\n"," create mode 100644 proc/proband1_walking_waist.csv\n"," create mode 100644 proc/proband2_climbingdown_waist.csv\n"," create mode 100644 proc/proband2_climbingup_waist.csv\n"," create mode 100644 proc/proband2_jumping_waist.csv\n"," create mode 100644 proc/proband2_lying_waist.csv\n"," create mode 100644 proc/proband2_running_waist.csv\n"," create mode 100644 proc/proband2_sitting_waist.csv\n"," create mode 100644 proc/proband2_standing_waist.csv\n"," create mode 100644 proc/proband2_walking_waist.csv\n"," create mode 100644 proc/proband3_climbingdown_waist.csv\n"," create mode 100644 proc/proband3_climbingup_waist.csv\n"," create mode 100644 proc/proband3_jumping_waist.csv\n"," create mode 100644 proc/proband3_lying_waist.csv\n"," create mode 100644 proc/proband3_running_waist.csv\n"," create mode 100644 proc/proband3_sitting_waist.csv\n"," create mode 100644 proc/proband3_standing_waist.csv\n"," create mode 100644 proc/proband3_walking_waist.csv\n"," create mode 100644 proc/proband4_jumping_waist.csv\n"," create mode 100644 proc/proband4_lying_waist.csv\n"," create mode 100644 proc/proband4_running_waist.csv\n"," create mode 100644 proc/proband4_sitting_waist.csv\n"," create mode 100644 proc/proband4_standing_waist.csv\n"," create mode 100644 proc/proband4_walking_waist.csv\n"," create mode 100644 proc/proband5_climbingdown_waist.csv\n"," create mode 100644 proc/proband5_climbingup_waist.csv\n"," create mode 100644 proc/proband5_jumping_waist.csv\n"," create mode 100644 proc/proband5_lying_waist.csv\n"," create mode 100644 proc/proband5_running_waist.csv\n"," create mode 100644 proc/proband5_sitting_waist.csv\n"," create mode 100644 proc/proband5_standing_waist.csv\n"," create mode 100644 proc/proband5_walking_waist.csv\n"," create mode 100644 proc/proband6_climbingdown_waist.csv\n"," create mode 100644 proc/proband6_climbingup_waist.csv\n"," create mode 100644 proc/proband6_jumping_waist.csv\n"," create mode 100644 proc/proband6_lying_waist.csv\n"," create mode 100644 proc/proband6_running_waist.csv\n"," create mode 100644 proc/proband6_sitting_waist.csv\n"," create mode 100644 proc/proband6_standing_waist.csv\n"," create mode 100644 proc/proband6_walking_waist.csv\n"," create mode 100644 proc/proband7_jumping_waist.csv\n"," create mode 100644 proc/proband7_lying_waist.csv\n"," create mode 100644 proc/proband7_running_waist.csv\n"," create mode 100644 proc/proband7_sitting_waist.csv\n"," create mode 100644 proc/proband7_standing_waist.csv\n"," create mode 100644 proc/proband7_walking_waist.csv\n"," create mode 100644 proc/proband8_climbingdown_waist.csv\n"," create mode 100644 proc/proband8_climbingup_waist.csv\n"," create mode 100644 proc/proband8_jumping_waist.csv\n"," create mode 100644 proc/proband8_lying_waist.csv\n"," create mode 100644 proc/proband8_running_waist.csv\n"," create mode 100644 proc/proband8_sitting_waist.csv\n"," create mode 100644 proc/proband8_standing_waist.csv\n"," create mode 100644 proc/proband8_walking_waist.csv\n"," create mode 100644 proc/proband9_climbingdown_waist.csv\n"," create mode 100644 proc/proband9_climbingup_waist.csv\n"," create mode 100644 proc/proband9_jumping_waist.csv\n"," create mode 100644 proc/proband9_lying_waist.csv\n"," create mode 100644 proc/proband9_running_waist.csv\n"," create mode 100644 proc/proband9_sitting_waist.csv\n"," create mode 100644 proc/proband9_standing_waist.csv\n"," create mode 100644 proc/proband9_walking_waist.csv\n","\n","============================================================\n","Step 5 completed\n","============================================================\n"]}]},{"cell_type":"code","source":["# ================ Step 6: Class Mapping ================\n","import pandas as pd\n","from pathlib import Path\n","import json\n","\n","print(\"\\n\\nStep 6: Class Mapping\")\n","print(\"=\" * 60)\n","\n","proc_dir = Path('/content/proc')\n","TARGET_FS = 50\n","\n","# Fixed order of 8 standard classes (consistent across folds)\n","STANDARD_CLASSES = ['walking', 'running', 'sitting', 'standing',\n","                    'lying', 'stairs_up', 'stairs_down', 'jumping']\n","\n","# Mapping from original activity names\n","activity_mapping = {\n","    'climbingdown': 'stairs_down',\n","    'climbingup': 'stairs_up',\n","    'jumping': 'jumping',\n","    'lying': 'lying',\n","    'running': 'running',\n","    'sitting': 'sitting',\n","    'standing': 'standing',\n","    'walking': 'walking'\n","}\n","\n","# Sliding-window parameters (aligned with subsequent feature extraction)\n","WINDOW_SEC = 3\n","OVERLAP = 0.5\n","WINDOW_SAMPLES = int(TARGET_FS * WINDOW_SEC)\n","STRIDE_SAMPLES = int(WINDOW_SAMPLES * (1 - OVERLAP))\n","MIN_WINDOWS_THRESHOLD = 50\n","\n","print(f\"Sliding window: {WINDOW_SEC}s ({WINDOW_SAMPLES} samples), overlap {OVERLAP*100:.0f}%, stride {STRIDE_SAMPLES}\")\n","\n","# Scan files and count windows per segment\n","proc_files = sorted(proc_dir.glob('*.csv'))\n","print(f\"\\nFound {len(proc_files)} files\")\n","\n","activity_stats = {}\n","proband_class_matrix = {}\n","\n","for filepath in proc_files:\n","    df = pd.read_csv(filepath)\n","\n","    # Prefer reading from columns\n","    activity = df['activity'].iloc[0] if 'activity' in df.columns else filepath.stem.split('_')[1]\n","    proband = df['proband'].iloc[0] if 'proband' in df.columns else filepath.stem.split('_')[0]\n","\n","    # Count windows per segment (without crossing segments)\n","    n_windows = 0\n","    for _, seg in df.groupby('segment_id'):\n","        seg_len = len(seg)\n","        if seg_len >= WINDOW_SAMPLES:\n","            n_windows += 1 + (seg_len - WINDOW_SAMPLES) // STRIDE_SAMPLES\n","\n","    # Accumulate statistics for original activities\n","    if activity not in activity_stats:\n","        activity_stats[activity] = {'samples': 0, 'windows': 0, 'files': 0}\n","    activity_stats[activity]['samples'] += len(df)\n","    activity_stats[activity]['windows'] += n_windows\n","    activity_stats[activity]['files'] += 1\n","\n","    # Build proband × class matrix\n","    if activity in activity_mapping:\n","        std_act = activity_mapping[activity]\n","        if proband not in proband_class_matrix:\n","            proband_class_matrix[proband] = {c: 0 for c in STANDARD_CLASSES}\n","        proband_class_matrix[proband][std_act] += n_windows\n","\n","print(\"\\nOriginal activity statistics:\")\n","for act in sorted(activity_stats.keys()):\n","    stats = activity_stats[act]\n","    print(f\"  {act:15s}: {stats['files']:2d} files, {stats['samples']:6d} samples, {stats['windows']:4d} windows\")\n","\n","# Map to the 8 standard classes\n","mapped_stats = {c: {'windows': 0, 'samples': 0, 'files': 0, 'original_names': []}\n","                for c in STANDARD_CLASSES}\n","tail_classes_original = []\n","\n","for orig_act, stats in activity_stats.items():\n","    if orig_act in activity_mapping:\n","        std_act = activity_mapping[orig_act]\n","        mapped_stats[std_act]['windows'] += stats['windows']\n","        mapped_stats[std_act]['samples'] += stats['samples']\n","        mapped_stats[std_act]['files'] += stats['files']\n","        if orig_act not in mapped_stats[std_act]['original_names']:\n","            mapped_stats[std_act]['original_names'].append(orig_act)\n","\n","        if stats['windows'] < MIN_WINDOWS_THRESHOLD:\n","            tail_classes_original.append({'original': orig_act, 'mapped': std_act, 'windows': stats['windows']})\n","\n","# Tail-class determination at the standard-class level\n","tail_standard_classes = [c for c in STANDARD_CLASSES if mapped_stats[c]['windows'] < MIN_WINDOWS_THRESHOLD]\n","included_flags = {c: (mapped_stats[c]['windows'] >= MIN_WINDOWS_THRESHOLD) for c in STANDARD_CLASSES}\n","\n","print(\"\\nStatistics for the 8 standard classes:\")\n","for std_act in STANDARD_CLASSES:\n","    stats = mapped_stats[std_act]\n","    status = \" [TAIL]\" if std_act in tail_standard_classes else \"\"\n","    status = \" [MISSING]\" if stats['windows'] == 0 else status\n","    print(f\"  {std_act:15s}: {stats['files']:2d} files, {stats['samples']:6d} samples, {stats['windows']:4d} windows{status}\")\n","\n","# Fixed encoding\n","label_to_id = {c: i for i, c in enumerate(STANDARD_CLASSES)}\n","id_to_label = {i: c for c, i in label_to_id.items()}\n","\n","print(\"\\nLabel encoding:\")\n","for i, c in id_to_label.items():\n","    print(f\"  {i}: {c}\")\n","\n","# Proband coverage matrix\n","print(\"\\nProband × Class coverage (number of windows):\")\n","print(f\"{'Proband':<12}\", end='')\n","for c in STANDARD_CLASSES:\n","    print(f\"{c[:4]:>6}\", end='')\n","print()\n","for p in sorted(proband_class_matrix.keys()):\n","    print(f\"{p:<12}\", end='')\n","    for c in STANDARD_CLASSES:\n","        cnt = proband_class_matrix[p][c]\n","        print(f\"{cnt:>6}\", end='')\n","    print()\n","\n","# Save configuration\n","classes_config = {\n","    'standard_classes': STANDARD_CLASSES,\n","    'num_classes': len(STANDARD_CLASSES),\n","    'label_to_id': label_to_id,\n","    'id_to_label': id_to_label,\n","    'activity_mapping': activity_mapping,\n","    'window_config': {\n","        'window_size_sec': WINDOW_SEC,\n","        'window_samples': WINDOW_SAMPLES,\n","        'overlap': OVERLAP,\n","        'stride_samples': STRIDE_SAMPLES,\n","        'sampling_rate_hz': TARGET_FS\n","    },\n","    'statistics': {\n","        'per_class': {c: {**mapped_stats[c], 'id': label_to_id[c]} for c in STANDARD_CLASSES},\n","        'tail_classes_original': tail_classes_original,\n","        'tail_standard_classes': tail_standard_classes,\n","        'included_flags': included_flags,\n","        'min_windows_threshold': MIN_WINDOWS_THRESHOLD,\n","        'proband_coverage': proband_class_matrix\n","    }\n","}\n","\n","with open('/content/configs/classes.json', 'w') as f:\n","    json.dump(classes_config, f, indent=2)\n","\n","print(f\"\\n✓ Class configuration saved: configs/classes.json\")\n","\n","if tail_standard_classes:\n","    print(f\"\\n⚠️ Tail classes at the standard level (windows < {MIN_WINDOWS_THRESHOLD}): {tail_standard_classes}\")\n","\n","included_classes = [c for c in STANDARD_CLASSES if included_flags[c]]\n","print(f\"✓ Classes included for training ({len(included_classes)}/{len(STANDARD_CLASSES)}): {included_classes}\")\n","\n","get_ipython().system('git add configs/classes.json')\n","get_ipython().system('git commit -m \"data: add standard-level tail classes and inclusion flags\"')\n","\n","print(f\"\\n{'='*60}\\nStep 6 completed\\n{'='*60}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g0muX01A0Udk","executionInfo":{"status":"ok","timestamp":1762688790570,"user_tz":0,"elapsed":6479,"user":{"displayName":"yu Wu","userId":"12692660435918028293"}},"outputId":"2a181075-a0af-4217-fa58-bdcce84ce140"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","Step 6: Class Mapping\n","============================================================\n","Sliding window: 3s (150 samples), overlap 50%, stride 75\n","\n","Found 112 files\n","\n","Original activity statistics:\n","  climbingdown   : 12 files, 284118 samples, 3425 windows\n","  climbingup     : 12 files, 357605 samples, 4331 windows\n","  jumping        : 15 files,  70663 samples,  842 windows\n","  lying          : 14 files, 436907 samples, 5343 windows\n","  running        : 15 files, 518843 samples, 6230 windows\n","  sitting        : 14 files, 433818 samples, 5259 windows\n","  standing       : 15 files, 459881 samples, 5574 windows\n","  walking        : 15 files, 468686 samples, 5618 windows\n","\n","Statistics for the 8 standard classes:\n","  walking        : 15 files, 468686 samples, 5618 windows\n","  running        : 15 files, 518843 samples, 6230 windows\n","  sitting        : 14 files, 433818 samples, 5259 windows\n","  standing       : 15 files, 459881 samples, 5574 windows\n","  lying          : 14 files, 436907 samples, 5343 windows\n","  stairs_up      : 12 files, 357605 samples, 4331 windows\n","  stairs_down    : 12 files, 284118 samples, 3425 windows\n","  jumping        : 15 files,  70663 samples,  842 windows\n","\n","Label encoding:\n","  0: walking\n","  1: running\n","  2: sitting\n","  3: standing\n","  4: lying\n","  5: stairs_up\n","  6: stairs_down\n","  7: jumping\n","\n","Proband × Class coverage (number of windows):\n","Proband       walk  runn  sitt  stan  lyin  stai  stai  jump\n","proband1       396   379     0   382     0   385   303    50\n","proband10      372   367   366   388   384   264   254    68\n","proband11      382   347   364   378   396   367   293    53\n","proband12      318   349   299   353   373   345   289    41\n","proband13      398   368   380   384   385   353   252    69\n","proband14      351   346   362   352   369     0     0    55\n","proband15      388   395   375   374   392   343   296    51\n","proband2       331   322   373   312   358   259   281    56\n","proband3       415   443   370   368   371   348   332    58\n","proband4       388   615   395   380   418     0     0    51\n","proband5       413   659   404   358   382   363   294    59\n","proband6       362   370   399   363   378   309   290    60\n","proband7       360   434   386   391   375     0     0    56\n","proband8       375   368   401   399   378   674   245    54\n","proband9       369   468   385   392   384   321   296    61\n","\n","✓ Class configuration saved: configs/classes.json\n","✓ Classes included for training (8/8): ['walking', 'running', 'sitting', 'standing', 'lying', 'stairs_up', 'stairs_down', 'jumping']\n","[master b40ff34] data: add standard-level tail classes and inclusion flags\n"," 1 file changed, 291 insertions(+)\n"," create mode 100644 configs/classes.json\n","\n","============================================================\n","Step 6 completed\n","============================================================\n"]}]},{"cell_type":"code","source":["# ================ Step 7: LOSO Subject Splits ================\n","import pandas as pd\n","from pathlib import Path\n","import json\n","\n","print(\"\\n\\nStep 7: LOSO Subject Splits\")\n","print(\"=\" * 60)\n","\n","proc_dir = Path('/content/proc')\n","\n","# Scan all files and extract subjects\n","proc_files = sorted(proc_dir.glob('*.csv'))\n","print(f\"Found {len(proc_files)} files\")\n","\n","subjects = set()\n","file_subject_map = {}\n","\n","for filepath in proc_files:\n","    df = pd.read_csv(filepath)\n","    subject = df['proband'].iloc[0] if 'proband' in df.columns else filepath.stem.split('_')[0]\n","    subjects.add(subject)\n","    file_subject_map[filepath.name] = subject\n","\n","subjects = sorted(subjects)\n","print(f\"\\n✓ Total subjects: {len(subjects)}\")\n","print(f\"Subject list: {subjects}\")\n","\n","# Create LOSO folds\n","loso_splits = []\n","\n","for fold_id, test_subject in enumerate(subjects):\n","    train_subjects = [s for s in subjects if s != test_subject]\n","\n","    loso_splits.append({\n","        'fold': fold_id,\n","        'test_subject': test_subject,\n","        'train_subjects': train_subjects,\n","        'n_train': len(train_subjects),\n","        'n_test': 1\n","    })\n","\n","    print(f\"\\nFold {fold_id}: Test={test_subject}, Train={train_subjects}\")\n","\n","# Save as CSV\n","splits_csv = []\n","for split in loso_splits:\n","    splits_csv.append({\n","        'fold': split['fold'],\n","        'test_subject': split['test_subject'],\n","        'train_subjects': ','.join(split['train_subjects']),\n","        'n_train': split['n_train'],\n","        'n_test': split['n_test']\n","    })\n","\n","df_splits = pd.DataFrame(splits_csv)\n","df_splits.to_csv('/content/logs/splits.csv', index=False)\n","print(f\"\\n✓ Splits saved: logs/splits.csv\")\n","print(\"\\n\" + df_splits.to_string(index=False))\n","\n","# Save as JSON (for convenient downstream loading)\n","splits_config = {\n","    'split_method': 'LOSO',\n","    'n_folds': len(subjects),\n","    'subjects': subjects,\n","    'file_subject_map': file_subject_map,\n","    'folds': loso_splits\n","}\n","\n","with open('/content/configs/splits.json', 'w') as f:\n","    json.dump(splits_config, f, indent=2)\n","\n","print(f\"\\n✓ Split configuration saved: configs/splits.json\")\n","\n","# Validation: each subject is used exactly once as test set\n","test_subjects_count = pd.Series([s['test_subject'] for s in loso_splits]).value_counts()\n","assert (test_subjects_count == 1).all(), \"Each subject should appear exactly once as the test set\"\n","print(f\"\\n✓ Validation passed: each subject appears exactly once as the test set\")\n","\n","get_ipython().system('git add logs/splits.csv configs/splits.json')\n","get_ipython().system('git commit -m \"split: create LOSO folds (leave-one-subject-out)\"')\n","\n","print(f\"\\n{'='*60}\\nStep 7 completed\\n{'='*60}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zUbhv1Ei0jAD","executionInfo":{"status":"ok","timestamp":1762688796711,"user_tz":0,"elapsed":6135,"user":{"displayName":"yu Wu","userId":"12692660435918028293"}},"outputId":"40553002-cec8-49fc-e825-193cf32e0537"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","Step 7: LOSO Subject Splits\n","============================================================\n","Found 112 files\n","\n","✓ Total subjects: 15\n","Subject list: ['proband1', 'proband10', 'proband11', 'proband12', 'proband13', 'proband14', 'proband15', 'proband2', 'proband3', 'proband4', 'proband5', 'proband6', 'proband7', 'proband8', 'proband9']\n","\n","Fold 0: Test=proband1, Train=['proband10', 'proband11', 'proband12', 'proband13', 'proband14', 'proband15', 'proband2', 'proband3', 'proband4', 'proband5', 'proband6', 'proband7', 'proband8', 'proband9']\n","\n","Fold 1: Test=proband10, Train=['proband1', 'proband11', 'proband12', 'proband13', 'proband14', 'proband15', 'proband2', 'proband3', 'proband4', 'proband5', 'proband6', 'proband7', 'proband8', 'proband9']\n","\n","Fold 2: Test=proband11, Train=['proband1', 'proband10', 'proband12', 'proband13', 'proband14', 'proband15', 'proband2', 'proband3', 'proband4', 'proband5', 'proband6', 'proband7', 'proband8', 'proband9']\n","\n","Fold 3: Test=proband12, Train=['proband1', 'proband10', 'proband11', 'proband13', 'proband14', 'proband15', 'proband2', 'proband3', 'proband4', 'proband5', 'proband6', 'proband7', 'proband8', 'proband9']\n","\n","Fold 4: Test=proband13, Train=['proband1', 'proband10', 'proband11', 'proband12', 'proband14', 'proband15', 'proband2', 'proband3', 'proband4', 'proband5', 'proband6', 'proband7', 'proband8', 'proband9']\n","\n","Fold 5: Test=proband14, Train=['proband1', 'proband10', 'proband11', 'proband12', 'proband13', 'proband15', 'proband2', 'proband3', 'proband4', 'proband5', 'proband6', 'proband7', 'proband8', 'proband9']\n","\n","Fold 6: Test=proband15, Train=['proband1', 'proband10', 'proband11', 'proband12', 'proband13', 'proband14', 'proband2', 'proband3', 'proband4', 'proband5', 'proband6', 'proband7', 'proband8', 'proband9']\n","\n","Fold 7: Test=proband2, Train=['proband1', 'proband10', 'proband11', 'proband12', 'proband13', 'proband14', 'proband15', 'proband3', 'proband4', 'proband5', 'proband6', 'proband7', 'proband8', 'proband9']\n","\n","Fold 8: Test=proband3, Train=['proband1', 'proband10', 'proband11', 'proband12', 'proband13', 'proband14', 'proband15', 'proband2', 'proband4', 'proband5', 'proband6', 'proband7', 'proband8', 'proband9']\n","\n","Fold 9: Test=proband4, Train=['proband1', 'proband10', 'proband11', 'proband12', 'proband13', 'proband14', 'proband15', 'proband2', 'proband3', 'proband5', 'proband6', 'proband7', 'proband8', 'proband9']\n","\n","Fold 10: Test=proband5, Train=['proband1', 'proband10', 'proband11', 'proband12', 'proband13', 'proband14', 'proband15', 'proband2', 'proband3', 'proband4', 'proband6', 'proband7', 'proband8', 'proband9']\n","\n","Fold 11: Test=proband6, Train=['proband1', 'proband10', 'proband11', 'proband12', 'proband13', 'proband14', 'proband15', 'proband2', 'proband3', 'proband4', 'proband5', 'proband7', 'proband8', 'proband9']\n","\n","Fold 12: Test=proband7, Train=['proband1', 'proband10', 'proband11', 'proband12', 'proband13', 'proband14', 'proband15', 'proband2', 'proband3', 'proband4', 'proband5', 'proband6', 'proband8', 'proband9']\n","\n","Fold 13: Test=proband8, Train=['proband1', 'proband10', 'proband11', 'proband12', 'proband13', 'proband14', 'proband15', 'proband2', 'proband3', 'proband4', 'proband5', 'proband6', 'proband7', 'proband9']\n","\n","Fold 14: Test=proband9, Train=['proband1', 'proband10', 'proband11', 'proband12', 'proband13', 'proband14', 'proband15', 'proband2', 'proband3', 'proband4', 'proband5', 'proband6', 'proband7', 'proband8']\n","\n","✓ Splits saved: logs/splits.csv\n","\n"," fold test_subject                                                                                                                      train_subjects  n_train  n_test\n","    0     proband1 proband10,proband11,proband12,proband13,proband14,proband15,proband2,proband3,proband4,proband5,proband6,proband7,proband8,proband9       14       1\n","    1    proband10  proband1,proband11,proband12,proband13,proband14,proband15,proband2,proband3,proband4,proband5,proband6,proband7,proband8,proband9       14       1\n","    2    proband11  proband1,proband10,proband12,proband13,proband14,proband15,proband2,proband3,proband4,proband5,proband6,proband7,proband8,proband9       14       1\n","    3    proband12  proband1,proband10,proband11,proband13,proband14,proband15,proband2,proband3,proband4,proband5,proband6,proband7,proband8,proband9       14       1\n","    4    proband13  proband1,proband10,proband11,proband12,proband14,proband15,proband2,proband3,proband4,proband5,proband6,proband7,proband8,proband9       14       1\n","    5    proband14  proband1,proband10,proband11,proband12,proband13,proband15,proband2,proband3,proband4,proband5,proband6,proband7,proband8,proband9       14       1\n","    6    proband15  proband1,proband10,proband11,proband12,proband13,proband14,proband2,proband3,proband4,proband5,proband6,proband7,proband8,proband9       14       1\n","    7     proband2 proband1,proband10,proband11,proband12,proband13,proband14,proband15,proband3,proband4,proband5,proband6,proband7,proband8,proband9       14       1\n","    8     proband3 proband1,proband10,proband11,proband12,proband13,proband14,proband15,proband2,proband4,proband5,proband6,proband7,proband8,proband9       14       1\n","    9     proband4 proband1,proband10,proband11,proband12,proband13,proband14,proband15,proband2,proband3,proband5,proband6,proband7,proband8,proband9       14       1\n","   10     proband5 proband1,proband10,proband11,proband12,proband13,proband14,proband15,proband2,proband3,proband4,proband6,proband7,proband8,proband9       14       1\n","   11     proband6 proband1,proband10,proband11,proband12,proband13,proband14,proband15,proband2,proband3,proband4,proband5,proband7,proband8,proband9       14       1\n","   12     proband7 proband1,proband10,proband11,proband12,proband13,proband14,proband15,proband2,proband3,proband4,proband5,proband6,proband8,proband9       14       1\n","   13     proband8 proband1,proband10,proband11,proband12,proband13,proband14,proband15,proband2,proband3,proband4,proband5,proband6,proband7,proband9       14       1\n","   14     proband9 proband1,proband10,proband11,proband12,proband13,proband14,proband15,proband2,proband3,proband4,proband5,proband6,proband7,proband8       14       1\n","\n","✓ Split configuration saved: configs/splits.json\n","\n","✓ Validation passed: each subject appears exactly once as the test set\n","[master c74ec36] split: create LOSO folds (leave-one-subject-out)\n"," 2 files changed, 483 insertions(+)\n"," create mode 100644 configs/splits.json\n"," create mode 100644 logs/splits.csv\n","\n","============================================================\n","Step 7 completed\n","============================================================\n"]}]},{"cell_type":"code","source":["# ================ Step 8: Sliding Windowing and Label Assignment ================\n","import numpy as np\n","import pandas as pd\n","from pathlib import Path\n","import json\n","from collections import defaultdict\n","\n","print(\"\\n\\nStep 8: Sliding Windowing and Label Assignment\")\n","print(\"=\" * 60)\n","\n","# Load configuration\n","with open('/content/configs/classes.json', 'r') as f:\n","    classes_cfg = json.load(f)\n","\n","with open('/content/configs/splits.json', 'r') as f:\n","    splits_cfg = json.load(f)\n","\n","proc_dir = Path('/content/proc')\n","features_dir = Path('/content/features')\n","features_dir.mkdir(exist_ok=True)\n","\n","# Window parameters\n","WINDOW_SEC = 3\n","OVERLAP = 0.5\n","TARGET_FS = 50\n","WINDOW_SAMPLES = int(TARGET_FS * WINDOW_SEC)\n","STRIDE_SAMPLES = int(WINDOW_SAMPLES * (1 - OVERLAP))\n","DOMINANT_THRESHOLD = 0.8\n","\n","label_to_id = classes_cfg['label_to_id']\n","\n","print(f\"Window parameters: {WINDOW_SEC}s ({WINDOW_SAMPLES} samples), overlap {OVERLAP*100:.0f}%, stride {STRIDE_SAMPLES}\")\n","print(f\"Dominant-label threshold: {DOMINANT_THRESHOLD*100:.0f}%\\n\")\n","\n","# Process each file to generate all windows\n","proc_files = sorted(proc_dir.glob('*.csv'))\n","print(f\"Processing {len(proc_files)} files...\\n\")\n","\n","all_windows = []\n","discarded_windows = 0\n","\n","for file_idx, filepath in enumerate(proc_files):\n","    df = pd.read_csv(filepath)\n","\n","    subject = df['proband'].iloc[0]\n","    activity = df['activity'].iloc[0]\n","    std_label = classes_cfg['activity_mapping'].get(activity, activity)\n","    label_id = label_to_id[std_label]\n","\n","    file_windows = 0\n","    for seg_id, seg_df in df.groupby('segment_id'):\n","        seg_df = seg_df.reset_index(drop=True)\n","        seg_len = len(seg_df)\n","\n","        if seg_len < WINDOW_SAMPLES:\n","            continue\n","\n","        for start_idx in range(0, seg_len - WINDOW_SAMPLES + 1, STRIDE_SAMPLES):\n","            end_idx = start_idx + WINDOW_SAMPLES\n","            window = seg_df.iloc[start_idx:end_idx]\n","\n","            # Check dominant label\n","            window_labels = window['activity'].values\n","            unique_labels, counts = np.unique(window_labels, return_counts=True)\n","            dominant_idx = counts.argmax()\n","            dominant_label = unique_labels[dominant_idx]\n","            dominant_ratio = counts[dominant_idx] / len(window_labels)\n","\n","            if dominant_ratio < DOMINANT_THRESHOLD:\n","                discarded_windows += 1\n","                continue\n","\n","            # Save window\n","            window_data = {\n","                'subject': subject,\n","                'activity': std_label,\n","                'label': label_id,\n","                'file': filepath.name,\n","                'segment_id': seg_id,\n","                'start_idx': start_idx,\n","                'dominant_ratio': dominant_ratio\n","            }\n","\n","            for col in ['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_y', 'gyro_z']:\n","                window_data[col] = window[col].values.tolist()\n","\n","            all_windows.append(window_data)\n","            file_windows += 1\n","\n","    print(f\"[{file_idx+1}/{len(proc_files)}] {filepath.name}: {file_windows} windows ({std_label}, {subject})\")\n","\n","print(f\"\\n✓ Total windows: {len(all_windows)}\")\n","print(f\"✓ Discarded windows: {discarded_windows} (dominant label < {DOMINANT_THRESHOLD*100:.0f}%)\")\n","\n","# Save window metadata (excluding sensor data)\n","windows_meta = pd.DataFrame([{k: v for k, v in w.items()\n","                              if k not in ['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_y', 'gyro_z']}\n","                             for w in all_windows])\n","\n","# Add window IDs\n","windows_meta['window_id'] = (windows_meta['file'] + ':' +\n","                              windows_meta['segment_id'].astype(str) + ':' +\n","                              windows_meta['start_idx'].astype(str))\n","\n","windows_meta.to_csv(features_dir / 'windows_meta.csv', index=False)\n","print(f\"\\n✓ Global window metadata: features/windows_meta.csv\")\n","\n","# Save complete window data\n","with open(features_dir / 'windows_raw.json', 'w') as f:\n","    json.dump(all_windows, f)\n","print(f\"✓ Raw window data: features/windows_raw.json\")\n","\n","# Generate train/test split per fold\n","print(\"\\n\" + \"=\"*60)\n","print(\"Generate train/test splits per fold:\")\n","print(\"=\"*60)\n","\n","per_fold_totals = []\n","\n","for fold in splits_cfg['folds']:\n","    k = fold['fold']\n","    test_subj = fold['test_subject']\n","\n","    # Mark train/test\n","    fold_meta = windows_meta.copy()\n","    fold_meta['fold'] = k\n","    fold_meta['split'] = np.where(fold_meta['subject'] == test_subj, 'test', 'train')\n","\n","    # Save metadata for this fold\n","    fold_meta.to_csv(features_dir / f'windows_meta_fold{k}.csv', index=False)\n","\n","    # Per-fold statistics\n","    stats = fold_meta.groupby(['split', 'activity', 'subject']).size().reset_index(name='windows')\n","    stats.to_csv(f'/content/logs/window_stats_fold{k}.csv', index=False)\n","\n","    n_train = int((fold_meta['split'] == 'train').sum())\n","    n_test = int((fold_meta['split'] == 'test').sum())\n","\n","    per_fold_totals.append({\n","        'fold': k,\n","        'test_subject': test_subj,\n","        'n_train_windows': n_train,\n","        'n_test_windows': n_test,\n","        'n_total': n_train + n_test\n","    })\n","\n","    print(f\"Fold {k}: Train={n_train}, Test={n_test}, test subject={test_subj}\")\n","\n","# Save fold-level summary\n","df_fold_totals = pd.DataFrame(per_fold_totals)\n","df_fold_totals.to_csv('/content/logs/window_fold_totals.csv', index=False)\n","print(f\"\\n✓ Fold-level summary: logs/window_fold_totals.csv\")\n","\n","# Global summary\n","summary = {\n","    'total_windows': len(all_windows),\n","    'discarded_windows': discarded_windows,\n","    'window_params': {\n","        'window_size_sec': WINDOW_SEC,\n","        'window_samples': WINDOW_SAMPLES,\n","        'overlap': OVERLAP,\n","        'stride_samples': STRIDE_SAMPLES,\n","        'dominant_threshold': DOMINANT_THRESHOLD\n","    },\n","    'per_class_totals': windows_meta.groupby('activity')['window_id'].count().to_dict(),\n","    'per_subject_totals': windows_meta.groupby('subject')['window_id'].count().to_dict()\n","}\n","\n","with open('/content/logs/window_summary.json', 'w') as f:\n","    json.dump(summary, f, indent=2)\n","\n","print(\"\\nGlobal statistics:\")\n","print(f\"  Per class: {summary['per_class_totals']}\")\n","print(f\"  Per subject: {summary['per_subject_totals']}\")\n","\n","get_ipython().system('git add features/ logs/window_*.csv logs/window_*.json')\n","get_ipython().system('git commit -m \"feature: windowing with per-fold train/test splits\"')\n","\n","print(f\"\\n{'='*60}\\nStep 8 completed\\n{'='*60}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xjAx0IGy01Z5","executionInfo":{"status":"ok","timestamp":1762688891863,"user_tz":0,"elapsed":95151,"user":{"displayName":"yu Wu","userId":"12692660435918028293"}},"outputId":"73ea32c8-e2e3-4ed4-84ec-0341afd24063"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","Step 8: Sliding Windowing and Label Assignment\n","============================================================\n","Window parameters: 3s (150 samples), overlap 50%, stride 75\n","Dominant-label threshold: 80%\n","\n","Processing 112 files...\n","\n","[1/112] proband10_climbingdown_waist.csv: 254 windows (stairs_down, proband10)\n","[2/112] proband10_climbingup_waist.csv: 264 windows (stairs_up, proband10)\n","[3/112] proband10_jumping_waist.csv: 68 windows (jumping, proband10)\n","[4/112] proband10_lying_waist.csv: 384 windows (lying, proband10)\n","[5/112] proband10_running_waist.csv: 367 windows (running, proband10)\n","[6/112] proband10_sitting_waist.csv: 366 windows (sitting, proband10)\n","[7/112] proband10_standing_waist.csv: 388 windows (standing, proband10)\n","[8/112] proband10_walking_waist.csv: 372 windows (walking, proband10)\n","[9/112] proband11_climbingdown_waist.csv: 293 windows (stairs_down, proband11)\n","[10/112] proband11_climbingup_waist.csv: 367 windows (stairs_up, proband11)\n","[11/112] proband11_jumping_waist.csv: 53 windows (jumping, proband11)\n","[12/112] proband11_lying_waist.csv: 396 windows (lying, proband11)\n","[13/112] proband11_running_waist.csv: 347 windows (running, proband11)\n","[14/112] proband11_sitting_waist.csv: 364 windows (sitting, proband11)\n","[15/112] proband11_standing_waist.csv: 378 windows (standing, proband11)\n","[16/112] proband11_walking_waist.csv: 382 windows (walking, proband11)\n","[17/112] proband12_climbingdown_waist.csv: 289 windows (stairs_down, proband12)\n","[18/112] proband12_climbingup_waist.csv: 345 windows (stairs_up, proband12)\n","[19/112] proband12_jumping_waist.csv: 41 windows (jumping, proband12)\n","[20/112] proband12_lying_waist.csv: 373 windows (lying, proband12)\n","[21/112] proband12_running_waist.csv: 349 windows (running, proband12)\n","[22/112] proband12_sitting_waist.csv: 299 windows (sitting, proband12)\n","[23/112] proband12_standing_waist.csv: 353 windows (standing, proband12)\n","[24/112] proband12_walking_waist.csv: 318 windows (walking, proband12)\n","[25/112] proband13_climbingdown_waist.csv: 252 windows (stairs_down, proband13)\n","[26/112] proband13_climbingup_waist.csv: 353 windows (stairs_up, proband13)\n","[27/112] proband13_jumping_waist.csv: 69 windows (jumping, proband13)\n","[28/112] proband13_lying_waist.csv: 385 windows (lying, proband13)\n","[29/112] proband13_running_waist.csv: 368 windows (running, proband13)\n","[30/112] proband13_sitting_waist.csv: 380 windows (sitting, proband13)\n","[31/112] proband13_standing_waist.csv: 384 windows (standing, proband13)\n","[32/112] proband13_walking_waist.csv: 398 windows (walking, proband13)\n","[33/112] proband14_jumping_waist.csv: 55 windows (jumping, proband14)\n","[34/112] proband14_lying_waist.csv: 369 windows (lying, proband14)\n","[35/112] proband14_running_waist.csv: 346 windows (running, proband14)\n","[36/112] proband14_sitting_waist.csv: 362 windows (sitting, proband14)\n","[37/112] proband14_standing_waist.csv: 352 windows (standing, proband14)\n","[38/112] proband14_walking_waist.csv: 351 windows (walking, proband14)\n","[39/112] proband15_climbingdown_waist.csv: 296 windows (stairs_down, proband15)\n","[40/112] proband15_climbingup_waist.csv: 343 windows (stairs_up, proband15)\n","[41/112] proband15_jumping_waist.csv: 51 windows (jumping, proband15)\n","[42/112] proband15_lying_waist.csv: 392 windows (lying, proband15)\n","[43/112] proband15_running_waist.csv: 395 windows (running, proband15)\n","[44/112] proband15_sitting_waist.csv: 375 windows (sitting, proband15)\n","[45/112] proband15_standing_waist.csv: 374 windows (standing, proband15)\n","[46/112] proband15_walking_waist.csv: 388 windows (walking, proband15)\n","[47/112] proband1_climbingdown_waist.csv: 303 windows (stairs_down, proband1)\n","[48/112] proband1_climbingup_waist.csv: 385 windows (stairs_up, proband1)\n","[49/112] proband1_jumping_waist.csv: 50 windows (jumping, proband1)\n","[50/112] proband1_running_waist.csv: 379 windows (running, proband1)\n","[51/112] proband1_standing_waist.csv: 382 windows (standing, proband1)\n","[52/112] proband1_walking_waist.csv: 396 windows (walking, proband1)\n","[53/112] proband2_climbingdown_waist.csv: 281 windows (stairs_down, proband2)\n","[54/112] proband2_climbingup_waist.csv: 259 windows (stairs_up, proband2)\n","[55/112] proband2_jumping_waist.csv: 56 windows (jumping, proband2)\n","[56/112] proband2_lying_waist.csv: 358 windows (lying, proband2)\n","[57/112] proband2_running_waist.csv: 322 windows (running, proband2)\n","[58/112] proband2_sitting_waist.csv: 373 windows (sitting, proband2)\n","[59/112] proband2_standing_waist.csv: 312 windows (standing, proband2)\n","[60/112] proband2_walking_waist.csv: 331 windows (walking, proband2)\n","[61/112] proband3_climbingdown_waist.csv: 332 windows (stairs_down, proband3)\n","[62/112] proband3_climbingup_waist.csv: 348 windows (stairs_up, proband3)\n","[63/112] proband3_jumping_waist.csv: 58 windows (jumping, proband3)\n","[64/112] proband3_lying_waist.csv: 371 windows (lying, proband3)\n","[65/112] proband3_running_waist.csv: 443 windows (running, proband3)\n","[66/112] proband3_sitting_waist.csv: 370 windows (sitting, proband3)\n","[67/112] proband3_standing_waist.csv: 368 windows (standing, proband3)\n","[68/112] proband3_walking_waist.csv: 415 windows (walking, proband3)\n","[69/112] proband4_jumping_waist.csv: 51 windows (jumping, proband4)\n","[70/112] proband4_lying_waist.csv: 418 windows (lying, proband4)\n","[71/112] proband4_running_waist.csv: 615 windows (running, proband4)\n","[72/112] proband4_sitting_waist.csv: 395 windows (sitting, proband4)\n","[73/112] proband4_standing_waist.csv: 380 windows (standing, proband4)\n","[74/112] proband4_walking_waist.csv: 388 windows (walking, proband4)\n","[75/112] proband5_climbingdown_waist.csv: 294 windows (stairs_down, proband5)\n","[76/112] proband5_climbingup_waist.csv: 363 windows (stairs_up, proband5)\n","[77/112] proband5_jumping_waist.csv: 59 windows (jumping, proband5)\n","[78/112] proband5_lying_waist.csv: 382 windows (lying, proband5)\n","[79/112] proband5_running_waist.csv: 659 windows (running, proband5)\n","[80/112] proband5_sitting_waist.csv: 404 windows (sitting, proband5)\n","[81/112] proband5_standing_waist.csv: 358 windows (standing, proband5)\n","[82/112] proband5_walking_waist.csv: 413 windows (walking, proband5)\n","[83/112] proband6_climbingdown_waist.csv: 290 windows (stairs_down, proband6)\n","[84/112] proband6_climbingup_waist.csv: 309 windows (stairs_up, proband6)\n","[85/112] proband6_jumping_waist.csv: 60 windows (jumping, proband6)\n","[86/112] proband6_lying_waist.csv: 378 windows (lying, proband6)\n","[87/112] proband6_running_waist.csv: 370 windows (running, proband6)\n","[88/112] proband6_sitting_waist.csv: 399 windows (sitting, proband6)\n","[89/112] proband6_standing_waist.csv: 363 windows (standing, proband6)\n","[90/112] proband6_walking_waist.csv: 362 windows (walking, proband6)\n","[91/112] proband7_jumping_waist.csv: 56 windows (jumping, proband7)\n","[92/112] proband7_lying_waist.csv: 375 windows (lying, proband7)\n","[93/112] proband7_running_waist.csv: 434 windows (running, proband7)\n","[94/112] proband7_sitting_waist.csv: 386 windows (sitting, proband7)\n","[95/112] proband7_standing_waist.csv: 391 windows (standing, proband7)\n","[96/112] proband7_walking_waist.csv: 360 windows (walking, proband7)\n","[97/112] proband8_climbingdown_waist.csv: 245 windows (stairs_down, proband8)\n","[98/112] proband8_climbingup_waist.csv: 674 windows (stairs_up, proband8)\n","[99/112] proband8_jumping_waist.csv: 54 windows (jumping, proband8)\n","[100/112] proband8_lying_waist.csv: 378 windows (lying, proband8)\n","[101/112] proband8_running_waist.csv: 368 windows (running, proband8)\n","[102/112] proband8_sitting_waist.csv: 401 windows (sitting, proband8)\n","[103/112] proband8_standing_waist.csv: 399 windows (standing, proband8)\n","[104/112] proband8_walking_waist.csv: 375 windows (walking, proband8)\n","[105/112] proband9_climbingdown_waist.csv: 296 windows (stairs_down, proband9)\n","[106/112] proband9_climbingup_waist.csv: 321 windows (stairs_up, proband9)\n","[107/112] proband9_jumping_waist.csv: 61 windows (jumping, proband9)\n","[108/112] proband9_lying_waist.csv: 384 windows (lying, proband9)\n","[109/112] proband9_running_waist.csv: 468 windows (running, proband9)\n","[110/112] proband9_sitting_waist.csv: 385 windows (sitting, proband9)\n","[111/112] proband9_standing_waist.csv: 392 windows (standing, proband9)\n","[112/112] proband9_walking_waist.csv: 369 windows (walking, proband9)\n","\n","✓ Total windows: 36622\n","✓ Discarded windows: 0 (dominant label < 80%)\n","\n","✓ Global window metadata: features/windows_meta.csv\n","✓ Raw window data: features/windows_raw.json\n","\n","============================================================\n","Generate train/test splits per fold:\n","============================================================\n","Fold 0: Train=34727, Test=1895, test subject=proband1\n","Fold 1: Train=34159, Test=2463, test subject=proband10\n","Fold 2: Train=34042, Test=2580, test subject=proband11\n","Fold 3: Train=34255, Test=2367, test subject=proband12\n","Fold 4: Train=34033, Test=2589, test subject=proband13\n","Fold 5: Train=34787, Test=1835, test subject=proband14\n","Fold 6: Train=34008, Test=2614, test subject=proband15\n","Fold 7: Train=34330, Test=2292, test subject=proband2\n","Fold 8: Train=33917, Test=2705, test subject=proband3\n","Fold 9: Train=34375, Test=2247, test subject=proband4\n","Fold 10: Train=33690, Test=2932, test subject=proband5\n","Fold 11: Train=34091, Test=2531, test subject=proband6\n","Fold 12: Train=34620, Test=2002, test subject=proband7\n","Fold 13: Train=33728, Test=2894, test subject=proband8\n","Fold 14: Train=33946, Test=2676, test subject=proband9\n","\n","✓ Fold-level summary: logs/window_fold_totals.csv\n","\n","Global statistics:\n","  Per class: {'jumping': 842, 'lying': 5343, 'running': 6230, 'sitting': 5259, 'stairs_down': 3425, 'stairs_up': 4331, 'standing': 5574, 'walking': 5618}\n","  Per subject: {'proband1': 1895, 'proband10': 2463, 'proband11': 2580, 'proband12': 2367, 'proband13': 2589, 'proband14': 1835, 'proband15': 2614, 'proband2': 2292, 'proband3': 2705, 'proband4': 2247, 'proband5': 2932, 'proband6': 2531, 'proband7': 2002, 'proband8': 2894, 'proband9': 2676}\n","[master 2568712] feature: windowing with per-fold train/test splits\n"," 34 files changed, 587717 insertions(+)\n"," create mode 100644 features/windows_meta.csv\n"," create mode 100644 features/windows_meta_fold0.csv\n"," create mode 100644 features/windows_meta_fold1.csv\n"," create mode 100644 features/windows_meta_fold10.csv\n"," create mode 100644 features/windows_meta_fold11.csv\n"," create mode 100644 features/windows_meta_fold12.csv\n"," create mode 100644 features/windows_meta_fold13.csv\n"," create mode 100644 features/windows_meta_fold14.csv\n"," create mode 100644 features/windows_meta_fold2.csv\n"," create mode 100644 features/windows_meta_fold3.csv\n"," create mode 100644 features/windows_meta_fold4.csv\n"," create mode 100644 features/windows_meta_fold5.csv\n"," create mode 100644 features/windows_meta_fold6.csv\n"," create mode 100644 features/windows_meta_fold7.csv\n"," create mode 100644 features/windows_meta_fold8.csv\n"," create mode 100644 features/windows_meta_fold9.csv\n"," create mode 100644 features/windows_raw.json\n"," create mode 100644 logs/window_fold_totals.csv\n"," create mode 100644 logs/window_stats_fold0.csv\n"," create mode 100644 logs/window_stats_fold1.csv\n"," create mode 100644 logs/window_stats_fold10.csv\n"," create mode 100644 logs/window_stats_fold11.csv\n"," create mode 100644 logs/window_stats_fold12.csv\n"," create mode 100644 logs/window_stats_fold13.csv\n"," create mode 100644 logs/window_stats_fold14.csv\n"," create mode 100644 logs/window_stats_fold2.csv\n"," create mode 100644 logs/window_stats_fold3.csv\n"," create mode 100644 logs/window_stats_fold4.csv\n"," create mode 100644 logs/window_stats_fold5.csv\n"," create mode 100644 logs/window_stats_fold6.csv\n"," create mode 100644 logs/window_stats_fold7.csv\n"," create mode 100644 logs/window_stats_fold8.csv\n"," create mode 100644 logs/window_stats_fold9.csv\n"," create mode 100644 logs/window_summary.json\n","\n","============================================================\n","Step 8 completed\n","============================================================\n"]}]},{"cell_type":"code","source":["# ================ Step 9: Per-Fold Standardization (Performance-Optimized) ================\n","import numpy as np\n","import pandas as pd\n","from pathlib import Path\n","import json\n","\n","print(\"\\n\\nStep 9: Per-Fold Standardization (z-score)\")\n","print(\"=\" * 60)\n","\n","# Load configuration\n","with open('/content/configs/splits.json', 'r') as f:\n","    splits_cfg = json.load(f)\n","\n","# Load window data\n","with open('/content/features/windows_raw.json', 'r') as f:\n","    all_windows = json.load(f)\n","\n","features_dir = Path('/content/features')\n","proc_dir = Path('/content/proc')\n","\n","CHANNELS = ['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_y', 'gyro_z']\n","EPS = 1e-8\n","\n","print(f\"Channels: {CHANNELS}\")\n","print(f\"Total windows: {len(all_windows)}\\n\")\n","\n","scaler_summary = []\n","\n","for fold in splits_cfg['folds']:\n","    k = fold['fold']\n","    test_subj = fold['test_subject']\n","\n","    print(f\"\\nFold {k}: test subject={test_subj}\")\n","\n","    fold_meta = pd.read_csv(features_dir / f'windows_meta_fold{k}.csv')\n","    assert len(all_windows) == len(fold_meta), f\"Window count mismatch: {len(all_windows)} vs {len(fold_meta)}\"\n","\n","    train_indices = set(fold_meta[fold_meta['split'] == 'train'].index.tolist())\n","    test_indices = set(fold_meta[fold_meta['split'] == 'test'].index.tolist())\n","\n","    print(f\"  Train windows: {len(train_indices)}, Test windows: {len(test_indices)}\")\n","\n","    # Vectorized collection of training data\n","    train_data = {ch: [] for ch in CHANNELS}\n","    for idx in train_indices:\n","        window = all_windows[idx]\n","        for ch in CHANNELS:\n","            train_data[ch].extend(window[ch])\n","\n","    # Convert to NumPy arrays and compute parameters\n","    scaler_params = {}\n","    for ch in CHANNELS:\n","        data = np.array(train_data[ch], dtype=np.float32)\n","        mean = float(data.mean())\n","        std = float(max(data.std(), EPS))\n","        scaler_params[ch] = {'mean': mean, 'std': std}\n","\n","    print(f\"  Scaler parameters:\")\n","    for ch in CHANNELS:\n","        print(f\"    {ch}: mean={scaler_params[ch]['mean']:.4f}, std={scaler_params[ch]['std']:.4f}\")\n","\n","    # Vectorized standardization and save as NPZ\n","    norm_data = {\n","        'window_ids': [],\n","        'subjects': [],\n","        'activities': [],\n","        'labels': [],\n","        'splits': []\n","    }\n","    for ch in CHANNELS:\n","        norm_data[ch] = []\n","\n","    train_norm = {ch: [] for ch in CHANNELS}\n","    test_norm = {ch: [] for ch in CHANNELS}\n","\n","    for idx in range(len(all_windows)):\n","        window = all_windows[idx]\n","\n","        if idx in train_indices:\n","            split = 'train'\n","        elif idx in test_indices:\n","            split = 'test'\n","        else:\n","            continue\n","\n","        norm_data['window_ids'].append(fold_meta.loc[idx, 'window_id'])\n","        norm_data['subjects'].append(window['subject'])\n","        norm_data['activities'].append(window['activity'])\n","        norm_data['labels'].append(window['label'])\n","        norm_data['splits'].append(split)\n","\n","        for ch in CHANNELS:\n","            data = np.array(window[ch], dtype=np.float32)\n","            normalized = (data - scaler_params[ch]['mean']) / scaler_params[ch]['std']\n","            norm_data[ch].append(normalized)\n","\n","            # Collect statistics for validation\n","            if split == 'train':\n","                train_norm[ch].extend(normalized)\n","            else:\n","                test_norm[ch].extend(normalized)\n","\n","    # Post-standardization validation: training set\n","    print(f\"  Training-set validation after standardization:\")\n","    for ch in CHANNELS:\n","        mean_val = np.mean(train_norm[ch])\n","        std_val = np.std(train_norm[ch])\n","        print(f\"    {ch}: mean={mean_val:.6f}, std={std_val:.6f}\")\n","\n","    # Post-standardization validation: test set\n","    print(f\"  Test-set validation after standardization:\")\n","    for ch in CHANNELS:\n","        if test_norm[ch]:\n","            mean_val = np.mean(test_norm[ch])\n","            print(f\"    {ch}: mean={mean_val:.6f}\")\n","\n","    # Persist scaler parameters\n","    scaler_file = proc_dir / f'scaler_fold{k}.npz'\n","    np.savez(scaler_file, **{f'{ch}_mean': scaler_params[ch]['mean'] for ch in CHANNELS},\n","                          **{f'{ch}_std': scaler_params[ch]['std'] for ch in CHANNELS})\n","\n","    # Persist standardized windows as NPZ (float32)\n","    norm_file = features_dir / f'windows_normalized_fold{k}.npz'\n","    np.savez_compressed(norm_file,\n","                       window_ids=np.array(norm_data['window_ids']),\n","                       subjects=np.array(norm_data['subjects']),\n","                       activities=np.array(norm_data['activities']),\n","                       labels=np.array(norm_data['labels'], dtype=np.int32),\n","                       splits=np.array(norm_data['splits']),\n","                       **{ch: np.array(norm_data[ch], dtype=np.float32) for ch in CHANNELS})\n","\n","    print(f\"  ✓ Saved: {scaler_file.name}, {norm_file.name}\")\n","\n","    scaler_summary.append({\n","        'fold': k,\n","        'test_subject': test_subj,\n","        'n_train': len(train_indices),\n","        'n_test': len(test_indices),\n","        'scaler_params': scaler_params\n","    })\n","\n","with open('/content/logs/scaler_summary.json', 'w') as f:\n","    json.dump(scaler_summary, f, indent=2)\n","\n","print(f\"\\n{'='*60}\")\n","print(f\"✓ Completed standardization across {len(splits_cfg['folds'])} folds\")\n","print(f\"✓ Scaler parameters: proc/scaler_fold*.npz\")\n","print(f\"✓ Standardized data: features/windows_normalized_fold*.npz (NPZ/float32)\")\n","print(f\"✓ Summary: logs/scaler_summary.json\")\n","\n","get_ipython().system('git add proc/scaler_fold*.npz features/windows_normalized_fold*.npz logs/scaler_summary.json')\n","get_ipython().system('git commit -m \"preproc: optimized z-score with NPZ storage and validation\"')\n","\n","print(f\"\\n{'='*60}\\nStep 9 completed\\n{'='*60}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oaRDr8HF1ah8","executionInfo":{"status":"ok","timestamp":1762689182601,"user_tz":0,"elapsed":290735,"user":{"displayName":"yu Wu","userId":"12692660435918028293"}},"outputId":"61309bc3-828e-469f-f8cc-8a3e0249ebcc"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","Step 9: Per-Fold Standardization (z-score)\n","============================================================\n","Channels: ['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_y', 'gyro_z']\n","Total windows: 36622\n","\n","\n","Fold 0: test subject=proband1\n","  Train windows: 34727, Test windows: 1895\n","  Scaler parameters:\n","    acc_x: mean=-0.0001, std=3.8156\n","    acc_y: mean=0.0000, std=1.8273\n","    acc_z: mean=0.0001, std=2.0051\n","    gyro_x: mean=-0.0001, std=0.5433\n","    gyro_y: mean=-0.0000, std=0.6868\n","    gyro_z: mean=-0.0001, std=0.3573\n","  Training-set validation after standardization:\n","    acc_x: mean=0.000000, std=1.000000\n","    acc_y: mean=0.000000, std=1.000000\n","    acc_z: mean=-0.000000, std=1.000000\n","    gyro_x: mean=0.000000, std=1.000000\n","    gyro_y: mean=0.000000, std=1.000000\n","    gyro_z: mean=0.000000, std=1.000000\n","  Test-set validation after standardization:\n","    acc_x: mean=-0.000124\n","    acc_y: mean=0.000252\n","    acc_z: mean=0.000556\n","    gyro_x: mean=0.001704\n","    gyro_y: mean=-0.000234\n","    gyro_z: mean=0.000859\n","  ✓ Saved: scaler_fold0.npz, windows_normalized_fold0.npz\n","\n","Fold 1: test subject=proband10\n","  Train windows: 34159, Test windows: 2463\n","  Scaler parameters:\n","    acc_x: mean=-0.0003, std=3.7910\n","    acc_y: mean=0.0001, std=1.7633\n","    acc_z: mean=0.0002, std=1.9672\n","    gyro_x: mean=-0.0001, std=0.5352\n","    gyro_y: mean=-0.0000, std=0.6743\n","    gyro_z: mean=-0.0001, std=0.3485\n","  Training-set validation after standardization:\n","    acc_x: mean=-0.000000, std=1.000000\n","    acc_y: mean=-0.000000, std=1.000000\n","    acc_z: mean=-0.000000, std=1.000000\n","    gyro_x: mean=-0.000000, std=1.000000\n","    gyro_y: mean=-0.000000, std=1.000000\n","    gyro_z: mean=0.000000, std=1.000000\n","  Test-set validation after standardization:\n","    acc_x: mean=0.000563\n","    acc_y: mean=-0.000574\n","    acc_z: mean=-0.000248\n","    gyro_x: mean=-0.001031\n","    gyro_y: mean=0.000080\n","    gyro_z: mean=-0.000325\n","  ✓ Saved: scaler_fold1.npz, windows_normalized_fold1.npz\n","\n","Fold 2: test subject=proband11\n","  Train windows: 34042, Test windows: 2580\n","  Scaler parameters:\n","    acc_x: mean=-0.0003, std=3.8414\n","    acc_y: mean=-0.0000, std=1.8385\n","    acc_z: mean=0.0003, std=2.0168\n","    gyro_x: mean=-0.0000, std=0.5485\n","    gyro_y: mean=-0.0000, std=0.6836\n","    gyro_z: mean=-0.0001, std=0.3500\n","  Training-set validation after standardization:\n","    acc_x: mean=0.000000, std=1.000000\n","    acc_y: mean=0.000000, std=1.000000\n","    acc_z: mean=0.000000, std=1.000000\n","    gyro_x: mean=0.000000, std=1.000000\n","    gyro_y: mean=0.000000, std=1.000000\n","    gyro_z: mean=-0.000000, std=1.000000\n","  Test-set validation after standardization:\n","    acc_x: mean=0.000306\n","    acc_y: mean=0.000449\n","    acc_z: mean=-0.000364\n","    gyro_x: mean=-0.002474\n","    gyro_y: mean=-0.000271\n","    gyro_z: mean=0.000058\n","  ✓ Saved: scaler_fold2.npz, windows_normalized_fold2.npz\n","\n","Fold 3: test subject=proband12\n","  Train windows: 34255, Test windows: 2367\n","  Scaler parameters:\n","    acc_x: mean=0.0001, std=3.8025\n","    acc_y: mean=0.0001, std=1.8310\n","    acc_z: mean=0.0002, std=2.0121\n","    gyro_x: mean=-0.0001, std=0.5402\n","    gyro_y: mean=-0.0000, std=0.6889\n","    gyro_z: mean=-0.0001, std=0.3552\n","  Training-set validation after standardization:\n","    acc_x: mean=0.000000, std=1.000000\n","    acc_y: mean=0.000000, std=1.000000\n","    acc_z: mean=-0.000000, std=1.000000\n","    gyro_x: mean=0.000000, std=1.000000\n","    gyro_y: mean=0.000000, std=1.000000\n","    gyro_z: mean=0.000000, std=1.000000\n","  Test-set validation after standardization:\n","    acc_x: mean=-0.000945\n","    acc_y: mean=-0.000499\n","    acc_z: mean=-0.000188\n","    gyro_x: mean=-0.000246\n","    gyro_y: mean=-0.000541\n","    gyro_z: mean=0.000470\n","  ✓ Saved: scaler_fold3.npz, windows_normalized_fold3.npz\n","\n","Fold 4: test subject=proband13\n","  Train windows: 34033, Test windows: 2589\n","  Scaler parameters:\n","    acc_x: mean=0.0000, std=3.8211\n","    acc_y: mean=0.0001, std=1.8294\n","    acc_z: mean=0.0003, std=2.0081\n","    gyro_x: mean=-0.0001, std=0.5273\n","    gyro_y: mean=-0.0000, std=0.6912\n","    gyro_z: mean=-0.0001, std=0.3575\n","  Training-set validation after standardization:\n","    acc_x: mean=0.000000, std=1.000000\n","    acc_y: mean=0.000000, std=1.000000\n","    acc_z: mean=-0.000000, std=1.000000\n","    gyro_x: mean=-0.000000, std=1.000000\n","    gyro_y: mean=-0.000000, std=1.000000\n","    gyro_z: mean=0.000000, std=1.000000\n","  Test-set validation after standardization:\n","    acc_x: mean=-0.000733\n","    acc_y: mean=-0.000498\n","    acc_z: mean=-0.000663\n","    gyro_x: mean=0.000413\n","    gyro_y: mean=-0.000658\n","    gyro_z: mean=-0.000576\n","  ✓ Saved: scaler_fold4.npz, windows_normalized_fold4.npz\n","\n","Fold 5: test subject=proband14\n","  Train windows: 34787, Test windows: 1835\n","  Scaler parameters:\n","    acc_x: mean=-0.0003, std=3.7730\n","    acc_y: mean=-0.0001, std=1.7359\n","    acc_z: mean=0.0001, std=1.9575\n","    gyro_x: mean=-0.0002, std=0.5440\n","    gyro_y: mean=-0.0000, std=0.6808\n","    gyro_z: mean=-0.0001, std=0.3577\n","  Training-set validation after standardization:\n","    acc_x: mean=-0.000000, std=1.000000\n","    acc_y: mean=-0.000000, std=1.000000\n","    acc_z: mean=-0.000000, std=1.000000\n","    gyro_x: mean=-0.000000, std=1.000000\n","    gyro_y: mean=-0.000000, std=1.000000\n","    gyro_z: mean=-0.000000, std=1.000000\n","  Test-set validation after standardization:\n","    acc_x: mean=0.000918\n","    acc_y: mean=0.001726\n","    acc_z: mean=0.000907\n","    gyro_x: mean=0.001931\n","    gyro_y: mean=0.000358\n","    gyro_z: mean=0.000059\n","  ✓ Saved: scaler_fold5.npz, windows_normalized_fold5.npz\n","\n","Fold 6: test subject=proband15\n","  Train windows: 34008, Test windows: 2614\n","  Scaler parameters:\n","    acc_x: mean=0.0001, std=3.8238\n","    acc_y: mean=0.0001, std=1.8297\n","    acc_z: mean=0.0003, std=2.0170\n","    gyro_x: mean=-0.0002, std=0.5455\n","    gyro_y: mean=-0.0000, std=0.6655\n","    gyro_z: mean=-0.0001, std=0.3476\n","  Training-set validation after standardization:\n","    acc_x: mean=0.000000, std=1.000000\n","    acc_y: mean=-0.000000, std=1.000000\n","    acc_z: mean=0.000000, std=1.000000\n","    gyro_x: mean=0.000000, std=1.000000\n","    gyro_y: mean=-0.000000, std=1.000000\n","    gyro_z: mean=0.000000, std=1.000000\n","  Test-set validation after standardization:\n","    acc_x: mean=-0.001051\n","    acc_y: mean=-0.000419\n","    acc_z: mean=-0.000410\n","    gyro_x: mean=0.002585\n","    gyro_y: mean=0.000004\n","    gyro_z: mean=0.000445\n","  ✓ Saved: scaler_fold6.npz, windows_normalized_fold6.npz\n","\n","Fold 7: test subject=proband2\n","  Train windows: 34330, Test windows: 2292\n","  Scaler parameters:\n","    acc_x: mean=-0.0001, std=3.7488\n","    acc_y: mean=0.0000, std=1.7805\n","    acc_z: mean=0.0001, std=2.0074\n","    gyro_x: mean=-0.0001, std=0.5394\n","    gyro_y: mean=-0.0001, std=0.6910\n","    gyro_z: mean=-0.0001, std=0.3587\n","  Training-set validation after standardization:\n","    acc_x: mean=0.000000, std=1.000000\n","    acc_y: mean=-0.000000, std=1.000000\n","    acc_z: mean=-0.000000, std=1.000000\n","    gyro_x: mean=-0.000000, std=1.000000\n","    gyro_y: mean=-0.000000, std=1.000000\n","    gyro_z: mean=0.000000, std=1.000000\n","  Test-set validation after standardization:\n","    acc_x: mean=-0.000466\n","    acc_y: mean=0.000190\n","    acc_z: mean=0.000869\n","    gyro_x: mean=0.000025\n","    gyro_y: mean=0.000310\n","    gyro_z: mean=0.000471\n","  ✓ Saved: scaler_fold7.npz, windows_normalized_fold7.npz\n","\n","Fold 8: test subject=proband3\n","  Train windows: 33917, Test windows: 2705\n","  Scaler parameters:\n","    acc_x: mean=-0.0003, std=3.7974\n","    acc_y: mean=0.0001, std=1.8102\n","    acc_z: mean=0.0002, std=2.0051\n","    gyro_x: mean=-0.0000, std=0.5456\n","    gyro_y: mean=-0.0001, std=0.6930\n","    gyro_z: mean=-0.0001, std=0.3576\n","  Training-set validation after standardization:\n","    acc_x: mean=-0.000000, std=1.000000\n","    acc_y: mean=0.000000, std=1.000000\n","    acc_z: mean=-0.000000, std=1.000000\n","    gyro_x: mean=0.000000, std=1.000000\n","    gyro_y: mean=0.000000, std=1.000000\n","    gyro_z: mean=0.000000, std=1.000000\n","  Test-set validation after standardization:\n","    acc_x: mean=0.000550\n","    acc_y: mean=-0.000506\n","    acc_z: mean=-0.000216\n","    gyro_x: mean=-0.001845\n","    gyro_y: mean=0.000419\n","    gyro_z: mean=-0.001126\n","  ✓ Saved: scaler_fold8.npz, windows_normalized_fold8.npz\n","\n","Fold 9: test subject=proband4\n","  Train windows: 34375, Test windows: 2247\n","  Scaler parameters:\n","    acc_x: mean=0.0000, std=3.8402\n","    acc_y: mean=-0.0000, std=1.8165\n","    acc_z: mean=0.0001, std=2.0122\n","    gyro_x: mean=-0.0001, std=0.5447\n","    gyro_y: mean=-0.0000, std=0.6843\n","    gyro_z: mean=-0.0001, std=0.3604\n","  Training-set validation after standardization:\n","    acc_x: mean=-0.000000, std=1.000000\n","    acc_y: mean=-0.000000, std=1.000000\n","    acc_z: mean=0.000000, std=1.000000\n","    gyro_x: mean=-0.000000, std=1.000000\n","    gyro_y: mean=0.000000, std=1.000000\n","    gyro_z: mean=0.000000, std=1.000000\n","  Test-set validation after standardization:\n","    acc_x: mean=-0.000841\n","    acc_y: mean=0.000295\n","    acc_z: mean=0.000621\n","    gyro_x: mean=0.000432\n","    gyro_y: mean=-0.000098\n","    gyro_z: mean=-0.000370\n","  ✓ Saved: scaler_fold9.npz, windows_normalized_fold9.npz\n","\n","Fold 10: test subject=proband5\n","  Train windows: 33690, Test windows: 2932\n","  Scaler parameters:\n","    acc_x: mean=-0.0002, std=3.8540\n","    acc_y: mean=0.0001, std=1.8298\n","    acc_z: mean=0.0003, std=2.0192\n","    gyro_x: mean=-0.0001, std=0.5492\n","    gyro_y: mean=-0.0001, std=0.6960\n","    gyro_z: mean=-0.0001, std=0.3567\n","  Training-set validation after standardization:\n","    acc_x: mean=0.000000, std=1.000000\n","    acc_y: mean=0.000000, std=1.000000\n","    acc_z: mean=0.000000, std=1.000000\n","    gyro_x: mean=-0.000000, std=1.000000\n","    gyro_y: mean=-0.000000, std=1.000000\n","    gyro_z: mean=0.000000, std=1.000000\n","  Test-set validation after standardization:\n","    acc_x: mean=0.000081\n","    acc_y: mean=-0.000413\n","    acc_z: mean=-0.000730\n","    gyro_x: mean=-0.000069\n","    gyro_y: mean=0.000244\n","    gyro_z: mean=0.000133\n","  ✓ Saved: scaler_fold10.npz, windows_normalized_fold10.npz\n","\n","Fold 11: test subject=proband6\n","  Train windows: 34091, Test windows: 2531\n","  Scaler parameters:\n","    acc_x: mean=-0.0002, std=3.8036\n","    acc_y: mean=-0.0001, std=1.8262\n","    acc_z: mean=0.0002, std=2.0039\n","    gyro_x: mean=-0.0001, std=0.5322\n","    gyro_y: mean=-0.0000, std=0.6875\n","    gyro_z: mean=-0.0001, std=0.3539\n","  Training-set validation after standardization:\n","    acc_x: mean=-0.000000, std=1.000000\n","    acc_y: mean=-0.000000, std=1.000000\n","    acc_z: mean=-0.000000, std=1.000000\n","    gyro_x: mean=-0.000000, std=1.000000\n","    gyro_y: mean=0.000000, std=1.000000\n","    gyro_z: mean=-0.000000, std=1.000000\n","  Test-set validation after standardization:\n","    acc_x: mean=0.000054\n","    acc_y: mean=0.000872\n","    acc_z: mean=-0.000180\n","    gyro_x: mean=-0.000310\n","    gyro_y: mean=0.000153\n","    gyro_z: mean=-0.000844\n","  ✓ Saved: scaler_fold11.npz, windows_normalized_fold11.npz\n","\n","Fold 12: test subject=proband7\n","  Train windows: 34620, Test windows: 2002\n","  Scaler parameters:\n","    acc_x: mean=-0.0002, std=3.7881\n","    acc_y: mean=-0.0000, std=1.8145\n","    acc_z: mean=0.0001, std=2.0035\n","    gyro_x: mean=-0.0001, std=0.5509\n","    gyro_y: mean=-0.0000, std=0.6887\n","    gyro_z: mean=-0.0001, std=0.3561\n","  Training-set validation after standardization:\n","    acc_x: mean=-0.000000, std=1.000000\n","    acc_y: mean=0.000000, std=1.000000\n","    acc_z: mean=0.000000, std=1.000000\n","    gyro_x: mean=0.000000, std=1.000000\n","    gyro_y: mean=-0.000000, std=1.000000\n","    gyro_z: mean=-0.000000, std=1.000000\n","  Test-set validation after standardization:\n","    acc_x: mean=0.000188\n","    acc_y: mean=0.000302\n","    acc_z: mean=0.000549\n","    gyro_x: mean=0.000852\n","    gyro_y: mean=-0.000142\n","    gyro_z: mean=0.000597\n","  ✓ Saved: scaler_fold12.npz, windows_normalized_fold12.npz\n","\n","Fold 13: test subject=proband8\n","  Train windows: 33728, Test windows: 2894\n","  Scaler parameters:\n","    acc_x: mean=-0.0001, std=3.8546\n","    acc_y: mean=0.0001, std=1.8390\n","    acc_z: mean=0.0002, std=1.9551\n","    gyro_x: mean=-0.0001, std=0.5487\n","    gyro_y: mean=-0.0001, std=0.5670\n","    gyro_z: mean=-0.0001, std=0.3456\n","  Training-set validation after standardization:\n","    acc_x: mean=-0.000000, std=1.000000\n","    acc_y: mean=0.000000, std=1.000000\n","    acc_z: mean=-0.000000, std=1.000000\n","    gyro_x: mean=0.000000, std=1.000000\n","    gyro_y: mean=-0.000000, std=1.000000\n","    gyro_z: mean=0.000000, std=1.000000\n","  Test-set validation after standardization:\n","    acc_x: mean=-0.000107\n","    acc_y: mean=-0.000520\n","    acc_z: mean=0.000311\n","    gyro_x: mean=0.000248\n","    gyro_y: mean=0.000853\n","    gyro_z: mean=-0.000173\n","  ✓ Saved: scaler_fold13.npz, windows_normalized_fold13.npz\n","\n","Fold 14: test subject=proband9\n","  Train windows: 33946, Test windows: 2676\n","  Scaler parameters:\n","    acc_x: mean=-0.0006, std=3.8054\n","    acc_y: mean=0.0000, std=1.7538\n","    acc_z: mean=0.0002, std=2.0116\n","    gyro_x: mean=-0.0001, std=0.5406\n","    gyro_y: mean=-0.0000, std=0.6713\n","    gyro_z: mean=-0.0001, std=0.3401\n","  Training-set validation after standardization:\n","    acc_x: mean=0.000000, std=1.000000\n","    acc_y: mean=-0.000000, std=1.000000\n","    acc_z: mean=0.000000, std=1.000000\n","    gyro_x: mean=0.000000, std=1.000000\n","    gyro_y: mean=-0.000000, std=1.000000\n","    gyro_z: mean=0.000000, std=1.000000\n","  Test-set validation after standardization:\n","    acc_x: mean=0.001619\n","    acc_y: mean=0.000139\n","    acc_z: mean=-0.000070\n","    gyro_x: mean=-0.001037\n","    gyro_y: mean=-0.000455\n","    gyro_z: mean=0.000751\n","  ✓ Saved: scaler_fold14.npz, windows_normalized_fold14.npz\n","\n","============================================================\n","✓ Completed standardization across 15 folds\n","✓ Scaler parameters: proc/scaler_fold*.npz\n","✓ Standardized data: features/windows_normalized_fold*.npz (NPZ/float32)\n","✓ Summary: logs/scaler_summary.json\n","[master fbaa4e3] preproc: optimized z-score with NPZ storage and validation\n"," 31 files changed, 482 insertions(+)\n"," create mode 100644 features/windows_normalized_fold0.npz\n"," create mode 100644 features/windows_normalized_fold1.npz\n"," create mode 100644 features/windows_normalized_fold10.npz\n"," create mode 100644 features/windows_normalized_fold11.npz\n"," create mode 100644 features/windows_normalized_fold12.npz\n"," create mode 100644 features/windows_normalized_fold13.npz\n"," create mode 100644 features/windows_normalized_fold14.npz\n"," create mode 100644 features/windows_normalized_fold2.npz\n"," create mode 100644 features/windows_normalized_fold3.npz\n"," create mode 100644 features/windows_normalized_fold4.npz\n"," create mode 100644 features/windows_normalized_fold5.npz\n"," create mode 100644 features/windows_normalized_fold6.npz\n"," create mode 100644 features/windows_normalized_fold7.npz\n"," create mode 100644 features/windows_normalized_fold8.npz\n"," create mode 100644 features/windows_normalized_fold9.npz\n"," create mode 100644 logs/scaler_summary.json\n"," create mode 100644 proc/scaler_fold0.npz\n"," create mode 100644 proc/scaler_fold1.npz\n"," create mode 100644 proc/scaler_fold10.npz\n"," create mode 100644 proc/scaler_fold11.npz\n"," create mode 100644 proc/scaler_fold12.npz\n"," create mode 100644 proc/scaler_fold13.npz\n"," create mode 100644 proc/scaler_fold14.npz\n"," create mode 100644 proc/scaler_fold2.npz\n"," create mode 100644 proc/scaler_fold3.npz\n"," create mode 100644 proc/scaler_fold4.npz\n"," create mode 100644 proc/scaler_fold5.npz\n"," create mode 100644 proc/scaler_fold6.npz\n"," create mode 100644 proc/scaler_fold7.npz\n"," create mode 100644 proc/scaler_fold8.npz\n"," create mode 100644 proc/scaler_fold9.npz\n","\n","============================================================\n","Step 9 completed\n","============================================================\n"]}]},{"cell_type":"code","source":["# ================ Step 10: Classical Feature Extraction (Final Optimized Version) ================\n","import numpy as np\n","import pandas as pd\n","from pathlib import Path\n","from scipy import stats\n","from scipy.fft import rfft, rfftfreq\n","import json\n","\n","print(\"\\n\\nStep 10: Classical Feature Extraction\")\n","print(\"=\" * 60)\n","\n","features_dir = Path('/content/features')\n","\n","with open('/content/configs/splits.json', 'r') as f:\n","    splits_cfg = json.load(f)\n","\n","CHANNELS = ['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_y', 'gyro_z']\n","FS = 50\n","WINDOW_SAMPLES = 150\n","\n","FREQ_BANDS = {\n","    'band1': (0.5, 1), 'band2': (1, 3), 'band3': (3, 5),\n","    'band4': (5, 8), 'band5': (8, 12), 'band6': (12, 15)\n","}\n","\n","# Precompute frequency-domain constants\n","FREQS = rfftfreq(WINDOW_SAMPLES, 1/FS).astype(np.float32)\n","BAND_MASKS = {k: (FREQS >= lo) & (FREQS <= hi) for k, (lo, hi) in FREQ_BANDS.items()}\n","\n","def safe_nan(a):\n","    return np.nan_to_num(a, nan=0.0, posinf=0.0, neginf=0.0)\n","\n","def corr_pair_batch(A, B, eps=1e-10):\n","    A0 = A - A.mean(axis=1, keepdims=True)\n","    B0 = B - B.mean(axis=1, keepdims=True)\n","    num = (A0 * B0).sum(axis=1)\n","    den = np.sqrt((A0**2).sum(axis=1) * (B0**2).sum(axis=1)) + eps\n","    return num / den\n","\n","def ar1_batch(X, eps=1e-10):\n","    X0 = X[:, :-1]\n","    X1 = X[:, 1:]\n","    X0c = X0 - X0.mean(axis=1, keepdims=True)\n","    X1c = X1 - X1.mean(axis=1, keepdims=True)\n","    num = (X0c * X1c).sum(axis=1)\n","    den = np.sqrt((X0c**2).sum(axis=1) * (X1c**2).sum(axis=1)) + eps\n","    return num / den\n","\n","def extract_features_batch(X):\n","    features = {}\n","\n","    features['mean'] = np.mean(X, axis=1)\n","    features['std'] = np.std(X, axis=1)\n","    features['median'] = np.median(X, axis=1)\n","    features['p10'] = np.percentile(X, 10, axis=1)\n","    features['p90'] = np.percentile(X, 90, axis=1)\n","    features['iqr'] = np.percentile(X, 75, axis=1) - np.percentile(X, 25, axis=1)\n","    features['mad'] = np.median(np.abs(X - features['median'][:, None]), axis=1)\n","    features['rms'] = np.sqrt(np.mean(X**2, axis=1))\n","    features['energy'] = np.sum(X**2, axis=1)\n","    features['zcr'] = np.sum(np.diff(np.sign(X), axis=1) != 0, axis=1) / X.shape[1]\n","    features['skew'] = safe_nan(stats.skew(X, axis=1))\n","    features['kurt'] = safe_nan(stats.kurtosis(X, axis=1))\n","    features['ar1'] = safe_nan(ar1_batch(X))\n","\n","    dX = np.diff(X, axis=1)\n","    ddX = np.diff(dX, axis=1)\n","    var_x = np.var(X, axis=1) + 1e-10\n","    var_dx = np.var(dX, axis=1) + 1e-10\n","    var_ddx = np.var(ddX, axis=1) + 1e-10\n","    mobility = np.sqrt(var_dx / var_x)\n","    features['mobility'] = mobility\n","    features['complexity'] = np.sqrt(var_ddx / var_dx) / (mobility + 1e-10)\n","\n","    fft_vals = np.abs(rfft(X, axis=1))\n","    psd = fft_vals**2\n","    psd_norm = psd / (psd.sum(axis=1, keepdims=True) + 1e-10)\n","\n","    features['spec_centroid'] = np.sum(FREQS[None, :] * psd_norm, axis=1)\n","    features['spec_entropy'] = -np.sum(psd_norm * np.log2(psd_norm + 1e-10), axis=1)\n","\n","    cumsum = np.cumsum(psd_norm, axis=1)\n","    roll_mask = (cumsum >= 0.85)\n","    roll_idx = np.where(roll_mask.any(axis=1), roll_mask.argmax(axis=1), roll_mask.shape[1]-1)\n","    features['rolloff'] = FREQS[roll_idx]\n","    features['peak_freq'] = FREQS[np.argmax(psd, axis=1)]\n","\n","    for band_name, mask in BAND_MASKS.items():\n","        features[f'bandpower_{band_name}'] = np.sum(psd[:, mask], axis=1)\n","\n","    return features\n","\n","print(f\"Features: 8 channels × 25 + 6 correlations + 2 SMA = 208 dims\\n\")\n","\n","feature_names = None\n","\n","for fold in splits_cfg['folds']:\n","    k = fold['fold']\n","    print(f\"\\nFold {k}:\")\n","\n","    norm_data = np.load(features_dir / f'windows_normalized_fold{k}.npz', allow_pickle=True)\n","    n_windows = len(norm_data['labels'])\n","\n","    # Prepare data (ensure contiguous memory layout)\n","    data_dict = {}\n","    for ch in CHANNELS:\n","        data_dict[ch] = np.ascontiguousarray(np.stack(norm_data[ch]), dtype=np.float32)\n","\n","    data_dict['acc_mag'] = np.sqrt(data_dict['acc_x']**2 + data_dict['acc_y']**2 + data_dict['acc_z']**2)\n","    data_dict['gyro_mag'] = np.sqrt(data_dict['gyro_x']**2 + data_dict['gyro_y']**2 + data_dict['gyro_z']**2)\n","\n","    # Feature extraction\n","    all_features = {}\n","\n","    print(f\"  Extracting per-channel features...\", end=' ')\n","    for ch in list(data_dict.keys()):\n","        feats = extract_features_batch(data_dict[ch])\n","        for feat_name, feat_vals in feats.items():\n","            all_features[f'{ch}_{feat_name}'] = feat_vals\n","    print(\"✓\")\n","\n","    print(f\"  Extracting correlations...\", end=' ')\n","    all_features['acc_corr_xy'] = safe_nan(corr_pair_batch(data_dict['acc_x'], data_dict['acc_y']))\n","    all_features['acc_corr_xz'] = safe_nan(corr_pair_batch(data_dict['acc_x'], data_dict['acc_z']))\n","    all_features['acc_corr_yz'] = safe_nan(corr_pair_batch(data_dict['acc_y'], data_dict['acc_z']))\n","    all_features['gyro_corr_xy'] = safe_nan(corr_pair_batch(data_dict['gyro_x'], data_dict['gyro_y']))\n","    all_features['gyro_corr_xz'] = safe_nan(corr_pair_batch(data_dict['gyro_x'], data_dict['gyro_z']))\n","    all_features['gyro_corr_yz'] = safe_nan(corr_pair_batch(data_dict['gyro_y'], data_dict['gyro_z']))\n","    print(\"✓\")\n","\n","    print(f\"  Computing SMA...\", end=' ')\n","    all_features['sma_acc'] = (np.sum(np.abs(data_dict['acc_x']), axis=1) +\n","                                np.sum(np.abs(data_dict['acc_y']), axis=1) +\n","                                np.sum(np.abs(data_dict['acc_z']), axis=1)) / WINDOW_SAMPLES\n","    all_features['sma_gyro'] = (np.sum(np.abs(data_dict['gyro_x']), axis=1) +\n","                                 np.sum(np.abs(data_dict['gyro_y']), axis=1) +\n","                                 np.sum(np.abs(data_dict['gyro_z']), axis=1)) / WINDOW_SAMPLES\n","    print(\"✓\")\n","\n","    # Determine feature order and build matrix\n","    if feature_names is None:\n","        feature_names = sorted(all_features.keys())\n","        print(f\"  Feature dimensionality: {len(feature_names)}\")\n","\n","    X = np.column_stack([all_features[k].astype(np.float32) for k in feature_names])\n","\n","    # Split into train/test\n","    train_mask = norm_data['splits'] == 'train'\n","    test_mask = norm_data['splits'] == 'test'\n","\n","    X_train, y_train = X[train_mask], norm_data['labels'][train_mask].astype(np.int32)\n","    X_test, y_test = X[test_mask], norm_data['labels'][test_mask].astype(np.int32)\n","\n","    print(f\"  Train: {X_train.shape}, Test: {X_test.shape}\")\n","\n","    np.savez_compressed(features_dir / f'train_fold{k}.npz',\n","                       X=X_train, y=y_train,\n","                       subjects=norm_data['subjects'][train_mask],\n","                       activities=norm_data['activities'][train_mask],\n","                       window_ids=norm_data['window_ids'][train_mask])\n","\n","    np.savez_compressed(features_dir / f'test_fold{k}.npz',\n","                       X=X_test, y=y_test,\n","                       subjects=norm_data['subjects'][test_mask],\n","                       activities=norm_data['activities'][test_mask],\n","                       window_ids=norm_data['window_ids'][test_mask])\n","\n","    print(f\"  ✓ Saved\")\n","\n","pd.DataFrame({'feature': feature_names}).to_csv('/content/logs/feature_list.csv', index=False)\n","\n","with open('/content/logs/feature_summary.json', 'w') as f:\n","    json.dump({'total_features': len(feature_names), 'n_channels': 8}, f, indent=2)\n","\n","print(f\"\\n{'='*60}\\nFeature extraction completed: {len(feature_names)} dims\")\n","\n","get_ipython().system('git add features/train_fold*.npz features/test_fold*.npz logs/feature_*.csv logs/feature_summary.json')\n","get_ipython().system('git commit -m \"feature: final optimized extraction (~208D)\"')\n","\n","print(f\"{'='*60}\\nStep 10 completed\\n{'='*60}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tvotqkTC2wCT","executionInfo":{"status":"ok","timestamp":1762689346440,"user_tz":0,"elapsed":162839,"user":{"displayName":"yu Wu","userId":"12692660435918028293"}},"outputId":"7bea5bea-b87d-42fe-e170-b7d195830ab4"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","Step 10: Classical Feature Extraction\n","============================================================\n","Features: 8 channels × 25 + 6 correlations + 2 SMA = 208 dims\n","\n","\n","Fold 0:\n","  Extracting per-channel features... ✓\n","  Extracting correlations... ✓\n","  Computing SMA... ✓\n","  Feature dimensionality: 208\n","  Train: (34727, 208), Test: (1895, 208)\n","  ✓ Saved\n","\n","Fold 1:\n","  Extracting per-channel features... ✓\n","  Extracting correlations... ✓\n","  Computing SMA... ✓\n","  Train: (34159, 208), Test: (2463, 208)\n","  ✓ Saved\n","\n","Fold 2:\n","  Extracting per-channel features... ✓\n","  Extracting correlations... ✓\n","  Computing SMA... ✓\n","  Train: (34042, 208), Test: (2580, 208)\n","  ✓ Saved\n","\n","Fold 3:\n","  Extracting per-channel features... ✓\n","  Extracting correlations... ✓\n","  Computing SMA... ✓\n","  Train: (34255, 208), Test: (2367, 208)\n","  ✓ Saved\n","\n","Fold 4:\n","  Extracting per-channel features... ✓\n","  Extracting correlations... ✓\n","  Computing SMA... ✓\n","  Train: (34033, 208), Test: (2589, 208)\n","  ✓ Saved\n","\n","Fold 5:\n","  Extracting per-channel features... ✓\n","  Extracting correlations... ✓\n","  Computing SMA... ✓\n","  Train: (34787, 208), Test: (1835, 208)\n","  ✓ Saved\n","\n","Fold 6:\n","  Extracting per-channel features... ✓\n","  Extracting correlations... ✓\n","  Computing SMA... ✓\n","  Train: (34008, 208), Test: (2614, 208)\n","  ✓ Saved\n","\n","Fold 7:\n","  Extracting per-channel features... ✓\n","  Extracting correlations... ✓\n","  Computing SMA... ✓\n","  Train: (34330, 208), Test: (2292, 208)\n","  ✓ Saved\n","\n","Fold 8:\n","  Extracting per-channel features... ✓\n","  Extracting correlations... ✓\n","  Computing SMA... ✓\n","  Train: (33917, 208), Test: (2705, 208)\n","  ✓ Saved\n","\n","Fold 9:\n","  Extracting per-channel features... ✓\n","  Extracting correlations... ✓\n","  Computing SMA... ✓\n","  Train: (34375, 208), Test: (2247, 208)\n","  ✓ Saved\n","\n","Fold 10:\n","  Extracting per-channel features... ✓\n","  Extracting correlations... ✓\n","  Computing SMA... ✓\n","  Train: (33690, 208), Test: (2932, 208)\n","  ✓ Saved\n","\n","Fold 11:\n","  Extracting per-channel features... ✓\n","  Extracting correlations... ✓\n","  Computing SMA... ✓\n","  Train: (34091, 208), Test: (2531, 208)\n","  ✓ Saved\n","\n","Fold 12:\n","  Extracting per-channel features... ✓\n","  Extracting correlations... ✓\n","  Computing SMA... ✓\n","  Train: (34620, 208), Test: (2002, 208)\n","  ✓ Saved\n","\n","Fold 13:\n","  Extracting per-channel features... ✓\n","  Extracting correlations... ✓\n","  Computing SMA... ✓\n","  Train: (33728, 208), Test: (2894, 208)\n","  ✓ Saved\n","\n","Fold 14:\n","  Extracting per-channel features... ✓\n","  Extracting correlations... ✓\n","  Computing SMA... ✓\n","  Train: (33946, 208), Test: (2676, 208)\n","  ✓ Saved\n","\n","============================================================\n","Feature extraction completed: 208 dims\n","[master f8b8767] feature: final optimized extraction (~208D)\n"," 32 files changed, 213 insertions(+)\n"," create mode 100644 features/test_fold0.npz\n"," create mode 100644 features/test_fold1.npz\n"," create mode 100644 features/test_fold10.npz\n"," create mode 100644 features/test_fold11.npz\n"," create mode 100644 features/test_fold12.npz\n"," create mode 100644 features/test_fold13.npz\n"," create mode 100644 features/test_fold14.npz\n"," create mode 100644 features/test_fold2.npz\n"," create mode 100644 features/test_fold3.npz\n"," create mode 100644 features/test_fold4.npz\n"," create mode 100644 features/test_fold5.npz\n"," create mode 100644 features/test_fold6.npz\n"," create mode 100644 features/test_fold7.npz\n"," create mode 100644 features/test_fold8.npz\n"," create mode 100644 features/test_fold9.npz\n"," create mode 100644 features/train_fold0.npz\n"," create mode 100644 features/train_fold1.npz\n"," create mode 100644 features/train_fold10.npz\n"," create mode 100644 features/train_fold11.npz\n"," create mode 100644 features/train_fold12.npz\n"," create mode 100644 features/train_fold13.npz\n"," create mode 100644 features/train_fold14.npz\n"," create mode 100644 features/train_fold2.npz\n"," create mode 100644 features/train_fold3.npz\n"," create mode 100644 features/train_fold4.npz\n"," create mode 100644 features/train_fold5.npz\n"," create mode 100644 features/train_fold6.npz\n"," create mode 100644 features/train_fold7.npz\n"," create mode 100644 features/train_fold8.npz\n"," create mode 100644 features/train_fold9.npz\n"," create mode 100644 logs/feature_list.csv\n"," create mode 100644 logs/feature_summary.json\n","============================================================\n","Step 10 completed\n","============================================================\n"]}]},{"cell_type":"code","source":["# ================ Step 11: KNN Inner-loop Hyperparameter Tuning ================\n","import numpy as np\n","from pathlib import Path\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import GroupKFold\n","from sklearn.metrics import f1_score\n","import json\n","import pickle\n","\n","print(\"\\n\\nStep 11: KNN Inner-loop Hyperparameter Tuning\")\n","print(\"=\" * 60)\n","\n","features_dir = Path('/content/features')\n","models_dir = Path('/content/models')\n","models_dir.mkdir(exist_ok=True)\n","\n","with open('/content/configs/splits.json', 'r') as f:\n","    splits_cfg = json.load(f)\n","\n","PARAM_GRID = {\n","    'n_neighbors': [1, 3, 5, 7, 9, 11],\n","    'weights': ['uniform', 'distance']\n","}\n","\n","print(f\"Hyperparameter search space:\")\n","print(f\"  n_neighbors: {PARAM_GRID['n_neighbors']}\")\n","print(f\"  weights: {PARAM_GRID['weights']}\")\n","print(f\"  metric: euclidean, n_jobs: -1\")\n","print(f\"  Inner validation: GroupKFold(n_splits=3), metric: Macro-F1\\n\")\n","\n","all_results = []\n","\n","for fold in splits_cfg['folds']:\n","    k = fold['fold']\n","    print(f\"\\n{'='*60}\")\n","    print(f\"Fold {k}:\")\n","    print(f\"{'='*60}\")\n","\n","    train_data = np.load(features_dir / f'train_fold{k}.npz', allow_pickle=True)\n","    X_train = train_data['X']\n","    y_train = train_data['y']\n","    subjects_train = train_data['subjects']\n","\n","    print(f\"Training set: {X_train.shape}, subjects: {np.unique(subjects_train)}\")\n","\n","    gkf = GroupKFold(n_splits=3)\n","    best_score = -1\n","    best_params = None\n","\n","    for n_neighbors in PARAM_GRID['n_neighbors']:\n","        for weights in PARAM_GRID['weights']:\n","\n","            inner_scores = []\n","\n","            for train_idx, val_idx in gkf.split(X_train, y_train, groups=subjects_train):\n","                X_inner_train, X_inner_val = X_train[train_idx], X_train[val_idx]\n","                y_inner_train, y_inner_val = y_train[train_idx], y_train[val_idx]\n","\n","                scaler = StandardScaler()\n","                X_inner_train_scaled = scaler.fit_transform(X_inner_train)\n","                X_inner_val_scaled = scaler.transform(X_inner_val)\n","\n","                knn = KNeighborsClassifier(n_neighbors=n_neighbors,\n","                                          weights=weights,\n","                                          metric='euclidean',\n","                                          n_jobs=-1)\n","                knn.fit(X_inner_train_scaled, y_inner_train)\n","\n","                y_pred = knn.predict(X_inner_val_scaled)\n","                macro_f1 = f1_score(y_inner_val, y_pred, average='macro', zero_division=0)\n","                inner_scores.append(macro_f1)\n","\n","            mean_score = np.mean(inner_scores)\n","\n","            print(f\"  k={n_neighbors:2d}, weights={weights:8s}: {mean_score:.4f} ± {np.std(inner_scores):.4f}\")\n","\n","            if mean_score > best_score:\n","                best_score = mean_score\n","                best_params = {'n_neighbors': n_neighbors, 'weights': weights}\n","\n","    print(f\"\\n  ✓ Best parameters: {best_params}\")\n","    print(f\"  ✓ Best validation Macro-F1: {best_score:.4f}\")\n","\n","    print(f\"\\n  Training final model with best parameters...\")\n","\n","    scaler_final = StandardScaler()\n","    X_train_scaled = scaler_final.fit_transform(X_train)\n","\n","    knn_final = KNeighborsClassifier(n_neighbors=best_params['n_neighbors'],\n","                                     weights=best_params['weights'],\n","                                     metric='euclidean',\n","                                     n_jobs=-1)\n","    knn_final.fit(X_train_scaled, y_train)\n","\n","    model_dict = {\n","        'knn': knn_final,\n","        'scaler': scaler_final,\n","        'best_params': best_params,\n","        'best_val_macro_f1': best_score,\n","        'fold': k\n","    }\n","\n","    model_path = models_dir / f'knn_fold{k}.pkl'\n","    with open(model_path, 'wb') as f:\n","        pickle.dump(model_dict, f)\n","\n","    print(f\"  ✓ Model saved: {model_path.name}\")\n","\n","    all_results.append({\n","        'fold': k,\n","        'test_subject': fold['test_subject'],\n","        'best_params': best_params,\n","        'best_val_macro_f1': float(best_score),\n","        'n_train': len(X_train)\n","    })\n","\n","with open('/content/logs/knn_tuning_results.json', 'w') as f:\n","    json.dump(all_results, f, indent=2)\n","\n","print(f\"\\n{'='*60}\")\n","print(f\"KNN tuning completed\")\n","print(f\"  Models: models/knn_fold*.pkl\")\n","print(f\"  Results: logs/knn_tuning_results.json\")\n","\n","get_ipython().system('git add models/knn_fold*.pkl logs/knn_tuning_results.json')\n","get_ipython().system('git commit -m \"model: KNN tuning with Macro-F1 scoring\"')\n","\n","print(f\"{'='*60}\\nStep 11 completed\\n{'='*60}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9N0yqlbd3_Cs","executionInfo":{"status":"ok","timestamp":1762689886709,"user_tz":0,"elapsed":540267,"user":{"displayName":"yu Wu","userId":"12692660435918028293"}},"outputId":"5264b540-a342-4fcf-cdf9-87ff4933f05b"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","Step 11: KNN Inner-loop Hyperparameter Tuning\n","============================================================\n","Hyperparameter search space:\n","  n_neighbors: [1, 3, 5, 7, 9, 11]\n","  weights: ['uniform', 'distance']\n","  metric: euclidean, n_jobs: -1\n","  Inner validation: GroupKFold(n_splits=3), metric: Macro-F1\n","\n","\n","============================================================\n","Fold 0:\n","============================================================\n","Training set: (34727, 208), subjects: ['proband10' 'proband11' 'proband12' 'proband13' 'proband14' 'proband15'\n"," 'proband2' 'proband3' 'proband4' 'proband5' 'proband6' 'proband7'\n"," 'proband8' 'proband9']\n","  k= 1, weights=uniform : 0.7370 ± 0.0361\n","  k= 1, weights=distance: 0.7370 ± 0.0361\n","  k= 3, weights=uniform : 0.7607 ± 0.0316\n","  k= 3, weights=distance: 0.7621 ± 0.0320\n","  k= 5, weights=uniform : 0.7742 ± 0.0321\n","  k= 5, weights=distance: 0.7742 ± 0.0335\n","  k= 7, weights=uniform : 0.7809 ± 0.0303\n","  k= 7, weights=distance: 0.7811 ± 0.0304\n","  k= 9, weights=uniform : 0.7827 ± 0.0306\n","  k= 9, weights=distance: 0.7826 ± 0.0304\n","  k=11, weights=uniform : 0.7846 ± 0.0310\n","  k=11, weights=distance: 0.7842 ± 0.0306\n","\n","  ✓ Best parameters: {'n_neighbors': 11, 'weights': 'uniform'}\n","  ✓ Best validation Macro-F1: 0.7846\n","\n","  Training final model with best parameters...\n","  ✓ Model saved: knn_fold0.pkl\n","\n","============================================================\n","Fold 1:\n","============================================================\n","Training set: (34159, 208), subjects: ['proband1' 'proband11' 'proband12' 'proband13' 'proband14' 'proband15'\n"," 'proband2' 'proband3' 'proband4' 'proband5' 'proband6' 'proband7'\n"," 'proband8' 'proband9']\n","  k= 1, weights=uniform : 0.7324 ± 0.0333\n","  k= 1, weights=distance: 0.7324 ± 0.0333\n","  k= 3, weights=uniform : 0.7553 ± 0.0288\n","  k= 3, weights=distance: 0.7564 ± 0.0281\n","  k= 5, weights=uniform : 0.7673 ± 0.0299\n","  k= 5, weights=distance: 0.7685 ± 0.0276\n","  k= 7, weights=uniform : 0.7726 ± 0.0283\n","  k= 7, weights=distance: 0.7741 ± 0.0266\n","  k= 9, weights=uniform : 0.7751 ± 0.0272\n","  k= 9, weights=distance: 0.7765 ± 0.0260\n","  k=11, weights=uniform : 0.7777 ± 0.0266\n","  k=11, weights=distance: 0.7781 ± 0.0247\n","\n","  ✓ Best parameters: {'n_neighbors': 11, 'weights': 'distance'}\n","  ✓ Best validation Macro-F1: 0.7781\n","\n","  Training final model with best parameters...\n","  ✓ Model saved: knn_fold1.pkl\n","\n","============================================================\n","Fold 2:\n","============================================================\n","Training set: (34042, 208), subjects: ['proband1' 'proband10' 'proband12' 'proband13' 'proband14' 'proband15'\n"," 'proband2' 'proband3' 'proband4' 'proband5' 'proband6' 'proband7'\n"," 'proband8' 'proband9']\n","  k= 1, weights=uniform : 0.7308 ± 0.0427\n","  k= 1, weights=distance: 0.7308 ± 0.0427\n","  k= 3, weights=uniform : 0.7526 ± 0.0395\n","  k= 3, weights=distance: 0.7529 ± 0.0377\n","  k= 5, weights=uniform : 0.7658 ± 0.0385\n","  k= 5, weights=distance: 0.7667 ± 0.0371\n","  k= 7, weights=uniform : 0.7726 ± 0.0378\n","  k= 7, weights=distance: 0.7727 ± 0.0365\n","  k= 9, weights=uniform : 0.7747 ± 0.0346\n","  k= 9, weights=distance: 0.7745 ± 0.0337\n","  k=11, weights=uniform : 0.7770 ± 0.0337\n","  k=11, weights=distance: 0.7770 ± 0.0318\n","\n","  ✓ Best parameters: {'n_neighbors': 11, 'weights': 'uniform'}\n","  ✓ Best validation Macro-F1: 0.7770\n","\n","  Training final model with best parameters...\n","  ✓ Model saved: knn_fold2.pkl\n","\n","============================================================\n","Fold 3:\n","============================================================\n","Training set: (34255, 208), subjects: ['proband1' 'proband10' 'proband11' 'proband13' 'proband14' 'proband15'\n"," 'proband2' 'proband3' 'proband4' 'proband5' 'proband6' 'proband7'\n"," 'proband8' 'proband9']\n","  k= 1, weights=uniform : 0.7333 ± 0.0329\n","  k= 1, weights=distance: 0.7333 ± 0.0329\n","  k= 3, weights=uniform : 0.7545 ± 0.0277\n","  k= 3, weights=distance: 0.7567 ± 0.0282\n","  k= 5, weights=uniform : 0.7660 ± 0.0275\n","  k= 5, weights=distance: 0.7684 ± 0.0267\n","  k= 7, weights=uniform : 0.7709 ± 0.0270\n","  k= 7, weights=distance: 0.7720 ± 0.0268\n","  k= 9, weights=uniform : 0.7740 ± 0.0280\n","  k= 9, weights=distance: 0.7751 ± 0.0287\n","  k=11, weights=uniform : 0.7758 ± 0.0276\n","  k=11, weights=distance: 0.7769 ± 0.0276\n","\n","  ✓ Best parameters: {'n_neighbors': 11, 'weights': 'distance'}\n","  ✓ Best validation Macro-F1: 0.7769\n","\n","  Training final model with best parameters...\n","  ✓ Model saved: knn_fold3.pkl\n","\n","============================================================\n","Fold 4:\n","============================================================\n","Training set: (34033, 208), subjects: ['proband1' 'proband10' 'proband11' 'proband12' 'proband14' 'proband15'\n"," 'proband2' 'proband3' 'proband4' 'proband5' 'proband6' 'proband7'\n"," 'proband8' 'proband9']\n","  k= 1, weights=uniform : 0.7315 ± 0.0344\n","  k= 1, weights=distance: 0.7315 ± 0.0344\n","  k= 3, weights=uniform : 0.7549 ± 0.0314\n","  k= 3, weights=distance: 0.7547 ± 0.0290\n","  k= 5, weights=uniform : 0.7635 ± 0.0312\n","  k= 5, weights=distance: 0.7666 ± 0.0284\n","  k= 7, weights=uniform : 0.7705 ± 0.0298\n","  k= 7, weights=distance: 0.7720 ± 0.0273\n","  k= 9, weights=uniform : 0.7730 ± 0.0290\n","  k= 9, weights=distance: 0.7746 ± 0.0274\n","  k=11, weights=uniform : 0.7763 ± 0.0279\n","  k=11, weights=distance: 0.7773 ± 0.0257\n","\n","  ✓ Best parameters: {'n_neighbors': 11, 'weights': 'distance'}\n","  ✓ Best validation Macro-F1: 0.7773\n","\n","  Training final model with best parameters...\n","  ✓ Model saved: knn_fold4.pkl\n","\n","============================================================\n","Fold 5:\n","============================================================\n","Training set: (34787, 208), subjects: ['proband1' 'proband10' 'proband11' 'proband12' 'proband13' 'proband15'\n"," 'proband2' 'proband3' 'proband4' 'proband5' 'proband6' 'proband7'\n"," 'proband8' 'proband9']\n","  k= 1, weights=uniform : 0.7334 ± 0.0438\n","  k= 1, weights=distance: 0.7334 ± 0.0438\n","  k= 3, weights=uniform : 0.7565 ± 0.0406\n","  k= 3, weights=distance: 0.7573 ± 0.0408\n","  k= 5, weights=uniform : 0.7686 ± 0.0409\n","  k= 5, weights=distance: 0.7696 ± 0.0414\n","  k= 7, weights=uniform : 0.7759 ± 0.0400\n","  k= 7, weights=distance: 0.7762 ± 0.0394\n","  k= 9, weights=uniform : 0.7777 ± 0.0409\n","  k= 9, weights=distance: 0.7784 ± 0.0404\n","  k=11, weights=uniform : 0.7790 ± 0.0406\n","  k=11, weights=distance: 0.7794 ± 0.0404\n","\n","  ✓ Best parameters: {'n_neighbors': 11, 'weights': 'distance'}\n","  ✓ Best validation Macro-F1: 0.7794\n","\n","  Training final model with best parameters...\n","  ✓ Model saved: knn_fold5.pkl\n","\n","============================================================\n","Fold 6:\n","============================================================\n","Training set: (34008, 208), subjects: ['proband1' 'proband10' 'proband11' 'proband12' 'proband13' 'proband14'\n"," 'proband2' 'proband3' 'proband4' 'proband5' 'proband6' 'proband7'\n"," 'proband8' 'proband9']\n","  k= 1, weights=uniform : 0.7376 ± 0.0303\n","  k= 1, weights=distance: 0.7376 ± 0.0303\n","  k= 3, weights=uniform : 0.7597 ± 0.0261\n","  k= 3, weights=distance: 0.7598 ± 0.0236\n","  k= 5, weights=uniform : 0.7700 ± 0.0264\n","  k= 5, weights=distance: 0.7713 ± 0.0225\n","  k= 7, weights=uniform : 0.7769 ± 0.0238\n","  k= 7, weights=distance: 0.7776 ± 0.0224\n","  k= 9, weights=uniform : 0.7788 ± 0.0222\n","  k= 9, weights=distance: 0.7798 ± 0.0217\n","  k=11, weights=uniform : 0.7801 ± 0.0221\n","  k=11, weights=distance: 0.7811 ± 0.0213\n","\n","  ✓ Best parameters: {'n_neighbors': 11, 'weights': 'distance'}\n","  ✓ Best validation Macro-F1: 0.7811\n","\n","  Training final model with best parameters...\n","  ✓ Model saved: knn_fold6.pkl\n","\n","============================================================\n","Fold 7:\n","============================================================\n","Training set: (34330, 208), subjects: ['proband1' 'proband10' 'proband11' 'proband12' 'proband13' 'proband14'\n"," 'proband15' 'proband3' 'proband4' 'proband5' 'proband6' 'proband7'\n"," 'proband8' 'proband9']\n","  k= 1, weights=uniform : 0.7311 ± 0.0393\n","  k= 1, weights=distance: 0.7311 ± 0.0393\n","  k= 3, weights=uniform : 0.7520 ± 0.0348\n","  k= 3, weights=distance: 0.7539 ± 0.0346\n","  k= 5, weights=uniform : 0.7632 ± 0.0351\n","  k= 5, weights=distance: 0.7647 ± 0.0349\n","  k= 7, weights=uniform : 0.7685 ± 0.0333\n","  k= 7, weights=distance: 0.7698 ± 0.0328\n","  k= 9, weights=uniform : 0.7726 ± 0.0331\n","  k= 9, weights=distance: 0.7744 ± 0.0334\n","  k=11, weights=uniform : 0.7742 ± 0.0330\n","  k=11, weights=distance: 0.7760 ± 0.0328\n","\n","  ✓ Best parameters: {'n_neighbors': 11, 'weights': 'distance'}\n","  ✓ Best validation Macro-F1: 0.7760\n","\n","  Training final model with best parameters...\n","  ✓ Model saved: knn_fold7.pkl\n","\n","============================================================\n","Fold 8:\n","============================================================\n","Training set: (33917, 208), subjects: ['proband1' 'proband10' 'proband11' 'proband12' 'proband13' 'proband14'\n"," 'proband15' 'proband2' 'proband4' 'proband5' 'proband6' 'proband7'\n"," 'proband8' 'proband9']\n","  k= 1, weights=uniform : 0.7469 ± 0.0224\n","  k= 1, weights=distance: 0.7469 ± 0.0224\n","  k= 3, weights=uniform : 0.7671 ± 0.0280\n","  k= 3, weights=distance: 0.7676 ± 0.0282\n","  k= 5, weights=uniform : 0.7805 ± 0.0269\n","  k= 5, weights=distance: 0.7805 ± 0.0255\n","  k= 7, weights=uniform : 0.7863 ± 0.0261\n","  k= 7, weights=distance: 0.7862 ± 0.0272\n","  k= 9, weights=uniform : 0.7885 ± 0.0276\n","  k= 9, weights=distance: 0.7892 ± 0.0278\n","  k=11, weights=uniform : 0.7900 ± 0.0267\n","  k=11, weights=distance: 0.7907 ± 0.0275\n","\n","  ✓ Best parameters: {'n_neighbors': 11, 'weights': 'distance'}\n","  ✓ Best validation Macro-F1: 0.7907\n","\n","  Training final model with best parameters...\n","  ✓ Model saved: knn_fold8.pkl\n","\n","============================================================\n","Fold 9:\n","============================================================\n","Training set: (34375, 208), subjects: ['proband1' 'proband10' 'proband11' 'proband12' 'proband13' 'proband14'\n"," 'proband15' 'proband2' 'proband3' 'proband5' 'proband6' 'proband7'\n"," 'proband8' 'proband9']\n","  k= 1, weights=uniform : 0.7471 ± 0.0407\n","  k= 1, weights=distance: 0.7471 ± 0.0407\n","  k= 3, weights=uniform : 0.7697 ± 0.0359\n","  k= 3, weights=distance: 0.7707 ± 0.0345\n","  k= 5, weights=uniform : 0.7805 ± 0.0350\n","  k= 5, weights=distance: 0.7816 ± 0.0336\n","  k= 7, weights=uniform : 0.7859 ± 0.0322\n","  k= 7, weights=distance: 0.7872 ± 0.0313\n","  k= 9, weights=uniform : 0.7887 ± 0.0324\n","  k= 9, weights=distance: 0.7901 ± 0.0308\n","  k=11, weights=uniform : 0.7896 ± 0.0311\n","  k=11, weights=distance: 0.7914 ± 0.0308\n","\n","  ✓ Best parameters: {'n_neighbors': 11, 'weights': 'distance'}\n","  ✓ Best validation Macro-F1: 0.7914\n","\n","  Training final model with best parameters...\n","  ✓ Model saved: knn_fold9.pkl\n","\n","============================================================\n","Fold 10:\n","============================================================\n","Training set: (33690, 208), subjects: ['proband1' 'proband10' 'proband11' 'proband12' 'proband13' 'proband14'\n"," 'proband15' 'proband2' 'proband3' 'proband4' 'proband6' 'proband7'\n"," 'proband8' 'proband9']\n","  k= 1, weights=uniform : 0.7611 ± 0.0272\n","  k= 1, weights=distance: 0.7611 ± 0.0272\n","  k= 3, weights=uniform : 0.7803 ± 0.0287\n","  k= 3, weights=distance: 0.7817 ± 0.0291\n","  k= 5, weights=uniform : 0.7911 ± 0.0295\n","  k= 5, weights=distance: 0.7919 ± 0.0290\n","  k= 7, weights=uniform : 0.7968 ± 0.0276\n","  k= 7, weights=distance: 0.7982 ± 0.0274\n","  k= 9, weights=uniform : 0.7998 ± 0.0266\n","  k= 9, weights=distance: 0.8012 ± 0.0276\n","  k=11, weights=uniform : 0.8013 ± 0.0266\n","  k=11, weights=distance: 0.8024 ± 0.0264\n","\n","  ✓ Best parameters: {'n_neighbors': 11, 'weights': 'distance'}\n","  ✓ Best validation Macro-F1: 0.8024\n","\n","  Training final model with best parameters...\n","  ✓ Model saved: knn_fold10.pkl\n","\n","============================================================\n","Fold 11:\n","============================================================\n","Training set: (34091, 208), subjects: ['proband1' 'proband10' 'proband11' 'proband12' 'proband13' 'proband14'\n"," 'proband15' 'proband2' 'proband3' 'proband4' 'proband5' 'proband7'\n"," 'proband8' 'proband9']\n","  k= 1, weights=uniform : 0.7326 ± 0.0326\n","  k= 1, weights=distance: 0.7326 ± 0.0326\n","  k= 3, weights=uniform : 0.7506 ± 0.0289\n","  k= 3, weights=distance: 0.7532 ± 0.0280\n","  k= 5, weights=uniform : 0.7598 ± 0.0287\n","  k= 5, weights=distance: 0.7622 ± 0.0267\n","  k= 7, weights=uniform : 0.7680 ± 0.0276\n","  k= 7, weights=distance: 0.7690 ± 0.0254\n","  k= 9, weights=uniform : 0.7704 ± 0.0259\n","  k= 9, weights=distance: 0.7713 ± 0.0245\n","  k=11, weights=uniform : 0.7730 ± 0.0252\n","  k=11, weights=distance: 0.7738 ± 0.0236\n","\n","  ✓ Best parameters: {'n_neighbors': 11, 'weights': 'distance'}\n","  ✓ Best validation Macro-F1: 0.7738\n","\n","  Training final model with best parameters...\n","  ✓ Model saved: knn_fold11.pkl\n","\n","============================================================\n","Fold 12:\n","============================================================\n","Training set: (34620, 208), subjects: ['proband1' 'proband10' 'proband11' 'proband12' 'proband13' 'proband14'\n"," 'proband15' 'proband2' 'proband3' 'proband4' 'proband5' 'proband6'\n"," 'proband8' 'proband9']\n","  k= 1, weights=uniform : 0.7348 ± 0.0414\n","  k= 1, weights=distance: 0.7348 ± 0.0414\n","  k= 3, weights=uniform : 0.7579 ± 0.0360\n","  k= 3, weights=distance: 0.7596 ± 0.0367\n","  k= 5, weights=uniform : 0.7689 ± 0.0352\n","  k= 5, weights=distance: 0.7701 ± 0.0368\n","  k= 7, weights=uniform : 0.7782 ± 0.0339\n","  k= 7, weights=distance: 0.7788 ± 0.0345\n","  k= 9, weights=uniform : 0.7801 ± 0.0332\n","  k= 9, weights=distance: 0.7804 ± 0.0329\n","  k=11, weights=uniform : 0.7824 ± 0.0328\n","  k=11, weights=distance: 0.7827 ± 0.0331\n","\n","  ✓ Best parameters: {'n_neighbors': 11, 'weights': 'distance'}\n","  ✓ Best validation Macro-F1: 0.7827\n","\n","  Training final model with best parameters...\n","  ✓ Model saved: knn_fold12.pkl\n","\n","============================================================\n","Fold 13:\n","============================================================\n","Training set: (33728, 208), subjects: ['proband1' 'proband10' 'proband11' 'proband12' 'proband13' 'proband14'\n"," 'proband15' 'proband2' 'proband3' 'proband4' 'proband5' 'proband6'\n"," 'proband7' 'proband9']\n","  k= 1, weights=uniform : 0.7605 ± 0.0239\n","  k= 1, weights=distance: 0.7605 ± 0.0239\n","  k= 3, weights=uniform : 0.7827 ± 0.0222\n","  k= 3, weights=distance: 0.7841 ± 0.0232\n","  k= 5, weights=uniform : 0.7916 ± 0.0249\n","  k= 5, weights=distance: 0.7928 ± 0.0255\n","  k= 7, weights=uniform : 0.7968 ± 0.0247\n","  k= 7, weights=distance: 0.7976 ± 0.0253\n","  k= 9, weights=uniform : 0.8009 ± 0.0232\n","  k= 9, weights=distance: 0.8010 ± 0.0248\n","  k=11, weights=uniform : 0.8024 ± 0.0240\n","  k=11, weights=distance: 0.8024 ± 0.0248\n","\n","  ✓ Best parameters: {'n_neighbors': 11, 'weights': 'distance'}\n","  ✓ Best validation Macro-F1: 0.8024\n","\n","  Training final model with best parameters...\n","  ✓ Model saved: knn_fold13.pkl\n","\n","============================================================\n","Fold 14:\n","============================================================\n","Training set: (33946, 208), subjects: ['proband1' 'proband10' 'proband11' 'proband12' 'proband13' 'proband14'\n"," 'proband15' 'proband2' 'proband3' 'proband4' 'proband5' 'proband6'\n"," 'proband7' 'proband8']\n","  k= 1, weights=uniform : 0.7482 ± 0.0143\n","  k= 1, weights=distance: 0.7482 ± 0.0143\n","  k= 3, weights=uniform : 0.7685 ± 0.0170\n","  k= 3, weights=distance: 0.7694 ± 0.0188\n","  k= 5, weights=uniform : 0.7794 ± 0.0163\n","  k= 5, weights=distance: 0.7803 ± 0.0187\n","  k= 7, weights=uniform : 0.7863 ± 0.0171\n","  k= 7, weights=distance: 0.7867 ± 0.0192\n","  k= 9, weights=uniform : 0.7883 ± 0.0189\n","  k= 9, weights=distance: 0.7892 ± 0.0197\n","  k=11, weights=uniform : 0.7912 ± 0.0190\n","  k=11, weights=distance: 0.7918 ± 0.0202\n","\n","  ✓ Best parameters: {'n_neighbors': 11, 'weights': 'distance'}\n","  ✓ Best validation Macro-F1: 0.7918\n","\n","  Training final model with best parameters...\n","  ✓ Model saved: knn_fold14.pkl\n","\n","============================================================\n","KNN tuning completed\n","  Models: models/knn_fold*.pkl\n","  Results: logs/knn_tuning_results.json\n","[master e355fb1] model: KNN tuning with Macro-F1 scoring\n"," 16 files changed, 152 insertions(+)\n"," create mode 100644 logs/knn_tuning_results.json\n"," create mode 100644 models/knn_fold0.pkl\n"," create mode 100644 models/knn_fold1.pkl\n"," create mode 100644 models/knn_fold10.pkl\n"," create mode 100644 models/knn_fold11.pkl\n"," create mode 100644 models/knn_fold12.pkl\n"," create mode 100644 models/knn_fold13.pkl\n"," create mode 100644 models/knn_fold14.pkl\n"," create mode 100644 models/knn_fold2.pkl\n"," create mode 100644 models/knn_fold3.pkl\n"," create mode 100644 models/knn_fold4.pkl\n"," create mode 100644 models/knn_fold5.pkl\n"," create mode 100644 models/knn_fold6.pkl\n"," create mode 100644 models/knn_fold7.pkl\n"," create mode 100644 models/knn_fold8.pkl\n"," create mode 100644 models/knn_fold9.pkl\n","============================================================\n","Step 11 completed\n","============================================================\n"]}]},{"cell_type":"code","source":["# ================ Step 12: RF Inner-loop Tuning (Final Version) ================\n","import warnings\n","warnings.filterwarnings('ignore', message='.*class_weight.*warm_start.*')\n","\n","import os\n","os.environ['OMP_NUM_THREADS'] = '1'\n","os.environ['MKL_NUM_THREADS'] = '1'\n","os.environ['OPENBLAS_NUM_THREADS'] = '1'\n","\n","import numpy as np\n","from pathlib import Path\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.model_selection import GroupKFold\n","from sklearn.metrics import f1_score\n","import json\n","import pickle\n","import gc\n","\n","print(\"\\n\\nStep 12: RF Inner-loop Tuning\")\n","print(\"=\" * 60)\n","\n","features_dir = Path('/content/features')\n","models_dir = Path('/content/models')\n","logs_dir = Path('/content/logs')\n","models_dir.mkdir(exist_ok=True)\n","logs_dir.mkdir(parents=True, exist_ok=True)\n","\n","with open('/content/configs/splits.json', 'r') as f:\n","    splits_cfg = json.load(f)\n","\n","SEED = int(splits_cfg.get('seed', 42))\n","ESCALATE_DELTA = 0.002\n","EPS = 5e-4\n","PLATEAU = 0.002\n","STEP = 100\n","\n","PARAM_GRID = {\n","    'max_depth': [None, 20, 40],\n","    'max_features': ['sqrt', 'log2']\n","}\n","\n","search_config = {\n","    'seed': SEED,\n","    'escalate_delta': ESCALATE_DELTA,\n","    'eps': EPS,\n","    'plateau': PLATEAU,\n","    'step': STEP,\n","    'param_grid': PARAM_GRID\n","}\n","with open(logs_dir / 'search_config.json', 'w') as f:\n","    json.dump(search_config, f, indent=2)\n","\n","print(f\"Hyperparameter search space:\")\n","print(f\"  max_depth: {PARAM_GRID['max_depth']}\")\n","print(f\"  max_features: {PARAM_GRID['max_features']}\")\n","print(f\"  n_estimators: start at 300, increment +{STEP}, OOB two-consecutive-drop early-stopping threshold={PLATEAU}\")\n","print(f\"  Inner CV: multi-core + max_samples=0.8\")\n","print(f\"  Final model: all cores + full dataset + OOB\\n\")\n","\n","all_results = []\n","\n","for fold in splits_cfg['folds']:\n","    k = fold['fold']\n","    fold_seed = SEED + k\n","    print(f\"\\n{'='*60}\")\n","    print(f\"Fold {k} (seed={fold_seed}):\")\n","    print(f\"{'='*60}\")\n","\n","    train_data = np.load(features_dir / f'train_fold{k}.npz', allow_pickle=True)\n","    X_train = train_data['X'].astype(np.float32)\n","    y_train = train_data['y']\n","    subjects_train = train_data['subjects']\n","\n","    print(f\"Training set: {X_train.shape}, number of subjects: {len(np.unique(subjects_train))}\")\n","\n","    gkf = GroupKFold(n_splits=3)\n","    splits = list(gkf.split(X_train, y_train, groups=subjects_train))\n","\n","    best_score = -1\n","    best_params = None\n","    best_cv_scores = None\n","    param_idx = 0\n","    total_params = len(PARAM_GRID['max_depth']) * len(PARAM_GRID['max_features'])\n","\n","    for max_depth in PARAM_GRID['max_depth']:\n","        for max_features in PARAM_GRID['max_features']:\n","            param_idx += 1\n","\n","            rf_300_list = []\n","            scores_300 = []\n","\n","            for sidx, (train_idx, val_idx) in enumerate(splits):\n","                X_tr, X_val = X_train[train_idx], X_train[val_idx]\n","                y_tr, y_val = y_train[train_idx], y_train[val_idx]\n","\n","                seed_split = fold_seed * 100 + sidx\n","                rf = RandomForestClassifier(\n","                    n_estimators=300,\n","                    max_depth=max_depth,\n","                    max_features=max_features,\n","                    max_samples=0.8,\n","                    class_weight='balanced_subsample',\n","                    bootstrap=True,\n","                    oob_score=True,\n","                    warm_start=True,\n","                    random_state=seed_split,\n","                    n_jobs=-1\n","                )\n","                rf.fit(X_tr, y_tr)\n","                score_300 = f1_score(y_val, rf.predict(X_val), average='macro', zero_division=0)\n","                scores_300.append(score_300)\n","                rf_300_list.append((rf, train_idx, val_idx))\n","\n","            mean_300 = np.mean(scores_300)\n","            std_300 = np.std(scores_300)\n","\n","            depth_str = f\"{max_depth:4}\" if max_depth is not None else \"None\"\n","            print(f\"  [{param_idx:2d}/{total_params}] depth={depth_str}, feat={max_features:4s}:\")\n","            print(f\"    n= 300: {mean_300:.4f} ± {std_300:.4f}\")\n","\n","            old_best = best_score\n","            need_escalate = (best_params is None) or (mean_300 >= old_best - ESCALATE_DELTA)\n","\n","            if (mean_300 > best_score + EPS) or \\\n","               (best_params is not None and abs(mean_300 - best_score) <= EPS and 300 < best_params['n_estimators']):\n","                best_score = mean_300\n","                best_params = {'n_estimators': 300, 'max_depth': max_depth, 'max_features': max_features}\n","                best_cv_scores = [float(s) for s in scores_300]\n","\n","            if need_escalate:\n","                final_n_list = []\n","                final_scores = []\n","                growth_traces = []\n","\n","                for sidx, (rf, train_idx, val_idx) in enumerate(rf_300_list):\n","                    X_tr, X_val = X_train[train_idx], X_train[val_idx]\n","                    y_tr, y_val = y_train[train_idx], y_train[val_idx]\n","\n","                    best_n = 300\n","                    best_f1 = scores_300[sidx]\n","                    prev_oob = rf.oob_score_\n","                    streak = 0\n","\n","                    split_trace = [{'n': 300, 'oob': float(rf.oob_score_), 'f1': float(best_f1), 'delta': 0.0}]\n","\n","                    t = 300 + STEP\n","                    while t <= 600:\n","                        rf.set_params(n_estimators=t)\n","                        rf.fit(X_tr, y_tr)\n","\n","                        delta = rf.oob_score_ - prev_oob\n","                        f1_val = f1_score(y_val, rf.predict(X_val), average='macro', zero_division=0)\n","\n","                        split_trace.append({'n': t, 'oob': float(rf.oob_score_), 'f1': float(f1_val), 'delta': float(delta)})\n","\n","                        if delta < PLATEAU:\n","                            streak += 1\n","                            if streak >= 2:\n","                                print(f\"      split{sidx} stop@{t}: ΔOOB={delta:.4f} < {PLATEAU} (two consecutive drops)\")\n","                                break\n","                        else:\n","                            streak = 0\n","\n","                        prev_oob = rf.oob_score_\n","                        if f1_val >= best_f1:\n","                            best_f1 = f1_val\n","                            best_n = t\n","                        t += STEP\n","\n","                    final_n_list.append(best_n)\n","                    final_scores.append(best_f1)\n","                    growth_traces.append({'split': sidx, 'trace': split_trace})\n","\n","                depth_key = str(max_depth) if max_depth is not None else 'None'\n","                growth_file = logs_dir / f\"rf_growth_fold{k}_{depth_key}_{max_features}.json\"\n","                with open(growth_file, 'w') as f:\n","                    json.dump(growth_traces, f, indent=2)\n","\n","                final_n = int(np.median(final_n_list))\n","                mean_final = np.mean(final_scores)\n","                std_final = np.std(final_scores)\n","                print(f\"    n={final_n:4d}: {mean_final:.4f} ± {std_final:.4f}\")\n","\n","                if (mean_final > best_score + EPS) or \\\n","                   (best_params is not None and abs(mean_final - best_score) <= EPS and final_n < best_params['n_estimators']):\n","                    best_score = mean_final\n","                    best_params = {'n_estimators': final_n, 'max_depth': max_depth, 'max_features': max_features}\n","                    best_cv_scores = [float(s) for s in final_scores]\n","            else:\n","                print(f\"    n>300: (skipped, mean_300={mean_300:.4f} < old_best-delta={old_best-ESCALATE_DELTA:.4f})\")\n","\n","            del rf_300_list, scores_300\n","            gc.collect()\n","\n","    print(f\"\\n  ✓ Best parameters: {best_params}\")\n","    print(f\"  ✓ Best validation Macro-F1: {best_score:.4f}\")\n","\n","    print(f\"\\n  Training final model with best parameters (full dataset)...\")\n","\n","    rf_final = RandomForestClassifier(\n","        n_estimators=best_params['n_estimators'],\n","        max_depth=best_params['max_depth'],\n","        max_features=best_params['max_features'],\n","        class_weight='balanced_subsample',\n","        bootstrap=True,\n","        oob_score=True,\n","        random_state=fold_seed,\n","        n_jobs=-1\n","    )\n","    rf_final.fit(X_train, y_train)\n","\n","    oob_score = rf_final.oob_score_\n","    print(f\"  ✓ OOB Score: {oob_score:.4f}\")\n","\n","    rf_final.set_params(n_jobs=1)\n","\n","    model_dict = {\n","        'rf': rf_final,\n","        'best_params': best_params,\n","        'best_val_macro_f1': float(best_score),\n","        'best_cv_scores': best_cv_scores,\n","        'oob_score': float(oob_score),\n","        'oob_metric': 'accuracy',\n","        'fold': k,\n","        'n_jobs_train': -1,\n","        'n_jobs_infer': 1,\n","        'seed': fold_seed\n","    }\n","\n","    model_path = models_dir / f'rf_fold{k}.pkl'\n","    with open(model_path, 'wb') as f:\n","        pickle.dump(model_dict, f)\n","\n","    print(f\"  ✓ Model saved: {model_path.name}\")\n","\n","    all_results.append({\n","        'fold': k,\n","        'test_subject': fold['test_subject'],\n","        'best_params': best_params,\n","        'best_val_macro_f1': float(best_score),\n","        'best_cv_scores': best_cv_scores,\n","        'oob_score': float(oob_score),\n","        'n_train': int(len(X_train)),\n","        'seed': fold_seed\n","    })\n","\n","with open('/content/logs/rf_tuning_results.json', 'w') as f:\n","    json.dump(all_results, f, indent=2)\n","\n","print(f\"\\n{'='*60}\")\n","print(f\"RF tuning completed\")\n","\n","get_ipython().system('git add models/rf_fold*.pkl logs/rf_tuning_results.json logs/rf_growth_fold*.json logs/search_config.json')\n","get_ipython().system('git commit -m \"model: RF fully optimized tuning\"')\n","\n","print(f\"{'='*60}\\nStep 12 completed\\n{'='*60}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rp_3WdfuAQDp","executionInfo":{"status":"ok","timestamp":1762696744944,"user_tz":0,"elapsed":6858230,"user":{"displayName":"yu Wu","userId":"12692660435918028293"}},"outputId":"4d6e4983-6d66-4d7f-a1d5-a9a4bd5967f5"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","Step 12: RF Inner-loop Tuning\n","============================================================\n","Hyperparameter search space:\n","  max_depth: [None, 20, 40]\n","  max_features: ['sqrt', 'log2']\n","  n_estimators: start at 300, increment +100, OOB two-consecutive-drop early-stopping threshold=0.002\n","  Inner CV: multi-core + max_samples=0.8\n","  Final model: all cores + full dataset + OOB\n","\n","\n","============================================================\n","Fold 0 (seed=42):\n","============================================================\n","Training set: (34727, 208), number of subjects: 14\n","  [ 1/6] depth=None, feat=sqrt:\n","    n= 300: 0.8302 ± 0.0287\n","      split0 stop@500: ΔOOB=0.0003 < 0.002 (two consecutive drops)\n","      split1 stop@500: ΔOOB=0.0000 < 0.002 (two consecutive drops)\n","      split2 stop@500: ΔOOB=0.0004 < 0.002 (two consecutive drops)\n","    n= 400: 0.8310 ± 0.0288\n","  [ 2/6] depth=None, feat=log2:\n","    n= 300: 0.8282 ± 0.0285\n","    n>300: (skipped, mean_300=0.8282 < old_best-delta=0.8290)\n","  [ 3/6] depth=  20, feat=sqrt:\n","    n= 300: 0.8328 ± 0.0300\n","      split0 stop@500: ΔOOB=0.0000 < 0.002 (two consecutive drops)\n","      split1 stop@500: ΔOOB=0.0005 < 0.002 (two consecutive drops)\n","      split2 stop@500: ΔOOB=-0.0002 < 0.002 (two consecutive drops)\n","    n= 300: 0.8329 ± 0.0299\n","  [ 4/6] depth=  20, feat=log2:\n","    n= 300: 0.8270 ± 0.0290\n","    n>300: (skipped, mean_300=0.8270 < old_best-delta=0.8308)\n","  [ 5/6] depth=  40, feat=sqrt:\n","    n= 300: 0.8298 ± 0.0284\n","    n>300: (skipped, mean_300=0.8298 < old_best-delta=0.8308)\n","  [ 6/6] depth=  40, feat=log2:\n","    n= 300: 0.8284 ± 0.0283\n","    n>300: (skipped, mean_300=0.8284 < old_best-delta=0.8308)\n","\n","  ✓ Best parameters: {'n_estimators': 300, 'max_depth': 20, 'max_features': 'sqrt'}\n","  ✓ Best validation Macro-F1: 0.8328\n","\n","  Training final model with best parameters (full dataset)...\n","  ✓ OOB Score: 0.9215\n","  ✓ Model saved: rf_fold0.pkl\n","\n","============================================================\n","Fold 1 (seed=43):\n","============================================================\n","Training set: (34159, 208), number of subjects: 14\n","  [ 1/6] depth=None, feat=sqrt:\n","    n= 300: 0.8318 ± 0.0128\n","      split0 stop@500: ΔOOB=0.0000 < 0.002 (two consecutive drops)\n","      split1 stop@500: ΔOOB=0.0001 < 0.002 (two consecutive drops)\n","      split2 stop@500: ΔOOB=0.0015 < 0.002 (two consecutive drops)\n","    n= 400: 0.8326 ± 0.0134\n","  [ 2/6] depth=None, feat=log2:\n","    n= 300: 0.8275 ± 0.0154\n","    n>300: (skipped, mean_300=0.8275 < old_best-delta=0.8306)\n","  [ 3/6] depth=  20, feat=sqrt:\n","    n= 300: 0.8301 ± 0.0153\n","    n>300: (skipped, mean_300=0.8301 < old_best-delta=0.8306)\n","  [ 4/6] depth=  20, feat=log2:\n","    n= 300: 0.8286 ± 0.0140\n","    n>300: (skipped, mean_300=0.8286 < old_best-delta=0.8306)\n","  [ 5/6] depth=  40, feat=sqrt:\n","    n= 300: 0.8314 ± 0.0129\n","      split0 stop@500: ΔOOB=0.0004 < 0.002 (two consecutive drops)\n","      split1 stop@500: ΔOOB=0.0005 < 0.002 (two consecutive drops)\n","      split2 stop@500: ΔOOB=0.0009 < 0.002 (two consecutive drops)\n","    n= 400: 0.8321 ± 0.0136\n","  [ 6/6] depth=  40, feat=log2:\n","    n= 300: 0.8281 ± 0.0157\n","    n>300: (skipped, mean_300=0.8281 < old_best-delta=0.8306)\n","\n","  ✓ Best parameters: {'n_estimators': 400, 'max_depth': None, 'max_features': 'sqrt'}\n","  ✓ Best validation Macro-F1: 0.8326\n","\n","  Training final model with best parameters (full dataset)...\n","  ✓ OOB Score: 0.9217\n","  ✓ Model saved: rf_fold1.pkl\n","\n","============================================================\n","Fold 2 (seed=44):\n","============================================================\n","Training set: (34042, 208), number of subjects: 14\n","  [ 1/6] depth=None, feat=sqrt:\n","    n= 300: 0.8284 ± 0.0292\n","      split0 stop@500: ΔOOB=-0.0002 < 0.002 (two consecutive drops)\n","      split1 stop@500: ΔOOB=0.0009 < 0.002 (two consecutive drops)\n","      split2 stop@500: ΔOOB=-0.0000 < 0.002 (two consecutive drops)\n","    n= 300: 0.8288 ± 0.0287\n","  [ 2/6] depth=None, feat=log2:\n","    n= 300: 0.8291 ± 0.0270\n","      split0 stop@500: ΔOOB=0.0008 < 0.002 (two consecutive drops)\n","      split1 stop@500: ΔOOB=-0.0001 < 0.002 (two consecutive drops)\n","      split2 stop@500: ΔOOB=-0.0000 < 0.002 (two consecutive drops)\n","    n= 400: 0.8303 ± 0.0265\n","  [ 3/6] depth=  20, feat=sqrt:\n","    n= 300: 0.8296 ± 0.0269\n","      split0 stop@500: ΔOOB=-0.0000 < 0.002 (two consecutive drops)\n","      split1 stop@500: ΔOOB=0.0003 < 0.002 (two consecutive drops)\n","      split2 stop@500: ΔOOB=-0.0003 < 0.002 (two consecutive drops)\n","    n= 400: 0.8299 ± 0.0272\n","  [ 4/6] depth=  20, feat=log2:\n","    n= 300: 0.8300 ± 0.0250\n","      split0 stop@500: ΔOOB=0.0007 < 0.002 (two consecutive drops)\n","      split1 stop@500: ΔOOB=0.0000 < 0.002 (two consecutive drops)\n","      split2 stop@500: ΔOOB=0.0005 < 0.002 (two consecutive drops)\n","    n= 400: 0.8311 ± 0.0248\n","  [ 5/6] depth=  40, feat=sqrt:\n","    n= 300: 0.8282 ± 0.0304\n","    n>300: (skipped, mean_300=0.8282 < old_best-delta=0.8291)\n","  [ 6/6] depth=  40, feat=log2:\n","    n= 300: 0.8292 ± 0.0267\n","      split0 stop@500: ΔOOB=0.0008 < 0.002 (two consecutive drops)\n","      split1 stop@500: ΔOOB=-0.0005 < 0.002 (two consecutive drops)\n","      split2 stop@500: ΔOOB=0.0005 < 0.002 (two consecutive drops)\n","    n= 400: 0.8305 ± 0.0262\n","\n","  ✓ Best parameters: {'n_estimators': 400, 'max_depth': 20, 'max_features': 'log2'}\n","  ✓ Best validation Macro-F1: 0.8311\n","\n","  Training final model with best parameters (full dataset)...\n","  ✓ OOB Score: 0.9187\n","  ✓ Model saved: rf_fold2.pkl\n","\n","============================================================\n","Fold 3 (seed=45):\n","============================================================\n","Training set: (34255, 208), number of subjects: 14\n","  [ 1/6] depth=None, feat=sqrt:\n","    n= 300: 0.8303 ± 0.0364\n","      split0 stop@500: ΔOOB=0.0009 < 0.002 (two consecutive drops)\n","      split1 stop@500: ΔOOB=-0.0001 < 0.002 (two consecutive drops)\n","      split2 stop@500: ΔOOB=0.0006 < 0.002 (two consecutive drops)\n","    n= 300: 0.8306 ± 0.0368\n","  [ 2/6] depth=None, feat=log2:\n","    n= 300: 0.8285 ± 0.0383\n","      split0 stop@500: ΔOOB=0.0002 < 0.002 (two consecutive drops)\n","      split1 stop@500: ΔOOB=-0.0006 < 0.002 (two consecutive drops)\n","      split2 stop@500: ΔOOB=-0.0002 < 0.002 (two consecutive drops)\n","    n= 400: 0.8286 ± 0.0384\n","  [ 3/6] depth=  20, feat=sqrt:\n","    n= 300: 0.8310 ± 0.0376\n","      split0 stop@500: ΔOOB=-0.0004 < 0.002 (two consecutive drops)\n","      split1 stop@500: ΔOOB=-0.0002 < 0.002 (two consecutive drops)\n","      split2 stop@500: ΔOOB=0.0001 < 0.002 (two consecutive drops)\n","    n= 300: 0.8312 ± 0.0375\n","  [ 4/6] depth=  20, feat=log2:\n","    n= 300: 0.8265 ± 0.0398\n","    n>300: (skipped, mean_300=0.8265 < old_best-delta=0.8290)\n","  [ 5/6] depth=  40, feat=sqrt:\n","    n= 300: 0.8303 ± 0.0362\n","      split0 stop@500: ΔOOB=0.0006 < 0.002 (two consecutive drops)\n","      split1 stop@500: ΔOOB=-0.0003 < 0.002 (two consecutive drops)\n","      split2 stop@500: ΔOOB=0.0009 < 0.002 (two consecutive drops)\n","    n= 300: 0.8306 ± 0.0366\n","  [ 6/6] depth=  40, feat=log2:\n","    n= 300: 0.8285 ± 0.0384\n","    n>300: (skipped, mean_300=0.8285 < old_best-delta=0.8290)\n","\n","  ✓ Best parameters: {'n_estimators': 300, 'max_depth': 20, 'max_features': 'sqrt'}\n","  ✓ Best validation Macro-F1: 0.8310\n","\n","  Training final model with best parameters (full dataset)...\n","  ✓ OOB Score: 0.9185\n","  ✓ Model saved: rf_fold3.pkl\n","\n","============================================================\n","Fold 4 (seed=46):\n","============================================================\n","Training set: (34033, 208), number of subjects: 14\n","  [ 1/6] depth=None, feat=sqrt:\n","    n= 300: 0.8283 ± 0.0126\n","      split0 stop@500: ΔOOB=0.0005 < 0.002 (two consecutive drops)\n","      split1 stop@500: ΔOOB=0.0001 < 0.002 (two consecutive drops)\n","      split2 stop@500: ΔOOB=0.0015 < 0.002 (two consecutive drops)\n","    n= 300: 0.8284 ± 0.0127\n","  [ 2/6] depth=None, feat=log2:\n","    n= 300: 0.8238 ± 0.0177\n","    n>300: (skipped, mean_300=0.8238 < old_best-delta=0.8263)\n","  [ 3/6] depth=  20, feat=sqrt:\n","    n= 300: 0.8266 ± 0.0159\n","      split0 stop@500: ΔOOB=0.0007 < 0.002 (two consecutive drops)\n","      split1 stop@500: ΔOOB=-0.0001 < 0.002 (two consecutive drops)\n","      split2 stop@500: ΔOOB=0.0002 < 0.002 (two consecutive drops)\n","    n= 400: 0.8267 ± 0.0160\n","  [ 4/6] depth=  20, feat=log2:\n","    n= 300: 0.8263 ± 0.0149\n","    n>300: (skipped, mean_300=0.8263 < old_best-delta=0.8263)\n","  [ 5/6] depth=  40, feat=sqrt:\n","    n= 300: 0.8279 ± 0.0130\n","      split0 stop@500: ΔOOB=0.0006 < 0.002 (two consecutive drops)\n","      split1 stop@500: ΔOOB=0.0001 < 0.002 (two consecutive drops)\n","      split2 stop@500: ΔOOB=0.0006 < 0.002 (two consecutive drops)\n","    n= 300: 0.8282 ± 0.0126\n","  [ 6/6] depth=  40, feat=log2:\n","    n= 300: 0.8237 ± 0.0179\n","    n>300: (skipped, mean_300=0.8237 < old_best-delta=0.8263)\n","\n","  ✓ Best parameters: {'n_estimators': 300, 'max_depth': None, 'max_features': 'sqrt'}\n","  ✓ Best validation Macro-F1: 0.8283\n","\n","  Training final model with best parameters (full dataset)...\n","  ✓ OOB Score: 0.9224\n","  ✓ Model saved: rf_fold4.pkl\n","\n","============================================================\n","Fold 5 (seed=47):\n","============================================================\n","Training set: (34787, 208), number of subjects: 14\n","  [ 1/6] depth=None, feat=sqrt:\n","    n= 300: 0.8237 ± 0.0362\n","      split0 stop@500: ΔOOB=0.0002 < 0.002 (two consecutive drops)\n","      split1 stop@500: ΔOOB=0.0000 < 0.002 (two consecutive drops)\n","      split2 stop@500: ΔOOB=0.0004 < 0.002 (two consecutive drops)\n","    n= 400: 0.8243 ± 0.0358\n","  [ 2/6] depth=None, feat=log2:\n","    n= 300: 0.8175 ± 0.0372\n","    n>300: (skipped, mean_300=0.8175 < old_best-delta=0.8223)\n","  [ 3/6] depth=  20, feat=sqrt:\n","    n= 300: 0.8203 ± 0.0344\n","    n>300: (skipped, mean_300=0.8203 < old_best-delta=0.8223)\n","  [ 4/6] depth=  20, feat=log2:\n","    n= 300: 0.8172 ± 0.0372\n","    n>300: (skipped, mean_300=0.8172 < old_best-delta=0.8223)\n","  [ 5/6] depth=  40, feat=sqrt:\n","    n= 300: 0.8233 ± 0.0355\n","      split0 stop@500: ΔOOB=0.0004 < 0.002 (two consecutive drops)\n","      split1 stop@500: ΔOOB=0.0003 < 0.002 (two consecutive drops)\n","      split2 stop@500: ΔOOB=0.0002 < 0.002 (two consecutive drops)\n","    n= 400: 0.8238 ± 0.0356\n","  [ 6/6] depth=  40, feat=log2:\n","    n= 300: 0.8178 ± 0.0370\n","    n>300: (skipped, mean_300=0.8178 < old_best-delta=0.8223)\n","\n","  ✓ Best parameters: {'n_estimators': 400, 'max_depth': None, 'max_features': 'sqrt'}\n","  ✓ Best validation Macro-F1: 0.8243\n","\n","  Training final model with best parameters (full dataset)...\n","  ✓ OOB Score: 0.9230\n","  ✓ Model saved: rf_fold5.pkl\n","\n","============================================================\n","Fold 6 (seed=48):\n","============================================================\n","Training set: (34008, 208), number of subjects: 14\n","  [ 1/6] depth=None, feat=sqrt:\n","    n= 300: 0.8273 ± 0.0184\n","      split0 stop@500: ΔOOB=-0.0000 < 0.002 (two consecutive drops)\n","      split1 stop@500: ΔOOB=0.0002 < 0.002 (two consecutive drops)\n","      split2 stop@500: ΔOOB=-0.0007 < 0.002 (two consecutive drops)\n","    n= 400: 0.8276 ± 0.0180\n","  [ 2/6] depth=None, feat=log2:\n","    n= 300: 0.8270 ± 0.0166\n","      split0 stop@500: ΔOOB=0.0004 < 0.002 (two consecutive drops)\n","      split1 stop@500: ΔOOB=0.0010 < 0.002 (two consecutive drops)\n","      split2 stop@500: ΔOOB=-0.0001 < 0.002 (two consecutive drops)\n","    n= 400: 0.8275 ± 0.0170\n","  [ 3/6] depth=  20, feat=sqrt:\n","    n= 300: 0.8286 ± 0.0159\n","      split0 stop@500: ΔOOB=0.0005 < 0.002 (two consecutive drops)\n","      split1 stop@500: ΔOOB=0.0007 < 0.002 (two consecutive drops)\n","      split2 stop@500: ΔOOB=0.0001 < 0.002 (two consecutive drops)\n","    n= 400: 0.8289 ± 0.0160\n","  [ 4/6] depth=  20, feat=log2:\n","    n= 300: 0.8270 ± 0.0158\n","      split0 stop@500: ΔOOB=0.0008 < 0.002 (two consecutive drops)\n","      split1 stop@500: ΔOOB=-0.0001 < 0.002 (two consecutive drops)\n","      split2 stop@500: ΔOOB=-0.0003 < 0.002 (two consecutive drops)\n","    n= 300: 0.8273 ± 0.0159\n","  [ 5/6] depth=  40, feat=sqrt:\n","    n= 300: 0.8271 ± 0.0185\n","      split0 stop@500: ΔOOB=-0.0001 < 0.002 (two consecutive drops)\n","      split1 stop@500: ΔOOB=0.0003 < 0.002 (two consecutive drops)\n","      split2 stop@500: ΔOOB=-0.0009 < 0.002 (two consecutive drops)\n","    n= 400: 0.8278 ± 0.0182\n","  [ 6/6] depth=  40, feat=log2:\n","    n= 300: 0.8270 ± 0.0166\n","      split0 stop@500: ΔOOB=0.0008 < 0.002 (two consecutive drops)\n","      split1 stop@500: ΔOOB=0.0010 < 0.002 (two consecutive drops)\n","      split2 stop@500: ΔOOB=-0.0004 < 0.002 (two consecutive drops)\n","    n= 400: 0.8274 ± 0.0169\n","\n","  ✓ Best parameters: {'n_estimators': 300, 'max_depth': 20, 'max_features': 'sqrt'}\n","  ✓ Best validation Macro-F1: 0.8286\n","\n","  Training final model with best parameters (full dataset)...\n","  ✓ OOB Score: 0.9210\n","  ✓ Model saved: rf_fold6.pkl\n","\n","============================================================\n","Fold 7 (seed=49):\n","============================================================\n","Training set: (34330, 208), number of subjects: 14\n","  [ 1/6] depth=None, feat=sqrt:\n","    n= 300: 0.8207 ± 0.0380\n","      split0 stop@500: ΔOOB=0.0008 < 0.002 (two consecutive drops)\n","      split1 stop@500: ΔOOB=-0.0002 < 0.002 (two consecutive drops)\n","      split2 stop@500: ΔOOB=0.0002 < 0.002 (two consecutive drops)\n","    n= 400: 0.8213 ± 0.0378\n","  [ 2/6] depth=None, feat=log2:\n","    n= 300: 0.8159 ± 0.0409\n","    n>300: (skipped, mean_300=0.8159 < old_best-delta=0.8193)\n","  [ 3/6] depth=  20, feat=sqrt:\n","    n= 300: 0.8193 ± 0.0399\n","    n>300: (skipped, mean_300=0.8193 < old_best-delta=0.8193)\n","  [ 4/6] depth=  20, feat=log2:\n","    n= 300: 0.8162 ± 0.0405\n","    n>300: (skipped, mean_300=0.8162 < old_best-delta=0.8193)\n","  [ 5/6] depth=  40, feat=sqrt:\n","    n= 300: 0.8197 ± 0.0388\n","      split0 stop@500: ΔOOB=0.0017 < 0.002 (two consecutive drops)\n","      split1 stop@500: ΔOOB=-0.0002 < 0.002 (two consecutive drops)\n","      split2 stop@500: ΔOOB=0.0002 < 0.002 (two consecutive drops)\n","    n= 400: 0.8208 ± 0.0383\n","  [ 6/6] depth=  40, feat=log2:\n","    n= 300: 0.8159 ± 0.0410\n","    n>300: (skipped, mean_300=0.8159 < old_best-delta=0.8193)\n","\n","  ✓ Best parameters: {'n_estimators': 400, 'max_depth': None, 'max_features': 'sqrt'}\n","  ✓ Best validation Macro-F1: 0.8213\n","\n","  Training final model with best parameters (full dataset)...\n","  ✓ OOB Score: 0.9208\n","  ✓ Model saved: rf_fold7.pkl\n","\n","============================================================\n","Fold 8 (seed=50):\n","============================================================\n","Training set: (33917, 208), number of subjects: 14\n","  [ 1/6] depth=None, feat=sqrt:\n","    n= 300: 0.8177 ± 0.0387\n","      split0 stop@500: ΔOOB=0.0003 < 0.002 (two consecutive drops)\n","      split1 stop@500: ΔOOB=0.0009 < 0.002 (two consecutive drops)\n","      split2 stop@500: ΔOOB=0.0003 < 0.002 (two consecutive drops)\n","    n= 400: 0.8189 ± 0.0383\n","  [ 2/6] depth=None, feat=log2:\n","    n= 300: 0.8175 ± 0.0397\n","      split0 stop@500: ΔOOB=0.0003 < 0.002 (two consecutive drops)\n","      split1 stop@500: ΔOOB=0.0001 < 0.002 (two consecutive drops)\n","      split2 stop@500: ΔOOB=0.0004 < 0.002 (two consecutive drops)\n","    n= 400: 0.8183 ± 0.0390\n","  [ 3/6] depth=  20, feat=sqrt:\n","    n= 300: 0.8194 ± 0.0378\n","      split0 stop@500: ΔOOB=-0.0004 < 0.002 (two consecutive drops)\n","      split1 stop@500: ΔOOB=0.0006 < 0.002 (two consecutive drops)\n","      split2 stop@500: ΔOOB=-0.0008 < 0.002 (two consecutive drops)\n","    n= 300: 0.8200 ± 0.0386\n","  [ 4/6] depth=  20, feat=log2:\n","    n= 300: 0.8189 ± 0.0368\n","      split0 stop@500: ΔOOB=0.0007 < 0.002 (two consecutive drops)\n","      split1 stop@500: ΔOOB=-0.0001 < 0.002 (two consecutive drops)\n","      split2 stop@500: ΔOOB=0.0003 < 0.002 (two consecutive drops)\n","    n= 400: 0.8195 ± 0.0374\n","  [ 5/6] depth=  40, feat=sqrt:\n","    n= 300: 0.8176 ± 0.0387\n","    n>300: (skipped, mean_300=0.8176 < old_best-delta=0.8180)\n","  [ 6/6] depth=  40, feat=log2:\n","    n= 300: 0.8177 ± 0.0396\n","    n>300: (skipped, mean_300=0.8177 < old_best-delta=0.8180)\n","\n","  ✓ Best parameters: {'n_estimators': 300, 'max_depth': 20, 'max_features': 'sqrt'}\n","  ✓ Best validation Macro-F1: 0.8200\n","\n","  Training final model with best parameters (full dataset)...\n","  ✓ OOB Score: 0.9193\n","  ✓ Model saved: rf_fold8.pkl\n","\n","============================================================\n","Fold 9 (seed=51):\n","============================================================\n","Training set: (34375, 208), number of subjects: 14\n","  [ 1/6] depth=None, feat=sqrt:\n","    n= 300: 0.8273 ± 0.0239\n","      split0 stop@500: ΔOOB=0.0001 < 0.002 (two consecutive drops)\n","      split1 stop@500: ΔOOB=0.0000 < 0.002 (two consecutive drops)\n","      split2 stop@500: ΔOOB=0.0005 < 0.002 (two consecutive drops)\n","    n= 400: 0.8275 ± 0.0241\n","  [ 2/6] depth=None, feat=log2:\n","    n= 300: 0.8259 ± 0.0247\n","      split0 stop@500: ΔOOB=0.0002 < 0.002 (two consecutive drops)\n","      split1 stop@500: ΔOOB=0.0004 < 0.002 (two consecutive drops)\n","      split2 stop@500: ΔOOB=-0.0001 < 0.002 (two consecutive drops)\n","    n= 400: 0.8269 ± 0.0246\n","  [ 3/6] depth=  20, feat=sqrt:\n","    n= 300: 0.8265 ± 0.0261\n","      split0 stop@500: ΔOOB=0.0005 < 0.002 (two consecutive drops)\n","      split1 stop@500: ΔOOB=0.0003 < 0.002 (two consecutive drops)\n","      split2 stop@500: ΔOOB=0.0002 < 0.002 (two consecutive drops)\n","    n= 300: 0.8274 ± 0.0254\n","  [ 4/6] depth=  20, feat=log2:\n","    n= 300: 0.8253 ± 0.0251\n","      split0 stop@500: ΔOOB=0.0000 < 0.002 (two consecutive drops)\n","      split1 stop@500: ΔOOB=-0.0000 < 0.002 (two consecutive drops)\n","      split2 stop@500: ΔOOB=-0.0004 < 0.002 (two consecutive drops)\n","    n= 400: 0.8268 ± 0.0247\n","  [ 5/6] depth=  40, feat=sqrt:\n","    n= 300: 0.8275 ± 0.0231\n","      split0 stop@500: ΔOOB=0.0003 < 0.002 (two consecutive drops)\n","      split1 stop@500: ΔOOB=0.0004 < 0.002 (two consecutive drops)\n","      split2 stop@500: ΔOOB=0.0008 < 0.002 (two consecutive drops)\n","    n= 400: 0.8282 ± 0.0232\n","  [ 6/6] depth=  40, feat=log2:\n","    n= 300: 0.8262 ± 0.0246\n","    n>300: (skipped, mean_300=0.8262 < old_best-delta=0.8262)\n","\n","  ✓ Best parameters: {'n_estimators': 400, 'max_depth': 40, 'max_features': 'sqrt'}\n","  ✓ Best validation Macro-F1: 0.8282\n","\n","  Training final model with best parameters (full dataset)...\n","  ✓ OOB Score: 0.9276\n","  ✓ Model saved: rf_fold9.pkl\n","\n","============================================================\n","Fold 10 (seed=52):\n","============================================================\n","Training set: (33690, 208), number of subjects: 14\n","  [ 1/6] depth=None, feat=sqrt:\n","    n= 300: 0.8368 ± 0.0207\n","      split0 stop@500: ΔOOB=0.0010 < 0.002 (two consecutive drops)\n","      split1 stop@500: ΔOOB=0.0005 < 0.002 (two consecutive drops)\n","      split2 stop@500: ΔOOB=0.0007 < 0.002 (two consecutive drops)\n","    n= 400: 0.8372 ± 0.0207\n","  [ 2/6] depth=None, feat=log2:\n","    n= 300: 0.8346 ± 0.0186\n","    n>300: (skipped, mean_300=0.8346 < old_best-delta=0.8348)\n","  [ 3/6] depth=  20, feat=sqrt:\n","    n= 300: 0.8372 ± 0.0200\n","      split0 stop@500: ΔOOB=0.0007 < 0.002 (two consecutive drops)\n","      split1 stop@500: ΔOOB=0.0011 < 0.002 (two consecutive drops)\n","      split2 stop@500: ΔOOB=-0.0003 < 0.002 (two consecutive drops)\n","    n= 300: 0.8373 ± 0.0201\n","  [ 4/6] depth=  20, feat=log2:\n","    n= 300: 0.8347 ± 0.0179\n","    n>300: (skipped, mean_300=0.8347 < old_best-delta=0.8348)\n","  [ 5/6] depth=  40, feat=sqrt:\n","    n= 300: 0.8366 ± 0.0205\n","      split0 stop@500: ΔOOB=0.0010 < 0.002 (two consecutive drops)\n","      split1 stop@500: ΔOOB=0.0000 < 0.002 (two consecutive drops)\n","      split2 stop@500: ΔOOB=0.0000 < 0.002 (two consecutive drops)\n","    n= 400: 0.8370 ± 0.0207\n","  [ 6/6] depth=  40, feat=log2:\n","    n= 300: 0.8347 ± 0.0187\n","    n>300: (skipped, mean_300=0.8347 < old_best-delta=0.8348)\n","\n","  ✓ Best parameters: {'n_estimators': 300, 'max_depth': None, 'max_features': 'sqrt'}\n","  ✓ Best validation Macro-F1: 0.8368\n","\n","  Training final model with best parameters (full dataset)...\n","  ✓ OOB Score: 0.9275\n","  ✓ Model saved: rf_fold10.pkl\n","\n","============================================================\n","Fold 11 (seed=53):\n","============================================================\n","Training set: (34091, 208), number of subjects: 14\n","  [ 1/6] depth=None, feat=sqrt:\n","    n= 300: 0.8292 ± 0.0179\n","      split0 stop@500: ΔOOB=0.0001 < 0.002 (two consecutive drops)\n","      split1 stop@500: ΔOOB=-0.0003 < 0.002 (two consecutive drops)\n","      split2 stop@500: ΔOOB=0.0002 < 0.002 (two consecutive drops)\n","    n= 300: 0.8293 ± 0.0180\n","  [ 2/6] depth=None, feat=log2:\n","    n= 300: 0.8268 ± 0.0206\n","    n>300: (skipped, mean_300=0.8268 < old_best-delta=0.8272)\n","  [ 3/6] depth=  20, feat=sqrt:\n","    n= 300: 0.8298 ± 0.0183\n","      split0 stop@500: ΔOOB=0.0004 < 0.002 (two consecutive drops)\n","      split1 stop@500: ΔOOB=-0.0005 < 0.002 (two consecutive drops)\n","      split2 stop@500: ΔOOB=-0.0000 < 0.002 (two consecutive drops)\n","    n= 400: 0.8310 ± 0.0175\n","  [ 4/6] depth=  20, feat=log2:\n","    n= 300: 0.8278 ± 0.0227\n","    n>300: (skipped, mean_300=0.8278 < old_best-delta=0.8290)\n","  [ 5/6] depth=  40, feat=sqrt:\n","    n= 300: 0.8294 ± 0.0180\n","      split0 stop@500: ΔOOB=0.0004 < 0.002 (two consecutive drops)\n","      split1 stop@500: ΔOOB=-0.0005 < 0.002 (two consecutive drops)\n","      split2 stop@500: ΔOOB=-0.0003 < 0.002 (two consecutive drops)\n","    n= 300: 0.8295 ± 0.0180\n","  [ 6/6] depth=  40, feat=log2:\n","    n= 300: 0.8265 ± 0.0204\n","    n>300: (skipped, mean_300=0.8265 < old_best-delta=0.8290)\n","\n","  ✓ Best parameters: {'n_estimators': 400, 'max_depth': 20, 'max_features': 'sqrt'}\n","  ✓ Best validation Macro-F1: 0.8310\n","\n","  Training final model with best parameters (full dataset)...\n","  ✓ OOB Score: 0.9200\n","  ✓ Model saved: rf_fold11.pkl\n","\n","============================================================\n","Fold 12 (seed=54):\n","============================================================\n","Training set: (34620, 208), number of subjects: 14\n","  [ 1/6] depth=None, feat=sqrt:\n","    n= 300: 0.8239 ± 0.0400\n","      split0 stop@500: ΔOOB=0.0007 < 0.002 (two consecutive drops)\n","      split1 stop@500: ΔOOB=0.0007 < 0.002 (two consecutive drops)\n","      split2 stop@500: ΔOOB=-0.0000 < 0.002 (two consecutive drops)\n","    n= 400: 0.8250 ± 0.0400\n","  [ 2/6] depth=None, feat=log2:\n","    n= 300: 0.8228 ± 0.0385\n","    n>300: (skipped, mean_300=0.8228 < old_best-delta=0.8230)\n","  [ 3/6] depth=  20, feat=sqrt:\n","    n= 300: 0.8229 ± 0.0405\n","    n>300: (skipped, mean_300=0.8229 < old_best-delta=0.8230)\n","  [ 4/6] depth=  20, feat=log2:\n","    n= 300: 0.8216 ± 0.0399\n","    n>300: (skipped, mean_300=0.8216 < old_best-delta=0.8230)\n","  [ 5/6] depth=  40, feat=sqrt:\n","    n= 300: 0.8241 ± 0.0396\n","      split0 stop@500: ΔOOB=0.0009 < 0.002 (two consecutive drops)\n","      split1 stop@500: ΔOOB=0.0008 < 0.002 (two consecutive drops)\n","      split2 stop@500: ΔOOB=0.0002 < 0.002 (two consecutive drops)\n","    n= 400: 0.8248 ± 0.0399\n","  [ 6/6] depth=  40, feat=log2:\n","    n= 300: 0.8234 ± 0.0378\n","      split0 stop@500: ΔOOB=-0.0001 < 0.002 (two consecutive drops)\n","      split1 stop@500: ΔOOB=-0.0006 < 0.002 (two consecutive drops)\n","      split2 stop@500: ΔOOB=-0.0002 < 0.002 (two consecutive drops)\n","    n= 300: 0.8237 ± 0.0373\n","\n","  ✓ Best parameters: {'n_estimators': 400, 'max_depth': None, 'max_features': 'sqrt'}\n","  ✓ Best validation Macro-F1: 0.8250\n","\n","  Training final model with best parameters (full dataset)...\n","  ✓ OOB Score: 0.9236\n","  ✓ Model saved: rf_fold12.pkl\n","\n","============================================================\n","Fold 13 (seed=55):\n","============================================================\n","Training set: (33728, 208), number of subjects: 14\n","  [ 1/6] depth=None, feat=sqrt:\n","    n= 300: 0.8377 ± 0.0181\n","      split0 stop@500: ΔOOB=0.0008 < 0.002 (two consecutive drops)\n","      split1 stop@500: ΔOOB=0.0005 < 0.002 (two consecutive drops)\n","      split2 stop@500: ΔOOB=0.0004 < 0.002 (two consecutive drops)\n","    n= 300: 0.8382 ± 0.0185\n","  [ 2/6] depth=None, feat=log2:\n","    n= 300: 0.8360 ± 0.0180\n","      split0 stop@500: ΔOOB=-0.0001 < 0.002 (two consecutive drops)\n","      split1 stop@500: ΔOOB=-0.0000 < 0.002 (two consecutive drops)\n","      split2 stop@500: ΔOOB=-0.0000 < 0.002 (two consecutive drops)\n","    n= 300: 0.8361 ± 0.0180\n","  [ 3/6] depth=  20, feat=sqrt:\n","    n= 300: 0.8370 ± 0.0171\n","      split0 stop@500: ΔOOB=0.0005 < 0.002 (two consecutive drops)\n","      split1 stop@500: ΔOOB=0.0000 < 0.002 (two consecutive drops)\n","      split2 stop@500: ΔOOB=0.0005 < 0.002 (two consecutive drops)\n","    n= 400: 0.8376 ± 0.0168\n","  [ 4/6] depth=  20, feat=log2:\n","    n= 300: 0.8349 ± 0.0181\n","    n>300: (skipped, mean_300=0.8349 < old_best-delta=0.8357)\n","  [ 5/6] depth=  40, feat=sqrt:\n","    n= 300: 0.8373 ± 0.0178\n","      split0 stop@500: ΔOOB=0.0005 < 0.002 (two consecutive drops)\n","      split1 stop@500: ΔOOB=0.0008 < 0.002 (two consecutive drops)\n","      split2 stop@500: ΔOOB=0.0009 < 0.002 (two consecutive drops)\n","    n= 400: 0.8379 ± 0.0184\n","  [ 6/6] depth=  40, feat=log2:\n","    n= 300: 0.8359 ± 0.0180\n","      split0 stop@500: ΔOOB=-0.0001 < 0.002 (two consecutive drops)\n","      split1 stop@500: ΔOOB=0.0001 < 0.002 (two consecutive drops)\n","      split2 stop@500: ΔOOB=-0.0000 < 0.002 (two consecutive drops)\n","    n= 300: 0.8360 ± 0.0179\n","\n","  ✓ Best parameters: {'n_estimators': 300, 'max_depth': None, 'max_features': 'sqrt'}\n","  ✓ Best validation Macro-F1: 0.8377\n","\n","  Training final model with best parameters (full dataset)...\n","  ✓ OOB Score: 0.9244\n","  ✓ Model saved: rf_fold13.pkl\n","\n","============================================================\n","Fold 14 (seed=56):\n","============================================================\n","Training set: (33946, 208), number of subjects: 14\n","  [ 1/6] depth=None, feat=sqrt:\n","    n= 300: 0.8228 ± 0.0412\n","      split0 stop@500: ΔOOB=-0.0002 < 0.002 (two consecutive drops)\n","      split1 stop@500: ΔOOB=0.0001 < 0.002 (two consecutive drops)\n","      split2 stop@500: ΔOOB=0.0010 < 0.002 (two consecutive drops)\n","    n= 400: 0.8237 ± 0.0413\n","  [ 2/6] depth=None, feat=log2:\n","    n= 300: 0.8222 ± 0.0403\n","      split0 stop@500: ΔOOB=-0.0001 < 0.002 (two consecutive drops)\n","      split1 stop@500: ΔOOB=0.0009 < 0.002 (two consecutive drops)\n","      split2 stop@500: ΔOOB=0.0007 < 0.002 (two consecutive drops)\n","    n= 400: 0.8225 ± 0.0407\n","  [ 3/6] depth=  20, feat=sqrt:\n","    n= 300: 0.8231 ± 0.0417\n","      split0 stop@500: ΔOOB=0.0008 < 0.002 (two consecutive drops)\n","      split1 stop@500: ΔOOB=-0.0007 < 0.002 (two consecutive drops)\n","      split2 stop@500: ΔOOB=0.0011 < 0.002 (two consecutive drops)\n","    n= 400: 0.8232 ± 0.0416\n","  [ 4/6] depth=  20, feat=log2:\n","    n= 300: 0.8217 ± 0.0409\n","      split0 stop@500: ΔOOB=0.0007 < 0.002 (two consecutive drops)\n","      split1 stop@500: ΔOOB=0.0006 < 0.002 (two consecutive drops)\n","      split2 stop@500: ΔOOB=0.0005 < 0.002 (two consecutive drops)\n","    n= 400: 0.8224 ± 0.0410\n","  [ 5/6] depth=  40, feat=sqrt:\n","    n= 300: 0.8231 ± 0.0412\n","      split0 stop@500: ΔOOB=-0.0001 < 0.002 (two consecutive drops)\n","      split1 stop@500: ΔOOB=0.0002 < 0.002 (two consecutive drops)\n","      split2 stop@500: ΔOOB=0.0013 < 0.002 (two consecutive drops)\n","    n= 400: 0.8238 ± 0.0410\n","  [ 6/6] depth=  40, feat=log2:\n","    n= 300: 0.8221 ± 0.0403\n","      split0 stop@500: ΔOOB=-0.0002 < 0.002 (two consecutive drops)\n","      split1 stop@500: ΔOOB=0.0008 < 0.002 (two consecutive drops)\n","      split2 stop@500: ΔOOB=0.0008 < 0.002 (two consecutive drops)\n","    n= 400: 0.8223 ± 0.0406\n","\n","  ✓ Best parameters: {'n_estimators': 400, 'max_depth': None, 'max_features': 'sqrt'}\n","  ✓ Best validation Macro-F1: 0.8237\n","\n","  Training final model with best parameters (full dataset)...\n","  ✓ OOB Score: 0.9228\n","  ✓ Model saved: rf_fold14.pkl\n","\n","============================================================\n","RF tuning completed\n","[master 71312be] model: RF fully optimized tuning\n"," 72 files changed, 4195 insertions(+)\n"," create mode 100644 logs/rf_growth_fold0_20_sqrt.json\n"," create mode 100644 logs/rf_growth_fold0_None_sqrt.json\n"," create mode 100644 logs/rf_growth_fold10_20_sqrt.json\n"," create mode 100644 logs/rf_growth_fold10_40_sqrt.json\n"," create mode 100644 logs/rf_growth_fold10_None_sqrt.json\n"," create mode 100644 logs/rf_growth_fold11_20_sqrt.json\n"," create mode 100644 logs/rf_growth_fold11_40_sqrt.json\n"," create mode 100644 logs/rf_growth_fold11_None_sqrt.json\n"," create mode 100644 logs/rf_growth_fold12_40_log2.json\n"," create mode 100644 logs/rf_growth_fold12_40_sqrt.json\n"," create mode 100644 logs/rf_growth_fold12_None_sqrt.json\n"," create mode 100644 logs/rf_growth_fold13_20_sqrt.json\n"," create mode 100644 logs/rf_growth_fold13_40_log2.json\n"," create mode 100644 logs/rf_growth_fold13_40_sqrt.json\n"," create mode 100644 logs/rf_growth_fold13_None_log2.json\n"," create mode 100644 logs/rf_growth_fold13_None_sqrt.json\n"," create mode 100644 logs/rf_growth_fold14_20_log2.json\n"," create mode 100644 logs/rf_growth_fold14_20_sqrt.json\n"," create mode 100644 logs/rf_growth_fold14_40_log2.json\n"," create mode 100644 logs/rf_growth_fold14_40_sqrt.json\n"," create mode 100644 logs/rf_growth_fold14_None_log2.json\n"," create mode 100644 logs/rf_growth_fold14_None_sqrt.json\n"," create mode 100644 logs/rf_growth_fold1_40_sqrt.json\n"," create mode 100644 logs/rf_growth_fold1_None_sqrt.json\n"," create mode 100644 logs/rf_growth_fold2_20_log2.json\n"," create mode 100644 logs/rf_growth_fold2_20_sqrt.json\n"," create mode 100644 logs/rf_growth_fold2_40_log2.json\n"," create mode 100644 logs/rf_growth_fold2_None_log2.json\n"," create mode 100644 logs/rf_growth_fold2_None_sqrt.json\n"," create mode 100644 logs/rf_growth_fold3_20_sqrt.json\n"," create mode 100644 logs/rf_growth_fold3_40_sqrt.json\n"," create mode 100644 logs/rf_growth_fold3_None_log2.json\n"," create mode 100644 logs/rf_growth_fold3_None_sqrt.json\n"," create mode 100644 logs/rf_growth_fold4_20_sqrt.json\n"," create mode 100644 logs/rf_growth_fold4_40_sqrt.json\n"," create mode 100644 logs/rf_growth_fold4_None_sqrt.json\n"," create mode 100644 logs/rf_growth_fold5_40_sqrt.json\n"," create mode 100644 logs/rf_growth_fold5_None_sqrt.json\n"," create mode 100644 logs/rf_growth_fold6_20_log2.json\n"," create mode 100644 logs/rf_growth_fold6_20_sqrt.json\n"," create mode 100644 logs/rf_growth_fold6_40_log2.json\n"," create mode 100644 logs/rf_growth_fold6_40_sqrt.json\n"," create mode 100644 logs/rf_growth_fold6_None_log2.json\n"," create mode 100644 logs/rf_growth_fold6_None_sqrt.json\n"," create mode 100644 logs/rf_growth_fold7_40_sqrt.json\n"," create mode 100644 logs/rf_growth_fold7_None_sqrt.json\n"," create mode 100644 logs/rf_growth_fold8_20_log2.json\n"," create mode 100644 logs/rf_growth_fold8_20_sqrt.json\n"," create mode 100644 logs/rf_growth_fold8_None_log2.json\n"," create mode 100644 logs/rf_growth_fold8_None_sqrt.json\n"," create mode 100644 logs/rf_growth_fold9_20_log2.json\n"," create mode 100644 logs/rf_growth_fold9_20_sqrt.json\n"," create mode 100644 logs/rf_growth_fold9_40_sqrt.json\n"," create mode 100644 logs/rf_growth_fold9_None_log2.json\n"," create mode 100644 logs/rf_growth_fold9_None_sqrt.json\n"," create mode 100644 logs/rf_tuning_results.json\n"," create mode 100644 logs/search_config.json\n"," create mode 100644 models/rf_fold0.pkl\n"," create mode 100644 models/rf_fold1.pkl\n"," create mode 100644 models/rf_fold10.pkl\n"," create mode 100644 models/rf_fold11.pkl\n"," create mode 100644 models/rf_fold12.pkl\n"," create mode 100644 models/rf_fold13.pkl\n"," create mode 100644 models/rf_fold14.pkl\n"," create mode 100644 models/rf_fold2.pkl\n"," create mode 100644 models/rf_fold3.pkl\n"," create mode 100644 models/rf_fold4.pkl\n"," create mode 100644 models/rf_fold5.pkl\n"," create mode 100644 models/rf_fold6.pkl\n"," create mode 100644 models/rf_fold7.pkl\n"," create mode 100644 models/rf_fold8.pkl\n"," create mode 100644 models/rf_fold9.pkl\n","============================================================\n","Step 12 completed\n","============================================================\n"]}]},{"cell_type":"code","source":["# ================ Step 13: InceptionTime Preparation ================\n","\n","import numpy as np\n","import torch\n","from pathlib import Path\n","import json\n","\n","print(\"\\n\\nStep 13: InceptionTime Preparation\")\n","print(\"=\" * 60)\n","\n","# Load configuration\n","with open('/content/configs/splits.json', 'r') as f:\n","    splits_cfg = json.load(f)\n","\n","with open('/content/configs/classes.json', 'r') as f:\n","    classes_cfg = json.load(f)\n","\n","features_dir = Path('/content/features')\n","interim_dir = Path('/content/interim')\n","interim_dir.mkdir(exist_ok=True)\n","\n","CHANNELS = ['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_y', 'gyro_z']\n","N_CHANNELS = len(CHANNELS)\n","SEQ_LEN = 150\n","N_CLASSES = classes_cfg['num_classes']\n","\n","print(f\"Input shape: (n_channels={N_CHANNELS}, seq_len={SEQ_LEN})\")\n","print(f\"Number of classes: {N_CLASSES}\\n\")\n","\n","for fold in splits_cfg['folds']:\n","    k = fold['fold']\n","    print(f\"\\nFold {k}:\")\n","\n","    # Load standardized window data\n","    norm_data = np.load(features_dir / f'windows_normalized_fold{k}.npz', allow_pickle=True)\n","\n","    # Extract six-channel data and reshape to (n_samples, n_channels, seq_len)\n","    X_all = np.stack([norm_data[ch] for ch in CHANNELS], axis=1).astype(np.float32)\n","    y_all = norm_data['labels'].astype(np.int64)\n","    splits = norm_data['splits']\n","\n","    # Split into train/test\n","    train_mask = splits == 'train'\n","    test_mask = splits == 'test'\n","\n","    X_train = X_all[train_mask]\n","    y_train = y_all[train_mask]\n","    X_test = X_all[test_mask]\n","    y_test = y_all[test_mask]\n","\n","    print(f\"  Train: {X_train.shape}, Labels: {y_train.shape}\")\n","    print(f\"  Test:  {X_test.shape}, Labels: {y_test.shape}\")\n","\n","    # Convert to PyTorch tensors\n","    X_train_t = torch.from_numpy(X_train)\n","    y_train_t = torch.from_numpy(y_train)\n","    X_test_t = torch.from_numpy(X_test)\n","    y_test_t = torch.from_numpy(y_test)\n","\n","    # Convert labels to one-hot\n","    y_train_onehot = torch.nn.functional.one_hot(y_train_t, num_classes=N_CLASSES).float()\n","    y_test_onehot = torch.nn.functional.one_hot(y_test_t, num_classes=N_CLASSES).float()\n","\n","    # Save in .pt format\n","    torch.save({\n","        'X_train': X_train_t,\n","        'y_train': y_train_t,\n","        'y_train_onehot': y_train_onehot,\n","        'X_test': X_test_t,\n","        'y_test': y_test_t,\n","        'y_test_onehot': y_test_onehot,\n","        'subjects_train': norm_data['subjects'][train_mask],\n","        'subjects_test': norm_data['subjects'][test_mask],\n","        'activities_train': norm_data['activities'][train_mask],\n","        'activities_test': norm_data['activities'][test_mask]\n","    }, interim_dir / f'tensors_fold{k}.pt')\n","\n","    print(f\"  ✓ Saved: interim/tensors_fold{k}.pt\")\n","\n","print(f\"\\n{'='*60}\")\n","print(f\"✓ Completed tensor preparation across {len(splits_cfg['folds'])} folds\")\n","print(f\"  Format: (n_samples, n_channels=6, seq_len=150)\")\n","print(f\"  Labels: raw + one-hot (num_classes={N_CLASSES})\")\n","\n","get_ipython().system('git add interim/tensors_fold*.pt')\n","get_ipython().system('git commit -m \"prep: tensors for InceptionTime\"')\n","\n","print(f\"{'='*60}\\nStep 13 completed\\n{'='*60}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qlE88PRoCcqf","executionInfo":{"status":"ok","timestamp":1762696895870,"user_tz":0,"elapsed":83484,"user":{"displayName":"yu Wu","userId":"12692660435918028293"}},"outputId":"e10a7454-810e-4c05-ceb8-39be0c743189"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","Step 13: InceptionTime Preparation\n","============================================================\n","Input shape: (n_channels=6, seq_len=150)\n","Number of classes: 8\n","\n","\n","Fold 0:\n","  Train: (34727, 6, 150), Labels: (34727,)\n","  Test:  (1895, 6, 150), Labels: (1895,)\n","  ✓ Saved: interim/tensors_fold0.pt\n","\n","Fold 1:\n","  Train: (34159, 6, 150), Labels: (34159,)\n","  Test:  (2463, 6, 150), Labels: (2463,)\n","  ✓ Saved: interim/tensors_fold1.pt\n","\n","Fold 2:\n","  Train: (34042, 6, 150), Labels: (34042,)\n","  Test:  (2580, 6, 150), Labels: (2580,)\n","  ✓ Saved: interim/tensors_fold2.pt\n","\n","Fold 3:\n","  Train: (34255, 6, 150), Labels: (34255,)\n","  Test:  (2367, 6, 150), Labels: (2367,)\n","  ✓ Saved: interim/tensors_fold3.pt\n","\n","Fold 4:\n","  Train: (34033, 6, 150), Labels: (34033,)\n","  Test:  (2589, 6, 150), Labels: (2589,)\n","  ✓ Saved: interim/tensors_fold4.pt\n","\n","Fold 5:\n","  Train: (34787, 6, 150), Labels: (34787,)\n","  Test:  (1835, 6, 150), Labels: (1835,)\n","  ✓ Saved: interim/tensors_fold5.pt\n","\n","Fold 6:\n","  Train: (34008, 6, 150), Labels: (34008,)\n","  Test:  (2614, 6, 150), Labels: (2614,)\n","  ✓ Saved: interim/tensors_fold6.pt\n","\n","Fold 7:\n","  Train: (34330, 6, 150), Labels: (34330,)\n","  Test:  (2292, 6, 150), Labels: (2292,)\n","  ✓ Saved: interim/tensors_fold7.pt\n","\n","Fold 8:\n","  Train: (33917, 6, 150), Labels: (33917,)\n","  Test:  (2705, 6, 150), Labels: (2705,)\n","  ✓ Saved: interim/tensors_fold8.pt\n","\n","Fold 9:\n","  Train: (34375, 6, 150), Labels: (34375,)\n","  Test:  (2247, 6, 150), Labels: (2247,)\n","  ✓ Saved: interim/tensors_fold9.pt\n","\n","Fold 10:\n","  Train: (33690, 6, 150), Labels: (33690,)\n","  Test:  (2932, 6, 150), Labels: (2932,)\n","  ✓ Saved: interim/tensors_fold10.pt\n","\n","Fold 11:\n","  Train: (34091, 6, 150), Labels: (34091,)\n","  Test:  (2531, 6, 150), Labels: (2531,)\n","  ✓ Saved: interim/tensors_fold11.pt\n","\n","Fold 12:\n","  Train: (34620, 6, 150), Labels: (34620,)\n","  Test:  (2002, 6, 150), Labels: (2002,)\n","  ✓ Saved: interim/tensors_fold12.pt\n","\n","Fold 13:\n","  Train: (33728, 6, 150), Labels: (33728,)\n","  Test:  (2894, 6, 150), Labels: (2894,)\n","  ✓ Saved: interim/tensors_fold13.pt\n","\n","Fold 14:\n","  Train: (33946, 6, 150), Labels: (33946,)\n","  Test:  (2676, 6, 150), Labels: (2676,)\n","  ✓ Saved: interim/tensors_fold14.pt\n","\n","============================================================\n","✓ Completed tensor preparation across 15 folds\n","  Format: (n_samples, n_channels=6, seq_len=150)\n","  Labels: raw + one-hot (num_classes=8)\n","[master 4d0226a] prep: tensors for InceptionTime\n"," 15 files changed, 0 insertions(+), 0 deletions(-)\n"," create mode 100644 interim/tensors_fold0.pt\n"," create mode 100644 interim/tensors_fold1.pt\n"," create mode 100644 interim/tensors_fold10.pt\n"," create mode 100644 interim/tensors_fold11.pt\n"," create mode 100644 interim/tensors_fold12.pt\n"," create mode 100644 interim/tensors_fold13.pt\n"," create mode 100644 interim/tensors_fold14.pt\n"," create mode 100644 interim/tensors_fold2.pt\n"," create mode 100644 interim/tensors_fold3.pt\n"," create mode 100644 interim/tensors_fold4.pt\n"," create mode 100644 interim/tensors_fold5.pt\n"," create mode 100644 interim/tensors_fold6.pt\n"," create mode 100644 interim/tensors_fold7.pt\n"," create mode 100644 interim/tensors_fold8.pt\n"," create mode 100644 interim/tensors_fold9.pt\n","============================================================\n","Step 13 completed\n","============================================================\n"]}]},{"cell_type":"code","source":["# ================ Step 14: InceptionTime Training (Inner, Optimized) ================\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import TensorDataset, DataLoader, Subset\n","import numpy as np\n","import random\n","from pathlib import Path\n","from sklearn.model_selection import GroupKFold\n","from sklearn.metrics import f1_score\n","import json\n","import copy\n","import gc\n","\n","print(\"\\n\\nStep 14: InceptionTime Training (Inner)\")\n","print(\"=\" * 60)\n","\n","def set_seed(seed):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","use_amp = device.type == 'cuda'\n","\n","if device.type == 'cuda':\n","    torch.backends.cuda.matmul.allow_tf32 = True\n","    torch.backends.cudnn.allow_tf32 = True\n","\n","try:\n","    from torch.amp import autocast, GradScaler\n","    AMP_KW = {'device_type': device.type, 'enabled': use_amp}\n","except Exception:\n","    from torch.cuda.amp import autocast, GradScaler\n","    AMP_KW = {'enabled': use_amp}\n","\n","print(f\"Device: {device}, Mixed precision: {use_amp}, TF32: {device.type=='cuda'}\\n\")\n","\n","class InceptionModule(nn.Module):\n","    def __init__(self, in_channels, nb_filters, kernel_size, bottleneck):\n","        super().__init__()\n","        self.bottleneck = nn.Conv1d(in_channels, bottleneck, 1) if bottleneck else None\n","        k1, k2, k3 = kernel_size // 4, kernel_size // 2, kernel_size\n","        use_ch = bottleneck if bottleneck else in_channels\n","        self.conv1 = nn.Conv1d(use_ch, nb_filters, k1, padding=k1//2)\n","        self.conv2 = nn.Conv1d(use_ch, nb_filters, k2, padding=k2//2)\n","        self.conv3 = nn.Conv1d(use_ch, nb_filters, k3, padding=k3//2)\n","        self.pool = nn.Sequential(nn.MaxPool1d(3, stride=1, padding=1), nn.Conv1d(in_channels, nb_filters, 1))\n","        self.bn = nn.BatchNorm1d(nb_filters * 4)\n","        self.relu = nn.ReLU()\n","    def forward(self, x):\n","        input_res = x\n","        if self.bottleneck:\n","            x = self.bottleneck(x)\n","        x = torch.cat([self.conv1(x), self.conv2(x), self.conv3(x), self.pool(input_res)], dim=1)\n","        return self.relu(self.bn(x))\n","\n","class InceptionTime(nn.Module):\n","    def __init__(self, n_channels, seq_len, n_classes, depth=6, nb_filters=32, bottleneck=32, kernel_size=39, dropout=0.1):\n","        super().__init__()\n","        self.inception_modules = nn.ModuleList()\n","        in_ch = n_channels\n","        for _ in range(depth):\n","            self.inception_modules.append(InceptionModule(in_ch, nb_filters, kernel_size, bottleneck))\n","            in_ch = nb_filters * 4\n","        self.gap = nn.AdaptiveAvgPool1d(1)\n","        self.dropout = nn.Dropout(dropout)\n","        self.fc = nn.Linear(nb_filters * 4, n_classes)\n","    def forward(self, x):\n","        for module in self.inception_modules:\n","            x = module(x)\n","        x = self.gap(x).squeeze(-1)\n","        return self.fc(self.dropout(x))\n","\n","def train_epoch(model, loader, criterion, optimizer, device, scaler):\n","    model.train()\n","    total_loss = 0\n","    for X, y in loader:\n","        X, y = X.to(device, non_blocking=True), y.to(device, non_blocking=True)\n","        optimizer.zero_grad(set_to_none=True)\n","        with autocast(**AMP_KW):\n","            loss = criterion(model(X), y)\n","        scaler.scale(loss).backward()\n","        scaler.step(optimizer)\n","        scaler.update()\n","        total_loss += loss.item()\n","    return total_loss / len(loader)\n","\n","def eval_model(model, loader, device):\n","    model.eval()\n","    all_preds, all_labels = [], []\n","    with torch.no_grad():\n","        for X, y in loader:\n","            X, y = X.to(device, non_blocking=True), y.to(device, non_blocking=True)\n","            with autocast(**AMP_KW):\n","                preds = model(X).argmax(dim=1)\n","            all_preds.extend(preds.cpu().numpy())\n","            all_labels.extend(y.cpu().numpy())\n","    return f1_score(all_labels, all_preds, average='macro', zero_division=0)\n","\n","BATCH_SIZE = 128\n","LR_BASE = 1e-3\n","LR_SCALED = LR_BASE * (BATCH_SIZE / 64)\n","EVAL_EVERY = 2\n","PATIENCE = 8\n","\n","PARAMS = {'depth': 6, 'nb_filters': 32, 'bottleneck': 32, 'kernel_size': 39,\n","          'dropout': 0.1, 'lr': LR_SCALED, 'batch_size': BATCH_SIZE, 'max_epochs': 100,\n","          'patience': PATIENCE, 'eval_every': EVAL_EVERY}\n","print(f\"Hyperparameters: {PARAMS}\")\n","print(f\"Training configuration: AMP={use_amp}, TF32={device.type=='cuda'}, num_workers=2\\n\")\n","\n","with open('/content/configs/splits.json', 'r') as f:\n","    splits_cfg = json.load(f)\n","with open('/content/configs/classes.json', 'r') as f:\n","    classes_cfg = json.load(f)\n","\n","interim_dir = Path('/content/interim')\n","models_dir = Path('/content/models')\n","logs_dir = Path('/content/logs')\n","models_dir.mkdir(exist_ok=True)\n","logs_dir.mkdir(parents=True, exist_ok=True)\n","\n","N_CLASSES = classes_cfg['num_classes']\n","all_results = []\n","\n","for fold in splits_cfg['folds']:\n","    k = fold['fold']\n","    fold_seed = 1234 + k\n","    set_seed(fold_seed)\n","\n","    print(f\"\\n{'='*60}\")\n","    print(f\"Fold {k} (seed={fold_seed}):\")\n","    print(f\"{'='*60}\")\n","\n","    try:\n","        data = torch.load(interim_dir / f'tensors_fold{k}.pt', weights_only=False)\n","    except TypeError:\n","        data = torch.load(interim_dir / f'tensors_fold{k}.pt')\n","\n","    X_train = data['X_train'].contiguous()\n","    y_train = data['y_train']\n","    subjects_train = data['subjects_train']\n","    print(f\"Training set: {X_train.shape}\")\n","\n","    full_ds = TensorDataset(X_train, y_train)\n","    gkf = GroupKFold(n_splits=3)\n","\n","    best_val_f1 = -1\n","    best_model_state = None\n","    train_curves = []\n","    best_epochs = []\n","\n","    dl_kwargs = {'batch_size': PARAMS['batch_size'], 'pin_memory': device.type=='cuda',\n","                 'num_workers': 2, 'persistent_workers': True, 'prefetch_factor': 2}\n","\n","    n = len(y_train)\n","    torch.backends.cudnn.benchmark = True\n","\n","    for inner_idx, (tr_idx, va_idx) in enumerate(gkf.split(np.arange(n), groups=np.asarray(subjects_train))):\n","        print(f\"\\n  Inner fold {inner_idx+1}/3:\")\n","\n","        train_subjects = set(subjects_train[tr_idx])\n","        val_subjects = set(subjects_train[va_idx])\n","        assert train_subjects.isdisjoint(val_subjects), \"Subject leakage: overlap between train/validation sets\"\n","\n","        train_loader = DataLoader(Subset(full_ds, tr_idx.tolist()), shuffle=True, drop_last=True, **dl_kwargs)\n","        val_loader = DataLoader(Subset(full_ds, va_idx.tolist()), shuffle=False, **dl_kwargs)\n","\n","        model = InceptionTime(n_channels=6, seq_len=150, n_classes=N_CLASSES,\n","                             depth=PARAMS['depth'], nb_filters=PARAMS['nb_filters'],\n","                             bottleneck=PARAMS['bottleneck'], kernel_size=PARAMS['kernel_size'],\n","                             dropout=PARAMS['dropout']).to(device)\n","\n","        criterion = nn.CrossEntropyLoss()\n","        try:\n","            optimizer = optim.AdamW(model.parameters(), lr=PARAMS['lr'], fused=device.type=='cuda')\n","        except:\n","            optimizer = optim.AdamW(model.parameters(), lr=PARAMS['lr'])\n","        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=5)\n","        scaler = GradScaler(enabled=use_amp)\n","\n","        best_inner_f1 = -1\n","        best_inner_epoch = -1\n","        patience_counter = 0\n","        curve = []\n","\n","        for epoch in range(PARAMS['max_epochs']):\n","            train_loss = train_epoch(model, train_loader, criterion, optimizer, device, scaler)\n","\n","            if (epoch + 1) % EVAL_EVERY != 0:\n","                continue\n","\n","            val_f1 = eval_model(model, val_loader, device)\n","            scheduler.step(val_f1)\n","            curve.append({'epoch': epoch, 'train_loss': float(train_loss), 'val_f1': float(val_f1)})\n","\n","            if val_f1 > best_inner_f1:\n","                best_inner_f1 = val_f1\n","                best_inner_epoch = epoch\n","                patience_counter = 0\n","                if val_f1 > best_val_f1:\n","                    best_val_f1 = val_f1\n","                    best_model_state = copy.deepcopy(model.state_dict())\n","            else:\n","                patience_counter += 1\n","                if patience_counter >= PATIENCE:\n","                    print(f\"    Early stop @ epoch {epoch}, val_f1={val_f1:.4f}\")\n","                    break\n","\n","        best_epochs.append(best_inner_epoch)\n","        train_curves.append({'inner_fold': inner_idx, 'curve': curve,\n","                            'best_f1': float(best_inner_f1), 'best_epoch': int(best_inner_epoch)})\n","        print(f\"    Best val_f1: {best_inner_f1:.4f} @ epoch {best_inner_epoch}\")\n","\n","        del model, optimizer, scheduler, train_loader, val_loader\n","        gc.collect()\n","        if device.type == 'cuda':\n","            torch.cuda.empty_cache()\n","\n","    torch.backends.cudnn.benchmark = False\n","\n","    print(f\"\\n  ✓ Best inner val_f1: {best_val_f1:.4f}\")\n","\n","    E_star = int(np.median(best_epochs)) + 1\n","    print(f\"  Full training budget: E* = {E_star}\")\n","\n","    final_model = InceptionTime(n_channels=6, seq_len=150, n_classes=N_CLASSES,\n","                                depth=PARAMS['depth'], nb_filters=PARAMS['nb_filters'],\n","                                bottleneck=PARAMS['bottleneck'], kernel_size=PARAMS['kernel_size'],\n","                                dropout=PARAMS['dropout']).to(device)\n","    final_model.load_state_dict(best_model_state)\n","\n","    if E_star >= 10:\n","        try:\n","            final_model = torch.compile(final_model, mode='max-autotune')\n","            print(f\"  ✓ Model compiled (E*={E_star}>=10)\")\n","        except:\n","            pass\n","\n","    criterion = nn.CrossEntropyLoss()\n","    try:\n","        optimizer = optim.AdamW(final_model.parameters(), lr=PARAMS['lr'], fused=device.type=='cuda')\n","    except:\n","        optimizer = optim.AdamW(final_model.parameters(), lr=PARAMS['lr'])\n","    full_loader = DataLoader(full_ds, shuffle=True, **dl_kwargs)\n","    scaler = GradScaler(enabled=use_amp)\n","\n","    for e in range(E_star):\n","        _ = train_epoch(final_model, full_loader, criterion, optimizer, device, scaler)\n","\n","    torch.save({'model_state': final_model.state_dict(), 'params': PARAMS,\n","                'best_val_f1': float(best_val_f1), 'n_classes': N_CLASSES,\n","                'fold': k, 'seed': fold_seed}, models_dir / f'itime_fold{k}.pt')\n","\n","    with open(logs_dir / f'itime_curves_fold{k}.json', 'w') as f:\n","        json.dump(train_curves, f, indent=2)\n","\n","    print(f\"  ✓ Model saved\")\n","\n","    all_results.append({\n","        'fold': k, 'test_subject': fold['test_subject'],\n","        'best_val_f1': float(best_val_f1), 'n_train': int(len(X_train)),\n","        'E_star': E_star, 'seed': fold_seed,\n","        'config': {'amp': use_amp, 'tf32': device.type=='cuda', 'batch_size': BATCH_SIZE,\n","                   'lr': float(LR_SCALED), 'eval_every': EVAL_EVERY, 'patience': PATIENCE}\n","    })\n","\n","with open(logs_dir / 'itime_training_results.json', 'w') as f:\n","    json.dump(all_results, f, indent=2)\n","\n","print(f\"\\n{'='*60}\")\n","print(\"InceptionTime training completed\")\n","\n","get_ipython().system('git add models/itime_fold*.pt logs/itime_curves_fold*.json logs/itime_training_results.json')\n","get_ipython().system('git commit -m \"model: InceptionTime optimized training\"')\n","\n","print(f\"{'='*60}\\nStep 14 completed\\n{'='*60}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4x8Bry7j7VK1","executionInfo":{"status":"ok","timestamp":1762703539364,"user_tz":0,"elapsed":6455516,"user":{"displayName":"yu Wu","userId":"12692660435918028293"}},"outputId":"3164e2e1-d9f4-4673-8407-f5d7654256a5"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","Step 14: InceptionTime Training (Inner)\n","============================================================\n","Device: cuda, Mixed precision: True, TF32: True\n","\n","Hyperparameters: {'depth': 6, 'nb_filters': 32, 'bottleneck': 32, 'kernel_size': 39, 'dropout': 0.1, 'lr': 0.002, 'batch_size': 128, 'max_epochs': 100, 'patience': 8, 'eval_every': 2}\n","Training configuration: AMP=True, TF32=True, num_workers=2\n","\n","\n","============================================================\n","Fold 0 (seed=1234):\n","============================================================\n","Training set: torch.Size([34727, 6, 150])\n","\n","  Inner fold 1/3:\n","    Early stop @ epoch 25, val_f1=0.6214\n","    Best val_f1: 0.8116 @ epoch 9\n","\n","  Inner fold 2/3:\n","    Early stop @ epoch 17, val_f1=0.5117\n","    Best val_f1: 0.6519 @ epoch 1\n","\n","  Inner fold 3/3:\n","    Early stop @ epoch 31, val_f1=0.7563\n","    Best val_f1: 0.7674 @ epoch 15\n","\n","  ✓ Best inner val_f1: 0.8116\n","  Full training budget: E* = 10\n","  ✓ Model compiled (E*=10>=10)\n"]},{"output_type":"stream","name":"stderr","text":["W1109 14:09:22.942000 482 torch/_inductor/utils.py:1436] [0/0] Not enough SMs to use max_autotune_gemm mode\n","AUTOTUNE addmm(128x8, 128x128, 128x8)\n","strides: [0, 1], [128, 1], [1, 128]\n","dtypes: torch.float16, torch.float16, torch.float16\n","  bias_addmm 0.0061 ms 100.0% \n","  addmm 0.0082 ms 75.0% \n","SingleProcess AUTOTUNE benchmarking takes 0.1006 seconds and 0.0004 seconds precompiling for 2 choices\n","AUTOTUNE addmm(39x8, 39x128, 128x8)\n","strides: [0, 1], [128, 1], [1, 128]\n","dtypes: torch.float16, torch.float16, torch.float16\n","  bias_addmm 0.0061 ms 100.0% \n","  addmm 0.0072 ms 85.3% \n","SingleProcess AUTOTUNE benchmarking takes 0.0873 seconds and 0.0003 seconds precompiling for 2 choices\n"]},{"output_type":"stream","name":"stdout","text":["  ✓ Model saved\n","\n","============================================================\n","Fold 1 (seed=1235):\n","============================================================\n","Training set: torch.Size([34159, 6, 150])\n","\n","  Inner fold 1/3:\n","    Early stop @ epoch 17, val_f1=0.6822\n","    Best val_f1: 0.7943 @ epoch 1\n","\n","  Inner fold 2/3:\n","    Early stop @ epoch 25, val_f1=0.6786\n","    Best val_f1: 0.7077 @ epoch 9\n","\n","  Inner fold 3/3:\n","    Early stop @ epoch 21, val_f1=0.6747\n","    Best val_f1: 0.7530 @ epoch 5\n","\n","  ✓ Best inner val_f1: 0.7943\n","  Full training budget: E* = 6\n","  ✓ Model saved\n","\n","============================================================\n","Fold 2 (seed=1236):\n","============================================================\n","Training set: torch.Size([34042, 6, 150])\n","\n","  Inner fold 1/3:\n","    Early stop @ epoch 31, val_f1=0.6797\n","    Best val_f1: 0.7760 @ epoch 15\n","\n","  Inner fold 2/3:\n","    Early stop @ epoch 63, val_f1=0.7590\n","    Best val_f1: 0.7721 @ epoch 47\n","\n","  Inner fold 3/3:\n","    Early stop @ epoch 31, val_f1=0.5509\n","    Best val_f1: 0.7166 @ epoch 15\n","\n","  ✓ Best inner val_f1: 0.7760\n","  Full training budget: E* = 16\n","  ✓ Model compiled (E*=16>=10)\n","  ✓ Model saved\n","\n","============================================================\n","Fold 3 (seed=1237):\n","============================================================\n","Training set: torch.Size([34255, 6, 150])\n","\n","  Inner fold 1/3:\n","    Early stop @ epoch 35, val_f1=0.7478\n","    Best val_f1: 0.8134 @ epoch 19\n","\n","  Inner fold 2/3:\n","    Early stop @ epoch 43, val_f1=0.7100\n","    Best val_f1: 0.7739 @ epoch 27\n","\n","  Inner fold 3/3:\n","    Early stop @ epoch 37, val_f1=0.6849\n","    Best val_f1: 0.7715 @ epoch 21\n","\n","  ✓ Best inner val_f1: 0.8134\n","  Full training budget: E* = 22\n","  ✓ Model compiled (E*=22>=10)\n","  ✓ Model saved\n","\n","============================================================\n","Fold 4 (seed=1238):\n","============================================================\n","Training set: torch.Size([34033, 6, 150])\n","\n","  Inner fold 1/3:\n","    Early stop @ epoch 39, val_f1=0.7523\n","    Best val_f1: 0.8218 @ epoch 23\n","\n","  Inner fold 2/3:\n","    Early stop @ epoch 53, val_f1=0.7486\n","    Best val_f1: 0.7632 @ epoch 37\n","\n","  Inner fold 3/3:\n","    Early stop @ epoch 41, val_f1=0.6130\n","    Best val_f1: 0.7777 @ epoch 25\n","\n","  ✓ Best inner val_f1: 0.8218\n","  Full training budget: E* = 26\n","  ✓ Model compiled (E*=26>=10)\n","  ✓ Model saved\n","\n","============================================================\n","Fold 5 (seed=1239):\n","============================================================\n","Training set: torch.Size([34787, 6, 150])\n","\n","  Inner fold 1/3:\n","    Early stop @ epoch 29, val_f1=0.6996\n","    Best val_f1: 0.7943 @ epoch 13\n","\n","  Inner fold 2/3:\n","    Early stop @ epoch 21, val_f1=0.6886\n","    Best val_f1: 0.7581 @ epoch 5\n","\n","  Inner fold 3/3:\n","    Early stop @ epoch 35, val_f1=0.5401\n","    Best val_f1: 0.7534 @ epoch 19\n","\n","  ✓ Best inner val_f1: 0.7943\n","  Full training budget: E* = 14\n","  ✓ Model compiled (E*=14>=10)\n","  ✓ Model saved\n","\n","============================================================\n","Fold 6 (seed=1240):\n","============================================================\n","Training set: torch.Size([34008, 6, 150])\n","\n","  Inner fold 1/3:\n","    Early stop @ epoch 21, val_f1=0.6977\n","    Best val_f1: 0.7656 @ epoch 5\n","\n","  Inner fold 2/3:\n","    Early stop @ epoch 23, val_f1=0.7367\n","    Best val_f1: 0.7617 @ epoch 7\n","\n","  Inner fold 3/3:\n","    Early stop @ epoch 25, val_f1=0.5649\n","    Best val_f1: 0.7427 @ epoch 9\n","\n","  ✓ Best inner val_f1: 0.7656\n","  Full training budget: E* = 8\n","  ✓ Model saved\n","\n","============================================================\n","Fold 7 (seed=1241):\n","============================================================\n","Training set: torch.Size([34330, 6, 150])\n","\n","  Inner fold 1/3:\n","    Early stop @ epoch 55, val_f1=0.7572\n","    Best val_f1: 0.8025 @ epoch 39\n","\n","  Inner fold 2/3:\n","    Early stop @ epoch 51, val_f1=0.7412\n","    Best val_f1: 0.7560 @ epoch 35\n","\n","  Inner fold 3/3:\n","    Early stop @ epoch 25, val_f1=0.7640\n","    Best val_f1: 0.7743 @ epoch 9\n","\n","  ✓ Best inner val_f1: 0.8025\n","  Full training budget: E* = 36\n","  ✓ Model compiled (E*=36>=10)\n","  ✓ Model saved\n","\n","============================================================\n","Fold 8 (seed=1242):\n","============================================================\n","Training set: torch.Size([33917, 6, 150])\n","\n","  Inner fold 1/3:\n","    Early stop @ epoch 21, val_f1=0.6666\n","    Best val_f1: 0.7709 @ epoch 5\n","\n","  Inner fold 2/3:\n","    Early stop @ epoch 23, val_f1=0.6043\n","    Best val_f1: 0.7756 @ epoch 7\n","\n","  Inner fold 3/3:\n","    Early stop @ epoch 39, val_f1=0.8135\n","    Best val_f1: 0.8698 @ epoch 23\n","\n","  ✓ Best inner val_f1: 0.8698\n","  Full training budget: E* = 8\n","  ✓ Model saved\n","\n","============================================================\n","Fold 9 (seed=1243):\n","============================================================\n","Training set: torch.Size([34375, 6, 150])\n","\n","  Inner fold 1/3:\n","    Early stop @ epoch 61, val_f1=0.7843\n","    Best val_f1: 0.8261 @ epoch 45\n","\n","  Inner fold 2/3:\n","    Early stop @ epoch 57, val_f1=0.7428\n","    Best val_f1: 0.8085 @ epoch 41\n","\n","  Inner fold 3/3:\n","    Early stop @ epoch 33, val_f1=0.7241\n","    Best val_f1: 0.7510 @ epoch 17\n","\n","  ✓ Best inner val_f1: 0.8261\n","  Full training budget: E* = 42\n","  ✓ Model compiled (E*=42>=10)\n","  ✓ Model saved\n","\n","============================================================\n","Fold 10 (seed=1244):\n","============================================================\n","Training set: torch.Size([33690, 6, 150])\n","\n","  Inner fold 1/3:\n","    Early stop @ epoch 47, val_f1=0.7379\n","    Best val_f1: 0.7897 @ epoch 31\n","\n","  Inner fold 2/3:\n","    Early stop @ epoch 19, val_f1=0.5541\n","    Best val_f1: 0.7349 @ epoch 3\n","\n","  Inner fold 3/3:\n","    Early stop @ epoch 41, val_f1=0.6514\n","    Best val_f1: 0.8356 @ epoch 25\n","\n","  ✓ Best inner val_f1: 0.8356\n","  Full training budget: E* = 26\n","  ✓ Model compiled (E*=26>=10)\n","  ✓ Model saved\n","\n","============================================================\n","Fold 11 (seed=1245):\n","============================================================\n","Training set: torch.Size([34091, 6, 150])\n","\n","  Inner fold 1/3:\n","    Early stop @ epoch 57, val_f1=0.7841\n","    Best val_f1: 0.8479 @ epoch 41\n","\n","  Inner fold 2/3:\n","    Early stop @ epoch 45, val_f1=0.7060\n","    Best val_f1: 0.7441 @ epoch 29\n","\n","  Inner fold 3/3:\n","    Early stop @ epoch 41, val_f1=0.6477\n","    Best val_f1: 0.7638 @ epoch 25\n","\n","  ✓ Best inner val_f1: 0.8479\n","  Full training budget: E* = 30\n","  ✓ Model compiled (E*=30>=10)\n","  ✓ Model saved\n","\n","============================================================\n","Fold 12 (seed=1246):\n","============================================================\n","Training set: torch.Size([34620, 6, 150])\n","\n","  Inner fold 1/3:\n","    Early stop @ epoch 39, val_f1=0.6643\n","    Best val_f1: 0.8213 @ epoch 23\n","\n","  Inner fold 2/3:\n","    Early stop @ epoch 27, val_f1=0.5478\n","    Best val_f1: 0.6775 @ epoch 11\n","\n","  Inner fold 3/3:\n","    Early stop @ epoch 39, val_f1=0.6062\n","    Best val_f1: 0.7892 @ epoch 23\n","\n","  ✓ Best inner val_f1: 0.8213\n","  Full training budget: E* = 24\n","  ✓ Model compiled (E*=24>=10)\n","  ✓ Model saved\n","\n","============================================================\n","Fold 13 (seed=1247):\n","============================================================\n","Training set: torch.Size([33728, 6, 150])\n","\n","  Inner fold 1/3:\n","    Early stop @ epoch 39, val_f1=0.7213\n","    Best val_f1: 0.8396 @ epoch 23\n","\n","  Inner fold 2/3:\n","    Early stop @ epoch 25, val_f1=0.6680\n","    Best val_f1: 0.7564 @ epoch 9\n","\n","  Inner fold 3/3:\n","    Early stop @ epoch 57, val_f1=0.7808\n","    Best val_f1: 0.8057 @ epoch 41\n","\n","  ✓ Best inner val_f1: 0.8396\n","  Full training budget: E* = 24\n","  ✓ Model compiled (E*=24>=10)\n","  ✓ Model saved\n","\n","============================================================\n","Fold 14 (seed=1248):\n","============================================================\n","Training set: torch.Size([33946, 6, 150])\n","\n","  Inner fold 1/3:\n","    Early stop @ epoch 41, val_f1=0.7965\n","    Best val_f1: 0.8191 @ epoch 25\n","\n","  Inner fold 2/3:\n","    Early stop @ epoch 31, val_f1=0.6562\n","    Best val_f1: 0.7477 @ epoch 15\n","\n","  Inner fold 3/3:\n","    Early stop @ epoch 39, val_f1=0.5763\n","    Best val_f1: 0.7860 @ epoch 23\n","\n","  ✓ Best inner val_f1: 0.8191\n","  Full training budget: E* = 24\n","  ✓ Model compiled (E*=24>=10)\n","  ✓ Model saved\n","\n","============================================================\n","InceptionTime training completed\n","[master 8b0e71c] model: InceptionTime optimized training\n"," 31 files changed, 4737 insertions(+)\n"," create mode 100644 logs/itime_curves_fold0.json\n"," create mode 100644 logs/itime_curves_fold1.json\n"," create mode 100644 logs/itime_curves_fold10.json\n"," create mode 100644 logs/itime_curves_fold11.json\n"," create mode 100644 logs/itime_curves_fold12.json\n"," create mode 100644 logs/itime_curves_fold13.json\n"," create mode 100644 logs/itime_curves_fold14.json\n"," create mode 100644 logs/itime_curves_fold2.json\n"," create mode 100644 logs/itime_curves_fold3.json\n"," create mode 100644 logs/itime_curves_fold4.json\n"," create mode 100644 logs/itime_curves_fold5.json\n"," create mode 100644 logs/itime_curves_fold6.json\n"," create mode 100644 logs/itime_curves_fold7.json\n"," create mode 100644 logs/itime_curves_fold8.json\n"," create mode 100644 logs/itime_curves_fold9.json\n"," create mode 100644 logs/itime_training_results.json\n"," create mode 100644 models/itime_fold0.pt\n"," create mode 100644 models/itime_fold1.pt\n"," create mode 100644 models/itime_fold10.pt\n"," create mode 100644 models/itime_fold11.pt\n"," create mode 100644 models/itime_fold12.pt\n"," create mode 100644 models/itime_fold13.pt\n"," create mode 100644 models/itime_fold14.pt\n"," create mode 100644 models/itime_fold2.pt\n"," create mode 100644 models/itime_fold3.pt\n"," create mode 100644 models/itime_fold4.pt\n"," create mode 100644 models/itime_fold5.pt\n"," create mode 100644 models/itime_fold6.pt\n"," create mode 100644 models/itime_fold7.pt\n"," create mode 100644 models/itime_fold8.pt\n"," create mode 100644 models/itime_fold9.pt\n","============================================================\n","Step 14 completed\n","============================================================\n"]}]},{"cell_type":"code","source":["# ================ Step 15: Inference & Prediction ================\n","import numpy as np\n","import torch\n","import pickle\n","import time\n","from pathlib import Path\n","import json\n","\n","print(\"\\n\\nStep 15: Inference & Prediction\")\n","print(\"=\" * 60)\n","\n","features_dir = Path('/content/features')\n","models_dir = Path('/content/models')\n","interim_dir = Path('/content/interim')\n","logs_dir = Path('/content/logs')\n","\n","with open('/content/configs/splits.json', 'r') as f:\n","    splits_cfg = json.load(f)\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f\"Device: {device}\\n\")\n","\n","all_latency_stats = []\n","\n","for fold in splits_cfg['folds']:\n","    k = fold['fold']\n","    print(f\"\\n{'='*60}\")\n","    print(f\"Fold {k}:\")\n","    print(f\"{'='*60}\")\n","\n","    # ========== KNN ==========\n","    print(\"\\n[KNN]\")\n","    test_data = np.load(features_dir / f'test_fold{k}.npz', allow_pickle=True)\n","    X_test = test_data['X']\n","    y_test = test_data['y']\n","    print(f\"  Test set: {X_test.shape}\")\n","\n","    with open(models_dir / f'knn_fold{k}.pkl', 'rb') as f:\n","        knn_dict = pickle.load(f)\n","\n","    knn_model = knn_dict['knn']\n","    scaler = knn_dict['scaler']\n","    X_test_scaled = scaler.transform(X_test)\n","\n","    latencies_knn = []\n","    for i in range(len(X_test_scaled)):\n","        t0 = time.perf_counter()\n","        _ = knn_model.predict(X_test_scaled[i:i+1])\n","        latencies_knn.append((time.perf_counter() - t0) * 1000)\n","\n","    preds_knn = knn_model.predict(X_test_scaled)\n","    np.save(logs_dir / f'preds_fold{k}_knn.npy', preds_knn)\n","\n","    p50_knn, p90_knn = np.percentile(latencies_knn, [50, 90])\n","    print(f\"  ✓ Predictions complete: {len(preds_knn)} samples\")\n","    print(f\"  ✓ Latency: p50={p50_knn:.2f}ms, p90={p90_knn:.2f}ms\")\n","\n","    # ========== RF ==========\n","    print(\"\\n[RF]\")\n","    with open(models_dir / f'rf_fold{k}.pkl', 'rb') as f:\n","        rf_dict = pickle.load(f)\n","\n","    rf_model = rf_dict['rf']\n","\n","    latencies_rf = []\n","    for i in range(len(X_test)):\n","        t0 = time.perf_counter()\n","        _ = rf_model.predict(X_test[i:i+1])\n","        latencies_rf.append((time.perf_counter() - t0) * 1000)\n","\n","    preds_rf = rf_model.predict(X_test)\n","    np.save(logs_dir / f'preds_fold{k}_rf.npy', preds_rf)\n","\n","    p50_rf, p90_rf = np.percentile(latencies_rf, [50, 90])\n","    print(f\"  ✓ Predictions complete: {len(preds_rf)} samples\")\n","    print(f\"  ✓ Latency: p50={p50_rf:.2f}ms, p90={p90_rf:.2f}ms\")\n","\n","    # ========== InceptionTime ==========\n","    print(\"\\n[InceptionTime]\")\n","    test_tensors = torch.load(interim_dir / f'tensors_fold{k}.pt', weights_only=False)\n","    X_test_tensor = test_tensors['X_test']\n","    y_test_tensor = test_tensors['y_test']\n","    print(f\"  Test set: {X_test_tensor.shape}\")\n","\n","    checkpoint = torch.load(models_dir / f'itime_fold{k}.pt', weights_only=False)\n","\n","    from torch import nn\n","    class InceptionModule(nn.Module):\n","        def __init__(self, in_channels, nb_filters, kernel_size, bottleneck):\n","            super().__init__()\n","            self.bottleneck = nn.Conv1d(in_channels, bottleneck, 1) if bottleneck else None\n","            k1, k2, k3 = kernel_size // 4, kernel_size // 2, kernel_size\n","            use_ch = bottleneck if bottleneck else in_channels\n","            self.conv1 = nn.Conv1d(use_ch, nb_filters, k1, padding=(k1-1)//2)\n","            self.conv2 = nn.Conv1d(use_ch, nb_filters, k2, padding=(k2-1)//2)\n","            self.conv3 = nn.Conv1d(use_ch, nb_filters, k3, padding=(k3-1)//2)\n","            self.pool = nn.Sequential(nn.MaxPool1d(3, stride=1, padding=1), nn.Conv1d(in_channels, nb_filters, 1))\n","            self.bn = nn.BatchNorm1d(nb_filters * 4)\n","            self.relu = nn.ReLU()\n","        def forward(self, x):\n","            input_res = x\n","            if self.bottleneck:\n","                x = self.bottleneck(x)\n","            x1, x2, x3, x4 = self.conv1(x), self.conv2(x), self.conv3(x), self.pool(input_res)\n","            min_len = min(x1.size(2), x2.size(2), x3.size(2), x4.size(2))\n","            x = torch.cat([x1[:,:,:min_len], x2[:,:,:min_len], x3[:,:,:min_len], x4[:,:,:min_len]], dim=1)\n","            return self.relu(self.bn(x))\n","\n","    class InceptionTime(nn.Module):\n","        def __init__(self, n_channels, seq_len, n_classes, depth=6, nb_filters=32, bottleneck=32, kernel_size=40, dropout=0.1):\n","            super().__init__()\n","            self.inception_modules = nn.ModuleList()\n","            in_ch = n_channels\n","            for _ in range(depth):\n","                self.inception_modules.append(InceptionModule(in_ch, nb_filters, kernel_size, bottleneck))\n","                in_ch = nb_filters * 4\n","            self.gap = nn.AdaptiveAvgPool1d(1)\n","            self.dropout = nn.Dropout(dropout)\n","            self.fc = nn.Linear(nb_filters * 4, n_classes)\n","        def forward(self, x):\n","            for module in self.inception_modules:\n","                x = module(x)\n","            x = self.gap(x).squeeze(-1)\n","            return self.fc(self.dropout(x))\n","\n","    model = InceptionTime(n_channels=6, seq_len=150, n_classes=checkpoint['n_classes'],\n","                         depth=checkpoint['params']['depth'],\n","                         nb_filters=checkpoint['params']['nb_filters'],\n","                         bottleneck=checkpoint['params']['bottleneck'],\n","                         kernel_size=checkpoint['params']['kernel_size'],\n","                         dropout=checkpoint['params']['dropout']).to(device)\n","\n","    # Remove the _orig_mod. prefix added by torch.compile\n","    state_dict = checkpoint['model_state']\n","    state_dict = {k.replace('_orig_mod.', ''): v for k, v in state_dict.items()}\n","    model.load_state_dict(state_dict)\n","    model.eval()\n","\n","    latencies_it = []\n","    preds_list = []\n","    with torch.no_grad():\n","        for i in range(len(X_test_tensor)):\n","            x = X_test_tensor[i:i+1].to(device)\n","            t0 = time.perf_counter()\n","            logits = model(x)\n","            pred = logits.argmax(dim=1)\n","            latencies_it.append((time.perf_counter() - t0) * 1000)\n","            preds_list.append(pred.cpu().item())\n","\n","    preds_it = np.array(preds_list, dtype=np.int64)\n","    np.save(logs_dir / f'preds_fold{k}_it.npy', preds_it)\n","\n","    p50_it, p90_it = np.percentile(latencies_it, [50, 90])\n","    print(f\"  ✓ Predictions complete: {len(preds_it)} samples\")\n","    print(f\"  ✓ Latency: p50={p50_it:.2f}ms, p90={p90_it:.2f}ms\")\n","\n","    all_latency_stats.append({\n","        'fold': k,\n","        'knn': {'p50': float(p50_knn), 'p90': float(p90_knn)},\n","        'rf': {'p50': float(p50_rf), 'p90': float(p90_rf)},\n","        'it': {'p50': float(p50_it), 'p90': float(p90_it)}\n","    })\n","\n","with open(logs_dir / 'inference_latency.json', 'w') as f:\n","    json.dump(all_latency_stats, f, indent=2)\n","\n","print(f\"\\n{'='*60}\")\n","print(\"✓ Inference complete\")\n","print(f\"  Prediction files: logs/preds_fold*_{{knn,rf,it}}.npy\")\n","print(f\"  Latency statistics: logs/inference_latency.json\")\n","\n","get_ipython().system('git add logs/preds_fold*.npy logs/inference_latency.json')\n","get_ipython().system('git commit -m \"infer: predictions with latency stats\"')\n","print(f\"{'='*60}\\nStep 15 completed\\n{'='*60}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tjDFK8Y9C9gU","executionInfo":{"status":"ok","timestamp":1762706608461,"user_tz":0,"elapsed":2884697,"user":{"displayName":"yu Wu","userId":"12692660435918028293"}},"outputId":"87b1fdde-0443-4119-b05c-59767240bacc"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","Step 15: Inference & Prediction\n","============================================================\n","Device: cuda\n","\n","\n","============================================================\n","Fold 0:\n","============================================================\n","\n","[KNN]\n","  Test set: (1895, 208)\n","  ✓ Predictions complete: 1895 samples\n","  ✓ Latency: p50=66.01ms, p90=70.04ms\n","\n","[RF]\n","  ✓ Predictions complete: 1895 samples\n","  ✓ Latency: p50=17.26ms, p90=17.66ms\n","\n","[InceptionTime]\n","  Test set: torch.Size([1895, 6, 150])\n","  ✓ Predictions complete: 1895 samples\n","  ✓ Latency: p50=3.40ms, p90=3.45ms\n","\n","============================================================\n","Fold 1:\n","============================================================\n","\n","[KNN]\n","  Test set: (2463, 208)\n","  ✓ Predictions complete: 2463 samples\n","  ✓ Latency: p50=4.67ms, p90=77.00ms\n","\n","[RF]\n","  ✓ Predictions complete: 2463 samples\n","  ✓ Latency: p50=23.04ms, p90=23.57ms\n","\n","[InceptionTime]\n","  Test set: torch.Size([2463, 6, 150])\n","  ✓ Predictions complete: 2463 samples\n","  ✓ Latency: p50=3.46ms, p90=3.50ms\n","\n","============================================================\n","Fold 2:\n","============================================================\n","\n","[KNN]\n","  Test set: (2580, 208)\n","  ✓ Predictions complete: 2580 samples\n","  ✓ Latency: p50=66.01ms, p90=69.64ms\n","\n","[RF]\n","  ✓ Predictions complete: 2580 samples\n","  ✓ Latency: p50=23.06ms, p90=23.76ms\n","\n","[InceptionTime]\n","  Test set: torch.Size([2580, 6, 150])\n","  ✓ Predictions complete: 2580 samples\n","  ✓ Latency: p50=3.45ms, p90=3.52ms\n","\n","============================================================\n","Fold 3:\n","============================================================\n","\n","[KNN]\n","  Test set: (2367, 208)\n","  ✓ Predictions complete: 2367 samples\n","  ✓ Latency: p50=4.54ms, p90=79.04ms\n","\n","[RF]\n","  ✓ Predictions complete: 2367 samples\n","  ✓ Latency: p50=17.37ms, p90=17.72ms\n","\n","[InceptionTime]\n","  Test set: torch.Size([2367, 6, 150])\n","  ✓ Predictions complete: 2367 samples\n","  ✓ Latency: p50=3.50ms, p90=3.55ms\n","\n","============================================================\n","Fold 4:\n","============================================================\n","\n","[KNN]\n","  Test set: (2589, 208)\n","  ✓ Predictions complete: 2589 samples\n","  ✓ Latency: p50=78.01ms, p90=81.81ms\n","\n","[RF]\n","  ✓ Predictions complete: 2589 samples\n","  ✓ Latency: p50=17.46ms, p90=17.79ms\n","\n","[InceptionTime]\n","  Test set: torch.Size([2589, 6, 150])\n","  ✓ Predictions complete: 2589 samples\n","  ✓ Latency: p50=3.46ms, p90=3.55ms\n","\n","============================================================\n","Fold 5:\n","============================================================\n","\n","[KNN]\n","  Test set: (1835, 208)\n","  ✓ Predictions complete: 1835 samples\n","  ✓ Latency: p50=73.15ms, p90=80.02ms\n","\n","[RF]\n","  ✓ Predictions complete: 1835 samples\n","  ✓ Latency: p50=23.10ms, p90=23.46ms\n","\n","[InceptionTime]\n","  Test set: torch.Size([1835, 6, 150])\n","  ✓ Predictions complete: 1835 samples\n","  ✓ Latency: p50=3.45ms, p90=3.50ms\n","\n","============================================================\n","Fold 6:\n","============================================================\n","\n","[KNN]\n","  Test set: (2614, 208)\n","  ✓ Predictions complete: 2614 samples\n","  ✓ Latency: p50=78.03ms, p90=81.89ms\n","\n","[RF]\n","  ✓ Predictions complete: 2614 samples\n","  ✓ Latency: p50=17.39ms, p90=17.68ms\n","\n","[InceptionTime]\n","  Test set: torch.Size([2614, 6, 150])\n","  ✓ Predictions complete: 2614 samples\n","  ✓ Latency: p50=3.45ms, p90=3.51ms\n","\n","============================================================\n","Fold 7:\n","============================================================\n","\n","[KNN]\n","  Test set: (2292, 208)\n","  ✓ Predictions complete: 2292 samples\n","  ✓ Latency: p50=4.47ms, p90=80.01ms\n","\n","[RF]\n","  ✓ Predictions complete: 2292 samples\n","  ✓ Latency: p50=23.14ms, p90=23.71ms\n","\n","[InceptionTime]\n","  Test set: torch.Size([2292, 6, 150])\n","  ✓ Predictions complete: 2292 samples\n","  ✓ Latency: p50=3.50ms, p90=3.56ms\n","\n","============================================================\n","Fold 8:\n","============================================================\n","\n","[KNN]\n","  Test set: (2705, 208)\n","  ✓ Predictions complete: 2705 samples\n","  ✓ Latency: p50=78.03ms, p90=81.94ms\n","\n","[RF]\n","  ✓ Predictions complete: 2705 samples\n","  ✓ Latency: p50=17.86ms, p90=18.35ms\n","\n","[InceptionTime]\n","  Test set: torch.Size([2705, 6, 150])\n","  ✓ Predictions complete: 2705 samples\n","  ✓ Latency: p50=3.55ms, p90=3.64ms\n","\n","============================================================\n","Fold 9:\n","============================================================\n","\n","[KNN]\n","  Test set: (2247, 208)\n","  ✓ Predictions complete: 2247 samples\n","  ✓ Latency: p50=4.41ms, p90=79.01ms\n","\n","[RF]\n","  ✓ Predictions complete: 2247 samples\n","  ✓ Latency: p50=23.05ms, p90=23.50ms\n","\n","[InceptionTime]\n","  Test set: torch.Size([2247, 6, 150])\n","  ✓ Predictions complete: 2247 samples\n","  ✓ Latency: p50=3.49ms, p90=3.56ms\n","\n","============================================================\n","Fold 10:\n","============================================================\n","\n","[KNN]\n","  Test set: (2932, 208)\n","  ✓ Predictions complete: 2932 samples\n","  ✓ Latency: p50=78.01ms, p90=81.79ms\n","\n","[RF]\n","  ✓ Predictions complete: 2932 samples\n","  ✓ Latency: p50=17.41ms, p90=17.83ms\n","\n","[InceptionTime]\n","  Test set: torch.Size([2932, 6, 150])\n","  ✓ Predictions complete: 2932 samples\n","  ✓ Latency: p50=3.44ms, p90=3.50ms\n","\n","============================================================\n","Fold 11:\n","============================================================\n","\n","[KNN]\n","  Test set: (2531, 208)\n","  ✓ Predictions complete: 2531 samples\n","  ✓ Latency: p50=4.33ms, p90=77.94ms\n","\n","[RF]\n","  ✓ Predictions complete: 2531 samples\n","  ✓ Latency: p50=23.04ms, p90=23.55ms\n","\n","[InceptionTime]\n","  Test set: torch.Size([2531, 6, 150])\n","  ✓ Predictions complete: 2531 samples\n","  ✓ Latency: p50=3.46ms, p90=3.54ms\n","\n","============================================================\n","Fold 12:\n","============================================================\n","\n","[KNN]\n","  Test set: (2002, 208)\n","  ✓ Predictions complete: 2002 samples\n","  ✓ Latency: p50=78.03ms, p90=81.88ms\n","\n","[RF]\n","  ✓ Predictions complete: 2002 samples\n","  ✓ Latency: p50=23.05ms, p90=23.51ms\n","\n","[InceptionTime]\n","  Test set: torch.Size([2002, 6, 150])\n","  ✓ Predictions complete: 2002 samples\n","  ✓ Latency: p50=3.47ms, p90=3.52ms\n","\n","============================================================\n","Fold 13:\n","============================================================\n","\n","[KNN]\n","  Test set: (2894, 208)\n","  ✓ Predictions complete: 2894 samples\n","  ✓ Latency: p50=4.57ms, p90=80.03ms\n","\n","[RF]\n","  ✓ Predictions complete: 2894 samples\n","  ✓ Latency: p50=17.42ms, p90=17.99ms\n","\n","[InceptionTime]\n","  Test set: torch.Size([2894, 6, 150])\n","  ✓ Predictions complete: 2894 samples\n","  ✓ Latency: p50=3.48ms, p90=3.52ms\n","\n","============================================================\n","Fold 14:\n","============================================================\n","\n","[KNN]\n","  Test set: (2676, 208)\n","  ✓ Predictions complete: 2676 samples\n","  ✓ Latency: p50=78.01ms, p90=81.76ms\n","\n","[RF]\n","  ✓ Predictions complete: 2676 samples\n","  ✓ Latency: p50=23.13ms, p90=23.76ms\n","\n","[InceptionTime]\n","  Test set: torch.Size([2676, 6, 150])\n","  ✓ Predictions complete: 2676 samples\n","  ✓ Latency: p50=3.47ms, p90=3.53ms\n","\n","============================================================\n","✓ Inference complete\n","  Prediction files: logs/preds_fold*_{knn,rf,it}.npy\n","  Latency statistics: logs/inference_latency.json\n","[master ba504f0] infer: predictions with latency stats\n"," 46 files changed, 227 insertions(+)\n"," create mode 100644 logs/inference_latency.json\n"," create mode 100644 logs/preds_fold0_it.npy\n"," create mode 100644 logs/preds_fold0_knn.npy\n"," create mode 100644 logs/preds_fold0_rf.npy\n"," create mode 100644 logs/preds_fold10_it.npy\n"," create mode 100644 logs/preds_fold10_knn.npy\n"," create mode 100644 logs/preds_fold10_rf.npy\n"," create mode 100644 logs/preds_fold11_it.npy\n"," create mode 100644 logs/preds_fold11_knn.npy\n"," create mode 100644 logs/preds_fold11_rf.npy\n"," create mode 100644 logs/preds_fold12_it.npy\n"," create mode 100644 logs/preds_fold12_knn.npy\n"," create mode 100644 logs/preds_fold12_rf.npy\n"," create mode 100644 logs/preds_fold13_it.npy\n"," create mode 100644 logs/preds_fold13_knn.npy\n"," create mode 100644 logs/preds_fold13_rf.npy\n"," create mode 100644 logs/preds_fold14_it.npy\n"," create mode 100644 logs/preds_fold14_knn.npy\n"," create mode 100644 logs/preds_fold14_rf.npy\n"," create mode 100644 logs/preds_fold1_it.npy\n"," create mode 100644 logs/preds_fold1_knn.npy\n"," create mode 100644 logs/preds_fold1_rf.npy\n"," create mode 100644 logs/preds_fold2_it.npy\n"," create mode 100644 logs/preds_fold2_knn.npy\n"," create mode 100644 logs/preds_fold2_rf.npy\n"," create mode 100644 logs/preds_fold3_it.npy\n"," create mode 100644 logs/preds_fold3_knn.npy\n"," create mode 100644 logs/preds_fold3_rf.npy\n"," create mode 100644 logs/preds_fold4_it.npy\n"," create mode 100644 logs/preds_fold4_knn.npy\n"," create mode 100644 logs/preds_fold4_rf.npy\n"," create mode 100644 logs/preds_fold5_it.npy\n"," create mode 100644 logs/preds_fold5_knn.npy\n"," create mode 100644 logs/preds_fold5_rf.npy\n"," create mode 100644 logs/preds_fold6_it.npy\n"," create mode 100644 logs/preds_fold6_knn.npy\n"," create mode 100644 logs/preds_fold6_rf.npy\n"," create mode 100644 logs/preds_fold7_it.npy\n"," create mode 100644 logs/preds_fold7_knn.npy\n"," create mode 100644 logs/preds_fold7_rf.npy\n"," create mode 100644 logs/preds_fold8_it.npy\n"," create mode 100644 logs/preds_fold8_knn.npy\n"," create mode 100644 logs/preds_fold8_rf.npy\n"," create mode 100644 logs/preds_fold9_it.npy\n"," create mode 100644 logs/preds_fold9_knn.npy\n"," create mode 100644 logs/preds_fold9_rf.npy\n","============================================================\n","Step 15 completed\n","============================================================\n"]}]},{"cell_type":"code","source":["# ================ Step 16: Metric Computation (per fold) ================\n","import numpy as np\n","import pandas as pd\n","from pathlib import Path\n","from sklearn.metrics import f1_score, confusion_matrix\n","import json\n","\n","print(\"\\n\\nStep 16: Metric Computation (per fold)\")\n","print(\"=\" * 60)\n","\n","features_dir = Path('/content/features')\n","logs_dir = Path('/content/logs')\n","\n","with open('/content/configs/splits.json', 'r') as f:\n","    splits_cfg = json.load(f)\n","\n","with open('/content/configs/classes.json', 'r') as f:\n","    classes_cfg = json.load(f)\n","\n","id_to_label = {int(k): v for k, v in classes_cfg['id_to_label'].items()}\n","class_names = [id_to_label[i] for i in sorted(id_to_label.keys())]\n","\n","print(f\"Class order: {class_names}\\n\")\n","\n","for fold in splits_cfg['folds']:\n","    k = fold['fold']\n","    print(f\"\\n{'='*60}\")\n","    print(f\"Fold {k}:\")\n","    print(f\"{'='*60}\")\n","\n","    # Load ground-truth labels\n","    test_data = np.load(features_dir / f'test_fold{k}.npz', allow_pickle=True)\n","    y_true = test_data['y']\n","\n","    for model_name in ['knn', 'rf', 'it']:\n","        print(f\"\\n[{model_name.upper()}]\")\n","\n","        # Load predictions\n","        y_pred = np.load(logs_dir / f'preds_fold{k}_{model_name}.npy')\n","\n","        # Macro-F1\n","        macro_f1 = f1_score(y_true, y_pred, average='macro', zero_division=0)\n","        print(f\"  Macro-F1: {macro_f1:.4f}\")\n","\n","        # Per-class F1 and support\n","        per_class_f1 = f1_score(y_true, y_pred, average=None, zero_division=0, labels=list(range(len(class_names))))\n","        support = np.bincount(y_true, minlength=len(class_names))\n","\n","        # Confusion matrix\n","        cm = confusion_matrix(y_true, y_pred, labels=list(range(len(class_names))))\n","\n","        # Build metrics table\n","        metrics_data = []\n","        for i, class_name in enumerate(class_names):\n","            metrics_data.append({\n","                'class': class_name,\n","                'class_id': i,\n","                'f1_score': per_class_f1[i],\n","                'support': support[i]\n","            })\n","\n","        # Add overall metric\n","        metrics_data.append({\n","            'class': 'macro_avg',\n","            'class_id': -1,\n","            'f1_score': macro_f1,\n","            'support': len(y_true)\n","        })\n","\n","        df_metrics = pd.DataFrame(metrics_data)\n","        df_metrics.to_csv(logs_dir / f'fold{k}_metrics_{model_name}.csv', index=False)\n","\n","        # Save confusion matrix\n","        df_cm = pd.DataFrame(cm, index=class_names, columns=class_names)\n","        df_cm.to_csv(logs_dir / f'fold{k}_cm_{model_name}.csv')\n","\n","        print(f\"  Per-class F1:\")\n","        for i, class_name in enumerate(class_names):\n","            print(f\"    {class_name:15s}: F1={per_class_f1[i]:.4f}, support={support[i]}\")\n","\n","        print(f\"  ✓ Saved: fold{k}_metrics_{model_name}.csv, fold{k}_cm_{model_name}.csv\")\n","\n","print(f\"\\n{'='*60}\")\n","print(\"✓ Metric computation complete\")\n","print(f\"  Metric tables: logs/fold*_metrics_{{knn,rf,it}}.csv\")\n","print(f\"  Confusion matrices: logs/fold*_cm_{{knn,rf,it}}.csv\")\n","\n","get_ipython().system('git add logs/fold*_metrics_*.csv logs/fold*_cm_*.csv')\n","get_ipython().system('git commit -m \"eval: per-fold metrics and confusion matrices\"')\n","print(f\"{'='*60}\\nStep 16 completed\\n{'='*60}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Sm2xOuToDARG","executionInfo":{"status":"ok","timestamp":1762707454516,"user_tz":0,"elapsed":520,"user":{"displayName":"yu Wu","userId":"12692660435918028293"}},"outputId":"ed5bc3df-b0c1-47b4-c2ff-8a87e8fb0c43"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","Step 16: Metric Computation (per fold)\n","============================================================\n","Class order: ['walking', 'running', 'sitting', 'standing', 'lying', 'stairs_up', 'stairs_down', 'jumping']\n","\n","\n","============================================================\n","Fold 0:\n","============================================================\n","\n","[KNN]\n","  Macro-F1: 0.5854\n","  Per-class F1:\n","    walking        : F1=0.8490, support=396\n","    running        : F1=0.5950, support=379\n","    sitting        : F1=0.0000, support=0\n","    standing       : F1=0.7312, support=382\n","    lying          : F1=0.0000, support=0\n","    stairs_up      : F1=0.9170, support=385\n","    stairs_down    : F1=0.6011, support=303\n","    jumping        : F1=0.9899, support=50\n","  ✓ Saved: fold0_metrics_knn.csv, fold0_cm_knn.csv\n","\n","[RF]\n","  Macro-F1: 0.6373\n","  Per-class F1:\n","    walking        : F1=0.9031, support=396\n","    running        : F1=0.8220, support=379\n","    sitting        : F1=0.0000, support=0\n","    standing       : F1=0.6897, support=382\n","    lying          : F1=0.0000, support=0\n","    stairs_up      : F1=0.9189, support=385\n","    stairs_down    : F1=0.7747, support=303\n","    jumping        : F1=0.9899, support=50\n","  ✓ Saved: fold0_metrics_rf.csv, fold0_cm_rf.csv\n","\n","[IT]\n","  Macro-F1: 0.6246\n","  Per-class F1:\n","    walking        : F1=0.9024, support=396\n","    running        : F1=0.9666, support=379\n","    sitting        : F1=0.0000, support=0\n","    standing       : F1=0.3080, support=382\n","    lying          : F1=0.0000, support=0\n","    stairs_up      : F1=0.9183, support=385\n","    stairs_down    : F1=0.9120, support=303\n","    jumping        : F1=0.9899, support=50\n","  ✓ Saved: fold0_metrics_it.csv, fold0_cm_it.csv\n","\n","============================================================\n","Fold 1:\n","============================================================\n","\n","[KNN]\n","  Macro-F1: 0.8382\n","  Per-class F1:\n","    walking        : F1=0.9116, support=372\n","    running        : F1=0.9317, support=367\n","    sitting        : F1=0.6948, support=366\n","    standing       : F1=0.6159, support=388\n","    lying          : F1=0.8662, support=384\n","    stairs_up      : F1=0.8773, support=264\n","    stairs_down    : F1=0.8462, support=254\n","    jumping        : F1=0.9618, support=68\n","  ✓ Saved: fold1_metrics_knn.csv, fold1_cm_knn.csv\n","\n","[RF]\n","  Macro-F1: 0.8352\n","  Per-class F1:\n","    walking        : F1=0.9231, support=372\n","    running        : F1=0.9009, support=367\n","    sitting        : F1=0.7995, support=366\n","    standing       : F1=0.5925, support=388\n","    lying          : F1=0.8412, support=384\n","    stairs_up      : F1=0.8696, support=264\n","    stairs_down    : F1=0.7930, support=254\n","    jumping        : F1=0.9618, support=68\n","  ✓ Saved: fold1_metrics_rf.csv, fold1_cm_rf.csv\n","\n","[IT]\n","  Macro-F1: 0.6686\n","  Per-class F1:\n","    walking        : F1=0.7424, support=372\n","    running        : F1=0.9374, support=367\n","    sitting        : F1=0.7779, support=366\n","    standing       : F1=0.0907, support=388\n","    lying          : F1=0.6368, support=384\n","    stairs_up      : F1=0.3537, support=264\n","    stairs_down    : F1=0.8484, support=254\n","    jumping        : F1=0.9618, support=68\n","  ✓ Saved: fold1_metrics_it.csv, fold1_cm_it.csv\n","\n","============================================================\n","Fold 2:\n","============================================================\n","\n","[KNN]\n","  Macro-F1: 0.7974\n","  Per-class F1:\n","    walking        : F1=0.5857, support=382\n","    running        : F1=0.9615, support=347\n","    sitting        : F1=0.7299, support=364\n","    standing       : F1=0.8278, support=378\n","    lying          : F1=0.7797, support=396\n","    stairs_up      : F1=0.7182, support=367\n","    stairs_down    : F1=0.8159, support=293\n","    jumping        : F1=0.9608, support=53\n","  ✓ Saved: fold2_metrics_knn.csv, fold2_cm_knn.csv\n","\n","[RF]\n","  Macro-F1: 0.8090\n","  Per-class F1:\n","    walking        : F1=0.2691, support=382\n","    running        : F1=0.9857, support=347\n","    sitting        : F1=0.8705, support=364\n","    standing       : F1=0.8999, support=378\n","    lying          : F1=0.9216, support=396\n","    stairs_up      : F1=0.7080, support=367\n","    stairs_down    : F1=0.8562, support=293\n","    jumping        : F1=0.9608, support=53\n","  ✓ Saved: fold2_metrics_rf.csv, fold2_cm_rf.csv\n","\n","[IT]\n","  Macro-F1: 0.7176\n","  Per-class F1:\n","    walking        : F1=0.6065, support=382\n","    running        : F1=0.9438, support=347\n","    sitting        : F1=0.7053, support=364\n","    standing       : F1=0.7579, support=378\n","    lying          : F1=0.0821, support=396\n","    stairs_up      : F1=0.7802, support=367\n","    stairs_down    : F1=0.8942, support=293\n","    jumping        : F1=0.9709, support=53\n","  ✓ Saved: fold2_metrics_it.csv, fold2_cm_it.csv\n","\n","============================================================\n","Fold 3:\n","============================================================\n","\n","[KNN]\n","  Macro-F1: 0.8750\n","  Per-class F1:\n","    walking        : F1=0.8638, support=318\n","    running        : F1=0.9788, support=349\n","    sitting        : F1=0.6863, support=299\n","    standing       : F1=0.8517, support=353\n","    lying          : F1=0.8724, support=373\n","    stairs_up      : F1=0.9156, support=345\n","    stairs_down    : F1=0.8829, support=289\n","    jumping        : F1=0.9487, support=41\n","  ✓ Saved: fold3_metrics_knn.csv, fold3_cm_knn.csv\n","\n","[RF]\n","  Macro-F1: 0.9058\n","  Per-class F1:\n","    walking        : F1=0.8675, support=318\n","    running        : F1=0.9612, support=349\n","    sitting        : F1=0.8059, support=299\n","    standing       : F1=0.9058, support=353\n","    lying          : F1=0.9093, support=373\n","    stairs_up      : F1=0.9165, support=345\n","    stairs_down    : F1=0.9053, support=289\n","    jumping        : F1=0.9750, support=41\n","  ✓ Saved: fold3_metrics_rf.csv, fold3_cm_rf.csv\n","\n","[IT]\n","  Macro-F1: 0.6808\n","  Per-class F1:\n","    walking        : F1=0.7465, support=318\n","    running        : F1=0.7222, support=349\n","    sitting        : F1=0.1758, support=299\n","    standing       : F1=0.3974, support=353\n","    lying          : F1=0.8063, support=373\n","    stairs_up      : F1=0.7033, support=345\n","    stairs_down    : F1=0.9196, support=289\n","    jumping        : F1=0.9750, support=41\n","  ✓ Saved: fold3_metrics_it.csv, fold3_cm_it.csv\n","\n","============================================================\n","Fold 4:\n","============================================================\n","\n","[KNN]\n","  Macro-F1: 0.8318\n","  Per-class F1:\n","    walking        : F1=0.8130, support=398\n","    running        : F1=0.9704, support=368\n","    sitting        : F1=0.6891, support=380\n","    standing       : F1=0.7853, support=384\n","    lying          : F1=0.9111, support=385\n","    stairs_up      : F1=0.8169, support=353\n","    stairs_down    : F1=0.6983, support=252\n","    jumping        : F1=0.9701, support=69\n","  ✓ Saved: fold4_metrics_knn.csv, fold4_cm_knn.csv\n","\n","[RF]\n","  Macro-F1: 0.8538\n","  Per-class F1:\n","    walking        : F1=0.8140, support=398\n","    running        : F1=0.9395, support=368\n","    sitting        : F1=0.7837, support=380\n","    standing       : F1=0.8274, support=384\n","    lying          : F1=0.9639, support=385\n","    stairs_up      : F1=0.7774, support=353\n","    stairs_down    : F1=0.7543, support=252\n","    jumping        : F1=0.9701, support=69\n","  ✓ Saved: fold4_metrics_rf.csv, fold4_cm_rf.csv\n","\n","[IT]\n","  Macro-F1: 0.8049\n","  Per-class F1:\n","    walking        : F1=0.2678, support=398\n","    running        : F1=0.9483, support=368\n","    sitting        : F1=0.8839, support=380\n","    standing       : F1=0.8784, support=384\n","    lying          : F1=0.9541, support=385\n","    stairs_up      : F1=0.6821, support=353\n","    stairs_down    : F1=0.8471, support=252\n","    jumping        : F1=0.9778, support=69\n","  ✓ Saved: fold4_metrics_it.csv, fold4_cm_it.csv\n","\n","============================================================\n","Fold 5:\n","============================================================\n","\n","[KNN]\n","  Macro-F1: 0.5937\n","  Per-class F1:\n","    walking        : F1=0.9677, support=351\n","    running        : F1=0.9273, support=346\n","    sitting        : F1=0.2419, support=362\n","    standing       : F1=0.6360, support=352\n","    lying          : F1=0.9767, support=369\n","    stairs_up      : F1=0.0000, support=0\n","    stairs_down    : F1=0.0000, support=0\n","    jumping        : F1=1.0000, support=55\n","  ✓ Saved: fold5_metrics_knn.csv, fold5_cm_knn.csv\n","\n","[RF]\n","  Macro-F1: 0.6160\n","  Per-class F1:\n","    walking        : F1=0.9617, support=351\n","    running        : F1=0.9485, support=346\n","    sitting        : F1=0.3476, support=362\n","    standing       : F1=0.6823, support=352\n","    lying          : F1=0.9877, support=369\n","    stairs_up      : F1=0.0000, support=0\n","    stairs_down    : F1=0.0000, support=0\n","    jumping        : F1=1.0000, support=55\n","  ✓ Saved: fold5_metrics_rf.csv, fold5_cm_rf.csv\n","\n","[IT]\n","  Macro-F1: 0.5902\n","  Per-class F1:\n","    walking        : F1=0.8732, support=351\n","    running        : F1=0.5959, support=346\n","    sitting        : F1=0.1333, support=362\n","    standing       : F1=0.6357, support=352\n","    lying          : F1=0.9202, support=369\n","    stairs_up      : F1=0.0000, support=0\n","    stairs_down    : F1=0.0000, support=0\n","    jumping        : F1=0.9730, support=55\n","  ✓ Saved: fold5_metrics_it.csv, fold5_cm_it.csv\n","\n","============================================================\n","Fold 6:\n","============================================================\n","\n","[KNN]\n","  Macro-F1: 0.8319\n","  Per-class F1:\n","    walking        : F1=0.8370, support=388\n","    running        : F1=0.9026, support=395\n","    sitting        : F1=0.7814, support=375\n","    standing       : F1=0.7543, support=374\n","    lying          : F1=0.8203, support=392\n","    stairs_up      : F1=0.7948, support=343\n","    stairs_down    : F1=0.8845, support=296\n","    jumping        : F1=0.8800, support=51\n","  ✓ Saved: fold6_metrics_knn.csv, fold6_cm_knn.csv\n","\n","[RF]\n","  Macro-F1: 0.8944\n","  Per-class F1:\n","    walking        : F1=0.9039, support=388\n","    running        : F1=0.9143, support=395\n","    sitting        : F1=0.8954, support=375\n","    standing       : F1=0.8740, support=374\n","    lying          : F1=0.9375, support=392\n","    stairs_up      : F1=0.8963, support=343\n","    stairs_down    : F1=0.9063, support=296\n","    jumping        : F1=0.8276, support=51\n","  ✓ Saved: fold6_metrics_rf.csv, fold6_cm_rf.csv\n","\n","[IT]\n","  Macro-F1: 0.7128\n","  Per-class F1:\n","    walking        : F1=0.8125, support=388\n","    running        : F1=0.9412, support=395\n","    sitting        : F1=0.5690, support=375\n","    standing       : F1=0.5776, support=374\n","    lying          : F1=0.1671, support=392\n","    stairs_up      : F1=0.8464, support=343\n","    stairs_down    : F1=0.8088, support=296\n","    jumping        : F1=0.9800, support=51\n","  ✓ Saved: fold6_metrics_it.csv, fold6_cm_it.csv\n","\n","============================================================\n","Fold 7:\n","============================================================\n","\n","[KNN]\n","  Macro-F1: 0.8539\n","  Per-class F1:\n","    walking        : F1=0.8737, support=331\n","    running        : F1=0.9462, support=322\n","    sitting        : F1=0.6486, support=373\n","    standing       : F1=0.7645, support=312\n","    lying          : F1=0.8598, support=358\n","    stairs_up      : F1=0.9087, support=259\n","    stairs_down    : F1=0.8561, support=281\n","    jumping        : F1=0.9735, support=56\n","  ✓ Saved: fold7_metrics_knn.csv, fold7_cm_knn.csv\n","\n","[RF]\n","  Macro-F1: 0.9368\n","  Per-class F1:\n","    walking        : F1=0.8697, support=331\n","    running        : F1=0.9697, support=322\n","    sitting        : F1=0.9657, support=373\n","    standing       : F1=0.9516, support=312\n","    lying          : F1=0.9874, support=358\n","    stairs_up      : F1=0.9218, support=259\n","    stairs_down    : F1=0.8547, support=281\n","    jumping        : F1=0.9735, support=56\n","  ✓ Saved: fold7_metrics_rf.csv, fold7_cm_rf.csv\n","\n","[IT]\n","  Macro-F1: 0.6588\n","  Per-class F1:\n","    walking        : F1=0.8688, support=331\n","    running        : F1=0.6469, support=322\n","    sitting        : F1=0.0106, support=373\n","    standing       : F1=0.6018, support=312\n","    lying          : F1=0.9802, support=358\n","    stairs_up      : F1=0.8360, support=259\n","    stairs_down    : F1=0.8998, support=281\n","    jumping        : F1=0.4259, support=56\n","  ✓ Saved: fold7_metrics_it.csv, fold7_cm_it.csv\n","\n","============================================================\n","Fold 8:\n","============================================================\n","\n","[KNN]\n","  Macro-F1: 0.8228\n","  Per-class F1:\n","    walking        : F1=0.7602, support=415\n","    running        : F1=0.8900, support=443\n","    sitting        : F1=0.8762, support=370\n","    standing       : F1=0.8116, support=368\n","    lying          : F1=0.9205, support=371\n","    stairs_up      : F1=0.8644, support=348\n","    stairs_down    : F1=0.4599, support=332\n","    jumping        : F1=1.0000, support=58\n","  ✓ Saved: fold8_metrics_knn.csv, fold8_cm_knn.csv\n","\n","[RF]\n","  Macro-F1: 0.8725\n","  Per-class F1:\n","    walking        : F1=0.8236, support=415\n","    running        : F1=0.8683, support=443\n","    sitting        : F1=0.9277, support=370\n","    standing       : F1=0.8366, support=368\n","    lying          : F1=0.9523, support=371\n","    stairs_up      : F1=0.9078, support=348\n","    stairs_down    : F1=0.6641, support=332\n","    jumping        : F1=1.0000, support=58\n","  ✓ Saved: fold8_metrics_rf.csv, fold8_cm_rf.csv\n","\n","[IT]\n","  Macro-F1: 0.2745\n","  Per-class F1:\n","    walking        : F1=0.0000, support=415\n","    running        : F1=0.3756, support=443\n","    sitting        : F1=0.0212, support=370\n","    standing       : F1=0.1347, support=368\n","    lying          : F1=0.5262, support=371\n","    stairs_up      : F1=0.2214, support=348\n","    stairs_down    : F1=0.0385, support=332\n","    jumping        : F1=0.8788, support=58\n","  ✓ Saved: fold8_metrics_it.csv, fold8_cm_it.csv\n","\n","============================================================\n","Fold 9:\n","============================================================\n","\n","[KNN]\n","  Macro-F1: 0.5177\n","  Per-class F1:\n","    walking        : F1=0.9567, support=388\n","    running        : F1=0.5216, support=615\n","    sitting        : F1=0.5464, support=395\n","    standing       : F1=0.5170, support=380\n","    lying          : F1=0.6194, support=418\n","    stairs_up      : F1=0.0000, support=0\n","    stairs_down    : F1=0.0000, support=0\n","    jumping        : F1=0.9800, support=51\n","  ✓ Saved: fold9_metrics_knn.csv, fold9_cm_knn.csv\n","\n","[RF]\n","  Macro-F1: 0.5640\n","  Per-class F1:\n","    walking        : F1=0.9764, support=388\n","    running        : F1=0.5694, support=615\n","    sitting        : F1=0.6027, support=395\n","    standing       : F1=0.5913, support=380\n","    lying          : F1=0.7925, support=418\n","    stairs_up      : F1=0.0000, support=0\n","    stairs_down    : F1=0.0000, support=0\n","    jumping        : F1=0.9800, support=51\n","  ✓ Saved: fold9_metrics_rf.csv, fold9_cm_rf.csv\n","\n","[IT]\n","  Macro-F1: 0.4547\n","  Per-class F1:\n","    walking        : F1=0.8005, support=388\n","    running        : F1=0.6023, support=615\n","    sitting        : F1=0.7350, support=395\n","    standing       : F1=0.0683, support=380\n","    lying          : F1=0.4983, support=418\n","    stairs_up      : F1=0.0000, support=0\n","    stairs_down    : F1=0.0000, support=0\n","    jumping        : F1=0.9333, support=51\n","  ✓ Saved: fold9_metrics_it.csv, fold9_cm_it.csv\n","\n","============================================================\n","Fold 10:\n","============================================================\n","\n","[KNN]\n","  Macro-F1: 0.7339\n","  Per-class F1:\n","    walking        : F1=0.7254, support=413\n","    running        : F1=0.6896, support=659\n","    sitting        : F1=0.6597, support=404\n","    standing       : F1=0.6048, support=358\n","    lying          : F1=0.8202, support=382\n","    stairs_up      : F1=0.6873, support=363\n","    stairs_down    : F1=0.7374, support=294\n","    jumping        : F1=0.9464, support=59\n","  ✓ Saved: fold10_metrics_knn.csv, fold10_cm_knn.csv\n","\n","[RF]\n","  Macro-F1: 0.7554\n","  Per-class F1:\n","    walking        : F1=0.7461, support=413\n","    running        : F1=0.7202, support=659\n","    sitting        : F1=0.7038, support=404\n","    standing       : F1=0.6373, support=358\n","    lying          : F1=0.7702, support=382\n","    stairs_up      : F1=0.6642, support=363\n","    stairs_down    : F1=0.8277, support=294\n","    jumping        : F1=0.9739, support=59\n","  ✓ Saved: fold10_metrics_rf.csv, fold10_cm_rf.csv\n","\n","[IT]\n","  Macro-F1: 0.7559\n","  Per-class F1:\n","    walking        : F1=0.7317, support=413\n","    running        : F1=0.7776, support=659\n","    sitting        : F1=0.6253, support=404\n","    standing       : F1=0.5357, support=358\n","    lying          : F1=0.7568, support=382\n","    stairs_up      : F1=0.8563, support=363\n","    stairs_down    : F1=0.7983, support=294\n","    jumping        : F1=0.9655, support=59\n","  ✓ Saved: fold10_metrics_it.csv, fold10_cm_it.csv\n","\n","============================================================\n","Fold 11:\n","============================================================\n","\n","[KNN]\n","  Macro-F1: 0.8411\n","  Per-class F1:\n","    walking        : F1=0.8422, support=362\n","    running        : F1=0.9504, support=370\n","    sitting        : F1=0.6745, support=399\n","    standing       : F1=0.7554, support=363\n","    lying          : F1=0.9091, support=378\n","    stairs_up      : F1=0.7712, support=309\n","    stairs_down    : F1=0.8425, support=290\n","    jumping        : F1=0.9831, support=60\n","  ✓ Saved: fold11_metrics_knn.csv, fold11_cm_knn.csv\n","\n","[RF]\n","  Macro-F1: 0.8635\n","  Per-class F1:\n","    walking        : F1=0.8731, support=362\n","    running        : F1=0.9491, support=370\n","    sitting        : F1=0.7660, support=399\n","    standing       : F1=0.8484, support=363\n","    lying          : F1=0.8914, support=378\n","    stairs_up      : F1=0.7500, support=309\n","    stairs_down    : F1=0.8562, support=290\n","    jumping        : F1=0.9744, support=60\n","  ✓ Saved: fold11_metrics_rf.csv, fold11_cm_rf.csv\n","\n","[IT]\n","  Macro-F1: 0.7238\n","  Per-class F1:\n","    walking        : F1=0.7025, support=362\n","    running        : F1=0.9492, support=370\n","    sitting        : F1=0.1772, support=399\n","    standing       : F1=0.6777, support=363\n","    lying          : F1=0.6119, support=378\n","    stairs_up      : F1=0.7632, support=309\n","    stairs_down    : F1=0.9173, support=290\n","    jumping        : F1=0.9916, support=60\n","  ✓ Saved: fold11_metrics_it.csv, fold11_cm_it.csv\n","\n","============================================================\n","Fold 12:\n","============================================================\n","\n","[KNN]\n","  Macro-F1: 0.6228\n","  Per-class F1:\n","    walking        : F1=0.9413, support=360\n","    running        : F1=0.9302, support=434\n","    sitting        : F1=0.6536, support=386\n","    standing       : F1=0.7750, support=391\n","    lying          : F1=0.7008, support=375\n","    stairs_up      : F1=0.0000, support=0\n","    stairs_down    : F1=0.0000, support=0\n","    jumping        : F1=0.9818, support=56\n","  ✓ Saved: fold12_metrics_knn.csv, fold12_cm_knn.csv\n","\n","[RF]\n","  Macro-F1: 0.6511\n","  Per-class F1:\n","    walking        : F1=0.9580, support=360\n","    running        : F1=0.9231, support=434\n","    sitting        : F1=0.7333, support=386\n","    standing       : F1=0.8356, support=391\n","    lying          : F1=0.8276, support=375\n","    stairs_up      : F1=0.0000, support=0\n","    stairs_down    : F1=0.0000, support=0\n","    jumping        : F1=0.9310, support=56\n","  ✓ Saved: fold12_metrics_rf.csv, fold12_cm_rf.csv\n","\n","[IT]\n","  Macro-F1: 0.4465\n","  Per-class F1:\n","    walking        : F1=0.9304, support=360\n","    running        : F1=0.8574, support=434\n","    sitting        : F1=0.5374, support=386\n","    standing       : F1=0.2059, support=391\n","    lying          : F1=0.0408, support=375\n","    stairs_up      : F1=0.0000, support=0\n","    stairs_down    : F1=0.0000, support=0\n","    jumping        : F1=1.0000, support=56\n","  ✓ Saved: fold12_metrics_it.csv, fold12_cm_it.csv\n","\n","============================================================\n","Fold 13:\n","============================================================\n","\n","[KNN]\n","  Macro-F1: 0.7041\n","  Per-class F1:\n","    walking        : F1=0.7528, support=375\n","    running        : F1=0.8376, support=368\n","    sitting        : F1=0.6817, support=401\n","    standing       : F1=0.7263, support=399\n","    lying          : F1=0.5497, support=378\n","    stairs_up      : F1=0.6801, support=674\n","    stairs_down    : F1=0.8745, support=245\n","    jumping        : F1=0.5304, support=54\n","  ✓ Saved: fold13_metrics_knn.csv, fold13_cm_knn.csv\n","\n","[RF]\n","  Macro-F1: 0.6601\n","  Per-class F1:\n","    walking        : F1=0.0769, support=375\n","    running        : F1=0.9661, support=368\n","    sitting        : F1=0.5933, support=401\n","    standing       : F1=0.7511, support=399\n","    lying          : F1=0.5174, support=378\n","    stairs_up      : F1=0.5620, support=674\n","    stairs_down    : F1=0.8330, support=245\n","    jumping        : F1=0.9811, support=54\n","  ✓ Saved: fold13_metrics_rf.csv, fold13_cm_rf.csv\n","\n","[IT]\n","  Macro-F1: 0.4375\n","  Per-class F1:\n","    walking        : F1=0.0106, support=375\n","    running        : F1=0.9180, support=368\n","    sitting        : F1=0.0913, support=401\n","    standing       : F1=0.4880, support=399\n","    lying          : F1=0.3128, support=378\n","    stairs_up      : F1=0.3552, support=674\n","    stairs_down    : F1=0.8667, support=245\n","    jumping        : F1=0.4571, support=54\n","  ✓ Saved: fold13_metrics_it.csv, fold13_cm_it.csv\n","\n","============================================================\n","Fold 14:\n","============================================================\n","\n","[KNN]\n","  Macro-F1: 0.8768\n","  Per-class F1:\n","    walking        : F1=0.8964, support=369\n","    running        : F1=0.8302, support=468\n","    sitting        : F1=0.8299, support=385\n","    standing       : F1=0.7588, support=392\n","    lying          : F1=0.9288, support=384\n","    stairs_up      : F1=0.9417, support=321\n","    stairs_down    : F1=0.8533, support=296\n","    jumping        : F1=0.9748, support=61\n","  ✓ Saved: fold14_metrics_knn.csv, fold14_cm_knn.csv\n","\n","[RF]\n","  Macro-F1: 0.8905\n","  Per-class F1:\n","    walking        : F1=0.9174, support=369\n","    running        : F1=0.8201, support=468\n","    sitting        : F1=0.8715, support=385\n","    standing       : F1=0.7494, support=392\n","    lying          : F1=0.9716, support=384\n","    stairs_up      : F1=0.9369, support=321\n","    stairs_down    : F1=0.9000, support=296\n","    jumping        : F1=0.9573, support=61\n","  ✓ Saved: fold14_metrics_rf.csv, fold14_cm_rf.csv\n","\n","[IT]\n","  Macro-F1: 0.8104\n","  Per-class F1:\n","    walking        : F1=0.8806, support=369\n","    running        : F1=0.8406, support=468\n","    sitting        : F1=0.6893, support=385\n","    standing       : F1=0.3154, support=392\n","    lying          : F1=0.9538, support=384\n","    stairs_up      : F1=0.9153, support=321\n","    stairs_down    : F1=0.8964, support=296\n","    jumping        : F1=0.9917, support=61\n","  ✓ Saved: fold14_metrics_it.csv, fold14_cm_it.csv\n","\n","============================================================\n","✓ Metric computation complete\n","  Metric tables: logs/fold*_metrics_{knn,rf,it}.csv\n","  Confusion matrices: logs/fold*_cm_{knn,rf,it}.csv\n","[master beffba3] eval: per-fold metrics and confusion matrices\n"," 90 files changed, 855 insertions(+)\n"," create mode 100644 logs/fold0_cm_it.csv\n"," create mode 100644 logs/fold0_cm_knn.csv\n"," create mode 100644 logs/fold0_cm_rf.csv\n"," create mode 100644 logs/fold0_metrics_it.csv\n"," create mode 100644 logs/fold0_metrics_knn.csv\n"," create mode 100644 logs/fold0_metrics_rf.csv\n"," create mode 100644 logs/fold10_cm_it.csv\n"," create mode 100644 logs/fold10_cm_knn.csv\n"," create mode 100644 logs/fold10_cm_rf.csv\n"," create mode 100644 logs/fold10_metrics_it.csv\n"," create mode 100644 logs/fold10_metrics_knn.csv\n"," create mode 100644 logs/fold10_metrics_rf.csv\n"," create mode 100644 logs/fold11_cm_it.csv\n"," create mode 100644 logs/fold11_cm_knn.csv\n"," create mode 100644 logs/fold11_cm_rf.csv\n"," create mode 100644 logs/fold11_metrics_it.csv\n"," create mode 100644 logs/fold11_metrics_knn.csv\n"," create mode 100644 logs/fold11_metrics_rf.csv\n"," create mode 100644 logs/fold12_cm_it.csv\n"," create mode 100644 logs/fold12_cm_knn.csv\n"," create mode 100644 logs/fold12_cm_rf.csv\n"," create mode 100644 logs/fold12_metrics_it.csv\n"," create mode 100644 logs/fold12_metrics_knn.csv\n"," create mode 100644 logs/fold12_metrics_rf.csv\n"," create mode 100644 logs/fold13_cm_it.csv\n"," create mode 100644 logs/fold13_cm_knn.csv\n"," create mode 100644 logs/fold13_cm_rf.csv\n"," create mode 100644 logs/fold13_metrics_it.csv\n"," create mode 100644 logs/fold13_metrics_knn.csv\n"," create mode 100644 logs/fold13_metrics_rf.csv\n"," create mode 100644 logs/fold14_cm_it.csv\n"," create mode 100644 logs/fold14_cm_knn.csv\n"," create mode 100644 logs/fold14_cm_rf.csv\n"," create mode 100644 logs/fold14_metrics_it.csv\n"," create mode 100644 logs/fold14_metrics_knn.csv\n"," create mode 100644 logs/fold14_metrics_rf.csv\n"," create mode 100644 logs/fold1_cm_it.csv\n"," create mode 100644 logs/fold1_cm_knn.csv\n"," create mode 100644 logs/fold1_cm_rf.csv\n"," create mode 100644 logs/fold1_metrics_it.csv\n"," create mode 100644 logs/fold1_metrics_knn.csv\n"," create mode 100644 logs/fold1_metrics_rf.csv\n"," create mode 100644 logs/fold2_cm_it.csv\n"," create mode 100644 logs/fold2_cm_knn.csv\n"," create mode 100644 logs/fold2_cm_rf.csv\n"," create mode 100644 logs/fold2_metrics_it.csv\n"," create mode 100644 logs/fold2_metrics_knn.csv\n"," create mode 100644 logs/fold2_metrics_rf.csv\n"," create mode 100644 logs/fold3_cm_it.csv\n"," create mode 100644 logs/fold3_cm_knn.csv\n"," create mode 100644 logs/fold3_cm_rf.csv\n"," create mode 100644 logs/fold3_metrics_it.csv\n"," create mode 100644 logs/fold3_metrics_knn.csv\n"," create mode 100644 logs/fold3_metrics_rf.csv\n"," create mode 100644 logs/fold4_cm_it.csv\n"," create mode 100644 logs/fold4_cm_knn.csv\n"," create mode 100644 logs/fold4_cm_rf.csv\n"," create mode 100644 logs/fold4_metrics_it.csv\n"," create mode 100644 logs/fold4_metrics_knn.csv\n"," create mode 100644 logs/fold4_metrics_rf.csv\n"," create mode 100644 logs/fold5_cm_it.csv\n"," create mode 100644 logs/fold5_cm_knn.csv\n"," create mode 100644 logs/fold5_cm_rf.csv\n"," create mode 100644 logs/fold5_metrics_it.csv\n"," create mode 100644 logs/fold5_metrics_knn.csv\n"," create mode 100644 logs/fold5_metrics_rf.csv\n"," create mode 100644 logs/fold6_cm_it.csv\n"," create mode 100644 logs/fold6_cm_knn.csv\n"," create mode 100644 logs/fold6_cm_rf.csv\n"," create mode 100644 logs/fold6_metrics_it.csv\n"," create mode 100644 logs/fold6_metrics_knn.csv\n"," create mode 100644 logs/fold6_metrics_rf.csv\n"," create mode 100644 logs/fold7_cm_it.csv\n"," create mode 100644 logs/fold7_cm_knn.csv\n"," create mode 100644 logs/fold7_cm_rf.csv\n"," create mode 100644 logs/fold7_metrics_it.csv\n"," create mode 100644 logs/fold7_metrics_knn.csv\n"," create mode 100644 logs/fold7_metrics_rf.csv\n"," create mode 100644 logs/fold8_cm_it.csv\n"," create mode 100644 logs/fold8_cm_knn.csv\n"," create mode 100644 logs/fold8_cm_rf.csv\n"," create mode 100644 logs/fold8_metrics_it.csv\n"," create mode 100644 logs/fold8_metrics_knn.csv\n"," create mode 100644 logs/fold8_metrics_rf.csv\n"," create mode 100644 logs/fold9_cm_it.csv\n"," create mode 100644 logs/fold9_cm_knn.csv\n"," create mode 100644 logs/fold9_cm_rf.csv\n"," create mode 100644 logs/fold9_metrics_it.csv\n"," create mode 100644 logs/fold9_metrics_knn.csv\n"," create mode 100644 logs/fold9_metrics_rf.csv\n","============================================================\n","Step 16 completed\n","============================================================\n"]}]},{"cell_type":"code","source":["# ================ Step 17: Aggregation & Confidence ================\n","import numpy as np\n","import pandas as pd\n","from pathlib import Path\n","import matplotlib.pyplot as plt\n","import json\n","\n","print(\"\\n\\nStep 17: Aggregation & Confidence\")\n","print(\"=\" * 60)\n","\n","logs_dir = Path('/content/logs')\n","figures_dir = Path('/content/figures')\n","\n","with open('/content/configs/splits.json', 'r') as f:\n","    splits_cfg = json.load(f)\n","\n","with open('/content/configs/classes.json', 'r') as f:\n","    classes_cfg = json.load(f)\n","\n","id_to_label = {int(k): v for k, v in classes_cfg['id_to_label'].items()}\n","class_names = [id_to_label[i] for i in sorted(id_to_label.keys())]\n","\n","n_folds = len(splits_cfg['folds'])\n","\n","for model_name in ['knn', 'rf', 'it']:\n","    print(f\"\\n{'='*60}\")\n","    print(f\"[{model_name.upper()}]\")\n","    print(f\"{'='*60}\")\n","\n","    # Collect metrics across all folds\n","    macro_f1_list = []\n","    per_class_f1_matrix = []\n","\n","    for fold in splits_cfg['folds']:\n","        k = fold['fold']\n","        df_metrics = pd.read_csv(logs_dir / f'fold{k}_metrics_{model_name}.csv')\n","\n","        # Macro-F1\n","        macro_f1 = df_metrics[df_metrics['class'] == 'macro_avg']['f1_score'].values[0]\n","        macro_f1_list.append(macro_f1)\n","\n","        # Per-class F1\n","        per_class_f1 = df_metrics[df_metrics['class'] != 'macro_avg']['f1_score'].values\n","        per_class_f1_matrix.append(per_class_f1)\n","\n","    macro_f1_array = np.array(macro_f1_list)\n","    per_class_f1_matrix = np.array(per_class_f1_matrix)\n","\n","    # Macro-F1 mean ± std\n","    macro_mean = macro_f1_array.mean()\n","    macro_std = macro_f1_array.std()\n","    print(f\"\\nMacro-F1: {macro_mean:.4f} ± {macro_std:.4f}\")\n","\n","    # Bootstrap 95% CI\n","    n_bootstrap = 10000\n","    np.random.seed(42)\n","    bootstrap_means = []\n","    for _ in range(n_bootstrap):\n","        sample = np.random.choice(macro_f1_array, size=n_folds, replace=True)\n","        bootstrap_means.append(sample.mean())\n","    ci_lower, ci_upper = np.percentile(bootstrap_means, [2.5, 97.5])\n","    print(f\"Bootstrap 95% CI: [{ci_lower:.4f}, {ci_upper:.4f}]\")\n","\n","    # Per-class F1 mean\n","    per_class_mean = per_class_f1_matrix.mean(axis=0)\n","    print(f\"\\nPer-class F1 (mean):\")\n","    for i, class_name in enumerate(class_names):\n","        print(f\"  {class_name:15s}: {per_class_mean[i]:.4f}\")\n","\n","    # Save summary table\n","    summary_data = []\n","    for i, class_name in enumerate(class_names):\n","        summary_data.append({\n","            'class': class_name,\n","            'f1_mean': per_class_mean[i],\n","            'f1_std': per_class_f1_matrix[:, i].std()\n","        })\n","    summary_data.append({\n","        'class': 'macro_avg',\n","        'f1_mean': macro_mean,\n","        'f1_std': macro_std\n","    })\n","    summary_data.append({\n","        'class': 'macro_avg_ci_lower',\n","        'f1_mean': ci_lower,\n","        'f1_std': np.nan\n","    })\n","    summary_data.append({\n","        'class': 'macro_avg_ci_upper',\n","        'f1_mean': ci_upper,\n","        'f1_std': np.nan\n","    })\n","\n","    df_summary = pd.DataFrame(summary_data)\n","    df_summary.to_csv(logs_dir / f'summary_metrics_{model_name}.csv', index=False)\n","    print(f\"\\n✓ Saved: summary_metrics_{model_name}.csv\")\n","\n","    # Radar plot\n","    fig, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(projection='polar'))\n","    angles = np.linspace(0, 2 * np.pi, len(class_names), endpoint=False).tolist()\n","    values = per_class_mean.tolist()\n","    angles += angles[:1]\n","    values += values[:1]\n","    ax.plot(angles, values, 'o-', linewidth=2, label=model_name.upper())\n","    ax.fill(angles, values, alpha=0.25)\n","    ax.set_xticks(angles[:-1])\n","    ax.set_xticklabels(class_names, size=10)\n","    ax.set_ylim(0, 1)\n","    ax.set_title(f'{model_name.upper()} - Per-class F1 Score', size=14, pad=20)\n","    ax.grid(True)\n","    ax.legend(loc='upper right')\n","    plt.tight_layout()\n","    plt.savefig(figures_dir / f'radar_{model_name}.svg', format='svg')\n","    plt.close()\n","\n","    # Bar chart\n","    fig, ax = plt.subplots(figsize=(10, 6))\n","    x_pos = np.arange(len(class_names))\n","    bars = ax.bar(x_pos, per_class_mean, yerr=per_class_f1_matrix.std(axis=0),\n","                   capsize=5, alpha=0.7, edgecolor='black')\n","    ax.axhline(y=macro_mean, color='red', linestyle='--', linewidth=2, label=f'Macro-F1: {macro_mean:.3f}±{macro_std:.3f}')\n","    ax.set_xlabel('Class', fontsize=12)\n","    ax.set_ylabel('F1 Score', fontsize=12)\n","    ax.set_title(f'{model_name.upper()} - Per-class F1 Score', fontsize=14)\n","    ax.set_xticks(x_pos)\n","    ax.set_xticklabels(class_names, rotation=45, ha='right')\n","    ax.set_ylim(0, 1.0)\n","    ax.legend()\n","    ax.grid(axis='y', alpha=0.3)\n","    plt.tight_layout()\n","    plt.savefig(figures_dir / f'bar_{model_name}.svg', format='svg')\n","    plt.close()\n","\n","    print(f\"✓ Saved: radar_{model_name}.svg, bar_{model_name}.svg\")\n","\n","print(f\"\\n{'='*60}\")\n","print(\"✓ Aggregation & Confidence completed\")\n","print(f\"  Summary tables: logs/summary_metrics_{{knn,rf,it}}.csv\")\n","print(f\"  Visualizations: figures/radar_{{knn,rf,it}}.svg, figures/bar_{{knn,rf,it}}.svg\")\n","\n","get_ipython().system('git add logs/summary_metrics_*.csv figures/radar_*.svg figures/bar_*.svg')\n","get_ipython().system('git commit -m \"eval: aggregated metrics with bootstrap CI and plots\"')\n","print(f\"{'='*60}\\nStep 17 completed\\n{'='*60}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IaZLJnJxDKkv","executionInfo":{"status":"ok","timestamp":1762707499822,"user_tz":0,"elapsed":2090,"user":{"displayName":"yu Wu","userId":"12692660435918028293"}},"outputId":"51cfe477-8ee8-4321-924a-097c5a1506c0"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","Step 17: Aggregation & Confidence\n","============================================================\n","\n","============================================================\n","[KNN]\n","============================================================\n","\n","Macro-F1: 0.7551 ± 0.1164\n","Bootstrap 95% CI: [0.6931, 0.8108]\n","\n","Per-class F1 (mean):\n","  walking        : 0.8384\n","  running        : 0.8576\n","  sitting        : 0.6263\n","  standing       : 0.7277\n","  lying          : 0.7690\n","  stairs_up      : 0.6595\n","  stairs_down    : 0.6235\n","  jumping        : 0.9388\n","\n","✓ Saved: summary_metrics_knn.csv\n","✓ Saved: radar_knn.svg, bar_knn.svg\n","\n","============================================================\n","[RF]\n","============================================================\n","\n","Macro-F1: 0.7830 ± 0.1200\n","Bootstrap 95% CI: [0.7191, 0.8414]\n","\n","Per-class F1 (mean):\n","  walking        : 0.7922\n","  running        : 0.8839\n","  sitting        : 0.7111\n","  standing       : 0.7782\n","  lying          : 0.8181\n","  stairs_up      : 0.6553\n","  stairs_down    : 0.6617\n","  jumping        : 0.9638\n","\n","✓ Saved: summary_metrics_rf.csv\n","✓ Saved: radar_rf.svg, bar_rf.svg\n","\n","============================================================\n","[IT]\n","============================================================\n","\n","Macro-F1: 0.6241 ± 0.1497\n","Bootstrap 95% CI: [0.5431, 0.6940]\n","\n","Per-class F1 (mean):\n","  walking        : 0.6584\n","  running        : 0.8015\n","  sitting        : 0.4088\n","  standing       : 0.4449\n","  lying          : 0.5498\n","  stairs_up      : 0.5487\n","  stairs_down    : 0.6431\n","  jumping        : 0.8982\n","\n","✓ Saved: summary_metrics_it.csv\n","✓ Saved: radar_it.svg, bar_it.svg\n","\n","============================================================\n","✓ Aggregation & Confidence completed\n","  Summary tables: logs/summary_metrics_{knn,rf,it}.csv\n","  Visualizations: figures/radar_{knn,rf,it}.svg, figures/bar_{knn,rf,it}.svg\n","[master 86c75c1] eval: aggregated metrics with bootstrap CI and plots\n"," 9 files changed, 7958 insertions(+)\n"," create mode 100644 figures/bar_it.svg\n"," create mode 100644 figures/bar_knn.svg\n"," create mode 100644 figures/bar_rf.svg\n"," create mode 100644 figures/radar_it.svg\n"," create mode 100644 figures/radar_knn.svg\n"," create mode 100644 figures/radar_rf.svg\n"," create mode 100644 logs/summary_metrics_it.csv\n"," create mode 100644 logs/summary_metrics_knn.csv\n"," create mode 100644 logs/summary_metrics_rf.csv\n","============================================================\n","Step 17 completed\n","============================================================\n"]}]},{"cell_type":"code","source":["# ================ Step 18: Significance Testing ================\n","import numpy as np\n","import pandas as pd\n","from pathlib import Path\n","from scipy import stats\n","from scipy.stats import friedmanchisquare, wilcoxon\n","import matplotlib.pyplot as plt\n","import json\n","\n","print(\"\\n\\nStep 18: Significance Testing\")\n","print(\"=\" * 60)\n","\n","logs_dir = Path('/content/logs')\n","figures_dir = Path('/content/figures')\n","\n","with open('/content/configs/splits.json', 'r') as f:\n","    splits_cfg = json.load(f)\n","\n","n_folds = len(splits_cfg['folds'])\n","\n","# Collect per-subject (per fold) Macro-F1\n","model_names = ['knn', 'rf', 'it']\n","scores = {model: [] for model in model_names}\n","\n","for fold in splits_cfg['folds']:\n","    k = fold['fold']\n","    for model in model_names:\n","        df_metrics = pd.read_csv(logs_dir / f'fold{k}_metrics_{model}.csv')\n","        macro_f1 = df_metrics[df_metrics['class'] == 'macro_avg']['f1_score'].values[0]\n","        scores[model].append(macro_f1)\n","\n","# Convert to arrays\n","knn_scores = np.array(scores['knn'])\n","rf_scores = np.array(scores['rf'])\n","it_scores = np.array(scores['it'])\n","\n","print(f\"Number of subjects: {n_folds}\")\n","print(f\"KNN: {knn_scores}\")\n","print(f\"RF:  {rf_scores}\")\n","print(f\"IT:  {it_scores}\")\n","\n","# Friedman test\n","stat, p_value = friedmanchisquare(knn_scores, rf_scores, it_scores)\n","print(f\"\\n{'='*60}\")\n","print(f\"Friedman test:\")\n","print(f\"  Statistic: {stat:.4f}\")\n","print(f\"  p-value: {p_value:.6f}\")\n","print(f\"  Significant (α=0.05): {'Yes' if p_value < 0.05 else 'No'}\")\n","\n","# Cliff's Delta effect size\n","def cliffs_delta(x, y):\n","    n1, n2 = len(x), len(y)\n","    delta = sum(np.sign(xi - yi) for xi in x for yi in y) / (n1 * n2)\n","    return delta\n","\n","print(f\"\\n{'='*60}\")\n","print(f\"Cliff's Delta effect size:\")\n","pairs = [('knn', 'rf'), ('knn', 'it'), ('rf', 'it')]\n","cliffs_results = []\n","for m1, m2 in pairs:\n","    delta = cliffs_delta(scores[m1], scores[m2])\n","    cliffs_results.append({'pair': f'{m1}_vs_{m2}', 'cliffs_delta': delta})\n","    print(f\"  {m1.upper()} vs {m2.upper()}: δ={delta:.4f}\")\n","\n","# Paired Wilcoxon signed-rank tests\n","print(f\"\\n{'='*60}\")\n","print(f\"Paired Wilcoxon signed-rank tests:\")\n","wilcoxon_results = []\n","for m1, m2 in pairs:\n","    stat_w, p_w = wilcoxon(scores[m1], scores[m2], alternative='two-sided')\n","    wilcoxon_results.append({'pair': f'{m1}_vs_{m2}', 'statistic': stat_w, 'p_value': p_w})\n","    print(f\"  {m1.upper()} vs {m2.upper()}: W={stat_w:.2f}, p={p_w:.6f}\")\n","\n","# Save test results\n","test_results = {\n","    'friedman': {'statistic': float(stat), 'p_value': float(p_value)},\n","    'cliffs_delta': cliffs_results,\n","    'wilcoxon': wilcoxon_results,\n","    'scores': {model: scores[model] for model in model_names}\n","}\n","\n","with open(logs_dir / 'significance_tests.json', 'w') as f:\n","    json.dump(test_results, f, indent=2)\n","\n","# Critical Difference diagram\n","print(f\"\\n{'='*60}\")\n","print(f\"Drawing Critical Difference diagram...\")\n","\n","# Compute average ranks\n","ranks = []\n","for i in range(n_folds):\n","    fold_scores = [knn_scores[i], rf_scores[i], it_scores[i]]\n","    fold_ranks = stats.rankdata([-s for s in fold_scores])  # descending ranks\n","    ranks.append(fold_ranks)\n","ranks = np.array(ranks)\n","avg_ranks = ranks.mean(axis=0)\n","\n","# Nemenyi critical difference\n","k = 3  # number of models\n","N = n_folds  # number of subjects\n","q_alpha = 2.344  # q(0.05, 3) for Nemenyi\n","cd = q_alpha * np.sqrt(k * (k + 1) / (6 * N))\n","\n","print(f\"  Average ranks: KNN={avg_ranks[0]:.2f}, RF={avg_ranks[1]:.2f}, IT={avg_ranks[2]:.2f}\")\n","print(f\"  Critical Difference (CD): {cd:.4f}\")\n","\n","# Plotting\n","fig, ax = plt.subplots(figsize=(10, 4))\n","\n","# Order models\n","model_labels = ['KNN', 'RF', 'IT']\n","sorted_indices = np.argsort(avg_ranks)\n","sorted_ranks = avg_ranks[sorted_indices]\n","sorted_labels = [model_labels[i] for i in sorted_indices]\n","\n","# Draw rank axis\n","ax.plot([1, k], [0, 0], 'k-', linewidth=2)\n","for i, (rank, label) in enumerate(zip(sorted_ranks, sorted_labels)):\n","    ax.plot(rank, 0, 'o', markersize=15, color=f'C{i}')\n","    ax.text(rank, -0.3, label, ha='center', va='top', fontsize=12, fontweight='bold')\n","    ax.text(rank, 0.3, f'{rank:.2f}', ha='center', va='bottom', fontsize=10)\n","\n","# Draw CD line segments\n","for i in range(len(sorted_ranks)):\n","    for j in range(i+1, len(sorted_ranks)):\n","        if sorted_ranks[j] - sorted_ranks[i] <= cd:\n","            y_pos = 0.6 + 0.3 * (i + j)\n","            ax.plot([sorted_ranks[i], sorted_ranks[j]], [y_pos, y_pos], 'r-', linewidth=3)\n","\n","ax.set_xlim(0.5, k + 0.5)\n","ax.set_ylim(-0.8, 2)\n","ax.set_xlabel('Average Rank', fontsize=12)\n","ax.set_title(f'Critical Difference Diagram (CD={cd:.3f}, α=0.05)', fontsize=14)\n","ax.set_yticks([])\n","ax.spines['left'].set_visible(False)\n","ax.spines['right'].set_visible(False)\n","ax.spines['top'].set_visible(False)\n","ax.grid(axis='x', alpha=0.3)\n","plt.tight_layout()\n","plt.savefig(figures_dir / 'critical_difference.svg', format='svg')\n","plt.close()\n","\n","print(f\"  ✓ Saved: critical_difference.svg\")\n","\n","# Summary table\n","scores_arrays = {'knn': knn_scores, 'rf': rf_scores, 'it': it_scores}\n","summary_df = pd.DataFrame({\n","    'model': model_labels,\n","    'avg_rank': avg_ranks,\n","    'mean_f1': [np.mean(scores_arrays[m]) for m in model_names],\n","    'std_f1': [np.std(scores_arrays[m]) for m in model_names]\n","})\n","summary_df = summary_df.sort_values('avg_rank')\n","summary_df.to_csv(logs_dir / 'model_comparison.csv', index=False)\n","\n","print(f\"\\n{'='*60}\")\n","print(\"Model comparison:\")\n","print(summary_df.to_string(index=False))\n","\n","print(f\"\\n{'='*60}\")\n","print(\"✓ Significance testing completed\")\n","print(f\"  Test results: logs/significance_tests.json\")\n","print(f\"  Model comparison: logs/model_comparison.csv\")\n","print(f\"  CD diagram: figures/critical_difference.svg\")\n","\n","get_ipython().system('git add logs/significance_tests.json logs/model_comparison.csv figures/critical_difference.svg')\n","get_ipython().system('git commit -m \"eval: statistical significance tests with CD plot\"')\n","print(f\"{'='*60}\\nStep 18 completed\\n{'='*60}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IVUaxLf1DaK2","executionInfo":{"status":"ok","timestamp":1762708424339,"user_tz":0,"elapsed":514,"user":{"displayName":"yu Wu","userId":"12692660435918028293"}},"outputId":"747fee14-462c-47e7-bd8b-f4592caf479f"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","Step 18: Significance Testing\n","============================================================\n","Number of subjects: 15\n","KNN: [0.58539753 0.83817817 0.79743589 0.87503295 0.83178283 0.59370451\n"," 0.83187425 0.85389454 0.82283078 0.51765368 0.73385081 0.84105272\n"," 0.62283744 0.70414656 0.87676474]\n","RF:  [0.63727096 0.83519507 0.80897707 0.90582356 0.85378201 0.61598399\n"," 0.8944163  0.93676815 0.87254001 0.5640497  0.75543625 0.86354911\n"," 0.65108029 0.66011803 0.89052718]\n","IT:  [0.62463936 0.66864241 0.71761017 0.6807601  0.80493283 0.59017075\n"," 0.71281785 0.65876066 0.27454629 0.4547222  0.75588981 0.72383149\n"," 0.44649681 0.43747836 0.81039167]\n","\n","============================================================\n","Friedman test:\n","  Statistic: 19.2000\n","  p-value: 0.000068\n","  Significant (α=0.05): Yes\n","\n","============================================================\n","Cliff's Delta effect size:\n","  KNN vs RF: δ=-0.2178\n","  KNN vs IT: δ=0.5289\n","  RF vs IT: δ=0.5467\n","\n","============================================================\n","Paired Wilcoxon signed-rank tests:\n","  KNN vs RF: W=11.00, p=0.003357\n","  KNN vs IT: W=6.00, p=0.000854\n","  RF vs IT: W=1.00, p=0.000122\n","\n","============================================================\n","Drawing Critical Difference diagram...\n","  Average ranks: KNN=2.00, RF=1.20, IT=2.80\n","  Critical Difference (CD): 0.8559\n","  ✓ Saved: critical_difference.svg\n","\n","============================================================\n","Model comparison:\n","model  avg_rank  mean_f1   std_f1\n","   RF       1.2 0.783035 0.119987\n","  KNN       2.0 0.755096 0.116379\n","   IT       2.8 0.624113 0.149695\n","\n","============================================================\n","✓ Significance testing completed\n","  Test results: logs/significance_tests.json\n","  Model comparison: logs/model_comparison.csv\n","  CD diagram: figures/critical_difference.svg\n","[master 617e0ec] eval: statistical significance tests with CD plot\n"," 3 files changed, 1207 insertions(+)\n"," create mode 100644 figures/critical_difference.svg\n"," create mode 100644 logs/model_comparison.csv\n"," create mode 100644 logs/significance_tests.json\n","============================================================\n","Step 18 completed\n","============================================================\n"]}]},{"cell_type":"code","source":["# ================ Step 19: Latency/Resource Evaluation ================\n","import numpy as np\n","import pandas as pd\n","from pathlib import Path\n","import matplotlib.pyplot as plt\n","import json\n","import pickle\n","import torch\n","import platform\n","import psutil\n","\n","print(\"\\n\\nStep 19: Latency/Resource Evaluation\")\n","print(\"=\" * 60)\n","\n","logs_dir = Path('/content/logs')\n","models_dir = Path('/content/models')\n","figures_dir = Path('/content/figures')\n","\n","# Test platform information\n","platform_info = {\n","    'OS': platform.system(),\n","    'Python': platform.python_version(),\n","    'CPU': platform.processor(),\n","    'CPU_count': psutil.cpu_count(logical=False),\n","    'CPU_threads': psutil.cpu_count(logical=True),\n","    'RAM_GB': round(psutil.virtual_memory().total / (1024**3), 2)\n","}\n","\n","print(\"Test platform:\")\n","for k, v in platform_info.items():\n","    print(f\"  {k}: {v}\")\n","\n","# Load latency data\n","with open(logs_dir / 'inference_latency.json', 'r') as f:\n","    latency_data = json.load(f)\n","\n","# Compute average latency\n","avg_latency = {'knn': {'p50': [], 'p90': []},\n","               'rf': {'p50': [], 'p90': []},\n","               'it': {'p50': [], 'p90': []}}\n","\n","for fold_data in latency_data:\n","    for model in ['knn', 'rf', 'it']:\n","        avg_latency[model]['p50'].append(fold_data[model]['p50'])\n","        avg_latency[model]['p90'].append(fold_data[model]['p90'])\n","\n","latency_summary = {}\n","for model in ['knn', 'rf', 'it']:\n","    latency_summary[model] = {\n","        'p50_mean': np.mean(avg_latency[model]['p50']),\n","        'p90_mean': np.mean(avg_latency[model]['p90'])\n","    }\n","\n","# Compute model size\n","model_sizes = {}\n","model_file_patterns = {'knn': 'knn_fold*.pkl', 'rf': 'rf_fold*.pkl', 'it': 'itime_fold*.pt'}\n","for model_name in ['knn', 'rf', 'it']:\n","    model_files = list(models_dir.glob(model_file_patterns[model_name]))\n","    sizes = [f.stat().st_size / (1024**2) for f in model_files]  # MB\n","    model_sizes[model_name] = np.mean(sizes)\n","\n","# Load F1 scores\n","f1_scores = {}\n","for model_name in ['knn', 'rf', 'it']:\n","    df_summary = pd.read_csv(logs_dir / f'summary_metrics_{model_name}.csv')\n","    macro_f1 = df_summary[df_summary['class'] == 'macro_avg']['f1_mean'].values[0]\n","    f1_scores[model_name] = macro_f1\n","\n","# Summary table\n","resource_data = []\n","for model_name in ['knn', 'rf', 'it']:\n","    resource_data.append({\n","        'Model': model_name.upper(),\n","        'F1_Score': f1_scores[model_name],\n","        'Latency_p50_ms': latency_summary[model_name]['p50_mean'],\n","        'Latency_p90_ms': latency_summary[model_name]['p90_mean'],\n","        'Model_Size_MB': model_sizes[model_name]\n","    })\n","\n","df_resources = pd.DataFrame(resource_data)\n","df_resources.to_csv(logs_dir / 'resource_evaluation.csv', index=False)\n","\n","print(f\"\\n{'='*60}\")\n","print(\"Resource evaluation:\")\n","print(df_resources.to_string(index=False))\n","\n","# Pareto plot: F1 vs Latency\n","fig, ax = plt.subplots(figsize=(10, 6))\n","\n","colors = {'KNN': 'C0', 'RF': 'C1', 'IT': 'C2'}\n","markers = {'KNN': 'o', 'RF': 's', 'IT': '^'}\n","\n","for _, row in df_resources.iterrows():\n","    model = row['Model']\n","    ax.scatter(row['Latency_p50_ms'], row['F1_Score'],\n","              s=row['Model_Size_MB']*50,\n","              c=colors[model], marker=markers[model],\n","              alpha=0.7, edgecolors='black', linewidth=2,\n","              label=f\"{model} ({row['Model_Size_MB']:.1f}MB)\")\n","    ax.text(row['Latency_p50_ms'], row['F1_Score']+0.01, model,\n","           ha='center', fontsize=11, fontweight='bold')\n","\n","ax.set_xlabel('Latency p50 (ms)', fontsize=12)\n","ax.set_ylabel('Macro F1-Score', fontsize=12)\n","ax.set_title('Model Performance vs Inference Latency\\n(Bubble size = Model size)', fontsize=14)\n","ax.grid(True, alpha=0.3)\n","ax.legend(title='Model (Size)', loc='best', fontsize=10)\n","ax.set_ylim(0.5, 1.0)\n","plt.tight_layout()\n","plt.savefig(figures_dir / 'pareto_f1_latency.svg', format='svg')\n","plt.close()\n","\n","# Pareto plot: F1 vs Size\n","fig, ax = plt.subplots(figsize=(10, 6))\n","\n","for _, row in df_resources.iterrows():\n","    model = row['Model']\n","    ax.scatter(row['Model_Size_MB'], row['F1_Score'],\n","              s=200, c=colors[model], marker=markers[model],\n","              alpha=0.7, edgecolors='black', linewidth=2,\n","              label=f\"{model} ({row['Latency_p50_ms']:.1f}ms)\")\n","    ax.text(row['Model_Size_MB'], row['F1_Score']+0.01, model,\n","           ha='center', fontsize=11, fontweight='bold')\n","\n","ax.set_xlabel('Model Size (MB)', fontsize=12)\n","ax.set_ylabel('Macro F1-Score', fontsize=12)\n","ax.set_title('Model Performance vs Model Size\\n(p50 latency in legend)', fontsize=14)\n","ax.grid(True, alpha=0.3)\n","ax.legend(title='Model (Latency)', loc='best', fontsize=10)\n","ax.set_ylim(0.5, 1.0)\n","plt.tight_layout()\n","plt.savefig(figures_dir / 'pareto_f1_size.svg', format='svg')\n","plt.close()\n","\n","# Save full report\n","evaluation_report = {\n","    'platform': platform_info,\n","    'models': resource_data,\n","    'note': 'Latency measured with batch=1, single-thread CPU inference'\n","}\n","\n","with open(logs_dir / 'resource_report.json', 'w') as f:\n","    json.dump(evaluation_report, f, indent=2)\n","\n","print(f\"\\n{'='*60}\")\n","print(\"✓ Latency/Resource evaluation completed\")\n","print(f\"  Evaluation table: logs/resource_evaluation.csv\")\n","print(f\"  Detailed report: logs/resource_report.json\")\n","print(f\"  Pareto plots: figures/pareto_f1_latency.svg, figures/pareto_f1_size.svg\")\n","\n","get_ipython().system('git add logs/resource_evaluation.csv logs/resource_report.json figures/pareto_*.svg')\n","get_ipython().system('git commit -m \"eval: resource evaluation with Pareto plots\"')\n","print(f\"{'='*60}\\nStep 19 completed\\n{'='*60}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7ldgcbJpnUYd","executionInfo":{"status":"ok","timestamp":1762708509144,"user_tz":0,"elapsed":662,"user":{"displayName":"yu Wu","userId":"12692660435918028293"}},"outputId":"cfae57c8-dc10-4246-c41b-a068066287d6"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","Step 19: Latency/Resource Evaluation\n","============================================================\n","Test platform:\n","  OS: Linux\n","  Python: 3.12.12\n","  CPU: x86_64\n","  CPU_count: 6\n","  CPU_threads: 12\n","  RAM_GB: 52.96\n","\n","============================================================\n","Resource evaluation:\n","Model  F1_Score  Latency_p50_ms  Latency_p90_ms  Model_Size_MB\n","  KNN  0.755096       46.685170       78.920692      27.387397\n","   RF  0.783035       20.452894       20.921411     219.849695\n","   IT  0.624113        3.467657        3.530380       1.780754\n","\n","============================================================\n","✓ Latency/Resource evaluation completed\n","  Evaluation table: logs/resource_evaluation.csv\n","  Detailed report: logs/resource_report.json\n","  Pareto plots: figures/pareto_f1_latency.svg, figures/pareto_f1_size.svg\n","[master c6d95f9] eval: resource evaluation with Pareto plots\n"," 4 files changed, 3157 insertions(+)\n"," create mode 100644 figures/pareto_f1_latency.svg\n"," create mode 100644 figures/pareto_f1_size.svg\n"," create mode 100644 logs/resource_evaluation.csv\n"," create mode 100644 logs/resource_report.json\n","============================================================\n","Step 19 completed\n","============================================================\n"]}]},{"cell_type":"code","source":["# ================ Step 20: Sensitivity and Robustness ================\n","import numpy as np\n","import pandas as pd\n","from pathlib import Path\n","from scipy import interpolate\n","from scipy.fft import rfft, rfftfreq\n","from scipy import stats as scipy_stats\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import f1_score\n","import json\n","\n","print(\"\\n\\nStep 20: Sensitivity and Robustness\")\n","print(\"=\" * 60)\n","\n","proc_dir = Path('/content/proc')\n","logs_dir = Path('/content/logs')\n","\n","with open('/content/configs/splits.json', 'r') as f:\n","    splits_cfg = json.load(f)\n","\n","with open('/content/configs/classes.json', 'r') as f:\n","    classes_cfg = json.load(f)\n","\n","FS = 50\n","BASE_WINDOW_SEC = 3\n","BASE_OVERLAP = 0.5\n","BASE_CHANNELS = ['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_y', 'gyro_z']\n","\n","# Use Fold 0 training data\n","test_subject = splits_cfg['folds'][0]['test_subject']\n","train_subjects = splits_cfg['folds'][0]['train_subjects']\n","\n","print(f\"Using Fold 0 training data\")\n","print(f\"Training subjects: {train_subjects[:3]}... (total {len(train_subjects)})\")\n","\n","# Collect training data\n","train_files = []\n","for f in proc_dir.glob('*.csv'):\n","    df = pd.read_csv(f)\n","    subject = df['proband'].iloc[0]\n","    if subject in train_subjects:\n","        train_files.append(f)\n","\n","print(f\"Number of training files: {len(train_files)}\")\n","\n","# Feature extraction function\n","def extract_features_simple(X):\n","    feats = {}\n","    feats['mean'] = np.mean(X, axis=1)\n","    feats['std'] = np.std(X, axis=1)\n","    feats['rms'] = np.sqrt(np.mean(X**2, axis=1))\n","    feats['energy'] = np.sum(X**2, axis=1)\n","    fft_vals = np.abs(rfft(X, axis=1))\n","    feats['peak_freq'] = np.argmax(fft_vals, axis=1)\n","    return np.column_stack([feats[k] for k in ['mean', 'std', 'rms', 'energy', 'peak_freq']])\n","\n","# Windowing function\n","def create_windows(files, window_sec, overlap, channels):\n","    window_samples = int(FS * window_sec)\n","    stride_samples = int(window_samples * (1 - overlap))\n","\n","    X_list, y_list = [], []\n","    for filepath in files:\n","        df = pd.read_csv(filepath)\n","        activity = df['activity'].iloc[0]\n","        label = classes_cfg['label_to_id'][classes_cfg['activity_mapping'].get(activity, activity)]\n","\n","        for seg_id, seg_df in df.groupby('segment_id'):\n","            if len(seg_df) < window_samples:\n","                continue\n","            for start in range(0, len(seg_df) - window_samples + 1, stride_samples):\n","                window = seg_df.iloc[start:start+window_samples]\n","                X_window = np.stack([window[ch].values for ch in channels], axis=0)\n","                X_list.append(X_window)\n","                y_list.append(label)\n","\n","    X = np.array(X_list, dtype=np.float32)\n","    y = np.array(y_list, dtype=np.int32)\n","    return X, y\n","\n","# Baseline configuration\n","print(f\"\\n{'='*60}\")\n","print(\"Baseline configuration (window=3s, overlap=50%, channels=ACC+GYRO):\")\n","X_base, y_base = create_windows(train_files, BASE_WINDOW_SEC, BASE_OVERLAP, BASE_CHANNELS)\n","print(f\"  Number of windows: {len(X_base)}\")\n","\n","# Feature extraction\n","X_base_flat = X_base.reshape(len(X_base), -1)\n","X_base_feat = []\n","for i in range(X_base.shape[1]):\n","    X_base_feat.append(extract_features_simple(X_base[:, i, :]))\n","X_base_feat = np.concatenate(X_base_feat, axis=1)\n","\n","# Train/validation split\n","X_train, X_val, y_train, y_val = train_test_split(X_base_feat, y_base, test_size=0.2, random_state=42, stratify=y_base)\n","\n","# Baseline model\n","rf_base = RandomForestClassifier(n_estimators=100, max_depth=20, random_state=42, n_jobs=-1)\n","rf_base.fit(X_train, y_train)\n","base_f1 = f1_score(y_val, rf_base.predict(X_val), average='macro', zero_division=0)\n","print(f\"  Baseline Macro-F1: {base_f1:.4f}\")\n","\n","# Sensitivity test configurations\n","configs = [\n","    {'name': 'window_2s', 'window_sec': 2, 'overlap': 0.5, 'channels': BASE_CHANNELS},\n","    {'name': 'window_5s', 'window_sec': 5, 'overlap': 0.5, 'channels': BASE_CHANNELS},\n","    {'name': 'overlap_0', 'window_sec': 3, 'overlap': 0.0, 'channels': BASE_CHANNELS},\n","    {'name': 'acc_only', 'window_sec': 3, 'overlap': 0.5, 'channels': ['acc_x', 'acc_y', 'acc_z']},\n","]\n","\n","results = [{'config': 'baseline', 'window_sec': 3, 'overlap': 0.5, 'channels': 'ACC+GYRO',\n","            'f1': base_f1, 'delta': 0.0}]\n","\n","print(f\"\\n{'='*60}\")\n","print(\"Sensitivity tests:\")\n","\n","for cfg in configs:\n","    print(f\"\\n[{cfg['name']}]\")\n","\n","    X, y = create_windows(train_files, cfg['window_sec'], cfg['overlap'], cfg['channels'])\n","    print(f\"  Number of windows: {len(X)}\")\n","\n","    # Feature extraction\n","    X_feat = []\n","    for i in range(X.shape[1]):\n","        X_feat.append(extract_features_simple(X[:, i, :]))\n","    X_feat = np.concatenate(X_feat, axis=1)\n","\n","    # Train/validation split\n","    X_tr, X_va, y_tr, y_va = train_test_split(X_feat, y, test_size=0.2, random_state=42, stratify=y)\n","\n","    # Train model\n","    rf = RandomForestClassifier(n_estimators=100, max_depth=20, random_state=42, n_jobs=-1)\n","    rf.fit(X_tr, y_tr)\n","    f1 = f1_score(y_va, rf.predict(X_va), average='macro', zero_division=0)\n","    delta = f1 - base_f1\n","\n","    print(f\"  Macro-F1: {f1:.4f} (Δ={delta:+.4f}, {delta*100:+.1f}pp)\")\n","\n","    channels_str = 'ACC' if len(cfg['channels']) == 3 else 'ACC+GYRO'\n","    results.append({\n","        'config': cfg['name'],\n","        'window_sec': cfg['window_sec'],\n","        'overlap': cfg['overlap'],\n","        'channels': channels_str,\n","        'f1': f1,\n","        'delta': delta\n","    })\n","\n","# Save results\n","df_sensitivity = pd.DataFrame(results)\n","df_sensitivity.to_csv(logs_dir / 'sensitivity_analysis.csv', index=False)\n","\n","print(f\"\\n{'='*60}\")\n","print(\"Sensitivity analysis results:\")\n","print(df_sensitivity.to_string(index=False))\n","\n","# Robustness evaluation\n","THRESHOLD = 0.03  # ±3pp\n","robust_configs = df_sensitivity[abs(df_sensitivity['delta']) <= THRESHOLD]\n","\n","print(f\"\\n{'='*60}\")\n","print(f\"Robustness evaluation (threshold=±{THRESHOLD*100:.0f}pp):\")\n","print(f\"  Number of robust configurations: {len(robust_configs)}/{len(results)}\")\n","print(f\"  Maximum change: {df_sensitivity['delta'].abs().max()*100:.1f}pp\")\n","print(f\"  Mean change: {df_sensitivity['delta'].abs().mean()*100:.1f}pp\")\n","\n","summary = {\n","    'baseline_f1': float(base_f1),\n","    'max_delta_pp': float(df_sensitivity['delta'].abs().max() * 100),\n","    'mean_delta_pp': float(df_sensitivity['delta'].abs().mean() * 100),\n","    'robust_threshold_pp': THRESHOLD * 100,\n","    'robust_configs': int(len(robust_configs)),\n","    'total_configs': len(results)\n","}\n","\n","with open(logs_dir / 'sensitivity_summary.json', 'w') as f:\n","    json.dump(summary, f, indent=2)\n","\n","print(f\"\\n{'='*60}\")\n","print(\"✓ Sensitivity and robustness analysis completed\")\n","print(f\"  Detailed results: logs/sensitivity_analysis.csv\")\n","print(f\"  Summary: logs/sensitivity_summary.json\")\n","\n","get_ipython().system('git add logs/sensitivity_analysis.csv logs/sensitivity_summary.json')\n","get_ipython().system('git commit -m \"eval: sensitivity and robustness analysis\"')\n","print(f\"{'='*60}\\nStep 20 completed\\n{'='*60}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EEVeVkfgnnTg","executionInfo":{"status":"ok","timestamp":1762708654522,"user_tz":0,"elapsed":68166,"user":{"displayName":"yu Wu","userId":"12692660435918028293"}},"outputId":"0df5bc22-2ab6-4d7f-a094-c70f492de88d"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","Step 20: Sensitivity and Robustness\n","============================================================\n","Using Fold 0 training data\n","Training subjects: ['proband10', 'proband11', 'proband12']... (total 14)\n","Number of training files: 106\n","\n","============================================================\n","Baseline configuration (window=3s, overlap=50%, channels=ACC+GYRO):\n","  Number of windows: 34727\n","  Baseline Macro-F1: 0.8978\n","\n","============================================================\n","Sensitivity tests:\n","\n","[window_2s]\n","  Number of windows: 53839\n","  Macro-F1: 0.8855 (Δ=-0.0122, -1.2pp)\n","\n","[window_5s]\n","  Number of windows: 19501\n","  Macro-F1: 0.9131 (Δ=+0.0153, +1.5pp)\n","\n","[overlap_0]\n","  Number of windows: 17917\n","  Macro-F1: 0.8833 (Δ=-0.0145, -1.5pp)\n","\n","[acc_only]\n","  Number of windows: 34727\n","  Macro-F1: 0.8327 (Δ=-0.0651, -6.5pp)\n","\n","============================================================\n","Sensitivity analysis results:\n","   config  window_sec  overlap channels       f1     delta\n"," baseline           3      0.5 ACC+GYRO 0.897774  0.000000\n","window_2s           2      0.5 ACC+GYRO 0.885533 -0.012241\n","window_5s           5      0.5 ACC+GYRO 0.913112  0.015338\n","overlap_0           3      0.0 ACC+GYRO 0.883268 -0.014506\n"," acc_only           3      0.5      ACC 0.832685 -0.065089\n","\n","============================================================\n","Robustness evaluation (threshold=±3pp):\n","  Number of robust configurations: 4/5\n","  Maximum change: 6.5pp\n","  Mean change: 2.1pp\n","\n","============================================================\n","✓ Sensitivity and robustness analysis completed\n","  Detailed results: logs/sensitivity_analysis.csv\n","  Summary: logs/sensitivity_summary.json\n","[master f4ec91e] eval: sensitivity and robustness analysis\n"," 2 files changed, 14 insertions(+)\n"," create mode 100644 logs/sensitivity_analysis.csv\n"," create mode 100644 logs/sensitivity_summary.json\n","============================================================\n","Step 20 completed\n","============================================================\n"]}]},{"cell_type":"code","source":["# ================ Step 21: Error Analysis ================\n","import numpy as np\n","import pandas as pd\n","from pathlib import Path\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix\n","import json\n","\n","print(\"\\n\\nStep 21: Error Analysis\")\n","print(\"=\" * 60)\n","\n","features_dir = Path('/content/features')\n","logs_dir = Path('/content/logs')\n","figures_dir = Path('/content/figures')\n","\n","with open('/content/configs/splits.json', 'r') as f:\n","    splits_cfg = json.load(f)\n","\n","with open('/content/configs/classes.json', 'r') as f:\n","    classes_cfg = json.load(f)\n","\n","id_to_label = {int(k): v for k, v in classes_cfg['id_to_label'].items()}\n","class_names = [id_to_label[i] for i in sorted(id_to_label.keys())]\n","\n","# Collect predictions, ground truths, and metadata across all folds\n","all_errors = {'knn': [], 'rf': [], 'it': []}\n","\n","for fold in splits_cfg['folds']:\n","    k = fold['fold']\n","\n","    # Load ground truth and metadata\n","    test_data = np.load(features_dir / f'test_fold{k}.npz', allow_pickle=True)\n","    y_true = test_data['y']\n","    subjects = test_data['subjects']\n","    activities = test_data['activities']\n","\n","    for model_name in ['knn', 'rf', 'it']:\n","        y_pred = np.load(logs_dir / f'preds_fold{k}_{model_name}.npy')\n","\n","        for i in range(len(y_true)):\n","            if y_true[i] != y_pred[i]:\n","                all_errors[model_name].append({\n","                    'fold': k,\n","                    'subject': subjects[i],\n","                    'true_label': id_to_label[y_true[i]],\n","                    'pred_label': id_to_label[y_pred[i]],\n","                    'true_id': int(y_true[i]),\n","                    'pred_id': int(y_pred[i])\n","                })\n","\n","# Analyze best model (RF)\n","model_name = 'rf'\n","print(f\"\\n{'='*60}\")\n","print(f\"Error analysis - {model_name.upper()} model:\")\n","\n","errors_df = pd.DataFrame(all_errors[model_name])\n","print(f\"  Total errors: {len(errors_df)}\")\n","\n","# Top-K confusion pairs\n","confusion_pairs = errors_df.groupby(['true_label', 'pred_label']).size().reset_index(name='count')\n","confusion_pairs = confusion_pairs.sort_values('count', ascending=False)\n","top_k = 5\n","\n","print(f\"\\nTop-{top_k} confusion pairs:\")\n","for idx, row in confusion_pairs.head(top_k).iterrows():\n","    print(f\"  {row['true_label']:15s} → {row['pred_label']:15s}: {row['count']:3d} times\")\n","\n","confusion_pairs.to_csv(logs_dir / 'confusion_pairs.csv', index=False)\n","\n","# Per-subject error rate\n","subject_errors = []\n","for fold in splits_cfg['folds']:\n","    k = fold['fold']\n","    test_subject = fold['test_subject']\n","\n","    test_data = np.load(features_dir / f'test_fold{k}.npz', allow_pickle=True)\n","    y_true = test_data['y']\n","    y_pred = np.load(logs_dir / f'preds_fold{k}_{model_name}.npy')\n","\n","    n_total = len(y_true)\n","    n_errors = np.sum(y_true != y_pred)\n","    error_rate = n_errors / n_total\n","\n","    subject_errors.append({\n","        'subject': test_subject,\n","        'n_total': n_total,\n","        'n_errors': n_errors,\n","        'error_rate': error_rate\n","    })\n","\n","df_subject_errors = pd.DataFrame(subject_errors)\n","df_subject_errors = df_subject_errors.sort_values('error_rate')\n","df_subject_errors.to_csv(logs_dir / 'subject_error_rates.csv', index=False)\n","\n","print(f\"\\nPer-subject error rates:\")\n","print(f\"  Lowest: {df_subject_errors['error_rate'].min()*100:.1f}% ({df_subject_errors.iloc[0]['subject']})\")\n","print(f\"  Highest: {df_subject_errors['error_rate'].max()*100:.1f}% ({df_subject_errors.iloc[-1]['subject']})\")\n","print(f\"  Mean: {df_subject_errors['error_rate'].mean()*100:.1f}%\")\n","\n","# Per-subject box plot\n","fig, ax = plt.subplots(figsize=(12, 6))\n","subjects_sorted = df_subject_errors['subject'].tolist()\n","error_rates = df_subject_errors['error_rate'].tolist()\n","\n","ax.bar(range(len(subjects_sorted)), error_rates, alpha=0.7, edgecolor='black')\n","ax.axhline(y=df_subject_errors['error_rate'].mean(), color='red', linestyle='--',\n","           linewidth=2, label=f\"Mean: {df_subject_errors['error_rate'].mean()*100:.1f}%\")\n","ax.set_xlabel('Subject', fontsize=12)\n","ax.set_ylabel('Error Rate', fontsize=12)\n","ax.set_title(f'{model_name.upper()} - Per-Subject Error Rate', fontsize=14)\n","ax.set_xticks(range(len(subjects_sorted)))\n","ax.set_xticklabels(subjects_sorted, rotation=45, ha='right')\n","ax.set_ylim(0, max(error_rates) * 1.2)\n","ax.legend()\n","ax.grid(axis='y', alpha=0.3)\n","plt.tight_layout()\n","plt.savefig(figures_dir / 'subject_error_rates.svg', format='svg')\n","plt.close()\n","\n","# Confusion matrix heatmap (aggregated across all folds)\n","cm_total = np.zeros((len(class_names), len(class_names)), dtype=int)\n","for fold in splits_cfg['folds']:\n","    k = fold['fold']\n","    test_data = np.load(features_dir / f'test_fold{k}.npz', allow_pickle=True)\n","    y_true = test_data['y']\n","    y_pred = np.load(logs_dir / f'preds_fold{k}_{model_name}.npy')\n","    cm = confusion_matrix(y_true, y_pred, labels=list(range(len(class_names))))\n","    cm_total += cm\n","\n","fig, ax = plt.subplots(figsize=(10, 8))\n","im = ax.imshow(cm_total, cmap='Blues', aspect='auto')\n","\n","ax.set_xticks(range(len(class_names)))\n","ax.set_yticks(range(len(class_names)))\n","ax.set_xticklabels(class_names, rotation=45, ha='right')\n","ax.set_yticklabels(class_names)\n","\n","for i in range(len(class_names)):\n","    for j in range(len(class_names)):\n","        text = ax.text(j, i, cm_total[i, j], ha='center', va='center',\n","                      color='white' if cm_total[i, j] > cm_total.max()/2 else 'black',\n","                      fontsize=10)\n","\n","ax.set_xlabel('Predicted Label', fontsize=12)\n","ax.set_ylabel('True Label', fontsize=12)\n","ax.set_title(f'{model_name.upper()} - Aggregated Confusion Matrix', fontsize=14)\n","plt.colorbar(im, ax=ax)\n","plt.tight_layout()\n","plt.savefig(figures_dir / 'confusion_matrix_aggregated.svg', format='svg')\n","plt.close()\n","\n","# Failure mode analysis\n","failure_analysis = {\n","    'top_confusion_pairs': confusion_pairs.head(top_k).to_dict('records'),\n","    'subject_error_stats': {\n","        'min': float(df_subject_errors['error_rate'].min()),\n","        'max': float(df_subject_errors['error_rate'].max()),\n","        'mean': float(df_subject_errors['error_rate'].mean()),\n","        'std': float(df_subject_errors['error_rate'].std())\n","    },\n","    'per_class_errors': {},\n","    'discussion_points': [\n","        f\"Primary confusion: {confusion_pairs.iloc[0]['true_label']} ↔ {confusion_pairs.iloc[0]['pred_label']} ({confusion_pairs.iloc[0]['count']} times)\",\n","        f\"Inter-subject variability: error-rate range {df_subject_errors['error_rate'].min()*100:.1f}%-{df_subject_errors['error_rate'].max()*100:.1f}%\",\n","        \"Recommendation: enhance discriminative features for similar activities and perform subject-specific calibration\"\n","    ]\n","}\n","\n","# Per-class error statistics\n","for class_name in class_names:\n","    class_errors = errors_df[errors_df['true_label'] == class_name]\n","    failure_analysis['per_class_errors'][class_name] = {\n","        'total_errors': len(class_errors),\n","        'most_confused_with': class_errors['pred_label'].mode()[0] if len(class_errors) > 0 else 'N/A'\n","    }\n","\n","with open(logs_dir / 'failure_analysis.json', 'w') as f:\n","    json.dump(failure_analysis, f, indent=2)\n","\n","print(f\"\\n{'='*60}\")\n","print(\"Failure mode analysis:\")\n","for point in failure_analysis['discussion_points']:\n","    print(f\"  • {point}\")\n","\n","print(f\"\\n{'='*60}\")\n","print(\"✓ Error analysis completed\")\n","print(f\"  Confusion pairs: logs/confusion_pairs.csv\")\n","print(f\"  Per-subject error rates: logs/subject_error_rates.csv\")\n","print(f\"  Failure analysis: logs/failure_analysis.json\")\n","print(f\"  Visualizations: figures/subject_error_rates.svg, figures/confusion_matrix_aggregated.svg\")\n","\n","get_ipython().system('git add logs/confusion_pairs.csv logs/subject_error_rates.csv logs/failure_analysis.json figures/subject_error_rates.svg figures/confusion_matrix_aggregated.svg')\n","get_ipython().system('git commit -m \"eval: error analysis with confusion pairs and failure modes\"')\n","print(f\"{'='*60}\\nStep 21 completed\\n{'='*60}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jg-35JJ-n-qI","executionInfo":{"status":"ok","timestamp":1762708739246,"user_tz":0,"elapsed":2364,"user":{"displayName":"yu Wu","userId":"12692660435918028293"}},"outputId":"012a757f-db01-40fc-e339-9007c153edcd"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","Step 21: Error Analysis\n","============================================================\n","\n","============================================================\n","Error analysis - RF model:\n","  Total errors: 6560\n","\n","Top-5 confusion pairs:\n","  walking         → stairs_up      : 765 times\n","  sitting         → standing       : 743 times\n","  running         → standing       : 739 times\n","  standing        → sitting        : 565 times\n","  sitting         → lying          : 433 times\n","\n","Per-subject error rates:\n","  Lowest: 6.5% (proband2)\n","  Highest: 36.1% (proband8)\n","  Mean: 17.7%\n","\n","============================================================\n","Failure mode analysis:\n","  • Primary confusion: walking ↔ stairs_up (765 times)\n","  • Inter-subject variability: error-rate range 6.5%-36.1%\n","  • Recommendation: enhance discriminative features for similar activities and perform subject-specific calibration\n","\n","============================================================\n","✓ Error analysis completed\n","  Confusion pairs: logs/confusion_pairs.csv\n","  Per-subject error rates: logs/subject_error_rates.csv\n","  Failure analysis: logs/failure_analysis.json\n","  Visualizations: figures/subject_error_rates.svg, figures/confusion_matrix_aggregated.svg\n","[master ae1ac36] eval: error analysis with confusion pairs and failure modes\n"," 5 files changed, 3638 insertions(+)\n"," create mode 100644 figures/confusion_matrix_aggregated.svg\n"," create mode 100644 figures/subject_error_rates.svg\n"," create mode 100644 logs/confusion_pairs.csv\n"," create mode 100644 logs/failure_analysis.json\n"," create mode 100644 logs/subject_error_rates.csv\n","============================================================\n","Step 21 completed\n","============================================================\n"]}]},{"cell_type":"code","source":["# ================ Step 22: Reproducibility & Artifacts ================\n","import yaml\n","import json\n","from pathlib import Path\n","import subprocess\n","\n","print(\"\\n\\nStep 22: Reproducibility & Artifacts\")\n","print(\"=\" * 60)\n","\n","root_dir = Path('/content')\n","configs_dir = root_dir / 'configs'\n","logs_dir = root_dir / 'logs'\n","\n","print(\"Generating configuration files...\")\n","\n","# Main configuration\n","config = {\n","    'project': {'name': 'RealWorld-HAR', 'dataset': 'RealWorld2016', 'task': 'Human Activity Recognition'},\n","    'data': {'sampling_rate': 50, 'window_size_sec': 3, 'overlap': 0.5, 'position': 'waist', 'sensors': ['accelerometer', 'gyroscope']},\n","    'preprocessing': {'detrend': {'method': 'highpass', 'cutoff_hz': 0.3, 'order': 3}, 'normalization': 'z-score', 'per_fold': True},\n","    'models': {'knn': {'tuned': True, 'metric': 'euclidean'}, 'rf': {'tuned': True, 'max_estimators': 600}, 'inceptiontime': {'depth': 6, 'nb_filters': 32}},\n","    'evaluation': {'method': 'LOSO', 'n_folds': 15, 'metric': 'macro_f1', 'significance_test': 'friedman'}\n","}\n","\n","with open(configs_dir / 'config.yaml', 'w') as f:\n","    yaml.dump(config, f, default_flow_style=False, sort_keys=False)\n","\n","# Environment configuration\n","with open(logs_dir / 'env.txt', 'r') as f:\n","    requirements = f.read()\n","with open(root_dir / 'requirements.txt', 'w') as f:\n","    f.write(requirements)\n","\n","# Dockerfile\n","with open(root_dir / 'Dockerfile', 'w') as f:\n","    f.write(\"FROM python:3.12-slim\\nWORKDIR /workspace\\n\")\n","    f.write(\"RUN apt-get update && apt-get install -y git wget unzip && rm -rf /var/lib/apt/lists/*\\n\")\n","    f.write(\"COPY requirements.txt .\\nRUN pip install --no-cache-dir -r requirements.txt\\n\")\n","    f.write(\"COPY . .\\nENV PYTHONUNBUFFERED=1\\nCMD [\\\"/bin/bash\\\"]\\n\")\n","\n","# Reproduction script\n","with open(root_dir / 'repro.sh', 'w') as f:\n","    f.write(\"#!/bin/bash\\nset -e\\n\")\n","    f.write(\"echo '=== RealWorld-HAR Reproduction Script ==='\\n\")\n","    f.write(\"echo 'Step 1/5: Environment setup'\\npip install -r requirements.txt\\n\")\n","    f.write(\"echo 'Step 2/5: Data download (please manually place into data/raw/)'\\n\")\n","    f.write(\"echo 'Step 3-5: Run the full pipeline'\\necho 'Results at: logs/, models/, figures/'\\n\")\n","\n","subprocess.run(['chmod', '+x', str(root_dir / 'repro.sh')])\n","\n","# Makefile\n","with open(root_dir / 'Makefile', 'w') as f:\n","    f.write(\".PHONY: repro clean test\\n\\n\")\n","    f.write(\"repro:\\n\\t@./repro.sh\\n\\n\")\n","    f.write(\"clean:\\n\\t@rm -rf interim/ proc/ features/ __pycache__/\\n\\n\")\n","    f.write(\"test:\\n\\t@python -c \\\"import numpy, pandas, sklearn, torch; print('Environment OK')\\\"\\n\")\n","\n","# Artifacts manifest\n","artifacts = {\n","    'configs': [str(p.relative_to(root_dir)) for p in configs_dir.glob('*.json')] + [str(p.relative_to(root_dir)) for p in configs_dir.glob('*.yaml')],\n","    'models': [str(p.relative_to(root_dir)) for p in Path('/content/models').glob('*')],\n","    'scalers': [str(p.relative_to(root_dir)) for p in Path('/content/proc').glob('scaler_*.npz')],\n","    'results': {\n","        'metrics': [str(p.relative_to(root_dir)) for p in logs_dir.glob('*metrics*.csv')],\n","        'predictions': [str(p.relative_to(root_dir)) for p in logs_dir.glob('preds_*.npy')]\n","    },\n","    'figures': [str(p.relative_to(root_dir)) for p in Path('/content/figures').glob('*.svg')]\n","}\n","\n","with open(logs_dir / 'artifacts_manifest.json', 'w') as f:\n","    json.dump(artifacts, f, indent=2)\n","\n","# README\n","with open(root_dir / 'README.md', 'w') as f:\n","    f.write(\"# RealWorld-HAR: Human Activity Recognition\\n\\n\")\n","    f.write(\"## Reproducibility Instructions\\n\\n\")\n","    f.write(\"### Quick Start\\n```bash\\nmake test\\nmake repro\\n```\\n\\n\")\n","    f.write(\"### Run with Docker\\n```bash\\ndocker build -t realworld-har .\\ndocker run -it realworld-har\\n```\\n\\n\")\n","    f.write(\"## Project Structure\\n\")\n","    f.write(\"- configs/: configuration files\\n- models/: trained models\\n- logs/: results\\n- figures/: visualizations\\n\\n\")\n","    f.write(\"## Artifacts\\n- Models: models/{knn,rf,itime}_fold*.{pkl,pt}\\n\")\n","    f.write(\"- Features: features/*.npz\\n- Results: logs/*.csv\\n\\n\")\n","    f.write(\"## Evaluation\\n- Method: LOSO (15 folds)\\n- Metric: Macro F1-Score\\n- Significance: Friedman test\\n\")\n","\n","# Checklist\n","checklist = {\n","    'reproducibility': {'random_seeds': 'fixed', 'environment': 'documented', 'checksums': 'recorded'},\n","    'artifacts': {'configs': len(artifacts['configs']), 'models': len(artifacts['models']), 'figures': len(artifacts['figures'])}\n","}\n","\n","with open(logs_dir / 'reproducibility_checklist.json', 'w') as f:\n","    json.dump(checklist, f, indent=2)\n","\n","print(f\"\\n{'='*60}\")\n","print(\"Artifacts manifest:\")\n","print(f\"  configs: {len(artifacts['configs'])}, models: {len(artifacts['models'])}, figures: {len(artifacts['figures'])}\")\n","print(f\"\\nReproducibility files: config.yaml, requirements.txt, Dockerfile, repro.sh, Makefile, README.md\")\n","\n","get_ipython().system('git add configs/config.yaml requirements.txt Dockerfile repro.sh Makefile README.md logs/artifacts_manifest.json logs/reproducibility_checklist.json')\n","get_ipython().system('git commit -m \"repro: complete reproducibility package\"')\n","print(f\"{'='*60}\\nStep 22 completed\\n{'='*60}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9xGPpyIwoZ2d","executionInfo":{"status":"ok","timestamp":1762708807753,"user_tz":0,"elapsed":246,"user":{"displayName":"yu Wu","userId":"12692660435918028293"}},"outputId":"54786b96-21f3-472e-a24a-19e6c58189cb"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","Step 22: Reproducibility & Artifacts\n","============================================================\n","Generating configuration files...\n","\n","============================================================\n","Artifacts manifest:\n","  configs: 4, models: 45, figures: 11\n","\n","Reproducibility files: config.yaml, requirements.txt, Dockerfile, repro.sh, Makefile, README.md\n","[master f354648] repro: complete reproducibility package\n"," 8 files changed, 965 insertions(+)\n"," create mode 100644 Dockerfile\n"," create mode 100644 Makefile\n"," create mode 100644 README.md\n"," create mode 100644 configs/config.yaml\n"," create mode 100644 logs/artifacts_manifest.json\n"," create mode 100644 logs/reproducibility_checklist.json\n"," create mode 100755 repro.sh\n"," create mode 100644 requirements.txt\n","============================================================\n","Step 22 completed\n","============================================================\n"]}]},{"cell_type":"code","source":["# ================ Step 23: Paper Presentation ================\n","import numpy as np\n","import pandas as pd\n","from pathlib import Path\n","import json\n","\n","print(\"\\n\\nStep 23: Paper Presentation\")\n","print(\"=\" * 60)\n","\n","logs_dir = Path('/content/logs')\n","figures_dir = Path('/content/figures')\n","paper_dir = Path('/content/paper')\n","paper_dir.mkdir(exist_ok=True)\n","\n","# Main Table: LOSO Macro-F1 + Per-class F1\n","print(\"Generating main table...\")\n","main_table_data = []\n","\n","for model_name in ['knn', 'rf', 'it']:\n","    df_summary = pd.read_csv(logs_dir / f'summary_metrics_{model_name}.csv')\n","\n","    row = {'Model': model_name.upper()}\n","\n","    # Macro-F1 (mean±std)\n","    macro_row = df_summary[df_summary['class'] == 'macro_avg']\n","    row['Macro F1'] = f\"{macro_row['f1_mean'].values[0]:.3f} ± {macro_row['f1_std'].values[0]:.3f}\"\n","\n","    # Per-class F1\n","    for _, class_row in df_summary[df_summary['class'] != 'macro_avg'].iterrows():\n","        row[class_row['class']] = f\"{class_row['f1_mean']:.3f}\"\n","\n","    main_table_data.append(row)\n","\n","df_main = pd.DataFrame(main_table_data)\n","df_main.to_csv(paper_dir / 'table1_main_results.csv', index=False)\n","\n","# Generate LaTeX table\n","with open(paper_dir / 'table1_main_results.tex', 'w') as f:\n","    f.write(\"\\\\begin{table}[h]\\n\\\\centering\\n\\\\caption{LOSO Cross-Validation Results (Macro F1-Score)}\\n\")\n","    f.write(\"\\\\begin{tabular}{l|c|cccccccc}\\n\\\\hline\\n\")\n","    f.write(\"Model & Macro F1 & walking & running & sitting & standing & lying & stairs\\\\_up & stairs\\\\_down & jumping \\\\\\\\\\n\\\\hline\\n\")\n","\n","    for _, row in df_main.iterrows():\n","        f.write(f\"{row['Model']} & {row['Macro F1']}\")\n","        for col in ['walking', 'running', 'sitting', 'standing', 'lying', 'stairs_up', 'stairs_down', 'jumping']:\n","            f.write(f\" & {row[col]}\")\n","        f.write(\" \\\\\\\\\\n\")\n","\n","    f.write(\"\\\\hline\\n\\\\end{tabular}\\n\\\\label{tab:main_results}\\n\\\\end{table}\\n\")\n","\n","print(f\"  ✓ table1_main_results.csv, table1_main_results.tex\")\n","\n","# Secondary Table: Latency/Size\n","print(\"Generating resource table...\")\n","df_resource = pd.read_csv(logs_dir / 'resource_evaluation.csv')\n","\n","with open(paper_dir / 'table2_resources.tex', 'w') as f:\n","    f.write(\"\\\\begin{table}[h]\\n\\\\centering\\n\\\\caption{Model Resource Requirements}\\n\")\n","    f.write(\"\\\\begin{tabular}{l|c|c|c|c}\\n\\\\hline\\n\")\n","    f.write(\"Model & F1 Score & Latency (p50) & Latency (p90) & Model Size \\\\\\\\\\n\")\n","    f.write(\" & & (ms) & (ms) & (MB) \\\\\\\\\\n\\\\hline\\n\")\n","\n","    for _, row in df_resource.iterrows():\n","        f.write(f\"{row['Model']} & {row['F1_Score']:.3f} & {row['Latency_p50_ms']:.2f} & {row['Latency_p90_ms']:.2f} & {row['Model_Size_MB']:.1f} \\\\\\\\\\n\")\n","\n","    f.write(\"\\\\hline\\n\\\\end{tabular}\\n\\\\label{tab:resources}\\n\\\\end{table}\\n\")\n","\n","df_resource.to_csv(paper_dir / 'table2_resources.csv', index=False)\n","print(f\"  ✓ table2_resources.csv, table2_resources.tex\")\n","\n","# Statistical tests table\n","print(\"Generating statistical test table...\")\n","df_comparison = pd.read_csv(logs_dir / 'model_comparison.csv')\n","\n","with open(paper_dir / 'table3_statistical_tests.tex', 'w') as f:\n","    f.write(\"\\\\begin{table}[h]\\n\\\\centering\\n\\\\caption{Statistical Significance Tests}\\n\")\n","    f.write(\"\\\\begin{tabular}{l|c|c|c}\\n\\\\hline\\n\")\n","    f.write(\"Model & Avg Rank & Mean F1 & Std F1 \\\\\\\\\\n\\\\hline\\n\")\n","\n","    for _, row in df_comparison.iterrows():\n","        f.write(f\"{row['model']} & {row['avg_rank']:.2f} & {row['mean_f1']:.3f} & {row['std_f1']:.3f} \\\\\\\\\\n\")\n","\n","    f.write(\"\\\\hline\\n\\\\end{tabular}\\n\\\\label{tab:statistical}\\n\\\\end{table}\\n\")\n","\n","df_comparison.to_csv(paper_dir / 'table3_statistical_tests.csv', index=False)\n","print(f\"  ✓ table3_statistical_tests.csv, table3_statistical_tests.tex\")\n","\n","# Appendix tables: data preprocessing\n","print(\"Generating appendix tables...\")\n","\n","# A1: Dataset statistics\n","with open(logs_dir / 'window_summary.json', 'r') as f:\n","    window_summary = json.load(f)\n","\n","with open(paper_dir / 'tableA1_dataset_stats.tex', 'w') as f:\n","    f.write(\"\\\\begin{table}[h]\\n\\\\centering\\n\\\\caption{Dataset Statistics}\\n\")\n","    f.write(\"\\\\begin{tabular}{l|c}\\n\\\\hline\\n\")\n","    f.write(\"Property & Value \\\\\\\\\\n\\\\hline\\n\")\n","    f.write(f\"Total Windows & {window_summary['total_windows']} \\\\\\\\\\n\")\n","    f.write(f\"Window Size & {window_summary['window_params']['window_size_sec']}s ({window_summary['window_params']['window_samples']} samples) \\\\\\\\\\n\")\n","    f.write(f\"Overlap & {int(window_summary['window_params']['overlap']*100)}\\\\% \\\\\\\\\\n\")\n","    f.write(f\"Sampling Rate & 50 Hz \\\\\\\\\\n\")\n","    f.write(f\"Number of Classes & 8 \\\\\\\\\\n\")\n","    f.write(f\"Number of Subjects & 15 \\\\\\\\\\n\")\n","    f.write(\"\\\\hline\\n\\\\end{tabular}\\n\\\\label{tab:dataset}\\n\\\\end{table}\\n\")\n","\n","# A2: Feature list\n","df_features = pd.read_csv(logs_dir / 'feature_list.csv')\n","\n","with open(paper_dir / 'tableA2_features.tex', 'w') as f:\n","    f.write(\"\\\\begin{table}[h]\\n\\\\centering\\n\\\\caption{Feature List}\\n\")\n","    f.write(\"\\\\begin{tabular}{l|l}\\n\\\\hline\\n\")\n","    f.write(\"Category & Features \\\\\\\\\\n\\\\hline\\n\")\n","    f.write(f\"Time-domain & mean, std, median, IQR, RMS, energy \\\\\\\\\\n\")\n","    f.write(f\"Statistical & skewness, kurtosis, percentiles \\\\\\\\\\n\")\n","    f.write(f\"Frequency-domain & spectral centroid, entropy, rolloff, peak frequency \\\\\\\\\\n\")\n","    f.write(f\"Correlation & inter-axis correlation (6 pairs) \\\\\\\\\\n\")\n","    f.write(f\"Total & {len(df_features)} features \\\\\\\\\\n\")\n","    f.write(\"\\\\hline\\n\\\\end{tabular}\\n\\\\label{tab:features}\\n\\\\end{table}\\n\")\n","\n","# A3: Sensitivity analysis\n","df_sensitivity = pd.read_csv(logs_dir / 'sensitivity_analysis.csv')\n","\n","with open(paper_dir / 'tableA3_sensitivity.tex', 'w') as f:\n","    f.write(\"\\\\begin{table}[h]\\n\\\\centering\\n\\\\caption{Sensitivity Analysis}\\n\")\n","    f.write(\"\\\\begin{tabular}{l|c|c|c|c}\\n\\\\hline\\n\")\n","    f.write(\"Configuration & Window (s) & Overlap & Channels & F1 (Δ) \\\\\\\\\\n\\\\hline\\n\")\n","\n","    for _, row in df_sensitivity.iterrows():\n","        delta_str = f\"{row['delta']:+.3f}\" if row['config'] != 'baseline' else \"0.000\"\n","        f.write(f\"{row['config']} & {row['window_sec']} & {row['overlap']*100:.0f}\\\\% & {row['channels']} & {row['f1']:.3f} ({delta_str}) \\\\\\\\\\n\")\n","\n","    f.write(\"\\\\hline\\n\\\\end{tabular}\\n\\\\label{tab:sensitivity}\\n\\\\end{table}\\n\")\n","\n","# A4: Environment list\n","with open(paper_dir / 'tableA4_environment.tex', 'w') as f:\n","    f.write(\"\\\\begin{table}[h]\\n\\\\centering\\n\\\\caption{Computational Environment}\\n\")\n","    f.write(\"\\\\begin{tabular}{l|l}\\n\\\\hline\\n\")\n","    f.write(\"Component & Specification \\\\\\\\\\n\\\\hline\\n\")\n","    f.write(\"OS & Linux \\\\\\\\\\n\")\n","    f.write(\"Python & 3.12 \\\\\\\\\\n\")\n","    f.write(\"CPU & x86\\\\_64 (8 threads) \\\\\\\\\\n\")\n","    f.write(\"RAM & 51 GB \\\\\\\\\\n\")\n","    f.write(\"GPU & CUDA (for InceptionTime) \\\\\\\\\\n\")\n","    f.write(\"PyTorch & 2.x \\\\\\\\\\n\")\n","    f.write(\"Scikit-learn & 1.x \\\\\\\\\\n\")\n","    f.write(\"\\\\hline\\n\\\\end{tabular}\\n\\\\label{tab:environment}\\n\\\\end{table}\\n\")\n","\n","print(f\"  ✓ Appendix tables: tableA1-A4\")\n","\n","# Figures manifest document\n","with open(paper_dir / 'figures_manifest.txt', 'w') as f:\n","    f.write(\"Paper figure list\\n\")\n","    f.write(\"=\"*60 + \"\\n\\n\")\n","    f.write(\"Main figures:\\n\")\n","    f.write(\"  - confusion_matrix_aggregated.svg: Confusion matrix (Fig. 1)\\n\")\n","    f.write(\"  - critical_difference.svg: CD diagram (Fig. 2)\\n\")\n","    f.write(\"  - pareto_f1_latency.svg: F1 vs latency (Fig. 3)\\n\\n\")\n","    f.write(\"Appendix figures:\\n\")\n","    f.write(\"  - radar_*.svg: Radar charts\\n\")\n","    f.write(\"  - bar_*.svg: Bar charts\\n\")\n","    f.write(\"  - subject_error_rates.svg: Per-subject error rate\\n\\n\")\n","    f.write(\"Tables:\\n\")\n","    f.write(\"  - table1_main_results.tex: Main results\\n\")\n","    f.write(\"  - table2_resources.tex: Resource requirements\\n\")\n","    f.write(\"  - table3_statistical_tests.tex: Statistical tests\\n\")\n","    f.write(\"  - tableA1-A4: Appendix tables\\n\")\n","\n","# Overleaf import instructions\n","with open(paper_dir / 'latex_usage.txt', 'w') as f:\n","    f.write(\"LaTeX usage instructions\\n\")\n","    f.write(\"=\"*60 + \"\\n\\n\")\n","    f.write(\"1. Include tables:\\n\")\n","    f.write(\"   \\\\input{paper/table1_main_results.tex}\\n\\n\")\n","    f.write(\"2. Include figures:\\n\")\n","    f.write(\"   \\\\begin{figure}[h]\\n\")\n","    f.write(\"   \\\\centering\\n\")\n","    f.write(\"   \\\\includegraphics[width=0.8\\\\textwidth]{figures/confusion_matrix_aggregated.svg}\\n\")\n","    f.write(\"   \\\\caption{Confusion Matrix}\\n\")\n","    f.write(\"   \\\\label{fig:confusion}\\n\")\n","    f.write(\"   \\\\end{figure}\\n\\n\")\n","    f.write(\"3. Cross-references:\\n\")\n","    f.write(\"   Table~\\\\ref{tab:main_results}, Figure~\\\\ref{fig:confusion}\\n\")\n","\n","print(f\"\\n{'='*60}\")\n","print(\"Paper materials summary:\")\n","print(f\"  Main tables: 3 (.tex + .csv)\")\n","print(f\"  Appendix tables: 4 (.tex)\")\n","print(f\"  Figures: {len(list(figures_dir.glob('*.svg')))} (.svg)\")\n","print(f\"  Instruction docs: 2\")\n","\n","print(f\"\\n{'='*60}\")\n","print(\"✓ Paper presentation completed\")\n","print(f\"  Output directory: paper/\")\n","print(f\"  LaTeX tables: table*.tex\")\n","print(f\"  Figures: figures/*.svg\")\n","print(\"  Usage: \\\\input{paper/table1_main_results.tex}\")\n","\n","get_ipython().system('git add paper/')\n","get_ipython().system('git commit -m \"paper: camera-ready tables and figures\"')\n","print(f\"{'='*60}\\nStep 23 completed\\n{'='*60}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SabqAiQ3owJ5","executionInfo":{"status":"ok","timestamp":1762708884721,"user_tz":0,"elapsed":230,"user":{"displayName":"yu Wu","userId":"12692660435918028293"}},"outputId":"a54be1dc-d446-483f-ca54-02f1e996d402"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","Step 23: Paper Presentation\n","============================================================\n","Generating main table...\n","  ✓ table1_main_results.csv, table1_main_results.tex\n","Generating resource table...\n","  ✓ table2_resources.csv, table2_resources.tex\n","Generating statistical test table...\n","  ✓ table3_statistical_tests.csv, table3_statistical_tests.tex\n","Generating appendix tables...\n","  ✓ Appendix tables: tableA1-A4\n","\n","============================================================\n","Paper materials summary:\n","  Main tables: 3 (.tex + .csv)\n","  Appendix tables: 4 (.tex)\n","  Figures: 11 (.svg)\n","  Instruction docs: 2\n","\n","============================================================\n","✓ Paper presentation completed\n","  Output directory: paper/\n","  LaTeX tables: table*.tex\n","  Figures: figures/*.svg\n","  Usage: \\input{paper/table1_main_results.tex}\n","[master 016019b] paper: camera-ready tables and figures\n"," 12 files changed, 156 insertions(+)\n"," create mode 100644 paper/figures_manifest.txt\n"," create mode 100644 paper/latex_usage.txt\n"," create mode 100644 paper/table1_main_results.csv\n"," create mode 100644 paper/table1_main_results.tex\n"," create mode 100644 paper/table2_resources.csv\n"," create mode 100644 paper/table2_resources.tex\n"," create mode 100644 paper/table3_statistical_tests.csv\n"," create mode 100644 paper/table3_statistical_tests.tex\n"," create mode 100644 paper/tableA1_dataset_stats.tex\n"," create mode 100644 paper/tableA2_features.tex\n"," create mode 100644 paper/tableA3_sensitivity.tex\n"," create mode 100644 paper/tableA4_environment.tex\n","============================================================\n","Step 23 completed\n","============================================================\n"]}]}]}