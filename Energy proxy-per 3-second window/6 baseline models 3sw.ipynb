{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","authorship_tag":"ABX9TyP9bPvjNcgQTTMiFERNt+tk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["# ================================================================\n","# Step 19: GPU Energy Consumption (NVML Integration Method)\n","# mJ per 3-second window (treat each inference sample as one window)\n","# ================================================================\n","!nvidia-smi\n","!pip -q install pynvml\n","\n","import os, json, math, time, multiprocessing as mp, pathlib, sys, subprocess\n","import numpy as np\n","import pandas as pd\n","\n","# ---------------- GPU synchronization (CuPy -> PyTorch) ----------------\n","def gpu_sync():\n","    try:\n","        import cupy as cp\n","        cp.cuda.runtime.deviceSynchronize()\n","    except Exception:\n","        pass\n","    try:\n","        import torch\n","        if torch.cuda.is_available():\n","            torch.cuda.synchronize()\n","    except Exception:\n","        pass\n","\n","# ---------------- NVML sampling subprocess ----------------\n","import pynvml\n","\n","def nvml_sampler(stop_event, q, dev_index=0, interval=0.02):\n","    \"\"\"Sample NVML power (mW) every `interval` and push (t_abs, mW).\"\"\"\n","    import pynvml, time\n","    pynvml.nvmlInit()\n","    h = pynvml.nvmlDeviceGetHandleByIndex(dev_index)\n","    try:\n","        while not stop_event.is_set():\n","            t = time.perf_counter()\n","            p_mw = pynvml.nvmlDeviceGetPowerUsage(h)\n","            q.put((t, p_mw))\n","            time.sleep(interval)\n","    finally:\n","        pynvml.nvmlShutdown()\n","\n","def integrate_energy_mJ_between(samples, t0, t1):\n","    \"\"\"Trapezoidal integrate power (mW) over [t0, t1] -> mJ.\"\"\"\n","    if not samples: return 0.0\n","    samples = sorted(samples, key=lambda x: x[0])\n","    ts = np.array([t for t,_ in samples], dtype=np.float64)\n","    ps = np.array([p for _,p in samples], dtype=np.float64)\n","    m = (ts >= t0) & (ts <= t1)\n","    ts_w = ts[m]; ps_w = ps[m]\n","    if ts_w.size == 0 or ts_w[0] > t0:\n","        p0 = np.interp(t0, ts, ps)\n","        ts_w = np.insert(ts_w, 0, t0); ps_w = np.insert(ps_w, 0, p0)\n","    if ts_w[-1] < t1:\n","        p1 = np.interp(t1, ts, ps)\n","        ts_w = np.append(ts_w, t1); ps_w = np.append(ps_w, p1)\n","    return float(np.trapz(ps_w, ts_w))  # mW*s = mJ\n","\n","def sample_idle_power_mW(duration_s=20.0, dev_index=0, interval=0.02, save_csv=None):\n","    \"\"\"Return mean idle power (mW) and power trace.\"\"\"\n","    q = mp.Queue(); stop = mp.Event()\n","    proc = mp.Process(target=nvml_sampler, args=(stop, q, dev_index, interval))\n","    proc.start()\n","    time.sleep(duration_s)\n","    stop.set(); proc.join()\n","    samples = []\n","    while not q.empty(): samples.append(q.get())\n","    if not samples: raise RuntimeError(\"NVML did not return idle samples.\")\n","    samples = sorted(samples, key=lambda x: x[0])\n","    t0, t1 = samples[0][0], samples[-1][0]\n","    E_idle_mJ = integrate_energy_mJ_between(samples, t0, t1)\n","    T_idle_s  = max(1e-9, t1 - t0)\n","    P_idle_mW = E_idle_mJ / T_idle_s\n","    if save_csv:\n","        pd.DataFrame(samples, columns=[\"t_abs_s\",\"power_mW\"]).to_csv(save_csv, index=False)\n","    return P_idle_mW, samples\n","\n","def calibrate_repeats(run_once, target_s=8.0, min_rep=3, max_rep=2000):\n","    \"\"\"Estimate repeats so a single measurement lasts ~target_s.\"\"\"\n","    gpu_sync()\n","    t0 = time.perf_counter(); run_once(); gpu_sync(); t1 = time.perf_counter()\n","    dt = max(1e-4, t1 - t0)\n","    reps = int(math.ceil(target_s / dt))\n","    return int(np.clip(reps, min_rep, max_rep))\n","\n","def measure_mJ_per_window_core(run_once, n_windows_per_call, repeats, P_idle_mW,\n","                               dev_index=0, interval=0.02, save_csv=None):\n","    \"\"\"\n","    Concurrent NVML sampling while `run_once()` is executed `repeats` times.\n","    Normalize energy by total windows -> mJ per window; also report ms per window.\n","    \"\"\"\n","    q = mp.Queue(); stop = mp.Event()\n","    proc = mp.Process(target=nvml_sampler, args=(stop, q, dev_index, interval))\n","    proc.start()\n","\n","    gpu_sync()\n","    t0 = time.perf_counter()\n","    for _ in range(repeats):\n","        run_once()\n","    gpu_sync()\n","    t1 = time.perf_counter()\n","\n","    stop.set(); proc.join()\n","    samples = []\n","    while not q.empty(): samples.append(q.get())\n","    if not samples: raise RuntimeError(\"NVML did not return active samples.\")\n","\n","    E_total_mJ = integrate_energy_mJ_between(samples, t0, t1)\n","    T_total_s  = max(1e-9, t1 - t0)\n","    E_idle_mJ  = P_idle_mW * T_total_s\n","    n_windows  = max(1, repeats * n_windows_per_call)\n","\n","    if save_csv:\n","        pd.DataFrame(samples, columns=[\"t_abs_s\",\"power_mW\"]).to_csv(save_csv, index=False)\n","\n","    return {\n","        \"mJ_per_window\": max(0.0, (E_total_mJ - E_idle_mJ) / n_windows),\n","        \"ms_per_window\": (T_total_s / n_windows) * 1e3,\n","        \"throughput_windows_per_s\": n_windows / T_total_s,\n","        \"n_windows\": n_windows,\n","        \"repeats\": repeats,\n","        \"T_total_s\": T_total_s,\n","        \"E_total_mJ\": E_total_mJ,\n","        \"E_idle_mJ\": E_idle_mJ,\n","        \"P_idle_mW\": P_idle_mW,\n","        \"t0_abs\": t0, \"t1_abs\": t1,\n","    }\n","\n","def measure_per_window_with_bootstrap(name, run_once, n_windows_per_call, repeats, n_runs=5, n_boot=1000):\n","    \"\"\"Repeat and bootstrap the per-window mean with 95% CI.\"\"\"\n","    results = []\n","    for i in range(n_runs):\n","        print(f\"[Measure] {name} - run {i+1}/{n_runs} ...\")\n","        res = measure_mJ_per_window_core(\n","            run_once, n_windows_per_call, repeats,\n","            P_idle_mW=P_idle_mW, dev_index=0, interval=0.02,\n","            save_csv=f\"logs/power_trace_{name}_run{i+1}.csv\"\n","        )\n","        results.append(res)\n","\n","    mJs = np.array([r[\"mJ_per_window\"] for r in results], dtype=np.float64)\n","    mss = np.array([r[\"ms_per_window\"] for r in results], dtype=np.float64)\n","\n","    rng = np.random.default_rng(123)\n","    boots = [float(np.mean(mJs[rng.integers(0, len(mJs), size=len(mJs))])) for _ in range(n_boot)]\n","    ci_low, ci_high = np.percentile(boots, [2.5, 97.5])\n","\n","    summary = {\n","        \"model\": name,\n","        \"mean_mJ_per_window\": float(np.mean(mJs)),\n","        \"ci95_low_mJ\": float(ci_low),\n","        \"ci95_high_mJ\": float(ci_high),\n","        \"mean_ms_per_window\": float(np.mean(mss)),\n","        \"runs\": results,\n","    }\n","    with open(f\"logs/energy_{name}.json\", \"w\") as f:\n","        json.dump(summary, f, indent=2)\n","    print(f\"[Result] {name}: {summary['mean_mJ_per_window']:.3f} mJ per window \"\n","          f\"(95% CI [{summary['ci95_low_mJ']:.3f}, {summary['ci95_high_mJ']:.3f}]); \"\n","          f\"{summary['mean_ms_per_window']:.3f} ms per window\")\n","    return summary\n","\n","# ---------------- Build synthetic data + cuML models (unchanged model hyperparams) ----------------\n","print(\"\\n[Info] Preparing data and models (cuML KNN / RandomForest on GPU)\")\n","import cupy as cp\n","from sklearn.datasets import make_classification\n","from sklearn.model_selection import train_test_split\n","from cuml.neighbors import KNeighborsClassifier as cuKNN\n","from cuml.ensemble import RandomForestClassifier as cuRF\n","\n","# If each sample corresponds to one 3 s window, the per-window metric equals mJ/sample.\n","WINDOW_SAMPLES = 150     # for reporting clarity only\n","FS = 50.0\n","WINDOW_SECONDS = WINDOW_SAMPLES / FS  # 3.0\n","\n","X, y = make_classification(n_samples=30000, n_features=64, n_informative=48,\n","                           n_redundant=0, n_classes=8, random_state=7)\n","X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=5000, random_state=42)\n","\n","Xtr = cp.asarray(X_tr, dtype=cp.float32); ytr = cp.asarray(y_tr.astype(np.int32))\n","Xte = cp.asarray(X_te, dtype=cp.float32); yte = cp.asarray(y_te.astype(np.int32))\n","print(f\"Train: {Xtr.shape}, Test: {Xte.shape} (treat 1 sample ≡ 1 window of ~{WINDOW_SECONDS:.1f}s)\")\n","\n","knn = cuKNN(n_neighbors=5, algorithm=\"brute\", metric=\"euclidean\")\n","knn.fit(Xtr, ytr); gpu_sync()\n","\n","rf = cuRF(n_estimators=100, max_depth=16, n_bins=128, bootstrap=True, n_streams=8)\n","rf.fit(Xtr, ytr); gpu_sync()\n","\n","def _run_knn_once():\n","    _ = knn.predict(Xte); gpu_sync()\n","\n","def _run_rf_once():\n","    _ = rf.predict(Xte); gpu_sync()\n","\n","print(\"\\n[Info] Warming up ...\")\n","for _ in range(30):\n","    _run_knn_once(); _run_rf_once()\n","gpu_sync()\n","\n","pathlib.Path(\"logs\").mkdir(exist_ok=True); pathlib.Path(\"figures\").mkdir(exist_ok=True)\n","\n","print(\"\\n[Info] Sampling idle power (20 s) ...\")\n","P_idle_mW, idle_trace = sample_idle_power_mW(duration_s=20.0, dev_index=0, interval=0.02,\n","                                             save_csv=\"logs/power_idle_trace.csv\")\n","print(f\"[Info] Mean idle power ~ {P_idle_mW:.1f} mW\")\n","\n","rep_knn = calibrate_repeats(_run_knn_once, target_s=8.0, min_rep=5, max_rep=2000)\n","rep_rf  = calibrate_repeats(_run_rf_once,  target_s=8.0, min_rep=5, max_rep=2000)\n","print(f\"[Info] KNN repeats = {rep_knn}, RF repeats = {rep_rf}\")\n","\n","print(\"\\n[Info] Measuring KNN (per-window) ...\")\n","sum_knn = measure_per_window_with_bootstrap(\n","    name=\"knn_cuml_per_window\",\n","    run_once=_run_knn_once,\n","    n_windows_per_call=int(Xte.shape[0]),\n","    repeats=rep_knn,\n","    n_runs=5, n_boot=1000\n",")\n","\n","print(\"\\n[Info] Measuring RandomForest (per-window) ...\")\n","sum_rf = measure_per_window_with_bootstrap(\n","    name=\"rf_cuml_per_window\",\n","    run_once=_run_rf_once,\n","    n_windows_per_call=int(Xte.shape[0]),\n","    repeats=rep_rf,\n","    n_runs=5, n_boot=1000\n",")\n","\n","df_sum = pd.DataFrame([\n","    {\"model\":\"KNN (cuML)\", \"mJ_per_3s_window_mean\":sum_knn[\"mean_mJ_per_window\"],\n","     \"CI95_low_mJ\":sum_knn[\"ci95_low_mJ\"], \"CI95_high_mJ\":sum_knn[\"ci95_high_mJ\"],\n","     \"ms_per_3s_window_mean\":sum_knn[\"mean_ms_per_window\"], \"window_seconds\": WINDOW_SECONDS},\n","    {\"model\":\"RandomForest (cuML)\", \"mJ_per_3s_window_mean\":sum_rf[\"mean_mJ_per_window\"],\n","     \"CI95_low_mJ\":sum_rf[\"ci95_low_mJ\"], \"CI95_high_mJ\":sum_rf[\"ci95_high_mJ\"],\n","     \"ms_per_3s_window_mean\":sum_rf[\"mean_ms_per_window\"], \"window_seconds\": WINDOW_SECONDS},\n","])\n","df_sum.to_csv(\"logs/energy_summary_per_3s_window.csv\", index=False)\n","print(\"\\n=== Energy measurement (per 3-second window) completed ===\")\n","print(df_sum)\n","print(\"\\nLog files:\")\n","print(\"- logs/power_idle_trace.csv\")\n","print(\"- logs/power_trace_knn_cuml_per_window_run*.csv\")\n","print(\"- logs/power_trace_rf_cuml_per_window_run*.csv\")\n","print(\"- logs/energy_knn_cuml_per_window.json\")\n","print(\"- logs/energy_rf_cuml_per_window.json\")\n","print(\"- logs/energy_summary_per_3s_window.csv\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cyAxrCXQbGtz","executionInfo":{"status":"ok","timestamp":1763745565293,"user_tz":0,"elapsed":71967,"user":{"displayName":"yu Wu","userId":"12692660435918028293"}},"outputId":"6970b6df-89ec-4fec-f93e-706995c8e9b6"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Fri Nov 21 17:18:13 2025       \n","+-----------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n","|-----------------------------------------+------------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                        |               MIG M. |\n","|=========================================+========================+======================|\n","|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n","| N/A   48C    P0             27W /   70W |     334MiB /  15360MiB |      0%      Default |\n","|                                         |                        |                  N/A |\n","+-----------------------------------------+------------------------+----------------------+\n","                                                                                         \n","+-----------------------------------------------------------------------------------------+\n","| Processes:                                                                              |\n","|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n","|        ID   ID                                                               Usage      |\n","|=========================================================================================|\n","+-----------------------------------------------------------------------------------------+\n","\n","[Info] Preparing data and models (cuML KNN / RandomForest on GPU)\n","Train: (25000, 64), Test: (5000, 64) (treat 1 sample ≡ 1 window of ~3.0s)\n","\n","[Info] Warming up ...\n","\n","[Info] Sampling idle power (20 s) ...\n","[Info] Mean idle power ~ 28367.3 mW\n","[Info] KNN repeats = 257, RF repeats = 2000\n","\n","[Info] Measuring KNN (per-window) ...\n","[Measure] knn_cuml_per_window - run 1/5 ...\n","[Measure] knn_cuml_per_window - run 2/5 ...\n","[Measure] knn_cuml_per_window - run 3/5 ...\n","[Measure] knn_cuml_per_window - run 4/5 ...\n","[Measure] knn_cuml_per_window - run 5/5 ...\n","[Result] knn_cuml_per_window: 0.115 mJ per window (95% CI [0.113, 0.117]); 0.003 ms per window\n","\n","[Info] Measuring RandomForest (per-window) ...\n","[Measure] rf_cuml_per_window - run 1/5 ...\n","[Measure] rf_cuml_per_window - run 2/5 ...\n","[Measure] rf_cuml_per_window - run 3/5 ...\n","[Measure] rf_cuml_per_window - run 4/5 ...\n","[Measure] rf_cuml_per_window - run 5/5 ...\n","[Result] rf_cuml_per_window: 0.010 mJ per window (95% CI [0.010, 0.011]); 0.000 ms per window\n","\n","=== Energy measurement (per 3-second window) completed ===\n","                 model  mJ_per_3s_window_mean  CI95_low_mJ  CI95_high_mJ  \\\n","0           KNN (cuML)               0.114875     0.113273      0.116750   \n","1  RandomForest (cuML)               0.010315     0.009992      0.010763   \n","\n","   ms_per_3s_window_mean  window_seconds  \n","0               0.002833             3.0  \n","1               0.000347             3.0  \n","\n","Log files:\n","- logs/power_idle_trace.csv\n","- logs/power_trace_knn_cuml_per_window_run*.csv\n","- logs/power_trace_rf_cuml_per_window_run*.csv\n","- logs/energy_knn_cuml_per_window.json\n","- logs/energy_rf_cuml_per_window.json\n","- logs/energy_summary_per_3s_window.csv\n"]}]},{"cell_type":"code","source":["!pip -q install sktime"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1sfn94Qhbe7j","executionInfo":{"status":"ok","timestamp":1763745600257,"user_tz":0,"elapsed":5658,"user":{"displayName":"yu Wu","userId":"12692660435918028293"}},"outputId":"bdcdc7e8-7603-486f-8bab-5689fe5031ea"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.6/35.6 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.5/149.5 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["# ================================================================\n","# Step 19b (FIXED): MiniROCKET / MultiROCKET + GPU Linear Head\n","# NVML-based GPU inference energy — mJ per 3-second window\n","# (CPU feature extraction is excluded from GPU energy accounting)\n","# ================================================================\n","\n","# Optional: system check and NVML dependency\n","!nvidia-smi\n","!pip -q install pynvml sktime\n","\n","import os, json, time, math, pathlib, warnings, multiprocessing as mp\n","from pathlib import Path\n","warnings.filterwarnings(\"ignore\")\n","\n","import numpy as np\n","import pandas as pd\n","\n","# ---------------- NVML utilities (per-window reporting) ----------------\n","import pynvml\n","\n","def gpu_sync():\n","    \"\"\"Synchronize CUDA work across CuPy and PyTorch if available.\"\"\"\n","    try:\n","        import cupy as cp\n","        cp.cuda.runtime.deviceSynchronize()\n","    except Exception:\n","        pass\n","    try:\n","        import torch\n","        if torch.cuda.is_available():\n","            torch.cuda.synchronize()\n","    except Exception:\n","        pass\n","\n","def _nvml_sampler(stop_event, q, dev_index=0, interval=0.02):\n","    \"\"\"Sample NVML power (mW) every `interval` seconds and push (t_abs, mW).\"\"\"\n","    import time, pynvml\n","    pynvml.nvmlInit()\n","    h = pynvml.nvmlDeviceGetHandleByIndex(dev_index)\n","    try:\n","        while not stop_event.is_set():\n","            q.put((time.perf_counter(), pynvml.nvmlDeviceGetPowerUsage(h)))\n","            time.sleep(interval)\n","    finally:\n","        pynvml.nvmlShutdown()\n","\n","def _integrate_mJ_between(samples, t0, t1):\n","    \"\"\"Trapezoidal integrate power (mW) over [t0, t1] -> mJ.\"\"\"\n","    if not samples:\n","        return 0.0\n","    samples = sorted(samples, key=lambda x: x[0])\n","    ts = np.array([t for t,_ in samples], dtype=np.float64)\n","    ps = np.array([p for _,p in samples], dtype=np.float64)\n","    m = (ts >= t0) & (ts <= t1)\n","    ts_w, ps_w = ts[m], ps[m]\n","    if ts_w.size == 0 or ts_w[0] > t0:\n","        p0 = np.interp(t0, ts, ps)\n","        ts_w = np.insert(ts_w, 0, t0)\n","        ps_w = np.insert(ps_w, 0, p0)\n","    if ts_w[-1] < t1:\n","        p1 = np.interp(t1, ts, ps)\n","        ts_w = np.append(ts_w, t1)\n","        ps_w = np.append(ps_w, p1)\n","    return float(np.trapz(ps_w, ts_w))  # mW*s = mJ\n","\n","def sample_idle_power_mW(duration_s=20.0, dev_index=0, interval=0.02, save_csv=None):\n","    \"\"\"Measure mean idle power (mW); optionally save the trace.\"\"\"\n","    q = mp.Queue(); stop = mp.Event()\n","    p = mp.Process(target=_nvml_sampler, args=(stop, q, dev_index, interval)); p.start()\n","    time.sleep(duration_s); stop.set(); p.join()\n","    samples = []\n","    while not q.empty(): samples.append(q.get())\n","    if not samples:\n","        raise RuntimeError(\"NVML did not capture idle samples.\")\n","    samples = sorted(samples, key=lambda x: x[0])\n","    t0, t1 = samples[0][0], samples[-1][0]\n","    E_idle_mJ = _integrate_mJ_between(samples, t0, t1)\n","    T_idle_s  = max(1e-9, t1 - t0)\n","    P_idle_mW = E_idle_mJ / T_idle_s\n","    if save_csv:\n","        pd.DataFrame(samples, columns=[\"t_abs_s\",\"power_mW\"]).to_csv(save_csv, index=False)\n","    return P_idle_mW, samples\n","\n","def calibrate_repeats(run_once, target_s=8.0, min_rep=3, max_rep=5000):\n","    \"\"\"Estimate repeats so a single measurement lasts ~target_s seconds.\"\"\"\n","    gpu_sync(); t0 = time.perf_counter(); run_once(); gpu_sync(); t1 = time.perf_counter()\n","    dt = max(1e-4, t1 - t0)\n","    return int(np.clip(int(math.ceil(target_s / dt)), min_rep, max_rep))\n","\n","def measure_mJ_per_window(run_once, n_windows_per_call, repeats, P_idle_mW,\n","                          dev_index=0, interval=0.02, save_csv=None):\n","    \"\"\"Concurrent NVML sampling while running `run_once()`; return per-window energy & latency.\"\"\"\n","    q = mp.Queue(); stop = mp.Event()\n","    p = mp.Process(target=_nvml_sampler, args=(stop, q, dev_index, interval)); p.start()\n","    gpu_sync(); t0 = time.perf_counter()\n","    for _ in range(repeats): run_once()\n","    gpu_sync(); t1 = time.perf_counter()\n","    stop.set(); p.join()\n","    samples = []\n","    while not q.empty(): samples.append(q.get())\n","    if not samples: raise RuntimeError(\"NVML did not capture active samples.\")\n","    E_total_mJ = _integrate_mJ_between(samples, t0, t1)\n","    T_total_s  = max(1e-9, t1 - t0)\n","    E_idle_mJ  = P_idle_mW * T_total_s\n","    n_windows  = max(1, repeats * n_windows_per_call)\n","    if save_csv:\n","        pd.DataFrame(samples, columns=[\"t_abs_s\",\"power_mW\"]).to_csv(save_csv, index=False)\n","    return {\n","        \"mJ_per_window\": max(0.0, (E_total_mJ - E_idle_mJ) / n_windows),\n","        \"ms_per_window\": (T_total_s / n_windows) * 1e3,\n","        \"throughput_windows_per_s\": n_windows / T_total_s,\n","        \"n_windows\": n_windows, \"repeats\": repeats,\n","        \"T_total_s\": T_total_s, \"E_total_mJ\": E_total_mJ, \"E_idle_mJ\": E_idle_mJ,\n","        \"P_idle_mW\": P_idle_mW, \"t0_abs\": t0, \"t1_abs\": t1\n","    }\n","\n","def measure_with_bootstrap_per_window(name, run_once, n_windows, repeats, n_runs=5, n_boot=1000):\n","    \"\"\"Repeat measurements and bootstrap the per-window mean with 95% CI.\"\"\"\n","    results = []\n","    for i in range(n_runs):\n","        print(f\"[Measure] {name} run {i+1}/{n_runs} ...\")\n","        res = measure_mJ_per_window(\n","            run_once, n_windows, repeats, P_idle_mW=P_idle_mW,\n","            dev_index=0, interval=0.02, save_csv=f\"logs/power_trace_{name}_run{i+1}.csv\"\n","        )\n","        results.append(res)\n","    mJ = np.array([r[\"mJ_per_window\"] for r in results], dtype=np.float64)\n","    ms = np.array([r[\"ms_per_window\"] for r in results], dtype=np.float64)\n","    rng = np.random.default_rng(123)\n","    boots_mJ = [float(np.mean(mJ[rng.integers(0, len(mJ), size=len(mJ))])) for _ in range(n_boot)]\n","    ci_lo, ci_hi = np.percentile(boots_mJ, [2.5, 97.5])\n","    summary = {\n","        \"model\": name,\n","        \"mean_mJ_per_window\": float(mJ.mean()),\n","        \"ci95_low_mJ\": float(ci_lo),\n","        \"ci95_high_mJ\": float(ci_hi),\n","        \"mean_ms_per_window\": float(ms.mean()),\n","        \"runs\": results\n","    }\n","    with open(f\"logs/energy_{name}.json\", \"w\") as f:\n","        json.dump(summary, f, indent=2)\n","    print(f\"[Result] {name}: {summary['mean_mJ_per_window']:.4f} mJ per window \"\n","          f\"(95% CI [{summary['ci95_low_mJ']:.4f}, {summary['ci95_high_mJ']:.4f}]); \"\n","          f\"{summary['mean_ms_per_window']:.3f} ms per window\")\n","    return summary\n","\n","# ---------------- Synthetic time-series + MiniROCKET / MultiROCKET (CPU) ----------------\n","from sklearn.linear_model import RidgeClassifier\n","from sklearn.model_selection import train_test_split\n","from sktime.transformations.panel.rocket import MiniRocketMultivariate, MultiRocketMultivariate\n","\n","def make_synth_ts(n_samples=2800, n_channels=6, length=150, n_classes=8, seed=2025):\n","    \"\"\"X: (N, C, L), y: (N,)\"\"\"\n","    rng = np.random.default_rng(seed)\n","    X = rng.normal(0, 1, size=(n_samples, n_channels, length)).astype(np.float32)\n","    y = rng.integers(0, n_classes, size=n_samples).astype(np.int32)\n","    t = np.linspace(0, 2*np.pi, length, dtype=np.float32)\n","    for c in range(n_classes):\n","        idx = (y == c)\n","        if idx.any():\n","            freq = 1.0 + 0.2 * c\n","            X[idx, 0, :] += 0.6 * np.sin(freq * t)\n","            X[idx, 1, :] += 0.4 * np.cos(0.5 * freq * t)\n","    return X, y\n","\n","X_ts, y_ts = make_synth_ts()\n","X_tr_ts, X_te_ts, y_tr_ts, y_te_ts = train_test_split(X_ts, y_ts, test_size=800, random_state=7, stratify=y_ts)\n","print(f\"[Info] Time-series windows: Train={X_tr_ts.shape}, Test={X_te_ts.shape}, Classes={len(np.unique(y_tr_ts))}\")\n","\n","print(\"\\n[MiniROCKET] feature transform (CPU, float64+C-contiguous) ...\")\n","mini = MiniRocketMultivariate(random_state=42)\n","Xtr_mini = mini.fit_transform(np.ascontiguousarray(X_tr_ts, dtype=np.float64)).astype(np.float32, copy=False)\n","Xte_mini = mini.transform(    np.ascontiguousarray(X_te_ts, dtype=np.float64)).astype(np.float32, copy=False)\n","print(f\"[MiniROCKET] features: train {Xtr_mini.shape}, test {Xte_mini.shape}\")\n","\n","print(\"[MiniROCKET] train Ridge (CPU) ...\")\n","rc_mini = RidgeClassifier(alpha=1.0).fit(Xtr_mini, y_tr_ts)\n","acc_mini = (rc_mini.predict(Xte_mini) == y_te_ts).mean()\n","print(f\"[Check] MiniROCKET Ridge Acc: {acc_mini:.3f}\")\n","\n","print(\"\\n[MultiROCKET] feature transform (CPU, float64+C-contiguous) ...\")\n","multi = MultiRocketMultivariate(random_state=123)\n","Xtr_multi = multi.fit_transform(np.ascontiguousarray(X_tr_ts, dtype=np.float64)).astype(np.float32, copy=False)\n","Xte_multi = multi.transform(    np.ascontiguousarray(X_te_ts, dtype=np.float64)).astype(np.float32, copy=False)\n","print(f\"[MultiROCKET] features: train {Xtr_multi.shape}, test {Xte_multi.shape}\")\n","\n","print(\"[MultiROCKET] train Ridge (CPU) ...\")\n","rc_multi = RidgeClassifier(alpha=1.0).fit(Xtr_multi, y_tr_ts)\n","acc_multi = (rc_multi.predict(Xte_multi) == y_te_ts).mean()\n","print(f\"[Check] MultiROCKET Ridge Acc: {acc_multi:.3f}\")\n","\n","# ---------------- Move linear heads to GPU; define run_once() ----------------\n","import cupy as cp\n","\n","def make_gpu_linear_runner(X_cpu: np.ndarray, clf: RidgeClassifier, batch: int = 512):\n","    \"\"\"\n","    X_cpu: (N, D) float32, clf.coef_: (C, D), clf.intercept_: (C,)\n","    run_once(): full test prediction on GPU in mini-batches; returns nothing.\n","    \"\"\"\n","    X_gpu = cp.asarray(X_cpu, dtype=cp.float32)                  # (N, D)\n","    W_gpu = cp.asarray(clf.coef_.T.astype(np.float32))           # (D, C)\n","    b_gpu = cp.asarray(clf.intercept_.astype(np.float32))        # (C,)\n","    N = X_cpu.shape[0]\n","    def run_once():\n","        for s in range(0, N, batch):\n","            e = min(N, s + batch)\n","            logits = X_gpu[s:e].dot(W_gpu) + b_gpu               # (B, C)\n","            _ = cp.argmax(logits, axis=1)\n","        gpu_sync()\n","    return run_once, N  # N windows per call\n","\n","run_mini,  N_mini  = make_gpu_linear_runner(Xte_mini,  rc_mini,  batch=1024)\n","run_multi, N_multi = make_gpu_linear_runner(Xte_multi, rc_multi, batch=512)\n","\n","# ---------------- Idle power (measure once or reuse) ----------------\n","Path(\"logs\").mkdir(exist_ok=True)\n","if 'P_idle_mW' not in globals():\n","    print(\"\\n[Info] Sampling idle power for 20 s ...\")\n","    P_idle_mW, _idle = sample_idle_power_mW(duration_s=20.0, dev_index=0, interval=0.02,\n","                                            save_csv=\"logs/power_idle_trace_rocket.csv\")\n","    print(f\"[Info] Mean idle power ~ {P_idle_mW:.1f} mW\")\n","else:\n","    print(f\"\\n[Info] Reusing idle power P_idle_mW = {P_idle_mW:.1f} mW\")\n","\n","# ---------------- Warm-up & repeats (target ≥ 8 s) ----------------\n","print(\"\\n[Warmup] GPU linear heads warmup ...\")\n","for _ in range(30): run_mini(); run_multi()\n","gpu_sync()\n","\n","rep_mini  = calibrate_repeats(run_mini,  target_s=8.0, min_rep=3, max_rep=5000)\n","rep_multi = calibrate_repeats(run_multi, target_s=8.0, min_rep=3, max_rep=5000)\n","print(f\"[Info] repeats: MiniROCKET={rep_mini}, MultiROCKET={rep_multi}\")\n","\n","# ---------------- NVML measurement (per-window) + bootstrap CI ----------------\n","sum_mini  = measure_with_bootstrap_per_window(\"minirocket_gpu_linear_per_window\",  run_mini,  N_mini,  rep_mini,  n_runs=5, n_boot=1000)\n","sum_multi = measure_with_bootstrap_per_window(\"multirocket_gpu_linear_per_window\", run_multi, N_multi, rep_multi, n_runs=5, n_boot=1000)\n","\n","# ---------------- Summary (mJ/ms per 3-second window) ----------------\n","WINDOW_SECONDS = 150 / 50.0  # 3.0, for explicit reporting when using 150-sample windows @ 50 Hz\n","df_sum = pd.DataFrame([\n","    {\"model\":\"MiniROCKET (GPU linear head)\",\n","     \"mJ_per_3s_window_mean\": sum_mini[\"mean_mJ_per_window\"],\n","     \"ci95_low_mJ\":           sum_mini[\"ci95_low_mJ\"],\n","     \"ci95_high_mJ\":          sum_mini[\"ci95_high_mJ\"],\n","     \"ms_per_3s_window_mean\": sum_mini[\"mean_ms_per_window\"],\n","     \"window_seconds\":        WINDOW_SECONDS,\n","     \"acc\":                   float(acc_mini)},\n","    {\"model\":\"MultiROCKET (GPU linear head)\",\n","     \"mJ_per_3s_window_mean\": sum_multi[\"mean_mJ_per_window\"],\n","     \"ci95_low_mJ\":           sum_multi[\"ci95_low_mJ\"],\n","     \"ci95_high_mJ\":          sum_multi[\"ci95_high_mJ\"],\n","     \"ms_per_3s_window_mean\": sum_multi[\"mean_ms_per_window\"],\n","     \"window_seconds\":        WINDOW_SECONDS,\n","     \"acc\":                   float(acc_multi)}\n","])\n","df_sum.to_csv(\"logs/energy_summary_rocket_gpuhead_per_3s_window.csv\", index=False)\n","\n","print(\"\\n=== Completed (ROCKET GPU linear head energy; per 3-second window) ===\")\n","print(df_sum)\n","print(\"\\nArtifacts:\")\n","print(\"- logs/power_idle_trace_rocket.csv\")\n","print(\"- logs/power_trace_minirocket_gpu_linear_per_window_run*.csv\")\n","print(\"- logs/power_trace_multirocket_gpu_linear_per_window_run*.csv\")\n","print(\"- logs/energy_minirocket_gpu_linear_per_window.json\")\n","print(\"- logs/energy_multirocket_gpu_linear_per_window.json\")\n","print(\"- logs/energy_summary_rocket_gpuhead_per_3s_window.csv\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vO81nTeebtqU","executionInfo":{"status":"ok","timestamp":1763745855683,"user_tz":0,"elapsed":155517,"user":{"displayName":"yu Wu","userId":"12692660435918028293"}},"outputId":"560f4867-f17f-4a60-d15a-59188591e699"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Fri Nov 21 17:21:40 2025       \n","+-----------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n","|-----------------------------------------+------------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                        |               MIG M. |\n","|=========================================+========================+======================|\n","|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n","| N/A   50C    P0             27W /   70W |     382MiB /  15360MiB |      0%      Default |\n","|                                         |                        |                  N/A |\n","+-----------------------------------------+------------------------+----------------------+\n","                                                                                         \n","+-----------------------------------------------------------------------------------------+\n","| Processes:                                                                              |\n","|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n","|        ID   ID                                                               Usage      |\n","|=========================================================================================|\n","+-----------------------------------------------------------------------------------------+\n","[Info] Time-series windows: Train=(2000, 6, 150), Test=(800, 6, 150), Classes=8\n","\n","[MiniROCKET] feature transform (CPU, float64+C-contiguous) ...\n","[MiniROCKET] features: train (2000, 9996), test (800, 9996)\n","[MiniROCKET] train Ridge (CPU) ...\n","[Check] MiniROCKET Ridge Acc: 0.616\n","\n","[MultiROCKET] feature transform (CPU, float64+C-contiguous) ...\n","[MultiROCKET] features: train (2000, 49728), test (800, 49728)\n","[MultiROCKET] train Ridge (CPU) ...\n","[Check] MultiROCKET Ridge Acc: 0.504\n","\n","[Info] Reusing idle power P_idle_mW = 28367.3 mW\n","\n","[Warmup] GPU linear heads warmup ...\n","[Info] repeats: MiniROCKET=5000, MultiROCKET=3807\n","[Measure] minirocket_gpu_linear_per_window run 1/5 ...\n","[Measure] minirocket_gpu_linear_per_window run 2/5 ...\n","[Measure] minirocket_gpu_linear_per_window run 3/5 ...\n","[Measure] minirocket_gpu_linear_per_window run 4/5 ...\n","[Measure] minirocket_gpu_linear_per_window run 5/5 ...\n","[Result] minirocket_gpu_linear_per_window: 0.0208 mJ per window (95% CI [0.0197, 0.0218]); 0.001 ms per window\n","[Measure] multirocket_gpu_linear_per_window run 1/5 ...\n","[Measure] multirocket_gpu_linear_per_window run 2/5 ...\n","[Measure] multirocket_gpu_linear_per_window run 3/5 ...\n","[Measure] multirocket_gpu_linear_per_window run 4/5 ...\n","[Measure] multirocket_gpu_linear_per_window run 5/5 ...\n","[Result] multirocket_gpu_linear_per_window: 0.0879 mJ per window (95% CI [0.0873, 0.0886]); 0.002 ms per window\n","\n","=== Completed (ROCKET GPU linear head energy; per 3-second window) ===\n","                           model  mJ_per_3s_window_mean  ci95_low_mJ  \\\n","0   MiniROCKET (GPU linear head)               0.020800     0.019655   \n","1  MultiROCKET (GPU linear head)               0.087909     0.087332   \n","\n","   ci95_high_mJ  ms_per_3s_window_mean  window_seconds      acc  \n","0      0.021831               0.000530             3.0  0.61625  \n","1      0.088570               0.002127             3.0  0.50375  \n","\n","Artifacts:\n","- logs/power_idle_trace_rocket.csv\n","- logs/power_trace_minirocket_gpu_linear_per_window_run*.csv\n","- logs/power_trace_multirocket_gpu_linear_per_window_run*.csv\n","- logs/energy_minirocket_gpu_linear_per_window.json\n","- logs/energy_multirocket_gpu_linear_per_window.json\n","- logs/energy_summary_rocket_gpuhead_per_3s_window.csv\n"]}]},{"cell_type":"code","source":["!pip -q install tsai fastai torch --upgrade"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4qmRfKfKbj5Z","executionInfo":{"status":"ok","timestamp":1763746048807,"user_tz":0,"elapsed":120933,"user":{"displayName":"yu Wu","userId":"12692660435918028293"}},"outputId":"c6f9c51d-1a72-4ace-ce5d-6b84d7998d36"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m324.1/324.1 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m821.0/821.0 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.7/155.7 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m263.3/263.3 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchaudio 2.8.0+cu126 requires torch==2.8.0, but you have torch 2.7.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["# ============ Step 19c (No-Train Hotfix · Self-contained):\n","# InceptionTime & TST Inference Energy Consumption (GPU, NVML)\n","# Per-window metric: mJ per 3-second window\n","# ============================================================\n","\n","import os, math, time, json, pathlib, multiprocessing as mp\n","os.environ.setdefault(\"TORCH_COMPILE_DISABLE\", \"1\")\n","os.environ.setdefault(\"TORCHDYNAMO_DISABLE\", \"1\")\n","\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","from sklearn.model_selection import train_test_split\n","\n","# ============================================\n","# 0. NVML-based GPU energy measurement helpers\n","#     (per-window reporting)\n","# ============================================\n","\n","def gpu_sync():\n","    \"\"\"Best-effort sync across CuPy and PyTorch.\"\"\"\n","    try:\n","        import cupy as cp\n","        cp.cuda.runtime.deviceSynchronize()\n","    except Exception:\n","        pass\n","    try:\n","        if torch.cuda.is_available():\n","            torch.cuda.synchronize()\n","    except Exception:\n","        pass\n","\n","def nvml_sampler(stop_event, q, dev_index=0, interval=0.02):\n","    \"\"\"Subprocess: periodically read NVML power (mW) and push (t_abs, power_mW).\"\"\"\n","    import pynvml, time as _time\n","    pynvml.nvmlInit()\n","    h = pynvml.nvmlDeviceGetHandleByIndex(dev_index)\n","    try:\n","        while not stop_event.is_set():\n","            q.put((_time.perf_counter(), pynvml.nvmlDeviceGetPowerUsage(h)))\n","            _time.sleep(interval)\n","    finally:\n","        pynvml.nvmlShutdown()\n","\n","def integrate_energy_mJ_between(samples, t0, t1):\n","    \"\"\"Trapezoidal integrate power (mW) over [t0, t1] -> mJ.\"\"\"\n","    if not samples:\n","        return 0.0\n","    samples = sorted(samples, key=lambda x: x[0])\n","    ts = np.array([t for t,_ in samples], dtype=np.float64)\n","    ps = np.array([p for _,p in samples], dtype=np.float64)\n","    m = (ts >= t0) & (ts <= t1)\n","    ts_w = ts[m]; ps_w = ps[m]\n","    if ts_w.size == 0 or ts_w[0] > t0:\n","        p0 = np.interp(t0, ts, ps); ts_w = np.insert(ts_w, 0, t0); ps_w = np.insert(ps_w, 0, p0)\n","    if ts_w[-1] < t1:\n","        p1 = np.interp(t1, ts, ps); ts_w = np.append(ts_w, t1); ps_w = np.append(ps_w, p1)\n","    return float(np.trapz(ps_w, ts_w))\n","\n","def sample_idle_power_mW(duration_s=20.0, dev_index=0, interval=0.02, save_csv=None):\n","    \"\"\"Return mean idle power (mW) and the trace.\"\"\"\n","    q = mp.Queue(); stop = mp.Event()\n","    proc = mp.Process(target=nvml_sampler, args=(stop, q, dev_index, interval))\n","    proc.start()\n","    time.sleep(duration_s)\n","    stop.set(); proc.join()\n","    samples = []\n","    while not q.empty():\n","        samples.append(q.get())\n","    if not samples:\n","        raise RuntimeError(\"NVML did not capture any power samples (idle).\")\n","    samples = sorted(samples, key=lambda x: x[0])\n","    t0, t1 = samples[0][0], samples[-1][0]\n","    E_idle_mJ = integrate_energy_mJ_between(samples, t0, t1)\n","    T_idle_s  = max(1e-9, (t1 - t0))\n","    P_idle_mW = E_idle_mJ / T_idle_s\n","    if save_csv:\n","        pd.DataFrame(samples, columns=[\"t_abs_s\",\"power_mW\"]).to_csv(save_csv, index=False)\n","    return P_idle_mW, samples\n","\n","def calibrate_repeats(run_once, target_s=8.0, min_rep=3, max_rep=5000):\n","    \"\"\"Estimate repeats so a single measurement lasts ~target_s.\"\"\"\n","    gpu_sync(); t0 = time.perf_counter(); run_once(); gpu_sync(); t1 = time.perf_counter()\n","    dt = max(1e-4, (t1 - t0))\n","    reps = int(math.ceil(target_s / dt))\n","    return int(np.clip(reps, min_rep, max_rep))\n","\n","def measure_mJ_per_window(run_once, n_windows_per_call: int, repeats: int,\n","                          P_idle_mW: float, dev_index=0, interval=0.02, save_csv=None):\n","    \"\"\"Concurrent NVML sampling during repeated run_once(); normalize by window count.\"\"\"\n","    q = mp.Queue(); stop = mp.Event()\n","    proc = mp.Process(target=nvml_sampler, args=(stop, q, dev_index, interval))\n","    proc.start()\n","    gpu_sync(); t0 = time.perf_counter()\n","    for _ in range(repeats): run_once()\n","    gpu_sync(); t1 = time.perf_counter()\n","    stop.set(); proc.join()\n","\n","    samples = []\n","    while not q.empty(): samples.append(q.get())\n","    if not samples:\n","        raise RuntimeError(\"NVML did not capture any power samples (active).\")\n","\n","    E_total_mJ = integrate_energy_mJ_between(samples, t0, t1)\n","    T_total_s  = max(1e-9, (t1 - t0))\n","    E_idle_mJ  = P_idle_mW * T_total_s\n","    n_windows  = max(1, repeats * n_windows_per_call)\n","\n","    if save_csv:\n","        pd.DataFrame(samples, columns=[\"t_abs_s\",\"power_mW\"]).to_csv(save_csv, index=False)\n","\n","    return {\n","        \"mJ_per_window\": max(0.0, (E_total_mJ - E_idle_mJ) / n_windows),\n","        \"ms_per_window\": (T_total_s / n_windows) * 1e3,\n","        \"throughput_windows_per_s\": n_windows / T_total_s,\n","        \"n_windows\": n_windows, \"repeats\": repeats,\n","        \"T_total_s\": T_total_s, \"E_total_mJ\": E_total_mJ, \"E_idle_mJ\": E_idle_mJ,\n","        \"P_idle_mW\": P_idle_mW, \"t0_abs\": t0, \"t1_abs\": t1\n","    }\n","\n","def measure_with_bootstrap_per_window(name, run_once, n_windows, repeats, n_runs=5, n_boot=1000):\n","    \"\"\"Repeat per-window measurement and bootstrap a 95% CI.\"\"\"\n","    pathlib.Path(\"logs\").mkdir(exist_ok=True)\n","    results = []\n","    for i in range(n_runs):\n","        print(f\"[Measure] {name} - run {i+1}/{n_runs} ...\")\n","        res = measure_mJ_per_window(\n","            run_once, n_windows_per_call=n_windows, repeats=repeats,\n","            P_idle_mW=P_idle_mW, dev_index=0, interval=0.02,\n","            save_csv=f\"logs/power_trace_{name}_run{i+1}.csv\"\n","        )\n","        results.append(res)\n","    mJ = np.array([r[\"mJ_per_window\"] for r in results], dtype=np.float64)\n","    ms = np.array([r[\"ms_per_window\"] for r in results], dtype=np.float64)\n","    rng = np.random.default_rng(123)\n","    boots = [float(np.mean(mJ[rng.integers(0, len(mJ), size=len(mJ))])) for _ in range(n_boot)]\n","    ci_low, ci_high = np.percentile(boots, [2.5, 97.5])\n","    summary = {\n","        \"model\": name,\n","        \"mean_mJ_per_window\": float(mJ.mean()),\n","        \"ci95_low_mJ\": float(ci_low),\n","        \"ci95_high_mJ\": float(ci_high),\n","        \"mean_ms_per_window\": float(ms.mean()),\n","        \"runs\": results\n","    }\n","    with open(f\"logs/energy_{name}.json\", \"w\") as f:\n","        json.dump(summary, f, indent=2)\n","    print(f\"[Result] {name}: {summary['mean_mJ_per_window']:.3f} mJ per window \"\n","          f\"(95% CI [{summary['ci95_low_mJ']:.3f}, {summary['ci95_high_mJ']:.3f}]); \"\n","          f\"{summary['mean_ms_per_window']:.3f} ms per window\")\n","    return summary\n","\n","# ==============================\n","# 1. Synthetic 3D IMU-like data\n","# ==============================\n","\n","def make_synth_ts(n_samples=2800, n_channels=6, length=150, n_classes=8, seed=2025):\n","    \"\"\"X: (N, C, L), y: (N,) with simple class-specific patterns.\"\"\"\n","    rng = np.random.default_rng(seed)\n","    X = rng.normal(0, 1, size=(n_samples, n_channels, length)).astype(np.float32)\n","    y = rng.integers(0, n_classes, size=n_samples).astype(np.int64)\n","    t = np.linspace(0, 2 * np.pi, length, dtype=np.float32)\n","    for c in range(n_classes):\n","        idx = (y == c)\n","        if idx.any():\n","            freq = 1.0 + 0.2 * c\n","            X[idx, 0, :] += 0.6 * np.sin(freq * t)\n","            X[idx, 1, :] += 0.4 * np.cos(0.5 * freq * t)\n","    return X, y\n","\n","X_ts, y_ts = make_synth_ts()\n","X_tr_ts, X_te_ts, y_tr_ts, y_te_ts = train_test_split(X_ts, y_ts, test_size=800, random_state=7, stratify=y_ts)\n","print(f\"[Info] Train={X_tr_ts.shape}, Test={X_te_ts.shape}, Classes={len(np.unique(y_tr_ts))}\")\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","torch.backends.cudnn.benchmark = True\n","pathlib.Path(\"logs\").mkdir(exist_ok=True)\n","\n","# ===========================\n","# 2. Lightweight InceptionTime\n","# ===========================\n","\n","class InceptionBlock1d(nn.Module):\n","    def __init__(self, in_ch, out_ch, bottleneck=32, ks=(9, 19, 39)):\n","        super().__init__()\n","        use_bn = in_ch > 1\n","        bott = bottleneck if use_bn else in_ch\n","        self.bottleneck = nn.Conv1d(in_ch, bott, 1, bias=False) if use_bn else nn.Identity()\n","        self.conv1 = nn.Conv1d(bott, out_ch // 4, ks[0], padding=ks[0] // 2, bias=False)\n","        self.conv2 = nn.Conv1d(bott, out_ch // 4, ks[1], padding=ks[1] // 2, bias=False)\n","        self.conv3 = nn.Conv1d(bott, out_ch // 4, ks[2], padding=ks[2] // 2, bias=False)\n","        self.pool = nn.MaxPool1d(3, stride=1, padding=1)\n","        self.conv_pool = nn.Conv1d(in_ch, out_ch // 4, 1, bias=False)\n","        self.bn = nn.BatchNorm1d(out_ch)\n","        self.act = nn.ReLU(inplace=True)\n","    def forward(self, x):\n","        z = self.bottleneck(x)\n","        y = torch.cat([self.conv1(z), self.conv2(z), self.conv3(z), self.conv_pool(self.pool(x))], dim=1)\n","        return self.act(self.bn(y))\n","\n","class InceptionResNetModule(nn.Module):\n","    def __init__(self, in_ch, out_ch, **kw):\n","        super().__init__()\n","        self.b1 = InceptionBlock1d(in_ch, out_ch, **kw)\n","        self.b2 = InceptionBlock1d(out_ch, out_ch, **kw)\n","        self.b3 = InceptionBlock1d(out_ch, out_ch, **kw)\n","        self.short = nn.Identity() if in_ch == out_ch else nn.Sequential(\n","            nn.Conv1d(in_ch, out_ch, 1, bias=False), nn.BatchNorm1d(out_ch)\n","        )\n","        self.act = nn.ReLU(inplace=True)\n","    def forward(self, x):\n","        res = self.short(x)\n","        y = self.b1(x); y = self.b2(y); y = self.b3(y)\n","        return self.act(y + res)\n","\n","class InceptionTimeSmall(nn.Module):\n","    def __init__(self, c_in, n_classes, nb_filters=64, n_modules=2, bottleneck=32):\n","        super().__init__()\n","        layers, in_ch = [], c_in\n","        for _ in range(n_modules):\n","            layers.append(InceptionResNetModule(in_ch, nb_filters, bottleneck=bottleneck))\n","            in_ch = nb_filters\n","        self.features = nn.Sequential(*layers)\n","        self.gap = nn.AdaptiveAvgPool1d(1)\n","        self.fc = nn.Linear(nb_filters, n_classes)\n","    def forward(self, x):\n","        x = self.features(x)\n","        x = self.gap(x).squeeze(-1)\n","        return self.fc(x)\n","\n","# ================\n","# 3. Lightweight TST\n","# ================\n","\n","class PatchEmbed1D(nn.Module):\n","    def __init__(self, c_in, d_model=128, patch_len=10, stride=None):\n","        super().__init__()\n","        self.proj = nn.Conv1d(c_in, d_model, kernel_size=patch_len, stride=stride or patch_len, bias=False)\n","    def forward(self, x):  # (B,C,L) -> (B,N,D)\n","        return self.proj(x).transpose(1, 2)\n","\n","class SinPosEncoding(nn.Module):\n","    def __init__(self, d_model):\n","        super().__init__()\n","        self.d = d_model\n","    def forward(self, x):\n","        B, N, D = x.shape\n","        device = x.device\n","        pos = torch.arange(N, device=device).unsqueeze(1)\n","        div = torch.exp(torch.arange(0, D, 2, device=device) * (-math.log(10000.0) / D))\n","        pe = torch.zeros(N, D, device=device)\n","        pe[:, 0::2] = torch.sin(pos * div); pe[:, 1::2] = torch.cos(pos * div)\n","        return x + pe.unsqueeze(0)\n","\n","class TSTSmall(nn.Module):\n","    def __init__(self, c_in, n_classes, d_model=128, n_heads=4, depth=2, dim_ff=256, patch_len=10, dropout=0.1):\n","        super().__init__()\n","        self.embed = PatchEmbed1D(c_in, d_model, patch_len)\n","        enc = nn.TransformerEncoderLayer(d_model=d_model, nhead=n_heads, dim_feedforward=dim_ff,\n","                                         dropout=dropout, batch_first=True, norm_first=True, activation='gelu')\n","        self.encoder = nn.TransformerEncoder(enc, num_layers=depth)\n","        self.pos = SinPosEncoding(d_model)\n","        self.head = nn.Linear(d_model, n_classes)\n","    def forward(self, x):\n","        x = self.embed(x); x = self.pos(x); x = self.encoder(x)\n","        return self.head(x.mean(dim=1))\n","\n","# ==========================\n","# 4. Build models (random)\n","# ==========================\n","\n","n_classes = int(len(np.unique(y_tr_ts)))\n","c_in = X_tr_ts.shape[1]\n","\n","it_model = InceptionTimeSmall(c_in=c_in, n_classes=n_classes, nb_filters=64, n_modules=2, bottleneck=32)\n","tst_model = TSTSmall(c_in=c_in, n_classes=n_classes, d_model=128, n_heads=4, depth=2, dim_ff=256, patch_len=10)\n","\n","# ==========================\n","# 5. Inference runner helpers\n","# ==========================\n","\n","def make_runner(model, X_np, bs=512):\n","    model = model.to(device).eval()\n","    X_gpu = torch.as_tensor(X_np, dtype=torch.float32, device=device)\n","    N = X_np.shape[0]\n","    @torch.no_grad()\n","    def run_once():\n","        for s in range(0, N, bs):\n","            e = min(N, s + bs)\n","            _ = model(X_gpu[s:e])\n","        if torch.cuda.is_available(): torch.cuda.synchronize()\n","        gpu_sync()\n","    return run_once, N  # N windows per call\n","\n","run_it,  N_it  = make_runner(it_model,  X_te_ts, bs=512)\n","run_tst, N_tst = make_runner(tst_model, X_te_ts, bs=512)\n","\n","# ===============\n","# 6. Idle power\n","# ===============\n","\n","if 'P_idle_mW' not in globals():\n","    print(\"\\n[Info] Sampling idle power for 20 s ...\")\n","    P_idle_mW, _idle = sample_idle_power_mW(duration_s=20.0, dev_index=0, interval=0.02,\n","                                            save_csv=\"logs/power_idle_trace_deepts_hotfix.csv\")\n","    print(f\"[Info] Mean idle power ~ {P_idle_mW:.1f} mW\")\n","else:\n","    print(f\"\\n[Info] Reusing previously measured idle power P_idle_mW = {P_idle_mW:.1f} mW\")\n","\n","# ===============\n","# 7. Warm-up\n","# ===============\n","\n","print(\"\\n[Warmup] warmup ...\")\n","for _ in range(20):\n","    run_it(); run_tst()\n","gpu_sync()\n","\n","# =====================================\n","# 8. Adaptive window + NVML measurement\n","# =====================================\n","\n","rep_it  = calibrate_repeats(run_it,  target_s=8.0, min_rep=3, max_rep=5000)\n","rep_tst = calibrate_repeats(run_tst, target_s=8.0, min_rep=3, max_rep=5000)\n","print(f\"[Info] repeats: InceptionTime={rep_it}, TST={rep_tst}\")\n","\n","sum_it  = measure_with_bootstrap_per_window(\"inceptiontime_torch_eager_per_window\", run_it,  N_it,  rep_it,  n_runs=5, n_boot=1000)\n","sum_tst = measure_with_bootstrap_per_window(\"tst_torch_eager_per_window\",          run_tst, N_tst, rep_tst, n_runs=5, n_boot=1000)\n","\n","# =========\n","# 9. Summary (mJ/ms per 3-second window)\n","# =========\n","\n","WINDOW_SECONDS = 150 / 50.0  # if you use 150-sample windows @ 50 Hz\n","df = pd.DataFrame([\n","    {\n","        \"model\": \"InceptionTime (eager, no-train)\",\n","        \"mJ_per_3s_window_mean\":  sum_it[\"mean_mJ_per_window\"],\n","        \"ci95_low_mJ\":           sum_it[\"ci95_low_mJ\"],\n","        \"ci95_high_mJ\":          sum_it[\"ci95_high_mJ\"],\n","        \"ms_per_3s_window_mean\": sum_it[\"mean_ms_per_window\"],\n","        \"window_seconds\":        WINDOW_SECONDS,\n","    },\n","    {\n","        \"model\": \"TST (eager, no-train)\",\n","        \"mJ_per_3s_window_mean\":  sum_tst[\"mean_mJ_per_window\"],\n","        \"ci95_low_mJ\":           sum_tst[\"ci95_low_mJ\"],\n","        \"ci95_high_mJ\":          sum_tst[\"ci95_high_mJ\"],\n","        \"ms_per_3s_window_mean\": sum_tst[\"mean_ms_per_window\"],\n","        \"window_seconds\":        WINDOW_SECONDS,\n","    },\n","])\n","pathlib.Path(\"logs\").mkdir(exist_ok=True)\n","df.to_csv(\"logs/energy_summary_deepts_eager_per_3s_window.csv\", index=False)\n","\n","print(\"\\n=== Completed (InceptionTime & TST inference energy — per 3-second window) ===\")\n","print(df)\n","print(\"\\nLog files:\")\n","print(\"- logs/power_idle_trace_deepts_hotfix.csv\")\n","print(\"- logs/power_trace_inceptiontime_torch_eager_per_window_run*.csv\")\n","print(\"- logs/power_trace_tst_torch_eager_per_window_run*.csv\")\n","print(\"- logs/energy_inceptiontime_torch_eager_per_window.json\")\n","print(\"- logs/energy_tst_torch_eager_per_window.json\")\n","print(\"- logs/energy_summary_deepts_eager_per_3s_window.csv\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dgRq3_Vycy3A","executionInfo":{"status":"ok","timestamp":1763746131012,"user_tz":0,"elapsed":82183,"user":{"displayName":"yu Wu","userId":"12692660435918028293"}},"outputId":"9baf8b1a-c606-46ee-c7a6-e1007a64cb2a"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["[Info] Train=(2000, 6, 150), Test=(800, 6, 150), Classes=8\n","\n","[Info] Reusing previously measured idle power P_idle_mW = 28367.3 mW\n","\n","[Warmup] warmup ...\n","[Info] repeats: InceptionTime=227, TST=1441\n","[Measure] inceptiontime_torch_eager_per_window - run 1/5 ...\n","[Measure] inceptiontime_torch_eager_per_window - run 2/5 ...\n","[Measure] inceptiontime_torch_eager_per_window - run 3/5 ...\n","[Measure] inceptiontime_torch_eager_per_window - run 4/5 ...\n","[Measure] inceptiontime_torch_eager_per_window - run 5/5 ...\n","[Result] inceptiontime_torch_eager_per_window: 1.902 mJ per window (95% CI [1.881, 1.924]); 0.046 ms per window\n","[Measure] tst_torch_eager_per_window - run 1/5 ...\n","[Measure] tst_torch_eager_per_window - run 2/5 ...\n","[Measure] tst_torch_eager_per_window - run 3/5 ...\n","[Measure] tst_torch_eager_per_window - run 4/5 ...\n","[Measure] tst_torch_eager_per_window - run 5/5 ...\n","[Result] tst_torch_eager_per_window: 0.262 mJ per window (95% CI [0.259, 0.265]); 0.006 ms per window\n","\n","=== Completed (InceptionTime & TST inference energy — per 3-second window) ===\n","                             model  mJ_per_3s_window_mean  ci95_low_mJ  \\\n","0  InceptionTime (eager, no-train)               1.902171     1.880651   \n","1            TST (eager, no-train)               0.262259     0.259288   \n","\n","   ci95_high_mJ  ms_per_3s_window_mean  window_seconds  \n","0      1.923691               0.045988             3.0  \n","1      0.264593               0.006316             3.0  \n","\n","Log files:\n","- logs/power_idle_trace_deepts_hotfix.csv\n","- logs/power_trace_inceptiontime_torch_eager_per_window_run*.csv\n","- logs/power_trace_tst_torch_eager_per_window_run*.csv\n","- logs/energy_inceptiontime_torch_eager_per_window.json\n","- logs/energy_tst_torch_eager_per_window.json\n","- logs/energy_summary_deepts_eager_per_3s_window.csv\n"]}]}]}