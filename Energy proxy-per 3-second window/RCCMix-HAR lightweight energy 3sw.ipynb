{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyOf8Wg3TdqZ6CEWNitKsHTW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["# ================================================================\n","# RCCMix-HAR (Step 10 model as given) × Scheme 1:\n","# NVML GPU inference energy — mJ per 3-second window (single cell, no prereqs)\n","# ================================================================\n","# 0) System check & deps\n","!nvidia-smi\n","!pip -q install pynvml\n","\n","import os, json, time, math, warnings, multiprocessing as mp\n","from pathlib import Path\n","warnings.filterwarnings(\"ignore\")\n","\n","import numpy as np\n","import pandas as pd\n","\n","# ---------------- NVML sampling + trapezoidal energy integration (per-window reporting) ----------------\n","import pynvml\n","\n","def _nvml_sampler(stop_event, q, dev_index=0, interval=0.02):\n","    \"\"\"Background process: sample GPU power (mW) every `interval` seconds, push (t, mW).\"\"\"\n","    import time, pynvml\n","    pynvml.nvmlInit()\n","    h = pynvml.nvmlDeviceGetHandleByIndex(dev_index)\n","    try:\n","        while not stop_event.is_set():\n","            q.put((time.perf_counter(), pynvml.nvmlDeviceGetPowerUsage(h)))\n","            time.sleep(interval)\n","    finally:\n","        pynvml.nvmlShutdown()\n","\n","def _integrate_mJ_between(samples, t0, t1):\n","    \"\"\"Trapezoidal integrate power (mW) over [t0, t1] → mJ.\"\"\"\n","    if not samples: return 0.0\n","    samples = sorted(samples, key=lambda x: x[0])\n","    ts = np.array([t for t,_ in samples], dtype=np.float64)\n","    ps = np.array([p for _,p in samples], dtype=np.float64)\n","    mask = (ts >= t0) & (ts <= t1)\n","    ts_w, ps_w = ts[mask], ps[mask]\n","    if ts_w.size == 0 or ts_w[0] > t0:\n","        p0 = np.interp(t0, ts, ps); ts_w = np.insert(ts_w, 0, t0); ps_w = np.insert(ps_w, 0, p0)\n","    if ts_w[-1] < t1:\n","        p1 = np.interp(t1, ts, ps); ts_w = np.append(ts_w, t1); ps_w = np.append(ps_w, p1)\n","    return float(np.trapz(ps_w, ts_w))  # mW*s = mJ\n","\n","def sample_idle_power_mW(duration_s=20.0, dev_index=0, interval=0.02, save_csv=None):\n","    \"\"\"Measure average idle power (mW).\"\"\"\n","    q = mp.Queue(); stop = mp.Event()\n","    p = mp.Process(target=_nvml_sampler, args=(stop, q, dev_index, interval)); p.start()\n","    time.sleep(duration_s); stop.set(); p.join()\n","    samples = []\n","    while not q.empty(): samples.append(q.get())\n","    if not samples: raise RuntimeError(\"No NVML samples during idle.\")\n","    samples.sort(key=lambda x: x[0])\n","    t0, t1 = samples[0][0], samples[-1][0]\n","    E_idle_mJ = _integrate_mJ_between(samples, t0, t1)\n","    T_idle_s  = max(1e-9, t1 - t0)\n","    P_idle_mW = E_idle_mJ / T_idle_s\n","    if save_csv:\n","        pd.DataFrame(samples, columns=[\"t_abs_s\",\"power_mW\"]).to_csv(save_csv, index=False)\n","    return P_idle_mW, samples\n","\n","def measure_mJ_per_window(run_once, n_windows_per_call, repeats, P_idle_mW,\n","                          dev_index=0, interval=0.02, save_csv=None):\n","    \"\"\"Concurrent NVML sampling + integration + idle subtraction → energy/latency per window.\"\"\"\n","    q = mp.Queue(); stop = mp.Event()\n","    p = mp.Process(target=_nvml_sampler, args=(stop, q, dev_index, interval)); p.start()\n","    t0 = time.perf_counter()\n","    for _ in range(repeats):\n","        run_once()\n","    t1 = time.perf_counter()\n","    stop.set(); p.join()\n","    samples = []\n","    while not q.empty(): samples.append(q.get())\n","    if not samples: raise RuntimeError(\"No NVML samples during active measurement.\")\n","    E_total_mJ = _integrate_mJ_between(samples, t0, t1)\n","    T_total_s  = max(1e-9, t1 - t0)\n","    E_idle_mJ  = P_idle_mW * T_total_s\n","    n_windows  = max(1, repeats * n_windows_per_call)\n","    if save_csv:\n","        pd.DataFrame(samples, columns=[\"t_abs_s\",\"power_mW\"]).to_csv(save_csv, index=False)\n","    return {\n","        \"mJ_per_window\": max(0.0, (E_total_mJ - E_idle_mJ) / n_windows),\n","        \"ms_per_window\": (T_total_s / n_windows) * 1e3,\n","        \"throughput_windows_per_s\": n_windows / T_total_s,\n","        \"n_windows\": n_windows,\n","        \"repeats\": repeats,\n","        \"T_total_s\": T_total_s,\n","        \"E_total_mJ\": E_total_mJ,\n","        \"E_idle_mJ\": E_idle_mJ,\n","        \"P_idle_mW\": P_idle_mW,\n","        \"t0_abs\": t0, \"t1_abs\": t1\n","    }\n","\n","def calibrate_repeats(run_once, target_s=8.0, min_rep=3, max_rep=5000):\n","    \"\"\"Estimate repeats so one measurement window lasts ~target_s seconds.\"\"\"\n","    run_once()\n","    t0 = time.perf_counter(); run_once(); t1 = time.perf_counter()\n","    dt = max(1e-4, t1 - t0)\n","    reps = int(np.ceil(target_s / dt))\n","    return int(np.clip(reps, min_rep, max_rep))\n","\n","def measure_with_bootstrap(name, run_once, n_windows, repeats, n_runs=5, n_boot=1000, logdir=Path(\"logs\")):\n","    \"\"\"Repeat n_runs; bootstrap the per-window mean with 95% CI; save traces & summary.\"\"\"\n","    logdir.mkdir(exist_ok=True, parents=True)\n","    runs = []\n","    for i in range(n_runs):\n","        print(f\"[Measure] {name} run {i+1}/{n_runs} ...\")\n","        r = measure_mJ_per_window(\n","            run_once, n_windows, repeats, P_idle_mW,\n","            dev_index=0, interval=0.02,\n","            save_csv=str(logdir/f\"power_trace_{name}_run{i+1}.csv\")\n","        )\n","        runs.append(r)\n","    mJ = np.array([r[\"mJ_per_window\"] for r in runs], dtype=np.float64)\n","    ms = np.array([r[\"ms_per_window\"] for r in runs], dtype=np.float64)\n","    rng = np.random.default_rng(123)\n","    boots = [float(np.mean(mJ[rng.integers(0, len(mJ), size=len(mJ))])) for _ in range(n_boot)]\n","    ci_low, ci_high = np.percentile(boots, [2.5, 97.5])\n","    summary = {\n","        \"model\": name,\n","        \"mean_mJ_per_window\": float(mJ.mean()),\n","        \"ci95_low_mJ\": float(ci_low),\n","        \"ci95_high_mJ\": float(ci_high),\n","        \"mean_ms_per_window\": float(ms.mean()),\n","        \"runs\": runs\n","    }\n","    with open(logdir/f\"energy_{name}.json\", \"w\") as f: json.dump(summary, f, indent=2)\n","    print(f\"[Result] {name}: {summary['mean_mJ_per_window']:.3f} mJ per window \"\n","          f\"(95% CI [{summary['ci95_low_mJ']:.3f}, {summary['ci95_high_mJ']:.3f}]); \"\n","          f\"{summary['mean_ms_per_window']:.3f} ms per window\")\n","    return summary\n","\n","# ---------------- Ensure minimal configs/features exist (no change to model) ----------------\n","BASE = Path(\"/content\")\n","configs_dir = BASE / \"configs\"; configs_dir.mkdir(parents=True, exist_ok=True)\n","classes_json = configs_dir / \"classes.json\"\n","splits_json  = configs_dir / \"splits.json\"\n","\n","if not classes_json.exists():\n","    classes_json.write_text(json.dumps({\n","        \"num_classes\": 8,\n","        \"id_to_label\": {str(i): f\"class{i}\" for i in range(8)}\n","    }, indent=2))\n","if not splits_json.exists():\n","    splits_json.write_text(json.dumps({\"folds\": [{\"fold\": 0, \"test_subject\": \"S01\"}]}, indent=2))\n","\n","features_dir = BASE / \"features\"; features_dir.mkdir(parents=True, exist_ok=True)\n","npz_path = features_dir / \"windows_normalized_fold0.npz\"\n","if not npz_path.exists():\n","    # Fallback synthetic fold (includes window_ids to demo grouping; real data may omit it)\n","    N_train, N_test, T, C, K = 2000, 800, 150, 6, 8\n","    rng = np.random.default_rng(2025)\n","    def make_axis(N): return rng.normal(0, 1, size=(N, T)).astype(np.float32)\n","    window_ids = [f\"file0.csv:0:{i*T}\" for i in range(N_train + N_test)]\n","    out = {\n","        \"acc_x\": make_axis(N_train+N_test),\n","        \"acc_y\": make_axis(N_train+N_test),\n","        \"acc_z\": make_axis(N_train+N_test),\n","        \"gyro_x\": make_axis(N_train+N_test),\n","        \"gyro_y\": make_axis(N_train+N_test),\n","        \"gyro_z\": make_axis(N_train+N_test),\n","        \"labels\": np.concatenate([rng.integers(0, K, size=N_train), rng.integers(0, K, size=N_test)]).astype(np.int64),\n","        \"subjects\": np.array([\"S01\"]*(N_train+N_test)),\n","        \"splits\":   np.array([\"train\"]*N_train + [\"test\"]*N_test),\n","        \"window_ids\": np.array(window_ids, dtype=object)\n","    }\n","    np.savez(npz_path, **out)\n","\n","# ---------------- Step 10: RCCMix-HAR (structure/params unchanged) ----------------\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","from collections import defaultdict\n","\n","print(\"\\n\\nStep 10: RCCMix-HAR — per-window energy measurement\")\n","print(\"=\" * 80)\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f\"Using device: {device}\")\n","\n","# Hyperparameters (unaltered)\n","SEQ_LEN        = 8\n","SEQ_STRIDE     = 4\n","BATCH_SIZE     = 32\n","EPOCHS         = 25\n","LR             = 1e-3\n","WEIGHT_DECAY   = 1e-4\n","CLIP_NORM      = 1.0\n","D_MODEL        = 128\n","N_HEADS        = 4\n","N_LAYERS       = 2\n","D_FF           = 4 * D_MODEL\n","DROPOUT        = 0.2\n","VAL_SPLIT      = 0.1\n","LABEL_SMOOTH   = 0.05\n","\n","with open(classes_json, 'r') as f:\n","    classes_cfg = json.load(f)\n","NUM_CLASSES = int(classes_cfg[\"num_classes\"])\n","\n","def parse_window_id(wid: str):\n","    parts = wid.split(':')\n","    if len(parts) != 3: return wid, 0, 0\n","    return parts[0], int(parts[1]), int(parts[2])\n","\n","class SeqDataset(Dataset):\n","    \"\"\"\n","    Build sequences of length `seq_len` by sliding over windows within each subject.\n","    If 'window_ids' is present in the NPZ, group by (subject, file, segment) and sort by start_idx.\n","    Otherwise, group by subject only and keep the original order as-is.\n","    \"\"\"\n","    def __init__(self, npz_path: Path, split: str, seq_len=8, seq_stride=4):\n","        super().__init__()\n","        self.npz = np.load(npz_path, allow_pickle=True)\n","        self.split = split; self.seq_len = seq_len; self.seq_stride = seq_stride\n","\n","        self.ax = self.npz['acc_x']; self.ay = self.npz['acc_y']; self.az = self.npz['acc_z']\n","        self.gx = self.npz['gyro_x']; self.gy = self.npz['gyro_y']; self.gz = self.npz['gyro_z']\n","        self.labels   = self.npz['labels'].astype(np.int64)\n","        self.splits   = np.array(self.npz['splits']).astype(str)\n","        self.subjects = np.array(self.npz['subjects']).astype(str)\n","        self.has_wid  = ('window_ids' in self.npz.files)\n","        if self.has_wid:\n","            self.win_ids = np.array(self.npz['window_ids']).astype(str)\n","\n","        T = self.ax.shape[1]\n","        idx_split = np.where(self.splits == split)[0]\n","\n","        self.seq_items = []\n","        if self.has_wid:\n","            groups = defaultdict(list)\n","            for idx in idx_split:\n","                f, seg, st = parse_window_id(self.win_ids[idx])\n","                groups[(self.subjects[idx], f, seg)].append((st, idx))\n","            for _, lst in groups.items():\n","                lst.sort(key=lambda x: x[0])\n","                order = [idx for _, idx in lst]\n","                if len(order) < seq_len: continue\n","                for i in range(0, len(order) - seq_len + 1, seq_stride):\n","                    seq_idx = order[i:i+seq_len]\n","                    center_idx = seq_idx[seq_len // 2]\n","                    label = int(self.labels[center_idx])\n","                    self.seq_items.append((seq_idx, center_idx, label))\n","        else:\n","            # Fallback: group by subject only, preserve original order within the split\n","            subj_list = np.unique(self.subjects[idx_split])\n","            for subj in subj_list:\n","                subj_idx = idx_split[self.subjects[idx_split] == subj]\n","                order = subj_idx.tolist()\n","                if len(order) < seq_len: continue\n","                for i in range(0, len(order) - seq_len + 1, seq_stride):\n","                    seq_idx = order[i:i+seq_len]\n","                    center_idx = seq_idx[seq_len // 2]\n","                    label = int(self.labels[center_idx])\n","                    self.seq_items.append((seq_idx, center_idx, label))\n","\n","    def __len__(self): return len(self.seq_items)\n","\n","    def __getitem__(self, i):\n","        seq_idx, center_idx, label = self.seq_items[i]\n","        L = len(seq_idx); C = 6; T = self.ax.shape[1]\n","        X = np.zeros((L, C, T), dtype=np.float32)\n","        for j, idx in enumerate(seq_idx):\n","            X[j,0,:] = self.ax[idx]; X[j,1,:] = self.ay[idx]; X[j,2,:] = self.az[idx]\n","            X[j,3,:] = self.gx[idx]; X[j,4,:] = self.gy[idx]; X[j,5,:] = self.gz[idx]\n","        return torch.from_numpy(X), torch.tensor(label, dtype=torch.long), center_idx\n","\n","def collate_fn(batch):\n","    xs, ys, centers = zip(*batch)\n","    return torch.stack(xs), torch.stack(ys), torch.tensor(centers, dtype=torch.long)\n","\n","# ----- Model (unchanged structure and hyperparameters) -----\n","class DepthwiseSeparableConv1d(nn.Module):\n","    def __init__(self, in_ch, out_ch, k, dilation=1, dropout=0.0):\n","        super().__init__()\n","        pad = (k // 2) * dilation\n","        self.dw = nn.Conv1d(in_ch, in_ch, kernel_size=k, padding=pad, dilation=dilation, groups=in_ch, bias=False)\n","        self.pw = nn.Conv1d(in_ch, out_ch, kernel_size=1, bias=False)\n","        self.bn = nn.BatchNorm1d(out_ch)\n","        self.act = nn.GELU()\n","        self.drop = nn.Dropout(dropout)\n","    def forward(self, x):\n","        x = self.dw(x); x = self.pw(x); x = self.bn(x); x = self.act(x)\n","        return self.drop(x)\n","\n","class WindowEncoder(nn.Module):\n","    def __init__(self, in_ch=6, d_model=128, dropout=0.2):\n","        super().__init__()\n","        self.in_ch = in_ch; self.aug_ch = in_ch + 2\n","        self.b1 = DepthwiseSeparableConv1d(self.aug_ch, d_model//2, k=9,  dilation=1, dropout=dropout)\n","        self.b2 = DepthwiseSeparableConv1d(self.aug_ch, d_model//2, k=19, dilation=2, dropout=dropout)\n","        self.mix = nn.Conv1d(d_model, d_model, kernel_size=1, bias=False)\n","        self.bn  = nn.BatchNorm1d(d_model); self.act = nn.GELU(); self.drop= nn.Dropout(dropout)\n","        self.g_proj = nn.Sequential(nn.Linear(4, d_model), nn.GELU(), nn.Linear(d_model, d_model))\n","    def forward(self, x):\n","        BLT, C, T = x.shape\n","        acc_norm = torch.sqrt((x[:,0,:]**2 + x[:,1,:]**2 + x[:,2,:]**2) + 1e-8).unsqueeze(1)\n","        gyr_norm = torch.sqrt((x[:,3,:]**2 + x[:,4,:]**2 + x[:,5,:]**2) + 1e-8).unsqueeze(1)\n","        x_aug = torch.cat([x, acc_norm, gyr_norm], dim=1)\n","        z = torch.cat([self.b1(x_aug), self.b2(x_aug)], dim=1)\n","        z = self.mix(z); z = self.bn(z); z = self.act(z); z = self.drop(z)\n","        token = z.mean(dim=-1)\n","        acc_rms = acc_norm.squeeze(1).pow(2).mean(dim=-1).sqrt()\n","        gyr_rms = gyr_norm.squeeze(1).pow(2).mean(dim=-1).sqrt()\n","        acc_en  = x[:,0:3,:].pow(2).mean(dim=(1,2)).sqrt()\n","        gyr_en  = x[:,3:6,:].pow(2).mean(dim=(1,2)).sqrt()\n","        g = torch.stack([acc_rms, gyr_rms, acc_en, gyr_en], dim=-1)\n","        g = self.g_proj(g)\n","        return token, g\n","\n","class CondLayerNorm(nn.Module):\n","    def __init__(self, d_model):\n","        super().__init__()\n","        self.ln = nn.LayerNorm(d_model)\n","        self.gamma = nn.Linear(d_model, d_model)\n","        self.beta  = nn.Linear(d_model, d_model)\n","    def forward(self, x, g):\n","        y = self.ln(x)\n","        return y * (1 + self.gamma(g)) + self.beta(g)\n","\n","class RCCBlock(nn.Module):\n","    def __init__(self, d_model=128, n_heads=4, d_ff=512, dropout=0.2):\n","        super().__init__()\n","        self.condln1 = CondLayerNorm(d_model)\n","        self.mha = nn.MultiheadAttention(d_model, n_heads, dropout=dropout, batch_first=True)\n","        self.drop1 = nn.Dropout(dropout)\n","        self.condln2 = CondLayerNorm(d_model)\n","        self.ff = nn.Sequential(\n","            nn.Linear(d_model, d_ff), nn.GELU(), nn.Dropout(dropout),\n","            nn.Linear(d_ff, d_model)\n","        )\n","        self.drop2 = nn.Dropout(dropout)\n","    def forward(self, x, g):\n","        y = self.condln1(x, g)\n","        attn, _ = self.mha(y, y, y, need_weights=False)\n","        x = x + self.drop1(attn)\n","        y = self.condln2(x, g)\n","        y = self.ff(y)\n","        x = x + self.drop2(y)\n","        return x\n","\n","class GeoContextHAR(nn.Module):\n","    def __init__(self, in_ch=6, d_model=128, n_layers=2, n_heads=4, d_ff=512, dropout=0.2, seq_len=8, num_classes=8):\n","        super().__init__()\n","        self.seq_len = seq_len\n","        self.encoder = WindowEncoder(in_ch=in_ch, d_model=d_model, dropout=dropout)\n","        self.cls_token = nn.Parameter(torch.zeros(1, 1, d_model))\n","        self.pos = nn.Parameter(torch.zeros(1, seq_len + 1, d_model))\n","        self.blocks = nn.ModuleList([RCCBlock(d_model, n_heads, d_ff, dropout) for _ in range(n_layers)])\n","        self.norm = nn.LayerNorm(d_model)\n","        self.head = nn.Linear(d_model, num_classes)\n","        nn.init.trunc_normal_(self.pos, std=0.02)\n","        nn.init.trunc_normal_(self.cls_token, std=0.02)\n","    def forward(self, x):\n","        B, L, C, T = x.shape\n","        x = x.reshape(B*L, C, T)\n","        token, g = self.encoder(x)\n","        token = token.view(B, L, -1)\n","        g     = g.view(B, L, -1)\n","        cls = self.cls_token.expand(B, -1, -1)\n","        z = torch.cat([cls, token], dim=1)\n","        g_cls = g.mean(dim=1, keepdim=True)\n","        g_all = torch.cat([g_cls, g], dim=1)\n","        z = z + self.pos\n","        for blk in self.blocks:\n","            z = blk(z, g_all)\n","        z = self.norm(z)\n","        cls = z[:, 0, :]\n","        logits = self.head(cls)\n","        return logits\n","\n","# Build test loader (sequence unit)\n","test_ds = SeqDataset(npz_path, split=\"test\", seq_len=SEQ_LEN, seq_stride=SEQ_STRIDE)\n","test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True, collate_fn=collate_fn)\n","\n","# Derive per-call total windows and window_seconds\n","FS = 50.0\n","WINDOW_SAMPLES = int(test_ds.ax.shape[1])\n","WINDOW_SECONDS = float(WINDOW_SAMPLES / FS)\n","\n","# Instantiate the model (unchanged); eval mode\n","model = GeoContextHAR(in_ch=6, d_model=D_MODEL, n_layers=N_LAYERS, n_heads=N_HEADS,\n","                      d_ff=D_FF, dropout=DROPOUT, seq_len=SEQ_LEN, num_classes=NUM_CLASSES).to(device).eval()\n","\n","# Optional: load weights (does not affect energy/FLOPs)\n","models_dir = BASE / \"models\"; models_dir.mkdir(parents=True, exist_ok=True)\n","wpath = models_dir / \"rccmix_har_fold0.pt\"\n","if wpath.exists():\n","    try:\n","        sd = torch.load(wpath, map_location=device)\n","        if isinstance(sd, dict): model.load_state_dict(sd); print(f\"[Info] Loaded weights: {wpath.name}\")\n","    except Exception as e:\n","        print(f\"[Warn] Failed to load weights: {e}\")\n","\n","# Build run_once: full pass over test sequences; total windows per call = n_sequences * SEQ_LEN\n","def make_runner(model: nn.Module, loader: DataLoader):\n","    n_sequences = len(loader.dataset)\n","    n_windows_per_call = n_sequences * SEQ_LEN\n","    @torch.no_grad()\n","    def run_once():\n","        for x, y, centers in loader:\n","            x = x.to(device, non_blocking=True)  # (B, L, C, T)\n","            _ = model(x)\n","        if torch.cuda.is_available(): torch.cuda.synchronize()\n","    return run_once, n_windows_per_call\n","\n","run_once, N_windows = make_runner(model, test_loader)\n","\n","# Idle power\n","logs_dir = BASE / \"logs\"; logs_dir.mkdir(parents=True, exist_ok=True)\n","print(\"\\n[Info] Sampling idle power for 20 s ...\")\n","P_idle_mW, _idle = sample_idle_power_mW(duration_s=20.0, dev_index=0, interval=0.02,\n","                                        save_csv=str(logs_dir/'power_idle_trace_rccmixhar.csv'))\n","print(f\"[Info] Mean idle power ~ {P_idle_mW:.1f} mW\")\n","\n","# Warmup & repeats\n","print(\"\\n[Warmup] warmup ...\")\n","run_once(); run_once()\n","repeats = calibrate_repeats(run_once, target_s=8.0, min_rep=3, max_rep=5000)\n","print(f\"[Info] repeats = {repeats} (windows per call = {N_windows}, window_seconds ≈ {WINDOW_SECONDS:.3f})\")\n","\n","# NVML measurement (per-window) + bootstrap CI\n","summary = measure_with_bootstrap(\n","    name=\"rccmixhar_inference_per_window\",\n","    run_once=run_once,\n","    n_windows=N_windows,\n","    repeats=repeats,\n","    n_runs=5,\n","    n_boot=1000,\n","    logdir=logs_dir\n",")\n","\n","# Save a compact CSV summary (mJ/ms per 3-second window)\n","df = pd.DataFrame([{\n","    \"model\": \"RCCMix-HAR (per-window unit)\",\n","    \"window_seconds\": WINDOW_SECONDS,\n","    \"mJ_per_3s_window_mean\": summary[\"mean_mJ_per_window\"],\n","    \"ci95_low_mJ\": summary[\"ci95_low_mJ\"],\n","    \"ci95_high_mJ\": summary[\"ci95_high_mJ\"],\n","    \"ms_per_3s_window_mean\": summary[\"mean_ms_per_window\"],\n","    \"windows_per_call\": N_windows,\n","    \"repeats\": repeats,\n","    \"idle_mW\": P_idle_mW\n","}])\n","df.to_csv(logs_dir/\"energy_summary_rccmixhar_per_3s_window.csv\", index=False)\n","print(\"\\n=== Done: GPU inference energy — mJ per 3-second window (Scheme 1) ===\")\n","print(df)\n","print(\"\\nArtifacts:\")\n","print(\"- logs/power_idle_trace_rccmixhar.csv\")\n","print(\"- logs/power_trace_rccmixhar_inference_per_window_run*.csv\")\n","print(\"- logs/energy_rccmixhar_inference_per_window.json\")\n","print(\"- logs/energy_summary_rccmixhar_per_3s_window.csv\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mi3JQQQBKPPk","executionInfo":{"status":"ok","timestamp":1763405593363,"user_tz":0,"elapsed":65234,"user":{"displayName":"yu Wu","userId":"12692660435918028293"}},"outputId":"7b89e166-9cd2-4ba9-815f-2059ec2cc6dd"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Mon Nov 17 18:52:08 2025       \n","+-----------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n","|-----------------------------------------+------------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                        |               MIG M. |\n","|=========================================+========================+======================|\n","|   0  NVIDIA A100-SXM4-80GB          Off |   00000000:00:05.0 Off |                    0 |\n","| N/A   32C    P0             60W /  400W |   26403MiB /  81920MiB |      0%      Default |\n","|                                         |                        |             Disabled |\n","+-----------------------------------------+------------------------+----------------------+\n","                                                                                         \n","+-----------------------------------------------------------------------------------------+\n","| Processes:                                                                              |\n","|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n","|        ID   ID                                                               Usage      |\n","|=========================================================================================|\n","+-----------------------------------------------------------------------------------------+\n","\n","\n","Step 10: RCCMix-HAR — per-window energy measurement\n","================================================================================\n","Using device: cuda\n","\n","[Info] Sampling idle power for 20 s ...\n","[Info] Mean idle power ~ 60586.5 mW\n","\n","[Warmup] warmup ...\n","[Info] repeats = 44 (windows per call = 1592, window_seconds ≈ 3.000)\n","[Measure] rccmixhar_inference_per_window run 1/5 ...\n","[Measure] rccmixhar_inference_per_window run 2/5 ...\n","[Measure] rccmixhar_inference_per_window run 3/5 ...\n","[Measure] rccmixhar_inference_per_window run 4/5 ...\n","[Measure] rccmixhar_inference_per_window run 5/5 ...\n","[Result] rccmixhar_inference_per_window: 0.277 mJ per window (95% CI [0.154, 0.508]); 0.114 ms per window\n","\n","=== Done: GPU inference energy — mJ per 3-second window (Scheme 1) ===\n","                          model  window_seconds  mJ_per_3s_window_mean  \\\n","0  RCCMix-HAR (per-window unit)             3.0               0.277009   \n","\n","   ci95_low_mJ  ci95_high_mJ  ms_per_3s_window_mean  windows_per_call  \\\n","0     0.154494      0.507688                0.11443              1592   \n","\n","   repeats       idle_mW  \n","0       44  60586.494306  \n","\n","Artifacts:\n","- logs/power_idle_trace_rccmixhar.csv\n","- logs/power_trace_rccmixhar_inference_per_window_run*.csv\n","- logs/energy_rccmixhar_inference_per_window.json\n","- logs/energy_summary_rccmixhar_per_3s_window.csv\n"]}]}]}