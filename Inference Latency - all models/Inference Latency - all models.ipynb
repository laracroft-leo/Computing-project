{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyOh3wfZYxxfdVfZpxH31z4N"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Test sequence:\n","1. lightweight RCCMix\n","2. RCCMix-HAR++\n","3. Knn\n","4. Random forest\n","5. InceptionTime\n","6. minirocket\n","7. minirocket(Deployment-Friendly)\n","8. TST\n","9. lightweight rTsfNet\n","10. rTsfNet\n","11. DeepConvContext – LSTM variant – 1-layer – bidirectional\n","12. DeepConvContext-LSTM (unidirectional, 1-layer)\n","13. DeepConvContext Bi‑Attention"],"metadata":{"id":"KWLPlBpPIqbO"}},{"cell_type":"markdown","source":["1.lightweight RCCMix"],"metadata":{"id":"HxraSgAFJq-2"}},{"cell_type":"code","source":["# ================ Step 10: RCCMix-HAR CPU Inference Latency Benchmark (Standalone) ================\n","import os\n","os.environ.setdefault(\"OMP_NUM_THREADS\", \"1\")\n","os.environ.setdefault(\"MKL_NUM_THREADS\", \"1\")\n","os.environ.setdefault(\"OPENBLAS_NUM_THREADS\", \"1\")\n","\n","import time\n","import random\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","\n","print(\"\\n[Step 10: RCCMix-HAR CPU Inference Latency Benchmark]\")\n","\n","# ---------------------------\n","# 0) Basic configuration\n","# ---------------------------\n","SEED = 42\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","if torch.cuda.is_available():\n","    torch.cuda.manual_seed_all(SEED)\n","\n","device = torch.device(\"cpu\")\n","torch.set_num_threads(1)\n","\n","print(f\"Using device: {device}\")\n","print(f\"torch.get_num_threads() = {torch.get_num_threads()}\")\n","\n","# Hyperparameters (must match Step 10)\n","SEQ_LEN        = 8        # number of consecutive windows per sequence\n","WINDOW_SAMPLES = 150      # samples per window (e.g., 3 s @ 50 Hz)\n","IN_CHANNELS    = 6        # 3D acc + 3D gyro\n","D_MODEL        = 128\n","N_HEADS        = 4\n","N_LAYERS       = 2\n","D_FF           = 4 * D_MODEL\n","DROPOUT        = 0.2\n","NUM_CLASSES    = 8\n","\n","print(f\"SEQ_LEN={SEQ_LEN}, WINDOW_SAMPLES={WINDOW_SAMPLES}, IN_CHANNELS={IN_CHANNELS}\")\n","print(f\"D_MODEL={D_MODEL}, N_LAYERS={N_LAYERS}, N_HEADS={N_HEADS}, NUM_CLASSES={NUM_CLASSES}\")\n","\n","\n","# ---------------------------\n","# 1) Model definition (exactly as in Step 10)\n","# ---------------------------\n","class DepthwiseSeparableConv1d(nn.Module):\n","    def __init__(self, in_ch, out_ch, k, dilation=1, dropout=0.0):\n","        super().__init__()\n","        pad = (k // 2) * dilation\n","        self.dw = nn.Conv1d(\n","            in_ch,\n","            in_ch,\n","            kernel_size=k,\n","            padding=pad,\n","            dilation=dilation,\n","            groups=in_ch,\n","            bias=False,\n","        )\n","        self.pw = nn.Conv1d(in_ch, out_ch, kernel_size=1, bias=False)\n","        self.bn = nn.BatchNorm1d(out_ch)\n","        self.act = nn.GELU()\n","        self.drop = nn.Dropout(dropout)\n","\n","    def forward(self, x):\n","        x = self.dw(x)\n","        x = self.pw(x)\n","        x = self.bn(x)\n","        x = self.act(x)\n","        return self.drop(x)\n","\n","\n","class WindowEncoder(nn.Module):\n","    \"\"\"\n","    rTsfNet-style per-window representation:\n","      - Axis-group enhancement: L2-norm channels of acc/gyro\n","      - Multi-scale depthwise separable convolution branches\n","      - Global pooling over time -> window token\n","      - Geometric conditioning vector g (RMS & energy stats)\n","    \"\"\"\n","    def __init__(self, in_ch=6, d_model=128, dropout=0.2):\n","        super().__init__()\n","        self.in_ch = in_ch\n","        self.aug_ch = in_ch + 2   # + acc_norm + gyro_norm\n","\n","        # Multi-scale branches\n","        self.b1 = DepthwiseSeparableConv1d(self.aug_ch, d_model // 2, k=9,  dilation=1, dropout=dropout)\n","        self.b2 = DepthwiseSeparableConv1d(self.aug_ch, d_model // 2, k=19, dilation=2, dropout=dropout)\n","        self.mix = nn.Conv1d(d_model, d_model, kernel_size=1, bias=False)\n","        self.bn  = nn.BatchNorm1d(d_model)\n","        self.act = nn.GELU()\n","        self.drop= nn.Dropout(dropout)\n","\n","        # Geometric conditioning vector: RMS & energy (4-dim) -> d_model\n","        self.g_proj = nn.Sequential(\n","            nn.Linear(4, d_model),\n","            nn.GELU(),\n","            nn.Linear(d_model, d_model),\n","        )\n","\n","    def forward(self, x):\n","        # x: [B*L, 6, T]\n","        bl, c, t = x.shape\n","\n","        # Norm channels\n","        acc_norm = torch.sqrt(\n","            x[:, 0, :] ** 2 + x[:, 1, :] ** 2 + x[:, 2, :] ** 2 + 1e-8\n","        ).unsqueeze(1)  # [BL,1,T]\n","        gyr_norm = torch.sqrt(\n","            x[:, 3, :] ** 2 + x[:, 4, :] ** 2 + x[:, 5, :] ** 2 + 1e-8\n","        ).unsqueeze(1)  # [BL,1,T]\n","\n","        x_aug = torch.cat([x, acc_norm, gyr_norm], dim=1)  # [BL,8,T]\n","\n","        # Multi-scale branches + fusion\n","        z = torch.cat([self.b1(x_aug), self.b2(x_aug)], dim=1)  # [BL, d_model, T]\n","        z = self.mix(z)\n","        z = self.bn(z)\n","        z = self.act(z)\n","        z = self.drop(z)\n","\n","        # Global average pooling over time → window token\n","        token = z.mean(dim=-1)  # [BL, d_model]\n","\n","        # Geometric conditioning stats (RMS & energy)\n","        acc_rms = acc_norm.squeeze(1).pow(2).mean(dim=-1).sqrt()\n","        gyr_rms = gyr_norm.squeeze(1).pow(2).mean(dim=-1).sqrt()\n","        acc_en  = x[:, 0:3, :].pow(2).mean(dim=(1, 2)).sqrt()\n","        gyr_en  = x[:, 3:6, :].pow(2).mean(dim=(1, 2)).sqrt()\n","\n","        g = torch.stack([acc_rms, gyr_rms, acc_en, gyr_en], dim=-1)  # [BL, 4]\n","        g = self.g_proj(g)  # [BL, d_model]\n","\n","        return token, g\n","\n","\n","class CondLayerNorm(nn.Module):\n","    \"\"\" FiLM-style conditional LayerNorm: LN(x) * (1 + gamma(g)) + beta(g) \"\"\"\n","    def __init__(self, d_model):\n","        super().__init__()\n","        self.ln = nn.LayerNorm(d_model)\n","        self.gamma = nn.Linear(d_model, d_model)\n","        self.beta  = nn.Linear(d_model, d_model)\n","\n","    def forward(self, x, g):\n","        # x, g: [B, L, d]\n","        y = self.ln(x)\n","        return y * (1.0 + self.gamma(g)) + self.beta(g)\n","\n","\n","class RCCBlock(nn.Module):\n","    \"\"\" Rotation-conditioned Transformer encoder block \"\"\"\n","    def __init__(self, d_model=128, n_heads=4, d_ff=512, dropout=0.2):\n","        super().__init__()\n","        self.condln1 = CondLayerNorm(d_model)\n","        self.mha = nn.MultiheadAttention(\n","            d_model,\n","            n_heads,\n","            dropout=dropout,\n","            batch_first=True,\n","        )\n","        self.drop1 = nn.Dropout(dropout)\n","\n","        self.condln2 = CondLayerNorm(d_model)\n","        self.ff = nn.Sequential(\n","            nn.Linear(d_model, d_ff),\n","            nn.GELU(),\n","            nn.Dropout(dropout),\n","            nn.Linear(d_ff, d_model),\n","        )\n","        self.drop2 = nn.Dropout(dropout)\n","\n","    def forward(self, x, g):\n","        # x, g: [B, L+1, d]\n","        y = self.condln1(x, g)\n","        attn, _ = self.mha(y, y, y, need_weights=False)\n","        x = x + self.drop1(attn)\n","\n","        y = self.condln2(x, g)\n","        y = self.ff(y)\n","        x = x + self.drop2(y)\n","        return x\n","\n","\n","class GeoContextHAR(nn.Module):\n","    \"\"\" Window encoder + rotation-conditioned context + CLS classification head \"\"\"\n","    def __init__(\n","        self,\n","        in_ch=6,\n","        d_model=128,\n","        n_layers=2,\n","        n_heads=4,\n","        d_ff=512,\n","        dropout=0.2,\n","        seq_len=8,\n","        num_classes=8,\n","    ):\n","        super().__init__()\n","        self.seq_len = seq_len\n","        self.encoder = WindowEncoder(in_ch=in_ch, d_model=d_model, dropout=dropout)\n","        self.cls_token = nn.Parameter(torch.zeros(1, 1, d_model))\n","        self.pos = nn.Parameter(torch.zeros(1, seq_len + 1, d_model))\n","        self.blocks = nn.ModuleList(\n","            [RCCBlock(d_model, n_heads, d_ff, dropout) for _ in range(n_layers)]\n","        )\n","        self.norm = nn.LayerNorm(d_model)\n","        self.head = nn.Linear(d_model, num_classes)\n","\n","        nn.init.trunc_normal_(self.pos, std=0.02)\n","        nn.init.trunc_normal_(self.cls_token, std=0.02)\n","\n","    def forward(self, x):\n","        # x: [B, L, C, T]\n","        b, l, c, t = x.shape\n","        x = x.view(b * l, c, t)\n","        token, g = self.encoder(x)              # [B*L, d], [B*L, d]\n","        token = token.view(b, l, -1)            # [B, L, d]\n","        g     = g.view(b, l, -1)                # [B, L, d]\n","\n","        # Append CLS token and global condition g_cls\n","        cls = self.cls_token.expand(b, 1, -1)   # [B, 1, d]\n","        z = torch.cat([cls, token], dim=1)      # [B, L+1, d]\n","        g_cls = g.mean(dim=1, keepdim=True)     # [B, 1, d]\n","        g_all = torch.cat([g_cls, g], dim=1)    # [B, L+1, d]\n","\n","        # Positional encoding\n","        z = z + self.pos\n","\n","        # Conditional Transformer blocks\n","        for blk in self.blocks:\n","            z = blk(z, g_all)\n","\n","        z = self.norm(z)\n","        cls_rep = z[:, 0, :]                   # [B, d]\n","        logits = self.head(cls_rep)            # [B, num_classes]\n","        return logits\n","\n","\n","# ---------------------------\n","# 2) Utility: parameter count\n","# ---------------------------\n","def count_parameters(model: nn.Module) -> int:\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","\n","# ---------------------------\n","# 3) Utility: latency measurement on CPU\n","# ---------------------------\n","def measure_latency(\n","    model: nn.Module,\n","    input_shape,\n","    device: torch.device,\n","    n_warmup: int = 20,\n","    n_runs: int = 100,\n","):\n","    \"\"\"\n","    Measure pure forward-pass latency on CPU.\n","    Returns latency stats in milliseconds per sequence (B, L, C, T).\n","    \"\"\"\n","    model = model.to(device)\n","    model.eval()\n","    torch.set_grad_enabled(False)\n","\n","    x = torch.randn(*input_shape, device=device, dtype=torch.float32)\n","\n","    # Warm-up\n","    for _ in range(n_warmup):\n","        _ = model(x)\n","\n","    # Timed runs\n","    times_ms = []\n","    for _ in range(n_runs):\n","        t0 = time.perf_counter()\n","        _ = model(x)\n","        t1 = time.perf_counter()\n","        times_ms.append((t1 - t0) * 1000.0)\n","\n","    times_ms = np.array(times_ms, dtype=float)\n","    stats = {\n","        \"sequence_latency_p50_ms\": float(np.percentile(times_ms, 50)),\n","        \"sequence_latency_p90_ms\": float(np.percentile(times_ms, 90)),\n","        \"sequence_latency_mean_ms\": float(times_ms.mean()),\n","        \"sequence_latency_std_ms\":  float(times_ms.std()),\n","        \"n_runs\": int(n_runs),\n","    }\n","    return stats\n","\n","\n","# ---------------------------\n","# 4) Instantiate model and run benchmark\n","# ---------------------------\n","model = GeoContextHAR(\n","    in_ch=IN_CHANNELS,\n","    d_model=D_MODEL,\n","    n_layers=N_LAYERS,\n","    n_heads=N_HEADS,\n","    d_ff=D_FF,\n","    dropout=DROPOUT,\n","    seq_len=SEQ_LEN,\n","    num_classes=NUM_CLASSES,\n",")\n","\n","n_params = count_parameters(model)\n","print(f\"Number of trainable parameters: {n_params:,}\")\n","\n","# Batch size for latency measurement\n","BATCH_SIZE = 1  # sequence-level model: one sequence = 8 windows\n","\n","input_shape = (BATCH_SIZE, SEQ_LEN, IN_CHANNELS, WINDOW_SAMPLES)\n","print(f\"\\nMeasuring CPU latency with input shape: {input_shape} (B, L, C, T)\")\n","\n","stats = measure_latency(\n","    model,\n","    input_shape=input_shape,\n","    device=device,\n","    n_warmup=20,\n","    n_runs=100,\n",")\n","\n","print(\"\\nCPU latency stats per sequence (8 windows):\")\n","for k, v in stats.items():\n","    if k.endswith(\"_ms\"):\n","        print(f\"  {k}: {v:.4f}\")\n","    else:\n","        print(f\"  {k}: {v}\")\n","\n","# Convert sequence latency → per-window latency (divide by SEQ_LEN=8)\n","per_window_p50  = stats[\"sequence_latency_p50_ms\"]  / SEQ_LEN\n","per_window_p90  = stats[\"sequence_latency_p90_ms\"]  / SEQ_LEN\n","per_window_mean = stats[\"sequence_latency_mean_ms\"] / SEQ_LEN\n","\n","print(\"\\nApproximate CPU latency per window (HAR window, 3 s @ 50 Hz):\")\n","print(f\"  window_latency_p50_ms  ≈ {per_window_p50:.4f}\")\n","print(f\"  window_latency_p90_ms  ≈ {per_window_p90:.4f}\")\n","print(f\"  window_latency_mean_ms ≈ {per_window_mean:.4f}\")\n","\n","print(\"\\n[RCCMix-HAR Step 10 CPU latency benchmark completed]\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TJIr4yZII8Ub","executionInfo":{"status":"ok","timestamp":1763455520848,"user_tz":0,"elapsed":693,"user":{"displayName":"yu Wu","userId":"12692660435918028293"}},"outputId":"4bd7f056-d4f2-4c32-e8d3-cdc07c7269f6"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","[Step 10: RCCMix-HAR CPU Inference Latency Benchmark]\n","Using device: cpu\n","torch.get_num_threads() = 1\n","SEQ_LEN=8, WINDOW_SAMPLES=150, IN_CHANNELS=6\n","D_MODEL=128, N_LAYERS=2, N_HEADS=4, NUM_CLASSES=8\n","Number of trainable parameters: 566,504\n","\n","Measuring CPU latency with input shape: (1, 8, 6, 150) (B, L, C, T)\n","\n","CPU latency stats per sequence (8 windows):\n","  sequence_latency_p50_ms: 5.5079\n","  sequence_latency_p90_ms: 5.8094\n","  sequence_latency_mean_ms: 5.5643\n","  sequence_latency_std_ms: 0.2565\n","  n_runs: 100\n","\n","Approximate CPU latency per window (HAR window, 3 s @ 50 Hz):\n","  window_latency_p50_ms  ≈ 0.6885\n","  window_latency_p90_ms  ≈ 0.7262\n","  window_latency_mean_ms ≈ 0.6955\n","\n","[RCCMix-HAR Step 10 CPU latency benchmark completed]\n"]}]},{"cell_type":"markdown","source":["2.RCCMix-HAR++"],"metadata":{"id":"n8dMOUbOJvrA"}},{"cell_type":"code","source":["# ================ Step 11: RCCMix-HAR++ CPU Inference Latency Benchmark (Standalone) ================\n","import os\n","os.environ.setdefault(\"OMP_NUM_THREADS\", \"1\")\n","os.environ.setdefault(\"MKL_NUM_THREADS\", \"1\")\n","os.environ.setdefault(\"OPENBLAS_NUM_THREADS\", \"1\")\n","\n","import time\n","import math\n","import random\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","\n","print(\"\\n[Step 11: RCCMix-HAR++ CPU Inference Latency Benchmark]\")\n","\n","# ---------------------------\n","# 0) Basic configuration\n","# ---------------------------\n","SEED = 42\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","if torch.cuda.is_available():\n","    torch.cuda.manual_seed_all(SEED)\n","\n","# Use CPU explicitly\n","device = torch.device(\"cpu\")\n","torch.set_num_threads(1)\n","\n","print(f\"Using device: {device}\")\n","print(f\"torch.get_num_threads() = {torch.get_num_threads()}\")\n","\n","# Hyperparameters (must match Step 11)\n","SEQ_LEN        = 8        # number of consecutive windows per sequence\n","WINDOW_SAMPLES = 150      # samples per window (e.g., 3s @ 50Hz)\n","IN_CHANNELS    = 6        # 3D acc + 3D gyro\n","D_MODEL        = 192      # divisible by 3\n","N_HEADS        = 6\n","N_LAYERS       = 3\n","D_FF           = 4 * D_MODEL\n","DROPOUT        = 0.2\n","NUM_CLASSES    = 8        # number of activity classes\n","\n","print(f\"SEQ_LEN={SEQ_LEN}, WINDOW_SAMPLES={WINDOW_SAMPLES}, IN_CHANNELS={IN_CHANNELS}\")\n","print(f\"D_MODEL={D_MODEL}, N_LAYERS={N_LAYERS}, N_HEADS={N_HEADS}, NUM_CLASSES={NUM_CLASSES}\")\n","\n","\n","# ---------------------------\n","# 1) Model definition (exactly as in Step 11)\n","# ---------------------------\n","class DepthwiseSeparableConv1d(nn.Module):\n","    def __init__(self, in_ch, out_ch, k, dilation=1, dropout=0.0):\n","        super().__init__()\n","        pad = (k // 2) * dilation\n","        self.dw = nn.Conv1d(\n","            in_ch,\n","            in_ch,\n","            kernel_size=k,\n","            padding=pad,\n","            dilation=dilation,\n","            groups=in_ch,\n","            bias=False,\n","        )\n","        self.pw = nn.Conv1d(in_ch, out_ch, kernel_size=1, bias=False)\n","        self.bn = nn.BatchNorm1d(out_ch)\n","        self.act = nn.GELU()\n","        self.drop = nn.Dropout(dropout)\n","\n","    def forward(self, x):\n","        x = self.dw(x)\n","        x = self.pw(x)\n","        x = self.bn(x)\n","        x = self.act(x)\n","        return self.drop(x)\n","\n","\n","class SEBlock(nn.Module):\n","    \"\"\"Channel attention applied to the 8 channels\"\"\"\n","    def __init__(self, ch, reduction=4):\n","        super().__init__()\n","        self.pool = nn.AdaptiveAvgPool1d(1)\n","        hidden = max(1, ch // reduction)\n","        self.fc = nn.Sequential(\n","            nn.Linear(ch, hidden, bias=False),\n","            nn.ReLU(inplace=True),\n","            nn.Linear(hidden, ch, bias=False),\n","            nn.Sigmoid(),\n","        )\n","\n","    def forward(self, x):\n","        # x: [B, C, T]\n","        b, c, t = x.shape\n","        s = self.pool(x).view(b, c)\n","        s = self.fc(s).view(b, c, 1)\n","        return x * s\n","\n","\n","class WindowEncoderV2(nn.Module):\n","    \"\"\"\n","    Improved per-window representation:\n","      - channel SE attention\n","      - 3-branch multi-scale depthwise conv\n","      - [avg + max] pooling token\n","      - 8-dimensional geometric conditioning vector g\n","    \"\"\"\n","    def __init__(self, in_ch=6, d_model=192, dropout=0.2):\n","        super().__init__()\n","        self.in_ch = in_ch\n","        self.aug_ch = in_ch + 2   # + acc_norm + gyro_norm\n","        self.se = SEBlock(self.aug_ch, reduction=4)\n","\n","        b_dim = d_model // 3\n","        assert b_dim * 3 == d_model, \"D_MODEL must be divisible by 3 for WindowEncoderV2\"\n","\n","        # Multi-scale branches\n","        self.b1 = DepthwiseSeparableConv1d(self.aug_ch, b_dim, k=7,  dilation=1, dropout=dropout)\n","        self.b2 = DepthwiseSeparableConv1d(self.aug_ch, b_dim, k=15, dilation=2, dropout=dropout)\n","        self.b3 = DepthwiseSeparableConv1d(self.aug_ch, b_dim, k=31, dilation=3, dropout=dropout)\n","\n","        self.mix = nn.Conv1d(d_model, d_model, kernel_size=1, bias=False)\n","        self.bn  = nn.BatchNorm1d(d_model)\n","        self.act = nn.GELU()\n","        self.drop= nn.Dropout(dropout)\n","\n","        # token pooling: [avg, max] -> 2*d_model projected back to d_model\n","        self.token_proj = nn.Sequential(\n","            nn.Linear(2 * d_model, d_model),\n","            nn.GELU(),\n","            nn.Dropout(dropout),\n","        )\n","\n","        # richer geometric conditioning (8-d stats)\n","        self.g_proj = nn.Sequential(\n","            nn.Linear(8, d_model),\n","            nn.GELU(),\n","            nn.Linear(d_model, d_model),\n","        )\n","\n","    def forward(self, x):\n","        # x: [B*L, 6, T]\n","        bl, c, t = x.shape\n","\n","        # norm channels\n","        acc_norm = torch.sqrt(\n","            x[:, 0, :] ** 2 + x[:, 1, :] ** 2 + x[:, 2, :] ** 2 + 1e-8\n","        ).unsqueeze(1)\n","        gyr_norm = torch.sqrt(\n","            x[:, 3, :] ** 2 + x[:, 4, :] ** 2 + x[:, 5, :] ** 2 + 1e-8\n","        ).unsqueeze(1)\n","\n","        x_aug = torch.cat([x, acc_norm, gyr_norm], dim=1)  # [BL, 8, T]\n","\n","        # channel-wise attention\n","        x_aug = self.se(x_aug)\n","\n","        # multi-scale conv\n","        z1 = self.b1(x_aug)\n","        z2 = self.b2(x_aug)\n","        z3 = self.b3(x_aug)\n","        z = torch.cat([z1, z2, z3], dim=1)  # [BL, d_model, T]\n","\n","        z = self.mix(z)\n","        z = self.bn(z)\n","        z = self.act(z)\n","        z = self.drop(z)\n","\n","        # dual pooling\n","        avg_pool = z.mean(dim=-1)\n","        max_pool, _ = z.max(dim=-1)\n","        token = torch.cat([avg_pool, max_pool], dim=-1)\n","        token = self.token_proj(token)  # [BL, d_model]\n","\n","        # geometric conditioning stats (8-dim)\n","        acc_rms = acc_norm.squeeze(1).pow(2).mean(dim=-1).sqrt()\n","        gyr_rms = gyr_norm.squeeze(1).pow(2).mean(dim=-1).sqrt()\n","\n","        acc_en  = x[:, 0:3, :].pow(2).mean(dim=(1, 2)).sqrt()\n","        gyr_en  = x[:, 3:6, :].pow(2).mean(dim=(1, 2)).sqrt()\n","\n","        acc_mean = x[:, 0:3, :].mean(dim=-1)\n","        gyr_mean = x[:, 3:6, :].mean(dim=-1)\n","        acc_mean_norm = acc_mean.pow(2).sum(dim=-1).sqrt()\n","        gyr_mean_norm = gyr_mean.pow(2).sum(dim=-1).sqrt()\n","\n","        acc_var = x[:, 0:3, :].var(dim=-1).mean(dim=-1)\n","        gyr_var = x[:, 3:6, :].var(dim=-1).mean(dim=-1)\n","\n","        g_raw = torch.stack(\n","            [\n","                acc_rms,\n","                gyr_rms,\n","                acc_en,\n","                gyr_en,\n","                acc_mean_norm,\n","                gyr_mean_norm,\n","                acc_var,\n","                gyr_var,\n","            ],\n","            dim=-1,\n","        )  # [BL, 8]\n","        g = self.g_proj(g_raw)  # [BL, d_model]\n","\n","        return token, g\n","\n","\n","class CondLayerNorm(nn.Module):\n","    \"\"\"FiLM-style conditional LayerNorm: LN(x) * (1 + gamma(g)) + beta(g)\"\"\"\n","    def __init__(self, d_model):\n","        super().__init__()\n","        self.ln = nn.LayerNorm(d_model)\n","        self.gamma = nn.Linear(d_model, d_model)\n","        self.beta  = nn.Linear(d_model, d_model)\n","\n","    def forward(self, x, g):\n","        y = self.ln(x)\n","        return y * (1.0 + self.gamma(g)) + self.beta(g)\n","\n","\n","class RCCBlock(nn.Module):\n","    \"\"\"Rotation-conditioned Transformer encoder block\"\"\"\n","    def __init__(self, d_model=192, n_heads=6, d_ff=768, dropout=0.2):\n","        super().__init__()\n","        self.condln1 = CondLayerNorm(d_model)\n","        self.mha = nn.MultiheadAttention(\n","            d_model,\n","            n_heads,\n","            dropout=dropout,\n","            batch_first=True,\n","        )\n","        self.drop1 = nn.Dropout(dropout)\n","\n","        self.condln2 = CondLayerNorm(d_model)\n","        self.ff = nn.Sequential(\n","            nn.Linear(d_model, d_ff),\n","            nn.GELU(),\n","            nn.Dropout(dropout),\n","            nn.Linear(d_ff, d_model),\n","        )\n","        self.drop2 = nn.Dropout(dropout)\n","\n","    def forward(self, x, g):\n","        # x, g: [B, L+1, d]\n","        y = self.condln1(x, g)\n","        attn, _ = self.mha(y, y, y, need_weights=False)\n","        x = x + self.drop1(attn)\n","\n","        y = self.condln2(x, g)\n","        y = self.ff(y)\n","        x = x + self.drop2(y)\n","        return x\n","\n","\n","class GeoContextHARV2(nn.Module):\n","    \"\"\"RCCMix-HAR++: WindowEncoderV2 + rotation-conditioned Transformer + [CLS||mean] head\"\"\"\n","    def __init__(\n","        self,\n","        in_ch=6,\n","        d_model=192,\n","        n_layers=3,\n","        n_heads=6,\n","        d_ff=768,\n","        dropout=0.2,\n","        seq_len=8,\n","        num_classes=8,\n","    ):\n","        super().__init__()\n","        self.seq_len = seq_len\n","        self.encoder = WindowEncoderV2(in_ch=in_ch, d_model=d_model, dropout=dropout)\n","        self.cls_token = nn.Parameter(torch.zeros(1, 1, d_model))\n","        self.pos = nn.Parameter(torch.zeros(1, seq_len + 1, d_model))\n","        self.blocks = nn.ModuleList(\n","            [RCCBlock(d_model, n_heads, d_ff, dropout) for _ in range(n_layers)]\n","        )\n","        self.norm = nn.LayerNorm(d_model)\n","        self.head_drop = nn.Dropout(dropout)\n","        # use [CLS || mean] representation\n","        self.head = nn.Linear(2 * d_model, num_classes)\n","\n","        nn.init.trunc_normal_(self.pos, std=0.02)\n","        nn.init.trunc_normal_(self.cls_token, std=0.02)\n","\n","    def forward(self, x):\n","        # x: [B, L, C, T]\n","        b, l, c, t = x.shape\n","        x = x.view(b * l, c, t)\n","        token, g = self.encoder(x)          # [B*L, d], [B*L, d]\n","        token = token.view(b, l, -1)        # [B, L, d]\n","        g     = g.view(b, l, -1)            # [B, L, d]\n","\n","        # CLS token + global g_cls\n","        cls = self.cls_token.expand(b, 1, -1)   # [B, 1, d]\n","        z = torch.cat([cls, token], dim=1)      # [B, L+1, d]\n","        g_cls = g.mean(dim=1, keepdim=True)     # [B, 1, d]\n","        g_all = torch.cat([g_cls, g], dim=1)    # [B, L+1, d]\n","\n","        # positional encoding\n","        z = z + self.pos\n","\n","        # conditional Transformer\n","        for blk in self.blocks:\n","            z = blk(z, g_all)\n","\n","        z = self.norm(z)\n","        cls_rep = z[:, 0, :]              # [B, d]\n","        mean_rep = z[:, 1:, :].mean(dim=1) # [B, d]\n","        feat = torch.cat([cls_rep, mean_rep], dim=-1)\n","        feat = self.head_drop(feat)\n","        logits = self.head(feat)          # [B, num_classes]\n","        return logits\n","\n","\n","# ---------------------------\n","# 2) Utility: parameter count\n","# ---------------------------\n","def count_parameters(model: nn.Module) -> int:\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","\n","# ---------------------------\n","# 3) Utility: latency measurement (CPU)\n","# ---------------------------\n","def _sync_device(dev: torch.device):\n","    # CPU execution is synchronous; nothing to do here.\n","    if dev.type == \"cuda\":\n","        torch.cuda.synchronize()\n","\n","\n","def measure_latency(\n","    model: nn.Module,\n","    input_shape,\n","    device: torch.device,\n","    n_warmup: int = 20,\n","    n_runs: int = 100,\n","):\n","    \"\"\"\n","    Measure pure forward-pass latency of the model (no data loading, no preprocessing).\n","    Returns latency stats in milliseconds per sequence.\n","    \"\"\"\n","    model = model.to(device)\n","    model.eval()\n","    torch.set_grad_enabled(False)\n","\n","    x = torch.randn(*input_shape, device=device, dtype=torch.float32)\n","\n","    # warm-up\n","    _sync_device(device)\n","    for _ in range(n_warmup):\n","        _ = model(x)\n","        _sync_device(device)\n","\n","    # timed runs\n","    times_ms = []\n","    for _ in range(n_runs):\n","        t0 = time.perf_counter()\n","        _ = model(x)\n","        _sync_device(device)\n","        t1 = time.perf_counter()\n","        times_ms.append((t1 - t0) * 1000.0)\n","\n","    times_ms = np.array(times_ms, dtype=float)\n","    stats = {\n","        \"sequence_latency_p50_ms\": float(np.percentile(times_ms, 50)),\n","        \"sequence_latency_p90_ms\": float(np.percentile(times_ms, 90)),\n","        \"sequence_latency_mean_ms\": float(times_ms.mean()),\n","        \"sequence_latency_std_ms\":  float(times_ms.std()),\n","        \"n_runs\": int(n_runs),\n","    }\n","    return stats\n","\n","\n","# ---------------------------\n","# 4) Instantiate model and run benchmark on CPU\n","# ---------------------------\n","model = GeoContextHARV2(\n","    in_ch=IN_CHANNELS,\n","    d_model=D_MODEL,\n","    n_layers=N_LAYERS,\n","    n_heads=N_HEADS,\n","    d_ff=D_FF,\n","    dropout=DROPOUT,\n","    seq_len=SEQ_LEN,\n","    num_classes=NUM_CLASSES,\n",")\n","\n","n_params = count_parameters(model)\n","print(f\"Number of trainable parameters: {n_params:,}\")\n","\n","# batch size for latency measurement\n","BATCH_SIZE = 1  # you can also try 2, 4, 8 for throughput analysis\n","\n","input_shape = (BATCH_SIZE, SEQ_LEN, IN_CHANNELS, WINDOW_SAMPLES)\n","print(f\"\\nMeasuring CPU latency with input shape: {input_shape} (B, L, C, T)\")\n","\n","stats = measure_latency(\n","    model,\n","    input_shape=input_shape,\n","    device=device,\n","    n_warmup=20,\n","    n_runs=100,\n",")\n","\n","print(\"\\nCPU latency stats (ms) per sequence (8 windows):\")\n","for k, v in stats.items():\n","    if k.endswith(\"_ms\"):\n","        print(f\"  {k}: {v:.4f}\")\n","    else:\n","        print(f\"  {k}: {v}\")\n","\n","per_window_p50 = stats[\"sequence_latency_p50_ms\"] / SEQ_LEN\n","per_window_p90 = stats[\"sequence_latency_p90_ms\"] / SEQ_LEN\n","per_window_mean = stats[\"sequence_latency_mean_ms\"] / SEQ_LEN\n","\n","print(\"\\nApproximate CPU latency per window (divide by SEQ_LEN=8):\")\n","print(f\"  window_latency_p50_ms  ≈ {per_window_p50:.4f}\")\n","print(f\"  window_latency_p90_ms  ≈ {per_window_p90:.4f}\")\n","print(f\"  window_latency_mean_ms ≈ {per_window_mean:.4f}\")\n","print(\"\\n[RCCMix-HAR++ Step 11 CPU latency benchmark completed]\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xko8PHqMc1NW","executionInfo":{"status":"ok","timestamp":1763451251534,"user_tz":0,"elapsed":7270,"user":{"displayName":"yu Wu","userId":"12692660435918028293"}},"outputId":"1cfa6139-9863-4124-855a-de0291980174"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","[Step 11: RCCMix-HAR++ CPU Inference Latency Benchmark]\n","Using device: cpu\n","torch.get_num_threads() = 1\n","SEQ_LEN=8, WINDOW_SAMPLES=150, IN_CHANNELS=6\n","D_MODEL=192, N_LAYERS=3, N_HEADS=6, NUM_CLASSES=8\n","Number of trainable parameters: 1,936,976\n","\n","Measuring CPU latency with input shape: (1, 8, 6, 150) (B, L, C, T)\n","\n","CPU latency stats (ms) per sequence (8 windows):\n","  sequence_latency_p50_ms: 12.2629\n","  sequence_latency_p90_ms: 15.5251\n","  sequence_latency_mean_ms: 12.8934\n","  sequence_latency_std_ms: 1.9676\n","  n_runs: 100\n","\n","Approximate CPU latency per window (divide by SEQ_LEN=8):\n","  window_latency_p50_ms  ≈ 1.5329\n","  window_latency_p90_ms  ≈ 1.9406\n","  window_latency_mean_ms ≈ 1.6117\n","\n","[RCCMix-HAR++ Step 11 CPU latency benchmark completed]\n"]}]},{"cell_type":"markdown","source":["3. Knn"],"metadata":{"id":"zG8abEDNJ8Vh"}},{"cell_type":"code","source":["# ================ KNN CPU Inference Latency Benchmark for HAR Windows (Standalone) ================\n","import os\n","os.environ.setdefault(\"OMP_NUM_THREADS\", \"1\")\n","os.environ.setdefault(\"MKL_NUM_THREADS\", \"1\")\n","os.environ.setdefault(\"OPENBLAS_NUM_THREADS\", \"1\")\n","\n","import time\n","import random\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","import numpy as np\n","from sklearn.neighbors import KNeighborsClassifier\n","\n","print(\"\\n[KNN CPU Inference Latency Benchmark for HAR Windows]\")\n","\n","# ---------------------------\n","# 0) Basic configuration\n","# ---------------------------\n","SEED = 42\n","random.seed(SEED)\n","np.random.seed(SEED)\n","\n","# HAR-like window settings: 6 channels, 150 time steps (e.g., 3 s @ 50 Hz)\n","N_CHANNELS   = 6\n","WINDOW_SAMPLES = 150\n","N_FEATURES   = N_CHANNELS * WINDOW_SAMPLES\n","\n","# Dataset scale for KNN (can be adjusted to match your real setting)\n","N_TRAIN   = 20000      # number of stored windows in the KNN \"training set\"\n","N_CLASSES = 8          # number of activity classes\n","\n","# Latency measurement settings\n","N_WARMUP  = 20\n","N_RUNS    = 200        # number of timed runs\n","BATCH_SIZE = 1         # number of query windows per call to predict()\n","\n","print(f\"N_TRAIN={N_TRAIN}, N_FEATURES={N_FEATURES}, N_CLASSES={N_CLASSES}\")\n","print(f\"N_WARMUP={N_WARMUP}, N_RUNS={N_RUNS}, BATCH_SIZE={BATCH_SIZE}\")\n","\n","# ---------------------------\n","# 1) Create synthetic HAR-like feature dataset\n","# ---------------------------\n","# Each sample represents one window, flattened: (6 channels × 150 samples) -> 900-dim vector.\n","X_train = np.random.randn(N_TRAIN, N_FEATURES).astype(np.float32)\n","y_train = np.random.randint(0, N_CLASSES, size=(N_TRAIN,), dtype=np.int32)\n","\n","print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n","\n","# ---------------------------\n","# 2) Define KNN model (typical HAR baseline configuration)\n","# ---------------------------\n","knn = KNeighborsClassifier(\n","    n_neighbors=5,\n","    weights=\"uniform\",   # or \"distance\" if you prefer\n","    metric=\"euclidean\",\n","    n_jobs=1,            # single-threaded for reproducible CPU latency\n",")\n","\n","# \"Training\" for KNN = storing the training set\n","t0_fit = time.perf_counter()\n","knn.fit(X_train, y_train)\n","t1_fit = time.perf_counter()\n","fit_time_ms = (t1_fit - t0_fit) * 1000.0\n","print(f\"\\nKNN fit (store training set) time: {fit_time_ms:.3f} ms\")\n","\n","# Approximate memory footprint of stored data (X + y)\n","memory_bytes = X_train.nbytes + y_train.nbytes\n","memory_mb = memory_bytes / (1024 ** 2)\n","print(f\"Approximate memory for stored data: {memory_mb:.3f} MB\")\n","\n","# ---------------------------\n","# 3) Utility: latency measurement on CPU\n","# ---------------------------\n","def measure_knn_latency(\n","    model: KNeighborsClassifier,\n","    feature_dim: int,\n","    batch_size: int = 1,\n","    n_warmup: int = 20,\n","    n_runs: int = 200,\n","):\n","    \"\"\"\n","    Measure pure KNN.predict() latency on CPU.\n","    Each query corresponds to one HAR window flattened to a feature vector.\n","    Returns latency stats in milliseconds per batch (i.e., per call to predict()).\n","    \"\"\"\n","    # Synthetic query batch (fixed to avoid cache effects from data allocation)\n","    X_query = np.random.randn(batch_size, feature_dim).astype(np.float32)\n","\n","    # Warm-up\n","    for _ in range(n_warmup):\n","        _ = model.predict(X_query)\n","\n","    # Timed runs\n","    times_ms = []\n","    for _ in range(n_runs):\n","        t0 = time.perf_counter()\n","        _ = model.predict(X_query)\n","        t1 = time.perf_counter()\n","        times_ms.append((t1 - t0) * 1000.0)\n","\n","    times_ms = np.array(times_ms, dtype=float)\n","    stats = {\n","        \"batch_latency_p50_ms\": float(np.percentile(times_ms, 50)),\n","        \"batch_latency_p90_ms\": float(np.percentile(times_ms, 90)),\n","        \"batch_latency_mean_ms\": float(times_ms.mean()),\n","        \"batch_latency_std_ms\":  float(times_ms.std()),\n","        \"n_runs\": int(n_runs),\n","        \"batch_size\": int(batch_size),\n","    }\n","    return stats\n","\n","\n","# ---------------------------\n","# 4) Run KNN CPU latency benchmark\n","# ---------------------------\n","stats = measure_knn_latency(\n","    knn,\n","    feature_dim=N_FEATURES,\n","    batch_size=BATCH_SIZE,\n","    n_warmup=N_WARMUP,\n","    n_runs=N_RUNS,\n",")\n","\n","print(\"\\nCPU latency stats for KNN.predict() (per batch):\")\n","for k, v in stats.items():\n","    if k.endswith(\"_ms\"):\n","        print(f\"  {k}: {v:.4f}\")\n","    else:\n","        print(f\"  {k}: {v}\")\n","\n","# Convert to \"per-window\" latency (since each sample = one HAR window)\n","per_window_p50  = stats[\"batch_latency_p50_ms\"]  / stats[\"batch_size\"]\n","per_window_p90  = stats[\"batch_latency_p90_ms\"]  / stats[\"batch_size\"]\n","per_window_mean = stats[\"batch_latency_mean_ms\"] / stats[\"batch_size\"]\n","\n","print(\"\\nApproximate CPU latency per window (HAR sample):\")\n","print(f\"  window_latency_p50_ms  ≈ {per_window_p50:.4f}\")\n","print(f\"  window_latency_p90_ms  ≈ {per_window_p90:.4f}\")\n","print(f\"  window_latency_mean_ms ≈ {per_window_mean:.4f}\")\n","\n","print(\"\\n[KNN CPU inference latency benchmark completed]\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HeH9pXoldZCP","executionInfo":{"status":"ok","timestamp":1763451289968,"user_tz":0,"elapsed":12825,"user":{"displayName":"yu Wu","userId":"12692660435918028293"}},"outputId":"1c7d142d-cd1e-454c-bb93-9da976c9888e"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","[KNN CPU Inference Latency Benchmark for HAR Windows]\n","N_TRAIN=20000, N_FEATURES=900, N_CLASSES=8\n","N_WARMUP=20, N_RUNS=200, BATCH_SIZE=1\n","X_train shape: (20000, 900), y_train shape: (20000,)\n","\n","KNN fit (store training set) time: 15.751 ms\n","Approximate memory for stored data: 68.741 MB\n","\n","CPU latency stats for KNN.predict() (per batch):\n","  batch_latency_p50_ms: 46.9475\n","  batch_latency_p90_ms: 48.5252\n","  batch_latency_mean_ms: 47.1534\n","  batch_latency_std_ms: 0.9841\n","  n_runs: 200\n","  batch_size: 1\n","\n","Approximate CPU latency per window (HAR sample):\n","  window_latency_p50_ms  ≈ 46.9475\n","  window_latency_p90_ms  ≈ 48.5252\n","  window_latency_mean_ms ≈ 47.1534\n","\n","[KNN CPU inference latency benchmark completed]\n"]}]},{"cell_type":"markdown","source":["4. Random forest"],"metadata":{"id":"EWpi0PA3J_tw"}},{"cell_type":"code","source":["# ================ Random Forest CPU Inference Latency Benchmark for HAR Windows (Standalone) ================\n","import os\n","os.environ.setdefault(\"OMP_NUM_THREADS\", \"1\")\n","os.environ.setdefault(\"MKL_NUM_THREADS\", \"1\")\n","os.environ.setdefault(\"OPENBLAS_NUM_THREADS\", \"1\")\n","\n","import time\n","import random\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","import numpy as np\n","from sklearn.ensemble import RandomForestClassifier\n","import pickle\n","\n","print(\"\\n[Random Forest CPU Inference Latency Benchmark for HAR Windows]\")\n","\n","# ---------------------------\n","# 0) Basic configuration\n","# ---------------------------\n","SEED = 42\n","random.seed(SEED)\n","np.random.seed(SEED)\n","\n","# HAR-like window settings: 6 channels, 150 time steps (e.g., 3 s @ 50 Hz)\n","N_CHANNELS      = 6\n","WINDOW_SAMPLES  = 150\n","N_FEATURES      = N_CHANNELS * WINDOW_SAMPLES\n","\n","# Dataset scale for Random Forest (can be adjusted to match your real setting)\n","N_TRAIN   = 20000      # number of training windows\n","N_CLASSES = 8          # number of activity classes\n","\n","# Latency measurement settings\n","N_WARMUP   = 20\n","N_RUNS     = 200        # number of timed runs\n","BATCH_SIZE = 1          # number of query windows per call to predict()\n","\n","print(f\"N_TRAIN={N_TRAIN}, N_FEATURES={N_FEATURES}, N_CLASSES={N_CLASSES}\")\n","print(f\"N_WARMUP={N_WARMUP}, N_RUNS={N_RUNS}, BATCH_SIZE={BATCH_SIZE}\")\n","\n","# ---------------------------\n","# 1) Create synthetic HAR-like feature dataset\n","# ---------------------------\n","# Each sample represents one window, flattened: (6 channels × 150 samples) -> 900-dim vector.\n","X_train = np.random.randn(N_TRAIN, N_FEATURES).astype(np.float32)\n","y_train = np.random.randint(0, N_CLASSES, size=(N_TRAIN,), dtype=np.int32)\n","\n","print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n","\n","# ---------------------------\n","# 2) Define Random Forest model (typical HAR baseline configuration)\n","# ---------------------------\n","rf = RandomForestClassifier(\n","    n_estimators=100,\n","    criterion=\"gini\",\n","    max_depth=None,\n","    min_samples_split=2,\n","    min_samples_leaf=1,\n","    max_features=\"sqrt\",\n","    bootstrap=True,\n","    n_jobs=1,             # single-threaded for reproducible CPU latency\n","    random_state=SEED,\n",")\n","\n","# Training Random Forest\n","t0_fit = time.perf_counter()\n","rf.fit(X_train, y_train)\n","t1_fit = time.perf_counter()\n","fit_time_ms = (t1_fit - t0_fit) * 1000.0\n","print(f\"\\nRandom Forest fit time: {fit_time_ms:.3f} ms\")\n","\n","# Approximate model size via pickle\n","model_bytes = len(pickle.dumps(rf))\n","model_mb = model_bytes / (1024 ** 2)\n","print(f\"Approximate Random Forest model size: {model_mb:.3f} MB\")\n","\n","# ---------------------------\n","# 3) Utility: latency measurement on CPU\n","# ---------------------------\n","def measure_rf_latency(\n","    model: RandomForestClassifier,\n","    feature_dim: int,\n","    batch_size: int = 1,\n","    n_warmup: int = 20,\n","    n_runs: int = 200,\n","):\n","    \"\"\"\n","    Measure pure RandomForest.predict() latency on CPU.\n","    Each query corresponds to one HAR window flattened to a feature vector.\n","    Returns latency stats in milliseconds per batch (i.e., per call to predict()).\n","    \"\"\"\n","    # Synthetic query batch (fixed to avoid allocation cost in the loop)\n","    X_query = np.random.randn(batch_size, feature_dim).astype(np.float32)\n","\n","    # Warm-up\n","    for _ in range(n_warmup):\n","        _ = model.predict(X_query)\n","\n","    # Timed runs\n","    times_ms = []\n","    for _ in range(n_runs):\n","        t0 = time.perf_counter()\n","        _ = model.predict(X_query)\n","        t1 = time.perf_counter()\n","        times_ms.append((t1 - t0) * 1000.0)\n","\n","    times_ms = np.array(times_ms, dtype=float)\n","    stats = {\n","        \"batch_latency_p50_ms\": float(np.percentile(times_ms, 50)),\n","        \"batch_latency_p90_ms\": float(np.percentile(times_ms, 90)),\n","        \"batch_latency_mean_ms\": float(times_ms.mean()),\n","        \"batch_latency_std_ms\":  float(times_ms.std()),\n","        \"n_runs\": int(n_runs),\n","        \"batch_size\": int(batch_size),\n","    }\n","    return stats\n","\n","\n","# ---------------------------\n","# 4) Run Random Forest CPU latency benchmark\n","# ---------------------------\n","stats = measure_rf_latency(\n","    rf,\n","    feature_dim=N_FEATURES,\n","    batch_size=BATCH_SIZE,\n","    n_warmup=N_WARMUP,\n","    n_runs=N_RUNS,\n",")\n","\n","print(\"\\nCPU latency stats for RandomForest.predict() (per batch):\")\n","for k, v in stats.items():\n","    if k.endswith(\"_ms\"):\n","        print(f\"  {k}: {v:.4f}\")\n","    else:\n","        print(f\"  {k}: {v}\")\n","\n","# Convert to \"per-window\" latency (since each sample = one HAR window)\n","per_window_p50  = stats[\"batch_latency_p50_ms\"]  / stats[\"batch_size\"]\n","per_window_p90  = stats[\"batch_latency_p90_ms\"]  / stats[\"batch_size\"]\n","per_window_mean = stats[\"batch_latency_mean_ms\"] / stats[\"batch_size\"]\n","\n","print(\"\\nApproximate CPU latency per window (HAR sample):\")\n","print(f\"  window_latency_p50_ms  ≈ {per_window_p50:.4f}\")\n","print(f\"  window_latency_p90_ms  ≈ {per_window_p90:.4f}\")\n","print(f\"  window_latency_mean_ms ≈ {per_window_mean:.4f}\")\n","\n","print(\"\\n[Random Forest CPU inference latency benchmark completed]\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i77cCYrtd2F2","executionInfo":{"status":"ok","timestamp":1763451898867,"user_tz":0,"elapsed":202672,"user":{"displayName":"yu Wu","userId":"12692660435918028293"}},"outputId":"0f84a972-3a64-41cb-92d5-295a076b2274"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","[Random Forest CPU Inference Latency Benchmark for HAR Windows]\n","N_TRAIN=20000, N_FEATURES=900, N_CLASSES=8\n","N_WARMUP=20, N_RUNS=200, BATCH_SIZE=1\n","X_train shape: (20000, 900), y_train shape: (20000,)\n","\n","Random Forest fit time: 200355.768 ms\n","Approximate Random Forest model size: 133.679 MB\n","\n","CPU latency stats for RandomForest.predict() (per batch):\n","  batch_latency_p50_ms: 6.8383\n","  batch_latency_p90_ms: 7.2557\n","  batch_latency_mean_ms: 6.9059\n","  batch_latency_std_ms: 0.2590\n","  n_runs: 200\n","  batch_size: 1\n","\n","Approximate CPU latency per window (HAR sample):\n","  window_latency_p50_ms  ≈ 6.8383\n","  window_latency_p90_ms  ≈ 7.2557\n","  window_latency_mean_ms ≈ 6.9059\n","\n","[Random Forest CPU inference latency benchmark completed]\n"]}]},{"cell_type":"markdown","source":["5.InceptionTime"],"metadata":{"id":"mO5MA_duJpDO"}},{"cell_type":"code","source":["# ================ InceptionTime CPU Inference Latency Benchmark for HAR Windows (Standalone) ================\n","import os\n","os.environ.setdefault(\"OMP_NUM_THREADS\", \"1\")\n","os.environ.setdefault(\"MKL_NUM_THREADS\", \"1\")\n","os.environ.setdefault(\"OPENBLAS_NUM_THREADS\", \"1\")\n","\n","import time\n","import random\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","\n","print(\"\\n[InceptionTime CPU Inference Latency Benchmark for HAR Windows]\")\n","\n","# ---------------------------\n","# 0) Basic configuration\n","# ---------------------------\n","SEED = 42\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","if torch.cuda.is_available():\n","    torch.cuda.manual_seed_all(SEED)\n","\n","device = torch.device(\"cpu\")\n","torch.set_num_threads(1)\n","\n","print(f\"Using device: {device}\")\n","print(f\"torch.get_num_threads() = {torch.get_num_threads()}\")\n","\n","# HAR-like window settings: 6 channels, 150 time steps (e.g., 3 s @ 50 Hz)\n","N_CHANNELS      = 6\n","WINDOW_SAMPLES  = 150\n","N_CLASSES       = 8\n","\n","print(f\"N_CHANNELS={N_CHANNELS}, WINDOW_SAMPLES={WINDOW_SAMPLES}, N_CLASSES={N_CLASSES}\")\n","\n","# InceptionTime hyperparameters (typical multivariate configuration)\n","NB_FILTERS        = 32\n","KERNEL_SIZES      = (10, 20, 40)   # following common InceptionTime practice\n","USE_BOTTLENECK   = True\n","BOTTLENECK_SIZE  = 32\n","NB_BLOCKS         = 3              # number of residual Inception blocks\n","DROPOUT           = 0.0            # InceptionTime usually does not use dropout in the original paper\n","\n","\n","# ---------------------------\n","# 1) InceptionTime model definition\n","#    (multivariate 1D time-series, following common implementations)\n","# ---------------------------\n","class InceptionModule(nn.Module):\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        n_filters: int = 32,\n","        kernel_sizes=(10, 20, 40),\n","        bottleneck_channels: int = 32,\n","        use_bottleneck: bool = True,\n","    ):\n","        super().__init__()\n","        self.use_bottleneck = use_bottleneck\n","\n","        if use_bottleneck and in_channels > 1:\n","            self.bottleneck = nn.Conv1d(\n","                in_channels,\n","                bottleneck_channels,\n","                kernel_size=1,\n","                stride=1,\n","                padding=0,\n","                bias=False,\n","            )\n","            conv_in_channels = bottleneck_channels\n","        else:\n","            self.bottleneck = None\n","            conv_in_channels = in_channels\n","\n","        self.conv_list = nn.ModuleList()\n","        for k in kernel_sizes:\n","            # padding chosen to roughly approximate \"same\", but may overshoot by 1 for even kernels\n","            pad = k // 2\n","            self.conv_list.append(\n","                nn.Conv1d(\n","                    conv_in_channels,\n","                    n_filters,\n","                    kernel_size=k,\n","                    stride=1,\n","                    padding=pad,\n","                    bias=False,\n","                )\n","            )\n","\n","        self.maxpool = nn.MaxPool1d(kernel_size=3, stride=1, padding=1)\n","        self.conv_pool = nn.Conv1d(\n","            in_channels, n_filters, kernel_size=1, stride=1, padding=0, bias=False\n","        )\n","\n","        self.bn = nn.BatchNorm1d(n_filters * (len(kernel_sizes) + 1))\n","        self.act = nn.ReLU(inplace=True)\n","\n","    def forward(self, x):\n","        # x: [B, C, T]\n","        if self.use_bottleneck and self.bottleneck is not None:\n","            z = self.bottleneck(x)\n","        else:\n","            z = x\n","\n","        out_branches = []\n","        for conv in self.conv_list:\n","            out_branches.append(conv(z))\n","\n","        out_pool = self.conv_pool(self.maxpool(x))\n","        out_branches.append(out_pool)\n","\n","        # Align all branches along the time dimension (T) by cropping to the minimum length\n","        min_len = min(t.shape[-1] for t in out_branches)\n","        out_branches = [t[..., :min_len] for t in out_branches]\n","\n","        out = torch.cat(out_branches, dim=1)\n","        out = self.bn(out)\n","        out = self.act(out)\n","        return out\n","\n","\n","class InceptionBlock(nn.Module):\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        n_filters: int = 32,\n","        kernel_sizes=(10, 20, 40),\n","        bottleneck_channels: int = 32,\n","        use_bottleneck: bool = True,\n","        use_residual: bool = True,\n","    ):\n","        super().__init__()\n","        self.use_residual = use_residual\n","\n","        self.inception1 = InceptionModule(\n","            in_channels=in_channels,\n","            n_filters=n_filters,\n","            kernel_sizes=kernel_sizes,\n","            bottleneck_channels=bottleneck_channels,\n","            use_bottleneck=use_bottleneck,\n","        )\n","        self.inception2 = InceptionModule(\n","            in_channels=n_filters * (len(kernel_sizes) + 1),\n","            n_filters=n_filters,\n","            kernel_sizes=kernel_sizes,\n","            bottleneck_channels=bottleneck_channels,\n","            use_bottleneck=use_bottleneck,\n","        )\n","        self.inception3 = InceptionModule(\n","            in_channels=n_filters * (len(kernel_sizes) + 1),\n","            n_filters=n_filters,\n","            kernel_sizes=kernel_sizes,\n","            bottleneck_channels=bottleneck_channels,\n","            use_bottleneck=use_bottleneck,\n","        )\n","\n","        out_channels = n_filters * (len(kernel_sizes) + 1)\n","\n","        if self.use_residual:\n","            self.residual = nn.Sequential(\n","                nn.Conv1d(in_channels, out_channels, kernel_size=1, stride=1, padding=0, bias=False),\n","                nn.BatchNorm1d(out_channels),\n","            )\n","        else:\n","            self.residual = None\n","\n","        self.act = nn.ReLU(inplace=True)\n","\n","    def forward(self, x):\n","        # x: [B, C, T]\n","        residual = x\n","        x = self.inception1(x)\n","        x = self.inception2(x)\n","        x = self.inception3(x)\n","\n","        if self.use_residual and self.residual is not None:\n","            # Align residual length to match x if needed\n","            res = self.residual(residual)\n","            if res.shape[-1] != x.shape[-1]:\n","                min_len = min(res.shape[-1], x.shape[-1])\n","                res = res[..., :min_len]\n","                x = x[..., :min_len]\n","            x = x + res\n","\n","        x = self.act(x)\n","        return x\n","\n","\n","class InceptionTime(nn.Module):\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        n_classes: int,\n","        n_filters: int = 32,\n","        kernel_sizes=(10, 20, 40),\n","        bottleneck_channels: int = 32,\n","        use_bottleneck: bool = True,\n","        n_blocks: int = 3,\n","        use_residual: bool = True,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__()\n","\n","        blocks = []\n","        input_channels = in_channels\n","        for i in range(n_blocks):\n","            block = InceptionBlock(\n","                in_channels=input_channels,\n","                n_filters=n_filters,\n","                kernel_sizes=kernel_sizes,\n","                bottleneck_channels=bottleneck_channels,\n","                use_bottleneck=use_bottleneck,\n","                use_residual=use_residual,\n","            )\n","            blocks.append(block)\n","            # after each block, number of channels becomes n_filters * (len(kernel_sizes) + 1)\n","            input_channels = n_filters * (len(kernel_sizes) + 1)\n","\n","        self.blocks = nn.ModuleList(blocks)\n","        self.gap = nn.AdaptiveAvgPool1d(1)\n","        self.dropout = nn.Dropout(dropout)\n","        self.fc = nn.Linear(input_channels, n_classes)\n","\n","    def forward(self, x):\n","        # x: [B, C, T]\n","        for block in self.blocks:\n","            x = block(x)\n","        x = self.gap(x).squeeze(-1)  # [B, C_out]\n","        x = self.dropout(x)\n","        logits = self.fc(x)          # [B, n_classes]\n","        return logits\n","\n","\n","# ---------------------------\n","# 2) Utility: parameter count\n","# ---------------------------\n","def count_parameters(model: nn.Module) -> int:\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","\n","# ---------------------------\n","# 3) Utility: latency measurement on CPU\n","# ---------------------------\n","def measure_latency(\n","    model: nn.Module,\n","    input_shape,\n","    device: torch.device,\n","    n_warmup: int = 20,\n","    n_runs: int = 100,\n","):\n","    \"\"\"\n","    Measure pure forward-pass latency on CPU.\n","    Returns latency stats in milliseconds per batch (per call to model()).\n","    For InceptionTime here, each batch element corresponds to one HAR window.\n","    \"\"\"\n","    model = model.to(device)\n","    model.eval()\n","    torch.set_grad_enabled(False)\n","\n","    x = torch.randn(*input_shape, device=device, dtype=torch.float32)\n","\n","    # Warm-up\n","    for _ in range(n_warmup):\n","        _ = model(x)\n","\n","    # Timed runs\n","    times_ms = []\n","    for _ in range(n_runs):\n","        t0 = time.perf_counter()\n","        _ = model(x)\n","        t1 = time.perf_counter()\n","        times_ms.append((t1 - t0) * 1000.0)\n","\n","    times_ms = np.array(times_ms, dtype=float)\n","    stats = {\n","        \"batch_latency_p50_ms\": float(np.percentile(times_ms, 50)),\n","        \"batch_latency_p90_ms\": float(np.percentile(times_ms, 90)),\n","        \"batch_latency_mean_ms\": float(times_ms.mean()),\n","        \"batch_latency_std_ms\":  float(times_ms.std()),\n","        \"n_runs\": int(n_runs),\n","        \"batch_size\": int(input_shape[0]),\n","    }\n","    return stats\n","\n","\n","# ---------------------------\n","# 4) Instantiate model and run benchmark\n","# ---------------------------\n","model = InceptionTime(\n","    in_channels=N_CHANNELS,\n","    n_classes=N_CLASSES,\n","    n_filters=NB_FILTERS,\n","    kernel_sizes=KERNEL_SIZES,\n","    bottleneck_channels=BOTTLENECK_SIZE,\n","    use_bottleneck=USE_BOTTLENECK,\n","    n_blocks=NB_BLOCKS,\n","    use_residual=True,\n","    dropout=DROPOUT,\n",")\n","\n","n_params = count_parameters(model)\n","print(f\"Number of trainable parameters: {n_params:,}\")\n","\n","# Batch size for latency measurement (per-window model)\n","BATCH_SIZE = 1  # you can also test larger batches for throughput analysis\n","input_shape = (BATCH_SIZE, N_CHANNELS, WINDOW_SAMPLES)  # [B, C, T]\n","\n","print(f\"\\nMeasuring CPU latency with input shape: {input_shape} (B, C, T)\")\n","\n","stats = measure_latency(\n","    model,\n","    input_shape=input_shape,\n","    device=device,\n","    n_warmup=20,\n","    n_runs=100,\n",")\n","\n","print(\"\\nCPU latency stats for InceptionTime.forward() (per batch):\")\n","for k, v in stats.items():\n","    if k.endswith(\"_ms\"):\n","        print(f\"  {k}: {v:.4f}\")\n","    else:\n","        print(f\"  {k}: {v}\")\n","\n","# Since each sample = one HAR window, per-window latency = per-batch latency / batch_size\n","per_window_p50  = stats[\"batch_latency_p50_ms\"]  / stats[\"batch_size\"]\n","per_window_p90  = stats[\"batch_latency_p90_ms\"]  / stats[\"batch_size\"]\n","per_window_mean = stats[\"batch_latency_mean_ms\"] / stats[\"batch_size\"]\n","\n","print(\"\\nApproximate CPU latency per window (HAR sample):\")\n","print(f\"  window_latency_p50_ms  ≈ {per_window_p50:.4f}\")\n","print(f\"  window_latency_p90_ms  ≈ {per_window_p90:.4f}\")\n","print(f\"  window_latency_mean_ms ≈ {per_window_mean:.4f}\")\n","\n","print(\"\\n[InceptionTime CPU inference latency benchmark completed]\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7OlizOSMJowP","executionInfo":{"status":"ok","timestamp":1763455808937,"user_tz":0,"elapsed":1324,"user":{"displayName":"yu Wu","userId":"12692660435918028293"}},"outputId":"02236747-82de-447c-e6f8-57e83cec1212"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","[InceptionTime CPU Inference Latency Benchmark for HAR Windows]\n","Using device: cpu\n","torch.get_num_threads() = 1\n","N_CHANNELS=6, WINDOW_SAMPLES=150, N_CLASSES=8\n","Number of trainable parameters: 748,680\n","\n","Measuring CPU latency with input shape: (1, 6, 150) (B, C, T)\n","\n","CPU latency stats for InceptionTime.forward() (per batch):\n","  batch_latency_p50_ms: 10.5010\n","  batch_latency_p90_ms: 11.5529\n","  batch_latency_mean_ms: 10.7735\n","  batch_latency_std_ms: 1.0131\n","  n_runs: 100\n","  batch_size: 1\n","\n","Approximate CPU latency per window (HAR sample):\n","  window_latency_p50_ms  ≈ 10.5010\n","  window_latency_p90_ms  ≈ 11.5529\n","  window_latency_mean_ms ≈ 10.7735\n","\n","[InceptionTime CPU inference latency benchmark completed]\n"]}]},{"cell_type":"code","source":["!pip -q install sktime"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CXrQTR8I77y3","executionInfo":{"status":"ok","timestamp":1763452116209,"user_tz":0,"elapsed":6972,"user":{"displayName":"yu Wu","userId":"12692660435918028293"}},"outputId":"eff201c5-f387-4c19-de52-08a411649cf8"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.6/35.6 MB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.5/149.5 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"markdown","source":["6. minirocket"],"metadata":{"id":"NWQBkvKDLJkq"}},{"cell_type":"code","source":["# ================ MiniRocket CPU Inference Latency Benchmark for HAR Windows (Standalone) ================\n","!pip -q install sktime\n","\n","import os\n","os.environ.setdefault(\"OMP_NUM_THREADS\", \"1\")\n","os.environ.setdefault(\"MKL_NUM_THREADS\", \"1\")\n","os.environ.setdefault(\"OPENBLAS_NUM_THREADS\", \"1\")\n","os.environ.setdefault(\"NUMBA_NUM_THREADS\", \"1\")\n","os.environ.setdefault(\"NUMBA_DEFAULT_NUM_THREADS\", \"1\")\n","\n","import time\n","import random\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","import numpy as np\n","import pandas as pd\n","import torch\n","import numba\n","from sklearn.linear_model import RidgeClassifier\n","from sktime.transformations.panel.rocket import MiniRocketMultivariate\n","\n","print(\"\\n[MiniRocket CPU Inference Latency Benchmark for HAR Windows]\")\n","\n","# ---------------------------\n","# 0) Basic configuration\n","# ---------------------------\n","SEED = 42\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","\n","# Single-core CPU\n","device = \"cpu\"\n","torch.set_num_threads(1)\n","numba.set_num_threads(1)\n","\n","print(f\"Using device: {device}\")\n","print(f\"torch.get_num_threads() = {torch.get_num_threads()}\")\n","print(f\"NUMBA threads = {numba.get_num_threads()}\")\n","\n","# HAR-like window settings: 6 channels, 150 time steps (e.g., 3 s @ 50 Hz)\n","N_CHANNELS      = 6\n","WINDOW_SAMPLES  = 150\n","N_CLASSES       = 8\n","\n","print(f\"N_CHANNELS={N_CHANNELS}, WINDOW_SAMPLES={WINDOW_SAMPLES}, N_CLASSES={N_CLASSES}\")\n","\n","# Training set size for MiniRocket + linear head (aligned with KNN/RF)\n","N_TRAIN   = 20000   # number of training windows\n","\n","# Latency measurement settings\n","N_WARMUP   = 20\n","N_RUNS     = 100\n","BATCH_SIZE = 1      # number of query windows per call\n","\n","print(f\"N_TRAIN={N_TRAIN}, N_WARMUP={N_WARMUP}, N_RUNS={N_RUNS}, BATCH_SIZE={BATCH_SIZE}\")\n","\n","\n","# ---------------------------\n","# 1) Helper: convert 3D numpy to sktime nested DataFrame\n","#    X_np: (n_instances, n_channels, n_timepoints)\n","# ---------------------------\n","def to_nested_dataframe(X_np: np.ndarray) -> pd.DataFrame:\n","    n_instances, n_channels, n_timepoints = X_np.shape\n","    data = {}\n","    for c in range(n_channels):\n","        data[f\"dim_{c}\"] = [pd.Series(X_np[i, c, :]) for i in range(n_instances)]\n","    return pd.DataFrame(data)\n","\n","\n","# ---------------------------\n","# 2) Create synthetic HAR-like training dataset\n","# ---------------------------\n","# Each sample: one window [channels, time] with Gaussian noise\n","X_train_np = np.random.randn(N_TRAIN, N_CHANNELS, WINDOW_SAMPLES).astype(np.float32)\n","y_train    = np.random.randint(0, N_CLASSES, size=(N_TRAIN,), dtype=np.int32)\n","\n","print(f\"X_train_np shape: {X_train_np.shape}, y_train shape: {y_train.shape}\")\n","\n","X_train = to_nested_dataframe(X_train_np)\n","print(f\"X_train nested DataFrame shape: {X_train.shape}\")\n","\n","\n","# ---------------------------\n","# 3) Define MiniRocket + linear classifier\n","# ---------------------------\n","minirocket = MiniRocketMultivariate(\n","    num_kernels=10000,             # standard MiniRocket setting\n","    max_dilations_per_kernel=32,\n","    n_jobs=1,                      # single-core for fair comparison\n","    random_state=SEED,\n",")\n","\n","clf = RidgeClassifier(\n","    alpha=1.0,\n","    fit_intercept=True\n",")\n","\n","# ---------------------------\n","# 4) Fit MiniRocket feature extractor + linear classifier\n","# ---------------------------\n","t0_fit = time.perf_counter()\n","minirocket.fit(X_train, y_train)\n","X_train_trans = minirocket.transform(X_train)\n","clf.fit(X_train_trans, y_train)\n","t1_fit = time.perf_counter()\n","fit_time_ms = (t1_fit - t0_fit) * 1000.0\n","\n","n_features_rocket = X_train_trans.shape[1]\n","n_linear_params = clf.coef_.size + clf.intercept_.size\n","\n","print(f\"\\nMiniRocket fit + linear head fit time: {fit_time_ms:.3f} ms\")\n","print(f\"MiniRocket transformed feature dimension: {n_features_rocket}\")\n","print(f\"Approximate number of linear head parameters: {n_linear_params:,}\")\n","\n","\n","# ---------------------------\n","# 5) Utility: latency measurement for MiniRocket + linear head\n","# ---------------------------\n","def measure_minirocket_latency(\n","    transformer: MiniRocketMultivariate,\n","    classifier,\n","    X_query_nested: pd.DataFrame,\n","    batch_size: int,\n","    n_warmup: int = 20,\n","    n_runs: int = 100,\n","):\n","    \"\"\"\n","    Measure MiniRocket.transform() + linear classifier.predict() latency on CPU.\n","    X_query_nested: nested DataFrame with shape (batch_size, n_channels).\n","    Returns latency stats in milliseconds per batch.\n","    \"\"\"\n","    # Warm-up\n","    for _ in range(n_warmup):\n","        X_feat = transformer.transform(X_query_nested)\n","        _ = classifier.predict(X_feat)\n","\n","    # Timed runs\n","    times_ms = []\n","    for _ in range(n_runs):\n","        t0 = time.perf_counter()\n","        X_feat = transformer.transform(X_query_nested)\n","        _ = classifier.predict(X_feat)\n","        t1 = time.perf_counter()\n","        times_ms.append((t1 - t0) * 1000.0)\n","\n","    times_ms = np.array(times_ms, dtype=float)\n","    stats = {\n","        \"batch_latency_p50_ms\": float(np.percentile(times_ms, 50)),\n","        \"batch_latency_p90_ms\": float(np.percentile(times_ms, 90)),\n","        \"batch_latency_mean_ms\": float(times_ms.mean()),\n","        \"batch_latency_std_ms\":  float(times_ms.std()),\n","        \"n_runs\": int(n_runs),\n","        \"batch_size\": int(batch_size),\n","    }\n","    return stats\n","\n","\n","# ---------------------------\n","# 6) Build a synthetic query batch and run the benchmark\n","# ---------------------------\n","X_query_np = np.random.randn(BATCH_SIZE, N_CHANNELS, WINDOW_SAMPLES).astype(np.float32)\n","X_query = to_nested_dataframe(X_query_np)\n","\n","print(f\"\\nQuery batch nested DataFrame shape: {X_query.shape}\")\n","\n","stats = measure_minirocket_latency(\n","    minirocket,\n","    clf,\n","    X_query_nested=X_query,\n","    batch_size=BATCH_SIZE,\n","    n_warmup=N_WARMUP,\n","    n_runs=N_RUNS,\n",")\n","\n","print(\"\\nCPU latency stats for MiniRocket + linear head (per batch):\")\n","for k, v in stats.items():\n","    if k.endswith(\"_ms\"):\n","        print(f\"  {k}: {v:.4f}\")\n","    else:\n","        print(f\"  {k}: {v}\")\n","\n","# Each sample corresponds to one HAR window, so per-window latency = per-batch / batch_size\n","per_window_p50  = stats[\"batch_latency_p50_ms\"]  / stats[\"batch_size\"]\n","per_window_p90  = stats[\"batch_latency_p90_ms\"]  / stats[\"batch_size\"]\n","per_window_mean = stats[\"batch_latency_mean_ms\"] / stats[\"batch_size\"]\n","\n","print(\"\\nApproximate CPU latency per window (HAR sample):\")\n","print(f\"  window_latency_p50_ms  ≈ {per_window_p50:.4f}\")\n","print(f\"  window_latency_p90_ms  ≈ {per_window_p90:.4f}\")\n","print(f\"  window_latency_mean_ms ≈ {per_window_mean:.4f}\")\n","\n","print(\"\\n[MiniRocket CPU inference latency benchmark completed]\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aktxdHzZ8hIN","executionInfo":{"status":"ok","timestamp":1763452379252,"user_tz":0,"elapsed":116128,"user":{"displayName":"yu Wu","userId":"12692660435918028293"}},"outputId":"768bb350-8927-49a6-e2db-90d0d8cd6e27"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","[MiniRocket CPU Inference Latency Benchmark for HAR Windows]\n","Using device: cpu\n","torch.get_num_threads() = 1\n","NUMBA threads = 1\n","N_CHANNELS=6, WINDOW_SAMPLES=150, N_CLASSES=8\n","N_TRAIN=20000, N_WARMUP=20, N_RUNS=100, BATCH_SIZE=1\n","X_train_np shape: (20000, 6, 150), y_train shape: (20000,)\n","X_train nested DataFrame shape: (20000, 6)\n","\n","MiniRocket fit + linear head fit time: 99168.711 ms\n","MiniRocket transformed feature dimension: 9996\n","Approximate number of linear head parameters: 79,976\n","\n","Query batch nested DataFrame shape: (1, 6)\n","\n","CPU latency stats for MiniRocket + linear head (per batch):\n","  batch_latency_p50_ms: 49.1377\n","  batch_latency_p90_ms: 51.1574\n","  batch_latency_mean_ms: 50.8583\n","  batch_latency_std_ms: 6.1007\n","  n_runs: 100\n","  batch_size: 1\n","\n","Approximate CPU latency per window (HAR sample):\n","  window_latency_p50_ms  ≈ 49.1377\n","  window_latency_p90_ms  ≈ 51.1574\n","  window_latency_mean_ms ≈ 50.8583\n","\n","[MiniRocket CPU inference latency benchmark completed]\n"]}]},{"cell_type":"markdown","source":["7. minirocket(Deployment-Friendly)"],"metadata":{"id":"zyzWC-1tLUHh"}},{"cell_type":"code","source":["# ================ MiniRocket-Lite CPU Inference Latency Benchmark for HAR Windows (Deployment-Friendly) ================\n","# This script is intended to be self-contained and comparable to the \"standard\" MiniRocket\n","# benchmark you ran before:\n","#   - 6 channels, 150 time steps (~3 s @ 50 Hz)\n","#   - N_TRAIN = 20,000 synthetic windows\n","#   - Latency metric: MiniRocket.transform() + RidgeClassifier.predict()\n","#   - Deployment-friendly configuration:\n","#       * NUM_KERNELS = 2000 (lighter than the standard 10k)\n","#       * Attempts to use up to 4 threads, but adapts to the effective Numba limit\n","#         in the current Python process (e.g., if Numba is locked to 1 thread, we\n","#         automatically set n_jobs=1 to avoid errors).\n","\n","!pip -q install sktime psutil\n","\n","import os\n","import time\n","import random\n","import warnings\n","import platform\n","\n","import numpy as np\n","import pandas as pd\n","import psutil\n","\n","warnings.filterwarnings(\"ignore\")\n","\n","print(\"\\n[MiniRocket-Lite CPU Inference Latency Benchmark for HAR Windows (Deployment-Friendly)]\")\n","\n","# ---------------------------\n","# 0) Reproducibility and thread budget (decide before importing torch/numba)\n","# ---------------------------\n","SEED = 42\n","random.seed(SEED)\n","np.random.seed(SEED)\n","\n","logical_cores = psutil.cpu_count(logical=True) or 1\n","physical_cores = psutil.cpu_count(logical=False) or logical_cores\n","TARGET_THREADS = min(4, logical_cores)\n","\n","# Configure BLAS-related environment variables for a deployment-friendly setting.\n","# These affect libraries such as OpenBLAS/MKL, but Numba's effective maximum may\n","# already be fixed by previous imports in the same process.\n","os.environ[\"OMP_NUM_THREADS\"] = str(TARGET_THREADS)\n","os.environ[\"MKL_NUM_THREADS\"] = str(TARGET_THREADS)\n","os.environ[\"OPENBLAS_NUM_THREADS\"] = str(TARGET_THREADS)\n","\n","# Import torch / numba / MiniRocket after setting env vars\n","import torch\n","import numba\n","from sklearn.linear_model import RidgeClassifier\n","from sktime.transformations.panel.rocket import MiniRocketMultivariate\n","\n","# Try to request TARGET_THREADS for PyTorch\n","torch.set_num_threads(TARGET_THREADS)\n","\n","# Try to request TARGET_THREADS for Numba, but Numba may already be constrained\n","try:\n","    numba.set_num_threads(TARGET_THREADS)\n","except ValueError as e:\n","    print(f\"[Warning] numba.set_num_threads({TARGET_THREADS}) failed: {e}\")\n","    print(\"          Falling back to Numba's existing thread configuration.\")\n","\n","# Effective Numba threads in this process\n","effective_numba_threads = numba.get_num_threads()\n","# MiniRocket will not request more threads than Numba actually allows\n","MINIROCKET_THREADS = min(TARGET_THREADS, effective_numba_threads)\n","\n","print(\"Platform                   :\", platform.system(), platform.release())\n","print(\"CPU                        :\", platform.processor())\n","print(\"Physical cores             :\", physical_cores)\n","print(\"Logical cores              :\", logical_cores)\n","print(\"Target threads (requested) :\", TARGET_THREADS)\n","print(\"Numba threads (effective)  :\", effective_numba_threads)\n","print(\"MiniRocket n_jobs (used)   :\", MINIROCKET_THREADS)\n","print(\"torch.get_num_threads()    :\", torch.get_num_threads())\n","\n","device = \"cpu\"\n","print(f\"\\nUsing device: {device}\")\n","\n","# ---------------------------\n","# 1) HAR-like window settings (aligned with previous MiniRocket benchmark)\n","# ---------------------------\n","N_CHANNELS      = 6\n","WINDOW_SAMPLES  = 150   # e.g., 3 s @ 50 Hz\n","N_CLASSES       = 8\n","\n","# Training set size (same as previous benchmark for comparability)\n","N_TRAIN   = 20000\n","\n","# Latency measurement settings\n","N_WARMUP   = 20\n","N_RUNS     = 100\n","BATCH_SIZE = 1  # per-window latency\n","\n","# Deployment-friendly MiniRocket configuration (lighter than the standard 10k-kernel version)\n","NUM_KERNELS = 2000\n","\n","SAMPLE_RATE_HZ   = 50.0\n","WINDOW_SECONDS   = WINDOW_SAMPLES / SAMPLE_RATE_HZ\n","\n","print(f\"\\nN_CHANNELS={N_CHANNELS}, WINDOW_SAMPLES={WINDOW_SAMPLES}, N_CLASSES={N_CLASSES}\")\n","print(f\"N_TRAIN={N_TRAIN}, N_WARMUP={N_WARMUP}, N_RUNS={N_RUNS}, BATCH_SIZE={BATCH_SIZE}\")\n","print(f\"NUM_KERNELS (MiniRocket-Lite) = {NUM_KERNELS}\")\n","print(f\"Assumed sampling rate = {SAMPLE_RATE_HZ} Hz → window length ≈ {WINDOW_SECONDS:.3f} s\")\n","\n","# ---------------------------\n","# 2) Helper: convert 3D numpy to sktime nested DataFrame\n","#    X_np: (n_instances, n_channels, n_timepoints)\n","# ---------------------------\n","def to_nested_dataframe(X_np: np.ndarray) -> pd.DataFrame:\n","    n_instances, n_channels, n_timepoints = X_np.shape\n","    data = {}\n","    for c in range(n_channels):\n","        # one pandas Series per instance and per channel\n","        data[f\"dim_{c}\"] = [pd.Series(X_np[i, c, :]) for i in range(n_instances)]\n","    return pd.DataFrame(data)\n","\n","# ---------------------------\n","# 3) Create synthetic HAR-like training dataset\n","# ---------------------------\n","X_train_np = np.random.randn(N_TRAIN, N_CHANNELS, WINDOW_SAMPLES).astype(np.float32)\n","y_train    = np.random.randint(0, N_CLASSES, size=(N_TRAIN,), dtype=np.int32)\n","\n","print(f\"\\nX_train_np shape: {X_train_np.shape}, y_train shape: {y_train.shape}\")\n","\n","X_train = to_nested_dataframe(X_train_np)\n","print(f\"X_train nested DataFrame shape: {X_train.shape}\")\n","\n","# ---------------------------\n","# 4) Define MiniRocket-Lite + linear classifier\n","# ---------------------------\n","minirocket_lite = MiniRocketMultivariate(\n","    num_kernels=NUM_KERNELS,\n","    max_dilations_per_kernel=32,\n","    n_jobs=MINIROCKET_THREADS,  # do not exceed Numba's effective thread limit\n","    random_state=SEED,\n",")\n","\n","clf = RidgeClassifier(\n","    alpha=1.0,\n","    fit_intercept=True\n",")\n","\n","# ---------------------------\n","# 5) Fit MiniRocket-Lite feature extractor + linear classifier\n","# ---------------------------\n","t0_fit = time.perf_counter()\n","minirocket_lite.fit(X_train, y_train)\n","X_train_trans = minirocket_lite.transform(X_train)\n","clf.fit(X_train_trans, y_train)\n","t1_fit = time.perf_counter()\n","fit_time_ms = (t1_fit - t0_fit) * 1000.0\n","\n","n_features_rocket = X_train_trans.shape[1]\n","n_linear_params = clf.coef_.size + clf.intercept_.size\n","\n","print(f\"\\nMiniRocket-Lite fit + linear head fit time: {fit_time_ms:.3f} ms\")\n","print(f\"MiniRocket-Lite transformed feature dimension: {n_features_rocket}\")\n","print(f\"Approximate number of linear head parameters: {n_linear_params:,}\")\n","\n","# ---------------------------\n","# 6) Utility: latency measurement for MiniRocket-Lite + linear head\n","# ---------------------------\n","def measure_minirocket_latency(\n","    transformer: MiniRocketMultivariate,\n","    classifier,\n","    X_query_nested: pd.DataFrame,\n","    batch_size: int,\n","    n_warmup: int = 20,\n","    n_runs: int = 100,\n","):\n","    \"\"\"\n","    Measure MiniRocket.transform() + linear classifier.predict() latency on CPU.\n","    X_query_nested: nested DataFrame with shape (batch_size, n_channels).\n","    Returns latency stats in milliseconds per batch.\n","    \"\"\"\n","    # Warm-up runs (excluded from statistics)\n","    for _ in range(n_warmup):\n","        X_feat = transformer.transform(X_query_nested)\n","        _ = classifier.predict(X_feat)\n","\n","    # Timed runs\n","    times_ms = []\n","    for _ in range(n_runs):\n","        t0 = time.perf_counter()\n","        X_feat = transformer.transform(X_query_nested)\n","        _ = classifier.predict(X_feat)\n","        t1 = time.perf_counter()\n","        times_ms.append((t1 - t0) * 1000.0)\n","\n","    times_ms = np.array(times_ms, dtype=float)\n","    stats = {\n","        \"batch_latency_p50_ms\": float(np.percentile(times_ms, 50)),\n","        \"batch_latency_p90_ms\": float(np.percentile(times_ms, 90)),\n","        \"batch_latency_mean_ms\": float(times_ms.mean()),\n","        \"batch_latency_std_ms\":  float(times_ms.std()),\n","        \"n_runs\": int(n_runs),\n","        \"batch_size\": int(batch_size),\n","    }\n","    return stats\n","\n","# ---------------------------\n","# 7) Build a synthetic query batch and run the benchmark\n","# ---------------------------\n","X_query_np = np.random.randn(BATCH_SIZE, N_CHANNELS, WINDOW_SAMPLES).astype(np.float32)\n","X_query = to_nested_dataframe(X_query_np)\n","\n","print(f\"\\nQuery batch nested DataFrame shape: {X_query.shape}\")\n","\n","stats = measure_minirocket_latency(\n","    minirocket_lite,\n","    clf,\n","    X_query_nested=X_query,\n","    batch_size=BATCH_SIZE,\n","    n_warmup=N_WARMUP,\n","    n_runs=N_RUNS,\n",")\n","\n","print(\"\\nCPU latency stats for MiniRocket-Lite + linear head (per batch):\")\n","for k, v in stats.items():\n","    if k.endswith(\"_ms\"):\n","        print(f\"  {k}: {v:.4f}\")\n","    else:\n","        print(f\"  {k}: {v}\")\n","\n","# Each sample corresponds to one HAR window, so per-window latency = per-batch / batch_size\n","per_window_p50  = stats[\"batch_latency_p50_ms\"]  / stats[\"batch_size\"]\n","per_window_p90  = stats[\"batch_latency_p90_ms\"]  / stats[\"batch_size\"]\n","per_window_mean = stats[\"batch_latency_mean_ms\"] / stats[\"batch_size\"]\n","\n","print(\"\\nApproximate CPU latency per window (HAR sample):\")\n","print(f\"  window_latency_p50_ms  ≈ {per_window_p50:.4f}\")\n","print(f\"  window_latency_p90_ms  ≈ {per_window_p90:.4f}\")\n","print(f\"  window_latency_mean_ms ≈ {per_window_mean:.4f}\")\n","\n","# Real-time factor relative to window length\n","rt_factor_p50  = per_window_p50  / (WINDOW_SECONDS * 1000.0)\n","rt_factor_mean = per_window_mean / (WINDOW_SECONDS * 1000.0)\n","\n","print(\"\\nReal-time factor (MiniRocket-Lite, CPU):\")\n","print(f\"  p50  RTF ≈ {rt_factor_p50:.4f} (CPU time / wall-clock window length)\")\n","print(f\"  mean RTF ≈ {rt_factor_mean:.4f}\")\n","\n","print(\"\\n[MiniRocket-Lite CPU inference latency benchmark (deployment-friendly) completed]\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fdxsrAcEIAaJ","executionInfo":{"status":"ok","timestamp":1763455335757,"user_tz":0,"elapsed":61435,"user":{"displayName":"yu Wu","userId":"12692660435918028293"}},"outputId":"a989be0e-7654-467f-c3d8-50a49890a9bb"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","[MiniRocket-Lite CPU Inference Latency Benchmark for HAR Windows (Deployment-Friendly)]\n","[Warning] numba.set_num_threads(4) failed: The number of threads must be between 1 and 1\n","          Falling back to Numba's existing thread configuration.\n","Platform                   : Linux 6.6.105+\n","CPU                        : x86_64\n","Physical cores             : 4\n","Logical cores              : 8\n","Target threads (requested) : 4\n","Numba threads (effective)  : 1\n","MiniRocket n_jobs (used)   : 1\n","torch.get_num_threads()    : 4\n","\n","Using device: cpu\n","\n","N_CHANNELS=6, WINDOW_SAMPLES=150, N_CLASSES=8\n","N_TRAIN=20000, N_WARMUP=20, N_RUNS=100, BATCH_SIZE=1\n","NUM_KERNELS (MiniRocket-Lite) = 2000\n","Assumed sampling rate = 50.0 Hz → window length ≈ 3.000 s\n","\n","X_train_np shape: (20000, 6, 150), y_train shape: (20000,)\n","X_train nested DataFrame shape: (20000, 6)\n","\n","MiniRocket-Lite fit + linear head fit time: 49031.609 ms\n","MiniRocket-Lite transformed feature dimension: 1932\n","Approximate number of linear head parameters: 15,464\n","\n","Query batch nested DataFrame shape: (1, 6)\n","\n","CPU latency stats for MiniRocket-Lite + linear head (per batch):\n","  batch_latency_p50_ms: 16.7372\n","  batch_latency_p90_ms: 17.4927\n","  batch_latency_mean_ms: 16.9080\n","  batch_latency_std_ms: 0.5232\n","  n_runs: 100\n","  batch_size: 1\n","\n","Approximate CPU latency per window (HAR sample):\n","  window_latency_p50_ms  ≈ 16.7372\n","  window_latency_p90_ms  ≈ 17.4927\n","  window_latency_mean_ms ≈ 16.9080\n","\n","Real-time factor (MiniRocket-Lite, CPU):\n","  p50  RTF ≈ 0.0056 (CPU time / wall-clock window length)\n","  mean RTF ≈ 0.0056\n","\n","[MiniRocket-Lite CPU inference latency benchmark (deployment-friendly) completed]\n"]}]},{"cell_type":"markdown","source":["8. TST"],"metadata":{"id":"hKCHC1RMQKGC"}},{"cell_type":"code","source":["# ================ TST (Time Series Transformer) CPU Inference Latency Benchmark (Standalone) ================\n","import os\n","os.environ.setdefault(\"OMP_NUM_THREADS\", \"1\")\n","os.environ.setdefault(\"MKL_NUM_THREADS\", \"1\")\n","os.environ.setdefault(\"OPENBLAS_NUM_THREADS\", \"1\")\n","\n","import time\n","import random\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","\n","print(\"\\n[TST CPU Inference Latency Benchmark for HAR Windows]\")\n","\n","# ---------------------------\n","# 0) Basic configuration\n","# ---------------------------\n","SEED = 42\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","\n","device = torch.device(\"cpu\")\n","torch.set_num_threads(1)\n","\n","print(f\"Using device: {device}\")\n","print(f\"torch.get_num_threads() = {torch.get_num_threads()}\")\n","\n","# HAR-like window settings: 6 channels, 150 time steps (e.g., 3 s @ 50 Hz)\n","N_CHANNELS      = 6\n","WINDOW_SAMPLES  = 150\n","N_CLASSES       = 8\n","\n","print(f\"\\nN_CHANNELS={N_CHANNELS}, WINDOW_SAMPLES={WINDOW_SAMPLES}, N_CLASSES={N_CLASSES}\")\n","\n","# TST hyperparameters (typical configuration)\n","D_MODEL    = 64\n","N_HEADS    = 8\n","D_FF       = 128\n","N_LAYERS   = 4\n","DROPOUT    = 0.1\n","\n","print(f\"TST config: d_model={D_MODEL}, n_heads={N_HEADS}, d_ff={D_FF}, n_layers={N_LAYERS}, dropout={DROPOUT}\")\n","\n","\n","# ---------------------------\n","# 1) Positional encoding\n","# ---------------------------\n","class PositionalEncoding(nn.Module):\n","    def __init__(self, d_model: int, max_len: int = 5000):\n","        super().__init__()\n","        pe = torch.zeros(max_len, d_model, dtype=torch.float32)\n","        position = torch.arange(0, max_len, dtype=torch.float32).unsqueeze(1)\n","        div_term = torch.exp(\n","            torch.arange(0, d_model, 2, dtype=torch.float32) * (-np.log(10000.0) / d_model)\n","        )\n","        pe[:, 0::2] = torch.sin(position * div_term)\n","        pe[:, 1::2] = torch.cos(position * div_term)\n","        pe = pe.unsqueeze(0)  # [1, max_len, d_model]\n","        self.register_buffer(\"pe\", pe, persistent=False)\n","\n","    def forward(self, x):\n","        # x: [B, T, d_model]\n","        T = x.size(1)\n","        return x + self.pe[:, :T, :]\n","\n","\n","# ---------------------------\n","# 2) Transformer encoder layer (batch_first)\n","# ---------------------------\n","class TransformerEncoderLayer(nn.Module):\n","    def __init__(self, d_model, n_heads, d_ff, dropout=0.1):\n","        super().__init__()\n","        self.self_attn = nn.MultiheadAttention(\n","            embed_dim=d_model,\n","            num_heads=n_heads,\n","            dropout=dropout,\n","            batch_first=True,\n","        )\n","        self.linear1 = nn.Linear(d_model, d_ff)\n","        self.linear2 = nn.Linear(d_ff, d_model)\n","        self.norm1 = nn.LayerNorm(d_model)\n","        self.norm2 = nn.LayerNorm(d_model)\n","        self.dropout = nn.Dropout(dropout)\n","        self.dropout_ff = nn.Dropout(dropout)\n","        self.activation = nn.GELU()\n","\n","    def forward(self, x):\n","        # x: [B, T, d_model]\n","        attn_in = x\n","        attn_out, _ = self.self_attn(attn_in, attn_in, attn_in, need_weights=False)\n","        x = x + self.dropout(attn_out)\n","        x = self.norm1(x)\n","\n","        ff = self.linear2(self.dropout_ff(self.activation(self.linear1(x))))\n","        x = x + self.dropout(ff)\n","        x = self.norm2(x)\n","        return x\n","\n","\n","# ---------------------------\n","# 3) TST classifier (window-level)\n","# ---------------------------\n","class TSTClassifier(nn.Module):\n","    \"\"\"\n","    A standard Time Series Transformer classifier:\n","      - Input: [B, C, T]\n","      - Linear projection over channels -> [B, T, d_model]\n","      - Add positional encoding\n","      - N transformer encoder layers\n","      - Global average pooling over time\n","      - Linear classifier to n_classes\n","    \"\"\"\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        seq_len: int,\n","        n_classes: int,\n","        d_model: int = 64,\n","        n_heads: int = 8,\n","        d_ff: int = 128,\n","        n_layers: int = 4,\n","        dropout: float = 0.1,\n","    ):\n","        super().__init__()\n","        self.in_channels = in_channels\n","        self.seq_len = seq_len\n","        self.d_model = d_model\n","\n","        self.input_proj = nn.Linear(in_channels, d_model)\n","        self.pos_enc = PositionalEncoding(d_model, max_len=seq_len)\n","\n","        self.layers = nn.ModuleList(\n","            [\n","                TransformerEncoderLayer(\n","                    d_model=d_model,\n","                    n_heads=n_heads,\n","                    d_ff=d_ff,\n","                    dropout=dropout,\n","                )\n","                for _ in range(n_layers)\n","            ]\n","        )\n","\n","        self.dropout = nn.Dropout(dropout)\n","        self.classifier = nn.Linear(d_model, n_classes)\n","\n","    def forward(self, x):\n","        # x: [B, C, T]\n","        x = x.permute(0, 2, 1)  # [B, T, C]\n","        x = self.input_proj(x)  # [B, T, d_model]\n","        x = self.pos_enc(x)     # [B, T, d_model]\n","\n","        for layer in self.layers:\n","            x = layer(x)\n","\n","        x = self.dropout(x)\n","        x = x.mean(dim=1)       # global average over time: [B, d_model]\n","        logits = self.classifier(x)  # [B, n_classes]\n","        return logits\n","\n","\n","# ---------------------------\n","# 4) Utility: parameter count\n","# ---------------------------\n","def count_parameters(model: nn.Module) -> int:\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","\n","# ---------------------------\n","# 5) Latency measurement on CPU\n","# ---------------------------\n","def measure_latency(\n","    model: nn.Module,\n","    input_shape,\n","    device: torch.device,\n","    n_warmup: int = 20,\n","    n_runs: int = 100,\n","):\n","    \"\"\"\n","    Measure pure forward-pass latency on CPU.\n","    Returns latency stats in milliseconds per batch (per call to model()).\n","    Each batch element corresponds to one HAR window.\n","    \"\"\"\n","    model = model.to(device)\n","    model.eval()\n","    torch.set_grad_enabled(False)\n","\n","    x = torch.randn(*input_shape, device=device, dtype=torch.float32)\n","\n","    # Warm-up\n","    for _ in range(n_warmup):\n","        _ = model(x)\n","\n","    # Timed runs\n","    times_ms = []\n","    for _ in range(n_runs):\n","        t0 = time.perf_counter()\n","        _ = model(x)\n","        t1 = time.perf_counter()\n","        times_ms.append((t1 - t0) * 1000.0)\n","\n","    times_ms = np.array(times_ms, dtype=float)\n","    stats = {\n","        \"batch_latency_p50_ms\": float(np.percentile(times_ms, 50)),\n","        \"batch_latency_p90_ms\": float(np.percentile(times_ms, 90)),\n","        \"batch_latency_mean_ms\": float(times_ms.mean()),\n","        \"batch_latency_std_ms\":  float(times_ms.std()),\n","        \"n_runs\": int(n_runs),\n","        \"batch_size\": int(input_shape[0]),\n","    }\n","    return stats\n","\n","\n","# ---------------------------\n","# 6) Instantiate model and run benchmark\n","# ---------------------------\n","model = TSTClassifier(\n","    in_channels=N_CHANNELS,\n","    seq_len=WINDOW_SAMPLES,\n","    n_classes=N_CLASSES,\n","    d_model=D_MODEL,\n","    n_heads=N_HEADS,\n","    d_ff=D_FF,\n","    n_layers=N_LAYERS,\n","    dropout=DROPOUT,\n",")\n","\n","n_params = count_parameters(model)\n","print(f\"\\nNumber of trainable parameters: {n_params:,}\")\n","\n","# Batch size for latency measurement (per-window model)\n","BATCH_SIZE = 1\n","input_shape = (BATCH_SIZE, N_CHANNELS, WINDOW_SAMPLES)  # [B, C, T]\n","\n","print(f\"\\nMeasuring CPU latency with input shape: {input_shape} (B, C, T)\")\n","\n","stats = measure_latency(\n","    model,\n","    input_shape=input_shape,\n","    device=device,\n","    n_warmup=20,\n","    n_runs=100,\n",")\n","\n","print(\"\\nCPU latency stats for TST.forward() (per batch):\")\n","for k, v in stats.items():\n","    if k.endswith(\"_ms\"):\n","        print(f\"  {k}: {v:.4f}\")\n","    else:\n","        print(f\"  {k}: {v}\")\n","\n","# Per-window latency (each batch element = one HAR window)\n","per_window_p50  = stats[\"batch_latency_p50_ms\"]  / stats[\"batch_size\"]\n","per_window_p90  = stats[\"batch_latency_p90_ms\"]  / stats[\"batch_size\"]\n","per_window_mean = stats[\"batch_latency_mean_ms\"] / stats[\"batch_size\"]\n","\n","print(\"\\nApproximate CPU latency per window (HAR sample):\")\n","print(f\"  window_latency_p50_ms  ≈ {per_window_p50:.4f}\")\n","print(f\"  window_latency_p90_ms  ≈ {per_window_p90:.4f}\")\n","print(f\"  window_latency_mean_ms ≈ {per_window_mean:.4f}\")\n","\n","print(\"\\n[TST CPU inference latency benchmark completed]\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CoEMmoffQUmF","executionInfo":{"status":"ok","timestamp":1763457455180,"user_tz":0,"elapsed":794,"user":{"displayName":"yu Wu","userId":"12692660435918028293"}},"outputId":"bd9ae975-a0de-41e8-b9f1-3ff9a5be3b5b"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","[TST CPU Inference Latency Benchmark for HAR Windows]\n","Using device: cpu\n","torch.get_num_threads() = 1\n","\n","N_CHANNELS=6, WINDOW_SAMPLES=150, N_CLASSES=8\n","TST config: d_model=64, n_heads=8, d_ff=128, n_layers=4, dropout=0.1\n","\n","Number of trainable parameters: 134,856\n","\n","Measuring CPU latency with input shape: (1, 6, 150) (B, C, T)\n","\n","CPU latency stats for TST.forward() (per batch):\n","  batch_latency_p50_ms: 5.6155\n","  batch_latency_p90_ms: 6.7708\n","  batch_latency_mean_ms: 5.8072\n","  batch_latency_std_ms: 0.4870\n","  n_runs: 100\n","  batch_size: 1\n","\n","Approximate CPU latency per window (HAR sample):\n","  window_latency_p50_ms  ≈ 5.6155\n","  window_latency_p90_ms  ≈ 6.7708\n","  window_latency_mean_ms ≈ 5.8072\n","\n","[TST CPU inference latency benchmark completed]\n"]}]},{"cell_type":"markdown","source":["9. lightweight rTsfNet"],"metadata":{"id":"rft_MQfgLGF6"}},{"cell_type":"code","source":["# ================ rTsfNet (lightweight) CPU Inference Latency Benchmark (Standalone) ================\n","# 0) Ensure a compatible TensorFlow + NumPy combination for Python 3.12\n","!pip -q install \"numpy<2.0.0\" \"tensorflow==2.16.1\"\n","\n","import os\n","os.environ.setdefault(\"OMP_NUM_THREADS\", \"1\")\n","os.environ.setdefault(\"MKL_NUM_THREADS\", \"1\")\n","os.environ.setdefault(\"OPENBLAS_NUM_THREADS\", \"1\")\n","os.environ.setdefault(\"CUDA_VISIBLE_DEVICES\", \"-1\")\n","\n","import time\n","import random\n","import math\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","import numpy as np\n","\n","import tensorflow as tf\n","from tensorflow.keras import Input\n","from tensorflow.keras.layers import (\n","    Dense, Dropout, LayerNormalization, LeakyReLU,\n","    Layer, Lambda, Flatten, GlobalAveragePooling1D, Activation\n",")\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.regularizers import l2\n","\n","print(\"\\n[rTsfNet (lightweight) CPU Inference Latency Benchmark]\")\n","\n","# ---------------------------\n","# 1) Basic configuration\n","# ---------------------------\n","SEED = 42\n","tf.random.set_seed(SEED)\n","np.random.seed(SEED)\n","random.seed(SEED)\n","\n","# Force single-threaded CPU inside TensorFlow\n","tf.config.threading.set_intra_op_parallelism_threads(1)\n","tf.config.threading.set_inter_op_parallelism_threads(1)\n","\n","print(\"Physical devices:\", tf.config.list_physical_devices())\n","print(f\"Intra-op threads: {tf.config.threading.get_intra_op_parallelism_threads()}\")\n","print(f\"Inter-op threads: {tf.config.threading.get_inter_op_parallelism_threads()}\")\n","\n","# HAR-like window settings: 6 channels, 150 time steps (3 s @ 50 Hz)\n","FS             = 50.0\n","N_CHANNELS     = 6\n","WINDOW_SAMPLES = 150\n","N_CLASSES      = 8\n","\n","print(f\"\\nN_CHANNELS={N_CHANNELS}, WINDOW_SAMPLES={WINDOW_SAMPLES}, N_CLASSES={N_CLASSES}\")\n","\n","# rTsfNet hyperparameters (must match your training script)\n","IMU_ROT_HEADS = 2\n","MLP_BASE      = 128\n","MLP_DEPTH     = 3\n","DROPOUT       = 0.5\n","LR            = 1e-3\n","WEIGHT_DECAY  = 1e-6\n","USE_ORIG_INPUT = True\n","\n","print(f\"FS={FS}, IMU_ROT_HEADS={IMU_ROT_HEADS}, MLP_BASE={MLP_BASE}, MLP_DEPTH={MLP_DEPTH}\")\n","print(f\"DROPOUT={DROPOUT}, LR={LR}, WEIGHT_DECAY={WEIGHT_DECAY}, USE_ORIG_INPUT={USE_ORIG_INPUT}\")\n","\n","\n","# ---------------------------\n","# 2) TSF feature layer (same as in your script)\n","# ---------------------------\n","class TSFFeatureLayer(Layer):\n","    \"\"\"\n","    Input: [B, T, C]  Output: [B, C, F]\n","    Time domain: mean/std/max/min/ptp/rms/energy/skew/kurt/zcr/ar1/ar2\n","    Frequency domain: centroid/entropy/flatness/soft-peak + bandpower (0.5–3 / 3–8 / 8–15 Hz)\n","    \"\"\"\n","    def __init__(self, fs=50.0, **kwargs):\n","        super().__init__(**kwargs)\n","        self.fs = float(fs)\n","        self.eps = 1e-8\n","\n","    def get_config(self):\n","        cfg = super().get_config()\n","        cfg.update({\"fs\": self.fs})\n","        return cfg\n","\n","    def call(self, x):  # x: [B, T, C]\n","        mean = tf.reduce_mean(x, axis=1, keepdims=True)\n","        std  = tf.math.reduce_std(x, axis=1, keepdims=True) + self.eps\n","\n","        maxv = tf.reduce_max(x, axis=1, keepdims=True)\n","        minv = tf.reduce_min(x, axis=1, keepdims=True)\n","        ptp  = maxv - minv\n","        rms  = tf.sqrt(tf.reduce_mean(tf.square(x), axis=1, keepdims=True))\n","        energy = tf.reduce_sum(tf.square(x), axis=1, keepdims=True)\n","\n","        skew = tf.reduce_mean(tf.pow((x - mean) / std, 3), axis=1, keepdims=True)\n","        kurt = tf.reduce_mean(tf.pow((x - mean) / std, 4), axis=1, keepdims=True)\n","\n","        signs = tf.sign(x)\n","        sign_changes = tf.abs(signs[:, 1:, :] - signs[:, :-1, :])\n","        zcr = tf.reduce_mean(sign_changes, axis=1, keepdims=True) / 2.0\n","\n","        x_t1 = x[:, :-1, :]\n","        x_tn1 = x[:, 1:, :]\n","        ar1 = tf.reduce_sum(x_t1 * x_tn1, axis=1, keepdims=True) / (\n","            tf.reduce_sum(tf.square(x_t1), axis=1, keepdims=True) + self.eps\n","        )\n","\n","        x_t2 = x[:, :-2, :]\n","        x_tn2 = x[:, 2:, :]\n","        ar2 = tf.reduce_sum(x_t2 * x_tn2, axis=1, keepdims=True) / (\n","            tf.reduce_sum(tf.square(x_t2), axis=1, keepdims=True) + self.eps\n","        )\n","\n","        # Frequency domain\n","        xc = x - mean\n","        x_bc_t = tf.transpose(xc, [0, 2, 1])               # [B, C, T]\n","        fft = tf.signal.rfft(x_bc_t)                       # [B, C, F]\n","        power = tf.square(tf.abs(fft)) + self.eps          # [B, C, F]\n","        power = tf.transpose(power, [0, 2, 1])             # [B, F, C]\n","\n","        F = tf.shape(power)[1]\n","        freqs = tf.linspace(0.0, tf.cast(self.fs, tf.float32) / 2.0, F)  # [F]\n","        freqs = tf.reshape(freqs, [1, F, 1])                             # [1, F, 1]\n","\n","        p = power / (tf.reduce_sum(power, axis=1, keepdims=True) + self.eps)\n","        centroid = tf.reduce_sum(p * freqs, axis=1, keepdims=True)       # [B, 1, C]\n","        entropy  = -tf.reduce_sum(p * tf.math.log(p + self.eps), axis=1, keepdims=True) / (\n","            tf.math.log(tf.cast(F, tf.float32) + self.eps)\n","        )\n","\n","        geo = tf.exp(tf.reduce_mean(tf.math.log(power), axis=1, keepdims=True))\n","        ari = tf.reduce_mean(power, axis=1, keepdims=True)\n","        flatness = geo / (ari + self.eps)\n","\n","        temp = 10.0\n","        w = tf.nn.softmax(power * temp, axis=1)                        # [B, F, C]\n","        soft_peak = tf.reduce_sum(w * freqs, axis=1, keepdims=True)    # [B, 1, C]\n","\n","        def band(low, high):\n","            mask = tf.cast((freqs >= low) & (freqs < high), tf.float32)\n","            bp = tf.reduce_sum(power * mask, axis=1, keepdims=True) / (\n","                tf.reduce_sum(power, axis=1, keepdims=True) + self.eps\n","            )\n","            return bp\n","\n","        bp1 = band(0.5, 3.0)\n","        bp2 = band(3.0, 8.0)\n","        bp3 = band(8.0, 15.0)\n","\n","        feats = [\n","            mean, std, maxv, minv, ptp, rms, energy, skew, kurt, zcr, ar1, ar2,\n","            centroid, entropy, flatness, soft_peak, bp1, bp2, bp3\n","        ]  # each [B,1,C]\n","        res = tf.concat(feats, axis=1)                       # [B, Fnum, C]\n","        return tf.transpose(res, [0, 2, 1])                  # [B, C, Fnum]\n","\n","\n","# ---------------------------\n","# 3) Multi-head 3D rotation (same as in your script)\n","# ---------------------------\n","class Multihead3DRotation(Layer):\n","    \"\"\"\n","    Input [B, T, 6] (ACC + GYR), output: list of length head_nums, each element [B, T, 6].\n","    \"\"\"\n","    def __init__(self, head_nums=2, base_kn=64, param_depth=2, **kwargs):\n","        super().__init__(**kwargs)\n","        self.head_nums = head_nums\n","        self.base_kn = base_kn\n","        self.param_depth = param_depth\n","        self.eps = 1e-8\n","\n","        self.gap = GlobalAveragePooling1D()\n","        self.mlp = [Dense(self.base_kn, activation=\"relu\") for _ in range(self.param_depth)]\n","        self.out_heads = [Dense(4, activation=\"tanh\") for _ in range(self.head_nums)]\n","\n","    def get_config(self):\n","        cfg = super().get_config()\n","        cfg.update(\n","            {\"head_nums\": self.head_nums, \"base_kn\": self.base_kn, \"param_depth\": self.param_depth}\n","        )\n","        return cfg\n","\n","    def compute_output_shape(self, input_shape):\n","        return [tf.TensorShape(input_shape) for _ in range(self.head_nums)]\n","\n","    def _axis_angle_to_R(self, axis_raw, angle_raw):\n","        axis = axis_raw / (tf.norm(axis_raw, axis=-1, keepdims=True) + self.eps)\n","        theta = angle_raw * math.pi                                       # [B,1]\n","        B = tf.shape(axis)[0]\n","\n","        ux, uy, uz = axis[:, 0], axis[:, 1], axis[:, 2]\n","        z = tf.zeros_like(ux)\n","        K = tf.stack(\n","            [\n","                z, -uz, uy,\n","                uz, z, -ux,\n","                -uy, ux, z\n","            ],\n","            axis=-1,\n","        )\n","        K = tf.reshape(K, [B, 3, 3])\n","\n","        I3 = tf.eye(3, dtype=axis.dtype)\n","        I  = tf.tile(I3[None, ...], [B, 1, 1])\n","\n","        u = tf.expand_dims(axis, -1)            # [B,3,1]\n","        uuT = tf.matmul(u, u, transpose_b=True) # [B,3,3]\n","\n","        cos = tf.reshape(tf.cos(theta), [-1, 1, 1])\n","        sin = tf.reshape(tf.sin(theta), [-1, 1, 1])\n","\n","        R = cos * I + (1.0 - cos) * uuT + sin * K\n","        return R\n","\n","    def call(self, x):   # x: [B, T, 6]\n","        acc, gyr = x[:, :, :3], x[:, :, 3:6]\n","        pooled = self.gap(x)                                  # [B, 6]\n","\n","        h = pooled\n","        for layer in self.mlp:\n","            h = layer(h)\n","\n","        out_list = []\n","        for oh in self.out_heads:\n","            p = oh(h)                                         # [B, 4]\n","            axis = p[:, :3]\n","            angle = tf.expand_dims(p[:, 3], -1)               # [B,1]\n","            R = self._axis_angle_to_R(axis, angle)            # [B,3,3]\n","\n","            acc_t = tf.transpose(acc, [0, 2, 1])              # [B,3,T]\n","            acc_rot_t = tf.matmul(R, acc_t)                   # [B,3,T]\n","            acc_rot = tf.transpose(acc_rot_t, [0, 2, 1])      # [B,T,3]\n","\n","            gyr_t = tf.transpose(gyr, [0, 2, 1])              # [B,3,T]\n","            gyr_rot_t = tf.matmul(R, gyr_t)                   # [B,3,T]\n","            gyr_rot = tf.transpose(gyr_rot_t, [0, 2, 1])      # [B,T,3]\n","\n","            out_list.append(tf.concat([acc_rot, gyr_rot], axis=-1))  # [B,T,6]\n","        return out_list\n","\n","\n","# ---------------------------\n","# 4) L2 norm channels (same as in your script)\n","# ---------------------------\n","def add_l2_channels(x):     # x: [B, T, 6]\n","    acc = x[:, :, :3]\n","    gyr = x[:, :, 3:6]\n","    l2_acc = tf.sqrt(tf.reduce_sum(tf.square(acc), axis=-1, keepdims=True))\n","    l2_gyr = tf.sqrt(tf.reduce_sum(tf.square(gyr), axis=-1, keepdims=True))\n","    return tf.concat([x, l2_acc, l2_gyr], axis=-1)  # [B, T, 8]\n","\n","\n","# ---------------------------\n","# 5) rTsfNet model (same structure & hyperparameters)\n","# ---------------------------\n","def r_tsf_net(\n","    x_shape,\n","    n_classes,\n","    learning_rate=1e-3,\n","    base_kn=128,\n","    depth=3,\n","    dropout_rate=0.5,\n","    imu_rot_heads=2,\n","    fs=50.0,\n","    use_orig_input=True,\n","):\n","    inputs = Input(shape=x_shape[1:])     # [T, 6]\n","    x = inputs\n","\n","    rot_layer = Multihead3DRotation(\n","        head_nums=imu_rot_heads, base_kn=64, param_depth=2, name=\"multihead_rot\"\n","    )\n","    rotated_list = rot_layer(x)   # list of [B, T, 6]\n","\n","    streams = []\n","    if use_orig_input:\n","        streams.append(Lambda(add_l2_channels, name=\"orig_plus_l2\")(x))\n","    for i, xr in enumerate(rotated_list):\n","        streams.append(Lambda(add_l2_channels, name=f\"rot{i}_plus_l2\")(xr))\n","\n","    concat_streams = Lambda(\n","        lambda lst: tf.concat(lst, axis=-1), name=\"concat_streams\"\n","    )(streams)  # [B,T,8*(1+heads)]\n","\n","    tsf = TSFFeatureLayer(fs=fs, name=\"tsf\")(concat_streams)  # [B, C_total, F]\n","\n","    z = Flatten(name=\"flatten\")(tsf)\n","    for k in range(depth - 1, -1, -1):\n","        z = Dense(base_kn * (2 ** k), kernel_regularizer=l2(WEIGHT_DECAY), name=f\"fc_{k}\")(z)\n","        z = LayerNormalization(epsilon=1e-7, name=f\"ln_{k}\")(z)\n","        z = LeakyReLU(name=f\"lrelu_{k}\")(z)\n","        z = Dropout(dropout_rate, name=f\"drop_{k}\")(z)\n","\n","    logits = Dense(n_classes, kernel_regularizer=l2(WEIGHT_DECAY), name=\"logits\")(z)\n","    probs  = Activation(\"softmax\", dtype=\"float32\", name=\"softmax\")(logits)\n","\n","    model = Model(inputs, probs, name=\"rTsfNet_officially_aligned_fixed\")\n","\n","    opt = Adam(learning_rate=learning_rate, amsgrad=True)\n","    # compile is not strictly needed for inference latency, but harmless\n","    model.compile(\n","        loss=\"sparse_categorical_crossentropy\",\n","        optimizer=opt,\n","        metrics=[\"accuracy\"],\n","    )\n","    return model\n","\n","\n","# ---------------------------\n","# 6) Instantiate model\n","# ---------------------------\n","BATCH_SIZE = 1\n","x_shape = (BATCH_SIZE, WINDOW_SAMPLES, N_CHANNELS)\n","\n","model = r_tsf_net(\n","    x_shape=x_shape,\n","    n_classes=N_CLASSES,\n","    learning_rate=LR,\n","    base_kn=MLP_BASE,\n","    depth=MLP_DEPTH,\n","    dropout_rate=DROPOUT,\n","    imu_rot_heads=IMU_ROT_HEADS,\n","    fs=FS,\n","    use_orig_input=USE_ORIG_INPUT,\n",")\n","\n","n_params = model.count_params()\n","print(f\"\\nTotal number of model parameters: {n_params:,}\")\n","\n","\n","# ---------------------------\n","# 7) Latency measurement (CPU, single batch = one window)\n","# ---------------------------\n","def measure_latency_tf(\n","    model,\n","    input_shape,\n","    n_warmup: int = 20,\n","    n_runs: int = 100,\n","):\n","    \"\"\"\n","    Measure pure forward-pass latency of the Keras model on CPU.\n","    Returns latency stats in milliseconds per batch (per call to model()).\n","    Each batch element corresponds to one HAR window.\n","    \"\"\"\n","    x = np.random.randn(*input_shape).astype(np.float32)\n","    x_tf = tf.constant(x)\n","\n","    # Warm-up\n","    for _ in range(n_warmup):\n","        _ = model(x_tf, training=False)\n","\n","    times_ms = []\n","    for _ in range(n_runs):\n","        t0 = time.perf_counter()\n","        _ = model(x_tf, training=False)\n","        t1 = time.perf_counter()\n","        times_ms.append((t1 - t0) * 1000.0)\n","\n","    times_ms = np.array(times_ms, dtype=float)\n","    stats = {\n","        \"batch_latency_p50_ms\": float(np.percentile(times_ms, 50)),\n","        \"batch_latency_p90_ms\": float(np.percentile(times_ms, 90)),\n","        \"batch_latency_mean_ms\": float(times_ms.mean()),\n","        \"batch_latency_std_ms\":  float(times_ms.std()),\n","        \"n_runs\": int(n_runs),\n","        \"batch_size\": int(input_shape[0]),\n","    }\n","    return stats\n","\n","\n","input_shape = (BATCH_SIZE, WINDOW_SAMPLES, N_CHANNELS)\n","print(f\"\\nMeasuring CPU latency with input shape: {input_shape} (B, T, C)\")\n","\n","stats = measure_latency_tf(\n","    model,\n","    input_shape=input_shape,\n","    n_warmup=20,\n","    n_runs=100,\n",")\n","\n","print(\"\\nCPU latency stats for rTsfNet.forward() (per batch):\")\n","for k, v in stats.items():\n","    if k.endswith(\"_ms\"):\n","        print(f\"  {k}: {v:.4f}\")\n","    else:\n","        print(f\"  {k}: {v}\")\n","\n","per_window_p50  = stats[\"batch_latency_p50_ms\"]  / stats[\"batch_size\"]\n","per_window_p90  = stats[\"batch_latency_p90_ms\"]  / stats[\"batch_size\"]\n","per_window_mean = stats[\"batch_latency_mean_ms\"] / stats[\"batch_size\"]\n","\n","print(\"\\nApproximate CPU latency per window (HAR sample):\")\n","print(f\"  window_latency_p50_ms  ≈ {per_window_p50:.4f}\")\n","print(f\"  window_latency_p90_ms  ≈ {per_window_p90:.4f}\")\n","print(f\"  window_latency_mean_ms ≈ {per_window_mean:.4f}\")\n","\n","print(\"\\n[rTsfNet (lightweight) CPU inference latency benchmark completed]\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rvI6590KL2rN","executionInfo":{"status":"ok","timestamp":1763456704842,"user_tz":0,"elapsed":64898,"user":{"displayName":"yu Wu","userId":"12692660435918028293"}},"outputId":"ead7dd01-ec64-4536-85a8-21f27589eeb2"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m589.9/589.9 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m90.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m124.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow-decision-forests 1.12.0 requires tensorflow==2.19.0, but you have tensorflow 2.16.1 which is incompatible.\n","opentelemetry-proto 1.37.0 requires protobuf<7.0,>=5.0, but you have protobuf 4.25.8 which is incompatible.\n","jax 0.7.2 requires ml_dtypes>=0.5.0, but you have ml-dtypes 0.3.2 which is incompatible.\n","jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n","jaxlib 0.7.2 requires ml_dtypes>=0.5.0, but you have ml-dtypes 0.3.2 which is incompatible.\n","jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n","grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.8 which is incompatible.\n","tensorstore 0.1.78 requires ml_dtypes>=0.5.0, but you have ml-dtypes 0.3.2 which is incompatible.\n","tf-keras 2.19.0 requires tensorflow<2.20,>=2.19, but you have tensorflow 2.16.1 which is incompatible.\n","ydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\n","tensorflow-text 2.19.0 requires tensorflow<2.20,>=2.19.0, but you have tensorflow 2.16.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m\n","[rTsfNet (lightweight) CPU Inference Latency Benchmark]\n","Physical devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n","Intra-op threads: 1\n","Inter-op threads: 1\n","\n","N_CHANNELS=6, WINDOW_SAMPLES=150, N_CLASSES=8\n","FS=50.0, IMU_ROT_HEADS=2, MLP_BASE=128, MLP_DEPTH=3\n","DROPOUT=0.5, LR=0.001, WEIGHT_DECAY=1e-06, USE_ORIG_INPUT=True\n","\n","Total number of model parameters: 406,160\n","\n","Measuring CPU latency with input shape: (1, 150, 6) (B, T, C)\n","\n","CPU latency stats for rTsfNet.forward() (per batch):\n","  batch_latency_p50_ms: 58.9771\n","  batch_latency_p90_ms: 82.1979\n","  batch_latency_mean_ms: 65.2620\n","  batch_latency_std_ms: 17.1524\n","  n_runs: 100\n","  batch_size: 1\n","\n","Approximate CPU latency per window (HAR sample):\n","  window_latency_p50_ms  ≈ 58.9771\n","  window_latency_p90_ms  ≈ 82.1979\n","  window_latency_mean_ms ≈ 65.2620\n","\n","[rTsfNet (lightweight) CPU inference latency benchmark completed]\n"]}]},{"cell_type":"markdown","source":["10. rTsfNet"],"metadata":{"id":"PLDGKo-hLfkO"}},{"cell_type":"code","source":["# ================ rTsfNet (IMWUT 2024 official) CPU Inference Latency Benchmark (Standalone) ================\n","# Ensure a compatible TensorFlow + NumPy combination (Python 3.12 safe)\n","!pip -q install \"numpy<2.0.0\" \"tensorflow==2.16.1\"\n","\n","import os\n","os.environ.setdefault(\"OMP_NUM_THREADS\", \"1\")\n","os.environ.setdefault(\"MKL_NUM_THREADS\", \"1\")\n","os.environ.setdefault(\"OPENBLAS_NUM_THREADS\", \"1\")\n","os.environ.setdefault(\"CUDA_VISIBLE_DEVICES\", \"-1\")\n","\n","import time\n","import random\n","import math\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras import Input\n","from tensorflow.keras.layers import (\n","    Dense, Dropout, LayerNormalization, LeakyReLU,\n","    Layer, Activation, TimeDistributed, Flatten, Concatenate\n",")\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.regularizers import l2\n","\n","print(\"\\n[rTsfNet (IMWUT 2024 official) CPU Inference Latency Benchmark]\")\n","\n","# ---------------------------\n","# 0) Basic configuration\n","# ---------------------------\n","SEED = 42\n","tf.random.set_seed(SEED)\n","np.random.seed(SEED)\n","random.seed(SEED)\n","\n","# Force single-threaded CPU inside TensorFlow\n","tf.config.threading.set_intra_op_parallelism_threads(1)\n","tf.config.threading.set_inter_op_parallelism_threads(1)\n","\n","print(\"Physical devices:\", tf.config.list_physical_devices())\n","print(f\"Intra-op threads: {tf.config.threading.get_intra_op_parallelism_threads()}\")\n","print(f\"Inter-op threads: {tf.config.threading.get_inter_op_parallelism_threads()}\")\n","\n","# HAR-like window settings: 6 channels, 150 time steps (3 s @ 50 Hz)\n","FS             = 50.0\n","N_CHANNELS     = 6\n","WINDOW_SAMPLES = 150\n","N_CLASSES      = 8\n","\n","print(f\"\\nN_CHANNELS={N_CHANNELS}, WINDOW_SAMPLES={WINDOW_SAMPLES}, N_CLASSES={N_CLASSES}\")\n","\n","# Hyperparameters (must match the official Step 10 script)\n","IMU_ROT_HEADS       = 2\n","MLP_BASE            = 128\n","MLP_DEPTH           = 3\n","DROPOUT             = 0.5\n","LR                  = 1e-3\n","WEIGHT_DECAY        = 1e-6\n","USE_ORIG_INPUT      = True\n","USE_BINARY_SELECTION= True\n","LN_EPS              = 1e-7\n","PAD_MODE            = \"SYMMETRIC\"\n","\n","# Block specs as in the official architecture\n","BLOCK_SPECS = [\n","    dict(name=\"short\", num_blocks=4, use_time=True,  use_freq=False),\n","    dict(name=\"long\",  num_blocks=1, use_time=False, use_freq=True),\n","]\n","\n","print(f\"\\nFS={FS}, IMU_ROT_HEADS={IMU_ROT_HEADS}, MLP_BASE={MLP_BASE}, MLP_DEPTH={MLP_DEPTH}\")\n","print(f\"DROPOUT={DROPOUT}, LR={LR}, WEIGHT_DECAY={WEIGHT_DECAY}\")\n","print(f\"USE_ORIG_INPUT={USE_ORIG_INPUT}, USE_BINARY_SELECTION={USE_BINARY_SELECTION}\")\n","print(f\"LN_EPS={LN_EPS}, PAD_MODE={PAD_MODE}, BLOCK_SPECS={BLOCK_SPECS}\")\n","\n","# ---------------------------\n","# 1) Shared TSF config (same as training script)\n","# ---------------------------\n","TIME_FEATS = 12  # mean/std/max/min/ptp/rms/energy/skew/kurt/zcr/ar1/ar2\n","FREQ_FEATS = 7   # centroid/entropy/flatness/soft-peak/bandpowers(3)\n","\n","\n","# ---------------------------\n","# 2) MLPStack (Keras 3–safe MLP stack)\n","# ---------------------------\n","class MLPStack(Layer):\n","    \"\"\"\n","    Dense -> LayerNorm -> LeakyReLU -> Dropout repeated 'depth' times,\n","    hidden width base_kn * (2**k), k: depth-1..0; output dimensionality\n","    is fixed to base_kn.\n","    \"\"\"\n","    def __init__(self, base_kn=128, depth=3, drop=0.5, wd=0.0, ln_eps=1e-7, name=None):\n","        super().__init__(name=name)\n","        self.base_kn = int(base_kn)\n","        self.depth = int(depth)\n","        self.drop = float(drop)\n","        self.wd = float(wd)\n","        self.ln_eps = float(ln_eps)\n","\n","        self.seq = []\n","        for k in range(self.depth - 1, -1, -1):\n","            self.seq.append(Dense(self.base_kn * (2**k), kernel_regularizer=l2(self.wd)))\n","            self.seq.append(LayerNormalization(epsilon=self.ln_eps))\n","            self.seq.append(LeakyReLU())\n","            self.seq.append(Dropout(self.drop))\n","\n","    @property\n","    def out_dim(self):\n","        return self.base_kn\n","\n","    def call(self, x, training=None):\n","        z = x\n","        for lyr in self.seq:\n","            if isinstance(lyr, Dropout):\n","                z = lyr(z, training=training)\n","            else:\n","                z = lyr(z)\n","        return z\n","\n","    def compute_output_shape(self, input_shape):\n","        return tf.TensorShape([input_shape[0], self.out_dim])\n","\n","\n","# ---------------------------\n","# 3) TSF extraction (axis-wise)\n","# ---------------------------\n","class TSFFeatureLayer(Layer):\n","    \"\"\"Compute axis-wise TSF features for a single block [B, L, C];\n","    output shape [B, C, F] where F is the fixed TSF feature dimensionality.\"\"\"\n","    def __init__(self, fs=50.0, use_time=True, use_freq=True, **kwargs):\n","        super().__init__(**kwargs)\n","        self.fs = float(fs)\n","        self.use_time = bool(use_time)\n","        self.use_freq = bool(use_freq)\n","        self.eps = 1e-8\n","        self._feat_dim = (TIME_FEATS if self.use_time else 0) + (FREQ_FEATS if self.use_freq else 0)\n","\n","    def get_config(self):\n","        cfg = super().get_config()\n","        cfg.update({\"fs\": self.fs, \"use_time\": self.use_time, \"use_freq\": self.use_freq})\n","        return cfg\n","\n","    def call(self, x):  # x: [B, L, C]\n","        feats = []\n","        if self.use_time:\n","            mean = tf.reduce_mean(x, axis=1, keepdims=True)\n","            std  = tf.math.reduce_std(x, axis=1, keepdims=True) + self.eps\n","            maxv = tf.reduce_max(x, axis=1, keepdims=True)\n","            minv = tf.reduce_min(x, axis=1, keepdims=True)\n","            ptp  = maxv - minv\n","            rms  = tf.sqrt(tf.reduce_mean(tf.square(x), axis=1, keepdims=True))\n","            energy = tf.reduce_sum(tf.square(x), axis=1, keepdims=True)\n","            skew = tf.reduce_mean(tf.pow((x - mean) / std, 3), axis=1, keepdims=True)\n","            kurt = tf.reduce_mean(tf.pow((x - mean) / std, 4), axis=1, keepdims=True)\n","            signs = tf.sign(x)\n","            sign_changes = tf.abs(signs[:, 1:, :] - signs[:, :-1, :])\n","            zcr = tf.reduce_mean(sign_changes, axis=1, keepdims=True) / 2.0\n","            x_t1 = x[:, :-1, :]; x_tn1 = x[:, 1:, :]\n","            ar1 = tf.reduce_sum(x_t1 * x_tn1, axis=1, keepdims=True) / (\n","                tf.reduce_sum(tf.square(x_t1), axis=1, keepdims=True) + self.eps\n","            )\n","            x_t2 = x[:, :-2, :]; x_tn2 = x[:, 2:, :]\n","            ar2 = tf.reduce_sum(x_t2 * x_tn2, axis=1, keepdims=True) / (\n","                tf.reduce_sum(tf.square(x_t2), axis=1, keepdims=True) + self.eps\n","            )\n","            feats += [mean, std, maxv, minv, ptp, rms, energy, skew, kurt, zcr, ar1, ar2]\n","\n","        if self.use_freq:\n","            mean = tf.reduce_mean(x, axis=1, keepdims=True)\n","            xc = x - mean\n","            x_bc_t = tf.transpose(xc, [0, 2, 1])               # [B, C, L]\n","            fft = tf.signal.rfft(x_bc_t)                      # [B, C, F]\n","            power = tf.square(tf.abs(fft)) + self.eps         # [B, C, F]\n","            power = tf.transpose(power, [0, 2, 1])            # [B, F, C]\n","\n","            F = tf.shape(power)[1]\n","            freqs = tf.linspace(0.0, tf.cast(self.fs, tf.float32) / 2.0, F)  # [F]\n","            freqs = tf.reshape(freqs, [1, F, 1])                             # [1, F, 1]\n","\n","            p = power / (tf.reduce_sum(power, axis=1, keepdims=True) + self.eps)\n","            centroid = tf.reduce_sum(p * freqs, axis=1, keepdims=True)       # [B, 1, C]\n","            entropy  = -tf.reduce_sum(p * tf.math.log(p + self.eps), axis=1, keepdims=True) / \\\n","                        (tf.math.log(tf.cast(F, tf.float32) + self.eps))\n","            geo = tf.exp(tf.reduce_mean(tf.math.log(power), axis=1, keepdims=True))\n","            ari = tf.reduce_mean(power, axis=1, keepdims=True)\n","            flatness = geo / (ari + self.eps)\n","            temp = 10.0\n","            w = tf.nn.softmax(power * temp, axis=1)                          # [B, F, C]\n","            soft_peak = tf.reduce_sum(w * freqs, axis=1, keepdims=True)      # [B, 1, C]\n","\n","            def band(low, high):\n","                mask = tf.cast((freqs >= low) & (freqs < high), tf.float32)\n","                bp = tf.reduce_sum(power * mask, axis=1, keepdims=True) / (\n","                    tf.reduce_sum(power, axis=1, keepdims=True) + self.eps\n","                )\n","                return bp\n","\n","            bp1 = band(0.5, 3.0); bp2 = band(3.0, 8.0); bp3 = band(8.0, 15.0)\n","            feats += [centroid, entropy, flatness, soft_peak, bp1, bp2, bp3]\n","\n","        res = tf.concat(feats, axis=1)                       # [B, Fnum, C]\n","        return tf.transpose(res, [0, 2, 1])                  # [B, C, Fnum]\n","\n","    def compute_output_shape(self, input_shape):\n","        return tf.TensorShape([input_shape[0], input_shape[2], self._feat_dim])\n","\n","\n","# ---------------------------\n","# 4) L2-norm channels (two variants as in original code)\n","# ---------------------------\n","class AddL2Channels(Layer):\n","    def call(self, x, training=None):\n","        acc = x[:, :, :3]; gyr = x[:, :, 3:6]\n","        l2_acc = tf.sqrt(tf.reduce_sum(tf.square(acc), axis=-1, keepdims=True))\n","        l2_gyr = tf.sqrt(tf.reduce_sum(tf.square(gyr), axis=-1, keepdims=True))\n","        return tf.concat([x, l2_acc, l2_gyr], axis=-1)  # [B, T, 8]\n","\n","    def compute_output_shape(self, input_shape):\n","        return tf.TensorShape([input_shape[0], input_shape[1], 8])\n","\n","\n","class AddL2ChannelsPublic(Layer):\n","    def call(self, x, training=None):\n","        acc = x[:, :, :3]; gyr = x[:, :, 3:6]\n","        l2_acc = tf.sqrt(tf.reduce_sum(tf.square(acc), axis=-1, keepdims=True))\n","        l2_gyr = tf.sqrt(tf.reduce_sum(tf.square(gyr), axis=-1, keepdims=True))\n","        return tf.concat([x, l2_acc, l2_gyr], axis=-1)  # [B, T, 8]\n","\n","    def compute_output_shape(self, input_shape):\n","        return tf.TensorShape([input_shape[0], input_shape[1], 8])\n","\n","\n","# ---------------------------\n","# 5) Block framing utilities\n","# ---------------------------\n","def _int_ceil_div(a, b):\n","    a = tf.cast(a, tf.int32); b = tf.cast(b, tf.int32)\n","    return tf.math.floordiv(a + b - 1, b)\n","\n","def frame_signal_with_padding(x, num_blocks, pad_mode=\"SYMMETRIC\"):\n","    \"\"\"\n","    [B, T, C] -> symmetric padding to length L * num_blocks\n","    and reshape to [B, num_blocks, L, C].\n","    \"\"\"\n","    B = tf.shape(x)[0]; T = tf.shape(x)[1]; C = tf.shape(x)[2]\n","    nb = tf.cast(num_blocks, tf.int32)\n","    L  = _int_ceil_div(T, nb)\n","    total = L * nb\n","    pad_len = total - T\n","    pad_left  = tf.math.floordiv(pad_len, 2)\n","    pad_right = pad_len - pad_left\n","    paddings = tf.stack([\n","        tf.constant([0, 0], dtype=tf.int32),\n","        tf.stack([pad_left, pad_right]),\n","        tf.constant([0, 0], dtype=tf.int32)\n","    ], axis=0)  # [3, 2]\n","    x_pad = tf.pad(x, paddings, mode=pad_mode)\n","    x_blocks = tf.reshape(x_pad, [B, nb, L, C])\n","    return x_blocks\n","\n","\n","class BlockTSFExtractor(Layer):\n","    \"\"\"\n","    Apply TSF extraction and axis-tag injection for a block set.\n","    Input:  x with shape [B, T, C_total]\n","    Output: TSF tensor [B, num_blocks, A, F_total] (A = C_total; last dimension includes tags).\n","    \"\"\"\n","    def __init__(self, num_blocks, fs, use_time, use_freq,\n","                 tag_spec=None, pad_mode=\"SYMMETRIC\", name=None, **kwargs):\n","        super().__init__(name=name, **kwargs)\n","        self.num_blocks = int(num_blocks)\n","        self.tsf = TSFFeatureLayer(fs=fs, use_time=use_time, use_freq=use_freq)\n","        self.tag_spec = tag_spec\n","        self.pad_mode = pad_mode\n","        self.tag_dim = 0 if (tag_spec is None or \"axis_tags\" not in tag_spec) else int(tag_spec[\"axis_tags\"].shape[1])\n","        self.base_feat_dim = (TIME_FEATS if use_time else 0) + (FREQ_FEATS if use_freq else 0)\n","        self.out_feat_dim = self.base_feat_dim + self.tag_dim\n","\n","    def get_config(self):\n","        cfg = super().get_config()\n","        cfg.update({\n","            \"num_blocks\": self.num_blocks,\n","            \"fs\": self.tsf.fs,\n","            \"use_time\": self.tsf.use_time,\n","            \"use_freq\": self.tsf.use_freq,\n","            \"pad_mode\": self.pad_mode\n","        })\n","        return cfg\n","\n","    def call(self, x, training=None):  # x: [B, T, C]\n","        xb = frame_signal_with_padding(x, self.num_blocks, pad_mode=self.pad_mode)  # [B, K, L, C]\n","        B = tf.shape(xb)[0]; K = tf.shape(xb)[1]; L = tf.shape(xb)[2]; C = tf.shape(xb)[3]\n","        xb2 = tf.reshape(xb, [B * K, L, C])                   # [B*K, L, C]\n","        tsf_axis = self.tsf(xb2)                             # [B*K, C, F]\n","        tsf_axis = tf.reshape(tsf_axis, [B, K, C, self.base_feat_dim])  # [B, K, A, F_base]\n","\n","        if self.tag_dim > 0:\n","            axis_tags = tf.convert_to_tensor(self.tag_spec[\"axis_tags\"], dtype=tsf_axis.dtype)  # [A, tag_dim]\n","            axis_tags = tf.reshape(axis_tags, [1, 1, tf.shape(tsf_axis)[2], -1])  # [1, 1, A, tag_dim]\n","            axis_tags = tf.tile(axis_tags, [B, K, 1, 1])                          # [B, K, A, tag_dim]\n","            tsf_axis = tf.concat([tsf_axis, axis_tags], axis=-1)                  # [B, K, A, F_base+tag_dim]\n","        return tsf_axis  # [B, K, A, F_total]\n","\n","    def compute_output_shape(self, input_shape):\n","        return tf.TensorShape([input_shape[0], self.num_blocks, input_shape[2], self.out_feat_dim])\n","\n","\n","# ---------------------------\n","# 6) Binary gate (straight-through estimator)\n","# ---------------------------\n","class BinaryGate(Layer):\n","    def call(self, p, training=None):\n","        p = tf.clip_by_value(p, 0.0, 1.0)\n","        hard = tf.round(p)\n","        return hard + tf.stop_gradient(p - hard)\n","\n","    def compute_output_shape(self, input_shape):\n","        return tf.TensorShape(input_shape)\n","\n","\n","# ---------------------------\n","# 7) TSF-Mixer sub-block and block\n","# ---------------------------\n","class TSFMixerSubBlock(Layer):\n","    \"\"\"\n","    Input: per-block axis-level TSF features with shape [B', A, F]\n","    Architecture: axis-shared MLP -> concatenate axes -> MLP\n","    Output: block-level feature [B', H_out]\n","    \"\"\"\n","    def __init__(self, axis_hidden=128, out_hidden=128, base_depth=2,\n","                 drop=0.5, wd=0.0, ln_eps=1e-7, name=None):\n","        super().__init__(name=name)\n","        self.axis_hidden = int(axis_hidden)\n","        self.out_hidden = int(out_hidden)\n","        self.base_depth = int(base_depth)\n","        self.drop = float(drop); self.wd = float(wd); self.ln_eps = float(ln_eps)\n","        self.axis_mlp_layers = []\n","        for k in range(self.base_depth - 1, -1, -1):\n","            self.axis_mlp_layers.append(Dense(self.axis_hidden * (2**k), kernel_regularizer=l2(self.wd)))\n","            self.axis_mlp_layers.append(LayerNormalization(epsilon=self.ln_eps))\n","            self.axis_mlp_layers.append(LeakyReLU())\n","            self.axis_mlp_layers.append(Dropout(self.drop))\n","        self.out_stack = MLPStack(base_kn=self.out_hidden, depth=self.base_depth,\n","                                  drop=self.drop, wd=self.wd, ln_eps=self.ln_eps, name=f\"{self.name}_out\")\n","\n","    def call(self, x, training=None, **kwargs):  # x: [B', A, F]\n","        Bp = tf.shape(x)[0]; A = tf.shape(x)[1]; F = tf.shape(x)[2]\n","        x2 = tf.reshape(x, [Bp * A, F])\n","        z = x2\n","        for lyr in self.axis_mlp_layers:\n","            if isinstance(lyr, Dropout):\n","                z = lyr(z, training=training)\n","            else:\n","                z = lyr(z)\n","        z = tf.reshape(z, [Bp, A, self.axis_hidden])   # [B', A, H_axis]\n","        z = tf.reshape(z, [Bp, A * self.axis_hidden])  # [B', A*H_axis]\n","        z = self.out_stack(z, training=training)       # [B', H_out]\n","        return z\n","\n","    def compute_output_shape(self, input_shape):\n","        return tf.TensorShape([input_shape[0], self.out_stack.out_dim])\n","\n","\n","class TSFMixerBlock(Layer):\n","    \"\"\"\n","    Extends the sub-Block with:\n","      - channel-wise binary selection (over feature dimension F)\n","      - axis-wise binary selection (over axis dimension A)\n","    Output shape: [B', out_hidden]\n","    \"\"\"\n","    def __init__(self, feat_dim, axis_hidden=128, out_hidden=128, base_depth=2,\n","                 drop=0.5, wd=0.0, ln_eps=1e-7, use_binary=True, name=None):\n","        super().__init__(name=name)\n","        self.use_binary = bool(use_binary)\n","        self.sub = TSFMixerSubBlock(axis_hidden, out_hidden, base_depth, drop, wd, ln_eps,\n","                                    name=f\"{name}_sub\")\n","        self.axis_gate_dense = Dense(1, activation=\"sigmoid\", name=f\"{name}_axis_gate\")\n","        self.chan_gate_dense = Dense(int(feat_dim), activation=\"sigmoid\", name=f\"{name}_chan_gate\")\n","        self.bin_gate = BinaryGate(name=f\"{name}_bin\")\n","        self.out_stack = MLPStack(base_kn=out_hidden, depth=base_depth,\n","                                  drop=drop, wd=wd, ln_eps=ln_eps, name=f\"{name}_out\")\n","\n","    def call(self, x, training=None, **kwargs):  # x: [B', A, F]\n","        Bp = tf.shape(x)[0]; A = tf.shape(x)[1]; F = tf.shape(x)[2]\n","        x_mean_axis = tf.reduce_mean(x, axis=1)            # [B', F]\n","        p_chan = self.chan_gate_dense(x_mean_axis)         # [B', F]\n","        p_chan = tf.reshape(p_chan, [Bp, 1, F])\n","        g_chan = self.bin_gate(p_chan, training=training) if self.use_binary else p_chan\n","        x = x * g_chan\n","\n","        x2 = tf.reshape(x, [Bp * A, F])\n","        z = x2\n","        for lyr in self.sub.axis_mlp_layers:\n","            if isinstance(lyr, Dropout):\n","                z = lyr(z, training=training)\n","            else:\n","                z = lyr(z)\n","        z = tf.reshape(z, [Bp, A, self.sub.axis_hidden])   # [B', A, H_axis]\n","\n","        p_axis = self.axis_gate_dense(z)                   # [B', A, 1]\n","        g_axis = self.bin_gate(p_axis, training=training) if self.use_binary else p_axis\n","        z = z * g_axis\n","\n","        z = tf.reshape(z, [Bp, A * self.sub.axis_hidden])  # [B', A*H_axis]\n","        z = self.out_stack(z, training=training)           # [B', H_out]\n","        return z\n","\n","    def compute_output_shape(self, input_shape):\n","        return tf.TensorShape([input_shape[0], self.out_stack.out_dim])\n","\n","\n","# ---------------------------\n","# 8) Rotation parameter estimation\n","# ---------------------------\n","def _feat_dim_for_spec(use_time, use_freq, tag_dim):\n","    base = (TIME_FEATS if use_time else 0) + (FREQ_FEATS if use_freq else 0)\n","    return base + tag_dim\n","\n","\n","class RotationParamEstimator(Layer):\n","    \"\"\"\n","    Input: [B, T, 6] raw IMU (ACC + GYR); internally append L2 channels,\n","    extract TSF (for multiple block sets), pass through TSF-Mixer,\n","    concatenate all block-level features, then MLP -> Dense(4, tanh)\n","    to produce Rodrigues 4-parameter representation.\n","    \"\"\"\n","    def __init__(self, block_specs, fs, mlp_base=128, mlp_depth=2,\n","                 drop=0.5, wd=0.0, ln_eps=1e-7,\n","                 use_binary=True, pad_mode=\"SYMMETRIC\", name=None):\n","        super().__init__(name=name)\n","        self.block_specs = block_specs\n","        self.fs = fs\n","        self.mlp_base = int(mlp_base)\n","        self.mlp_depth = int(mlp_depth)\n","        self.drop = float(drop)\n","        self.wd = float(wd)\n","        self.ln_eps = float(ln_eps)\n","        self.use_binary = bool(use_binary)\n","        self.pad_mode = pad_mode\n","\n","        axis_tags = []\n","        for i in range(8):\n","            axis_type = i + 1\n","            sensor_type = 1 if (i <= 2 or i == 6) else 2\n","            axis_tags.append([axis_type, sensor_type])\n","        axis_tags = np.array(axis_tags, dtype=np.float32)\n","        self.tag_spec = {\"axis_tags\": axis_tags}\n","        tag_dim = axis_tags.shape[1]\n","\n","        self.extractors = []\n","        self.td_mixers  = []\n","        self.flatteners = []\n","        for spec in block_specs:\n","            ext = BlockTSFExtractor(num_blocks=spec[\"num_blocks\"], fs=fs,\n","                                    use_time=spec[\"use_time\"], use_freq=spec[\"use_freq\"],\n","                                    tag_spec=self.tag_spec, pad_mode=self.pad_mode,\n","                                    name=f\"rot_ext_{spec['name']}\")\n","            self.extractors.append(ext)\n","            feat_dim = _feat_dim_for_spec(spec[\"use_time\"], spec[\"use_freq\"], tag_dim)\n","            mix = TSFMixerBlock(feat_dim=feat_dim, axis_hidden=self.mlp_base,\n","                                out_hidden=self.mlp_base,\n","                                base_depth=max(1, self.mlp_depth - 1),\n","                                drop=self.drop, wd=self.wd,\n","                                ln_eps=self.ln_eps, use_binary=self.use_binary,\n","                                name=f\"rot_mix_{spec['name']}\")\n","            self.td_mixers.append(TimeDistributed(mix, name=f\"rot_td_{spec['name']}\"))\n","            self.flatteners.append(Flatten(name=f\"rot_flat_{spec['name']}\"))\n","\n","        self.concat_sets = Concatenate(name=\"rot_concat_sets\")\n","        self.post_stack = MLPStack(base_kn=self.mlp_base, depth=self.mlp_depth,\n","                                   drop=self.drop, wd=self.wd, ln_eps=self.ln_eps, name=\"rot_post\")\n","        self.out_head = Dense(4, activation=\"tanh\", name=\"rot4_tanh\")\n","        self.add_l2 = AddL2Channels()\n","\n","    def call(self, x, training=None, **kwargs):  # x: [B, T, 6]\n","        x8 = self.add_l2(x)  # [B, T, 8]\n","        feats_all = []\n","        for ext, td, flt in zip(self.extractors, self.td_mixers, self.flatteners):\n","            tsf_blocks = ext(x8, training=training)        # [B, K, A, F]\n","            blk_feat   = td(tsf_blocks, training=training) # [B, K, H]\n","            blk_feat   = flt(blk_feat)                     # [B, K*H]\n","            feats_all.append(blk_feat)\n","        h = self.concat_sets(feats_all)                    # [B, sum(K*H)]\n","        h = self.post_stack(h, training=training)\n","        rot4 = self.out_head(h)\n","        return rot4  # [B, 4]\n","\n","    def compute_output_shape(self, input_shape):\n","        return tf.TensorShape([input_shape[0], 4])\n","\n","\n","# ---------------------------\n","# 9) Multi-head 3D rotation (official)\n","# ---------------------------\n","class Multihead3DRotationOfficial(Layer):\n","    \"\"\"\n","    Input [B, T, 6] (ACC + GYR); output: list whose each element is a\n","    rotated stream [B, T, 6]. Rotation parameters are estimated by\n","    RotationParamEstimator; for head index >= 2, the 4 parameters are\n","    accumulated over previous heads.\n","    \"\"\"\n","    def __init__(self, head_nums=2, fs=50.0, mlp_base=128, mlp_depth=2,\n","                 drop=0.5, wd=0.0, ln_eps=1e-7,\n","                 block_specs=None, use_binary=True, pad_mode=\"SYMMETRIC\", name=None):\n","        super().__init__(name=name)\n","        if block_specs is None:\n","            block_specs = BLOCK_SPECS\n","        self.head_nums = int(head_nums)\n","        self.estimator = RotationParamEstimator(block_specs=block_specs, fs=fs,\n","                                                mlp_base=mlp_base, mlp_depth=mlp_depth,\n","                                                drop=drop, wd=wd,\n","                                                ln_eps=ln_eps, use_binary=use_binary,\n","                                                pad_mode=pad_mode,\n","                                                name=\"rot_estimator\")\n","        self.eps = 1e-8\n","\n","    def compute_output_shape(self, input_shape):\n","        return [tf.TensorShape(input_shape) for _ in range(self.head_nums)]\n","\n","    def call(self, x, training=None, **kwargs):  # x: [B, T, 6]\n","        acc, gyr = x[:, :, :3], x[:, :, 3:6]\n","        out_list = []\n","        prev_rot4 = None\n","        for _ in range(self.head_nums):\n","            rot4 = self.estimator(x, training=training)     # [B, 4]\n","            if prev_rot4 is not None:\n","                rot4 = rot4 + prev_rot4\n","            prev_rot4 = rot4\n","            axis = rot4[:, :3]; angle = tf.expand_dims(rot4[:, 3], -1)\n","            R = self._axis_angle_to_R(axis, angle)          # [B, 3, 3]\n","\n","            acc_t = tf.transpose(acc, [0, 2, 1])            # [B, 3, T]\n","            acc_rot = tf.transpose(tf.matmul(R, acc_t), [0, 2, 1])\n","            gyr_t = tf.transpose(gyr, [0, 2, 1])\n","            gyr_rot = tf.transpose(tf.matmul(R, gyr_t), [0, 2, 1])\n","\n","            out_list.append(tf.concat([acc_rot, gyr_rot], axis=-1))  # [B, T, 6]\n","        return out_list\n","\n","    def _axis_angle_to_R(self, axis_raw, angle_raw):\n","        axis = axis_raw / (tf.norm(axis_raw, axis=-1, keepdims=True) + self.eps)  # [B, 3]\n","        theta = angle_raw * math.pi                                               # [B, 1]\n","        B = tf.shape(axis)[0]\n","        ux, uy, uz = axis[:, 0], axis[:, 1], axis[:, 2]\n","        z = tf.zeros_like(ux)\n","        K = tf.stack([z, -uz,  uy,\n","                      uz,  z, -ux,\n","                     -uy,  ux,  z], axis=-1)\n","        K = tf.reshape(K, [B, 3, 3])\n","        I  = tf.tile(tf.eye(3, dtype=axis.dtype)[None, ...], [B, 1, 1])\n","        u = tf.expand_dims(axis, -1)                                              # [B, 3, 1]\n","        uuT = tf.matmul(u, u, transpose_b=True)                                   # [B, 3, 3]\n","        cos = tf.reshape(tf.cos(theta), [-1, 1, 1])\n","        sin = tf.reshape(tf.sin(theta), [-1, 1, 1])\n","        R = cos * I + (1.0 - cos) * uuT + sin * K                                 # [B, 3, 3]\n","        return R\n","\n","\n","# ---------------------------\n","# 10) Official rTsfNet body\n","# ---------------------------\n","def r_tsf_net_official(\n","    x_shape,\n","    n_classes,\n","    learning_rate=1e-3,\n","    base_kn=128,\n","    depth=3,\n","    dropout_rate=0.5,\n","    imu_rot_heads=2,\n","    fs=50.0,\n","    use_orig_input=True,\n","    use_binary_selection=True,\n","    ln_eps=1e-7,\n","    pad_mode=\"SYMMETRIC\",\n","):\n","    inputs = Input(shape=x_shape[1:])\n","    x = inputs\n","\n","    rot_layer = Multihead3DRotationOfficial(\n","        head_nums=imu_rot_heads, fs=fs,\n","        mlp_base=base_kn, mlp_depth=max(1, depth - 1), drop=dropout_rate, wd=WEIGHT_DECAY,\n","        ln_eps=ln_eps, block_specs=BLOCK_SPECS, use_binary=use_binary_selection, pad_mode=pad_mode,\n","        name=\"multihead_rot_official\"\n","    )\n","    rotated_list = rot_layer(x)\n","\n","    streams = []\n","    add_l2 = AddL2ChannelsPublic()\n","    if use_orig_input:\n","        streams.append(add_l2(x))\n","    for xr in rotated_list:\n","        streams.append(add_l2(xr))\n","    concat_streams = Concatenate(axis=-1, name=\"concat_streams\")(streams)\n","\n","    feats_all_sets = []\n","    num_streams = (1 if use_orig_input else 0) + imu_rot_heads\n","    axis_tags_one_stream = []\n","    for i in range(8):\n","        axis_type = i + 1\n","        sensor_type = 1 if (i <= 2 or i == 6) else 2\n","        axis_tags_one_stream.append([axis_type, sensor_type])\n","    axis_tags_one_stream = np.array(axis_tags_one_stream, dtype=np.float32)\n","    axis_tags_all = np.concatenate([axis_tags_one_stream for _ in range(num_streams)], axis=0)\n","    tag_spec_main = {\"axis_tags\": axis_tags_all}\n","    tag_dim_main = axis_tags_all.shape[1]\n","\n","    for spec in BLOCK_SPECS:\n","        ext = BlockTSFExtractor(num_blocks=spec[\"num_blocks\"], fs=fs,\n","                                use_time=spec[\"use_time\"], use_freq=spec[\"use_freq\"],\n","                                tag_spec=tag_spec_main, pad_mode=pad_mode,\n","                                name=f\"main_ext_{spec['name']}\")\n","        feat_dim = _feat_dim_for_spec(spec[\"use_time\"], spec[\"use_freq\"], tag_dim_main)\n","        mix = TSFMixerBlock(feat_dim=feat_dim, axis_hidden=base_kn, out_hidden=base_kn,\n","                            base_depth=max(1, depth - 1), drop=dropout_rate, wd=WEIGHT_DECAY,\n","                            ln_eps=ln_eps, use_binary=use_binary_selection,\n","                            name=f\"main_mix_{spec['name']}\")\n","        td  = TimeDistributed(mix, name=f\"main_td_{spec['name']}\")\n","        flt = Flatten(name=f\"main_flat_{spec['name']}\")\n","\n","        tsf_blocks = ext(concat_streams)   # [B, K, A_all, F]\n","        blk_feat   = td(tsf_blocks)        # [B, K, H]\n","        blk_feat   = flt(blk_feat)         # [B, K*H]\n","        feats_all_sets.append(blk_feat)\n","\n","    z = Concatenate(name=\"main_concat_sets\")(feats_all_sets)\n","    cls_stack = MLPStack(base_kn=base_kn, depth=depth, drop=dropout_rate,\n","                         wd=WEIGHT_DECAY, ln_eps=ln_eps, name=\"cls\")\n","    z = cls_stack(z)\n","    logits = Dense(n_classes, kernel_regularizer=l2(WEIGHT_DECAY), name=\"logits\")(z)\n","    probs  = Activation(\"softmax\", dtype=\"float32\", name=\"softmax\")(logits)\n","\n","    model = Model(inputs, probs, name=\"rTsfNet_official_aligned\")\n","\n","    opt = Adam(learning_rate=learning_rate, amsgrad=True)\n","    model.compile(\n","        loss=\"sparse_categorical_crossentropy\",\n","        optimizer=opt,\n","        metrics=[\"accuracy\"],\n","    )\n","    return model\n","\n","\n","# ---------------------------\n","# 11) Instantiate model\n","# ---------------------------\n","BATCH_SIZE = 1\n","x_shape = (BATCH_SIZE, WINDOW_SAMPLES, N_CHANNELS)\n","\n","model = r_tsf_net_official(\n","    x_shape=x_shape,\n","    n_classes=N_CLASSES,\n","    learning_rate=LR,\n","    base_kn=MLP_BASE,\n","    depth=MLP_DEPTH,\n","    dropout_rate=DROPOUT,\n","    imu_rot_heads=IMU_ROT_HEADS,\n","    fs=FS,\n","    use_orig_input=USE_ORIG_INPUT,\n","    use_binary_selection=USE_BINARY_SELECTION,\n","    ln_eps=LN_EPS,\n","    pad_mode=PAD_MODE,\n",")\n","\n","n_params = model.count_params()\n","print(f\"\\nTotal number of model parameters: {n_params:,}\")\n","\n","\n","# ---------------------------\n","# 12) Latency measurement (CPU, forward only)\n","# ---------------------------\n","def measure_latency_tf(\n","    model,\n","    input_shape,\n","    n_warmup: int = 20,\n","    n_runs: int = 100,\n","):\n","    \"\"\"\n","    Measure pure forward-pass latency of the Keras model on CPU.\n","    Returns latency stats in milliseconds per batch (per call to model()).\n","    Each batch element corresponds to one HAR window.\n","    \"\"\"\n","    x = np.random.randn(*input_shape).astype(np.float32)\n","    x_tf = tf.constant(x)\n","\n","    # Warm-up\n","    for _ in range(n_warmup):\n","        _ = model(x_tf, training=False)\n","\n","    times_ms = []\n","    for _ in range(n_runs):\n","        t0 = time.perf_counter()\n","        _ = model(x_tf, training=False)\n","        t1 = time.perf_counter()\n","        times_ms.append((t1 - t0) * 1000.0)\n","\n","    times_ms = np.array(times_ms, dtype=float)\n","    stats = {\n","        \"batch_latency_p50_ms\": float(np.percentile(times_ms, 50)),\n","        \"batch_latency_p90_ms\": float(np.percentile(times_ms, 90)),\n","        \"batch_latency_mean_ms\": float(times_ms.mean()),\n","        \"batch_latency_std_ms\":  float(times_ms.std()),\n","        \"n_runs\": int(n_runs),\n","        \"batch_size\": int(input_shape[0]),\n","    }\n","    return stats\n","\n","\n","input_shape = (BATCH_SIZE, WINDOW_SAMPLES, N_CHANNELS)\n","print(f\"\\nMeasuring CPU latency with input shape: {input_shape} (B, T, C)\")\n","\n","stats = measure_latency_tf(\n","    model,\n","    input_shape=input_shape,\n","    n_warmup=20,\n","    n_runs=100,\n",")\n","\n","print(\"\\nCPU latency stats for rTsfNet (IMWUT 2024 official) forward() (per batch):\")\n","for k, v in stats.items():\n","    if k.endswith(\"_ms\"):\n","        print(f\"  {k}: {v:.4f}\")\n","    else:\n","        print(f\"  {k}: {v}\")\n","\n","per_window_p50  = stats[\"batch_latency_p50_ms\"]  / stats[\"batch_size\"]\n","per_window_p90  = stats[\"batch_latency_p90_ms\"]  / stats[\"batch_size\"]\n","per_window_mean = stats[\"batch_latency_mean_ms\"] / stats[\"batch_size\"]\n","\n","print(\"\\nApproximate CPU latency per window (HAR sample):\")\n","print(f\"  window_latency_p50_ms  ≈ {per_window_p50:.4f}\")\n","print(f\"  window_latency_p90_ms  ≈ {per_window_p90:.4f}\")\n","print(f\"  window_latency_mean_ms ≈ {per_window_mean:.4f}\")\n","\n","print(\"\\n[rTsfNet (IMWUT 2024 official) CPU inference latency benchmark completed]\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Sb_JIO9XOOHZ","executionInfo":{"status":"ok","timestamp":1763457063357,"user_tz":0,"elapsed":59743,"user":{"displayName":"yu Wu","userId":"12692660435918028293"}},"outputId":"a9c8b48c-3fd2-472c-a97c-42ab4ccef994"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","[rTsfNet (IMWUT 2024 official) CPU Inference Latency Benchmark]\n","Physical devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n","Intra-op threads: 1\n","Inter-op threads: 1\n","\n","N_CHANNELS=6, WINDOW_SAMPLES=150, N_CLASSES=8\n","\n","FS=50.0, IMU_ROT_HEADS=2, MLP_BASE=128, MLP_DEPTH=3\n","DROPOUT=0.5, LR=0.001, WEIGHT_DECAY=1e-06\n","USE_ORIG_INPUT=True, USE_BINARY_SELECTION=True\n","LN_EPS=1e-07, PAD_MODE=SYMMETRIC, BLOCK_SPECS=[{'name': 'short', 'num_blocks': 4, 'use_time': True, 'use_freq': False}, {'name': 'long', 'num_blocks': 1, 'use_time': False, 'use_freq': True}]\n","\n","Total number of model parameters: 960,698\n","\n","Measuring CPU latency with input shape: (1, 150, 6) (B, T, C)\n","\n","CPU latency stats for rTsfNet (IMWUT 2024 official) forward() (per batch):\n","  batch_latency_p50_ms: 439.6153\n","  batch_latency_p90_ms: 454.8026\n","  batch_latency_mean_ms: 441.3187\n","  batch_latency_std_ms: 9.5725\n","  n_runs: 100\n","  batch_size: 1\n","\n","Approximate CPU latency per window (HAR sample):\n","  window_latency_p50_ms  ≈ 439.6153\n","  window_latency_p90_ms  ≈ 454.8026\n","  window_latency_mean_ms ≈ 441.3187\n","\n","[rTsfNet (IMWUT 2024 official) CPU inference latency benchmark completed]\n"]}]},{"cell_type":"markdown","source":["11. DeepConvContext – LSTM variant – 1-layer – bidirectional"],"metadata":{"id":"n1rYEiDUPhSH"}},{"cell_type":"code","source":["# ============ DeepConvContext CPU Inference Latency Benchmark (Standalone) ============\n","\n","import os\n","os.environ.setdefault(\"OMP_NUM_THREADS\", \"1\")\n","os.environ.setdefault(\"MKL_NUM_THREADS\", \"1\")\n","os.environ.setdefault(\"OPENBLAS_NUM_THREADS\", \"1\")\n","\n","import time\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","\n","print(\"\\n[DeepConvContext CPU Inference Latency Benchmark]\")\n","\n","# ---------------------------\n","# 0) Basic configuration\n","# ---------------------------\n","SEED = 42\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","\n","device = torch.device(\"cpu\")\n","torch.set_num_threads(1)\n","\n","print(f\"Using device: {device}\")\n","print(f\"torch.get_num_threads() = {torch.get_num_threads()}\")\n","\n","# Windowing: 3 s @ 50 Hz = 150 samples; 50% overlap → stride = 75\n","# sequence length S = 100 windows, 6 channels\n","NUM_CHANNELS      = 6\n","SAMPLES_PER_WIN   = 150\n","CONTEXT_LEN_WINS  = 100\n","NUM_CLASSES       = 8   # RealWorld-HAR uses 8 classes\n","\n","print(f\"\\nConfig: num_classes={NUM_CLASSES}, channels={NUM_CHANNELS}, \"\n","      f\"samples_per_window={SAMPLES_PER_WIN}, sequence_length={CONTEXT_LEN_WINS}\")\n","\n","\n","# ---------------------------\n","# 1) DeepConvContext model (same architecture as Step 10)\n","# ---------------------------\n","class DeepConvLSTM_Intra(nn.Module):\n","    def __init__(self, in_ch=6, conv_ch=64, kernel_size=9, lstm_units=128):\n","        super().__init__()\n","        pad = kernel_size // 2\n","        self.conv1 = nn.Conv1d(in_ch,   conv_ch, kernel_size, padding=pad)\n","        self.conv2 = nn.Conv1d(conv_ch, conv_ch, kernel_size, padding=pad)\n","        self.conv3 = nn.Conv1d(conv_ch, conv_ch, kernel_size, padding=pad)\n","        self.conv4 = nn.Conv1d(conv_ch, conv_ch, kernel_size, padding=pad)\n","        self.relu  = nn.ReLU(inplace=True)\n","        self.lstm  = nn.LSTM(input_size=conv_ch, hidden_size=lstm_units,\n","                             num_layers=1, batch_first=True)\n","\n","    def forward(self, x_win):           # x_win: (N, C, T)\n","        x = self.relu(self.conv1(x_win))\n","        x = self.relu(self.conv2(x))\n","        x = self.relu(self.conv3(x))\n","        x = self.relu(self.conv4(x))\n","        x = x.permute(0, 2, 1)          # (N, T, C)\n","        _, (h_n, _) = self.lstm(x)\n","        return h_n[-1]                  # (N, 128)\n","\n","\n","class DeepConvContext(nn.Module):\n","    def __init__(self, num_channels=6, num_classes=8,\n","                 conv_channels=64, intra_lstm_units=128,\n","                 inter_lstm_units=128, projection_dim=128,\n","                 dropout=0.5, bidirectional=True):\n","        super().__init__()\n","        self.intra = DeepConvLSTM_Intra(num_channels, conv_channels, 9, intra_lstm_units)\n","        self.proj  = nn.Linear(intra_lstm_units, projection_dim)\n","        self.inter = nn.LSTM(input_size=projection_dim, hidden_size=inter_lstm_units,\n","                             num_layers=1, batch_first=True, bidirectional=bidirectional)\n","        inter_out = inter_lstm_units * (2 if bidirectional else 1)\n","        self.dropout = nn.Dropout(dropout)\n","        self.fc = nn.Linear(inter_out, num_classes)\n","\n","    def forward(self, x):               # x: (B, S, C, T) → logits: (B, S, K)\n","        B, S, C, T = x.shape\n","        x2d = x.reshape(B * S, C, T)\n","        feats = self.intra(x2d).view(B, S, -1)     # (B, S, 128)\n","        proj  = self.proj(feats)                   # (B, S, 128)\n","        inter_out, _ = self.inter(proj)            # (B, S, 128*dir)\n","        inter_out = self.dropout(inter_out)\n","        logits = self.fc(inter_out)                # (B, S, num_classes)\n","        return logits\n","\n","\n","# ---------------------------\n","# 2) Utility: parameter count\n","# ---------------------------\n","def count_parameters(model: nn.Module) -> int:\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","\n","# ---------------------------\n","# 3) Latency measurement on CPU\n","# ---------------------------\n","def measure_latency(\n","    model: nn.Module,\n","    input_shape,\n","    device: torch.device,\n","    n_warmup: int = 20,\n","    n_runs: int = 100,\n","):\n","    \"\"\"\n","    Measure pure forward-pass latency on CPU.\n","    Returns latency stats in milliseconds per sequence (B, S, C, T).\n","    \"\"\"\n","    model = model.to(device)\n","    model.eval()\n","    torch.set_grad_enabled(False)\n","\n","    x = torch.randn(*input_shape, device=device, dtype=torch.float32)\n","\n","    # Warm-up\n","    for _ in range(n_warmup):\n","        _ = model(x)\n","\n","    # Timed runs\n","    times_ms = []\n","    for _ in range(n_runs):\n","        t0 = time.perf_counter()\n","        _ = model(x)\n","        t1 = time.perf_counter()\n","        times_ms.append((t1 - t0) * 1000.0)\n","\n","    times_ms = np.array(times_ms, dtype=float)\n","    stats = {\n","        \"sequence_latency_p50_ms\": float(np.percentile(times_ms, 50)),\n","        \"sequence_latency_p90_ms\": float(np.percentile(times_ms, 90)),\n","        \"sequence_latency_mean_ms\": float(times_ms.mean()),\n","        \"sequence_latency_std_ms\":  float(times_ms.std()),\n","        \"n_runs\": int(n_runs),\n","    }\n","    return stats\n","\n","\n","# ---------------------------\n","# 4) Instantiate model and run benchmark\n","# ---------------------------\n","model = DeepConvContext(\n","    num_channels=NUM_CHANNELS,\n","    num_classes=NUM_CLASSES,\n","    conv_channels=64,\n","    intra_lstm_units=128,\n","    inter_lstm_units=128,\n","    projection_dim=128,\n","    dropout=0.5,\n","    bidirectional=True,\n",")\n","\n","n_params = count_parameters(model)\n","print(f\"\\nNumber of trainable parameters: {n_params:,}\")\n","\n","BATCH_SIZE = 1   # one sequence per batch\n","input_shape = (BATCH_SIZE, CONTEXT_LEN_WINS, NUM_CHANNELS, SAMPLES_PER_WIN)  # (B, S, C, T)\n","\n","print(f\"\\nMeasuring CPU latency with input shape: {input_shape} (B, S, C, T)\")\n","\n","stats = measure_latency(\n","    model,\n","    input_shape=input_shape,\n","    device=device,\n","    n_warmup=20,\n","    n_runs=100,\n",")\n","\n","print(\"\\nCPU latency stats for DeepConvContext.forward() (per sequence of 100 windows):\")\n","for k, v in stats.items():\n","    if k.endswith(\"_ms\"):\n","        print(f\"  {k}: {v:.4f}\")\n","    else:\n","        print(f\"  {k}: {v}\")\n","\n","# Convert sequence latency → per-window latency (divide by sequence length = 100)\n","per_window_p50  = stats[\"sequence_latency_p50_ms\"]  / CONTEXT_LEN_WINS\n","per_window_p90  = stats[\"sequence_latency_p90_ms\"]  / CONTEXT_LEN_WINS\n","per_window_mean = stats[\"sequence_latency_mean_ms\"] / CONTEXT_LEN_WINS\n","\n","print(\"\\nApproximate CPU latency per window (3 s HAR window):\")\n","print(f\"  window_latency_p50_ms  ≈ {per_window_p50:.4f}\")\n","print(f\"  window_latency_p90_ms  ≈ {per_window_p90:.4f}\")\n","print(f\"  window_latency_mean_ms ≈ {per_window_mean:.4f}\")\n","\n","print(\"\\n[DeepConvContext CPU inference latency benchmark completed]\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-SABwIUFPXJs","executionInfo":{"status":"ok","timestamp":1763457227450,"user_tz":0,"elapsed":24687,"user":{"displayName":"yu Wu","userId":"12692660435918028293"}},"outputId":"54deab51-f61a-4650-c4f9-09a6cbc24d91"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","[DeepConvContext CPU Inference Latency Benchmark]\n","Using device: cpu\n","torch.get_num_threads() = 1\n","\n","Config: num_classes=8, channels=6, samples_per_window=150, sequence_length=100\n","\n","Number of trainable parameters: 496,392\n","\n","Measuring CPU latency with input shape: (1, 100, 6, 150) (B, S, C, T)\n","\n","CPU latency stats for DeepConvContext.forward() (per sequence of 100 windows):\n","  sequence_latency_p50_ms: 202.3898\n","  sequence_latency_p90_ms: 206.5136\n","  sequence_latency_mean_ms: 203.3992\n","  sequence_latency_std_ms: 3.6146\n","  n_runs: 100\n","\n","Approximate CPU latency per window (3 s HAR window):\n","  window_latency_p50_ms  ≈ 2.0239\n","  window_latency_p90_ms  ≈ 2.0651\n","  window_latency_mean_ms ≈ 2.0340\n","\n","[DeepConvContext CPU inference latency benchmark completed]\n"]}]},{"cell_type":"markdown","source":["12. DeepConvContext-LSTM (unidirectional, 1-layer)"],"metadata":{"id":"kOeLVsNZQdCz"}},{"cell_type":"code","source":["# ================ DeepConvContext (from-scratch, official architecture) CPU Inference Latency Benchmark ================\n","import os\n","os.environ.setdefault(\"OMP_NUM_THREADS\", \"1\")\n","os.environ.setdefault(\"MKL_NUM_THREADS\", \"1\")\n","os.environ.setdefault(\"OPENBLAS_NUM_THREADS\", \"1\")\n","\n","import time\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","\n","print(\"\\n[DeepConvContext (from-scratch) CPU Inference Latency Benchmark]\")\n","\n","# ---------------------------\n","# 0) Basic configuration (CPU, single-thread)\n","# ---------------------------\n","SEED = 1\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","\n","device = torch.device(\"cpu\")\n","torch.set_num_threads(1)\n","\n","print(f\"Using device: {device}\")\n","print(f\"torch.get_num_threads() = {torch.get_num_threads()}\")\n","\n","# Window configuration: 3s @ 50 Hz → 150 samples; 50% overlap → stride 75; context length S = 100\n","NUM_CHANNELS      = 6\n","SAMPLES_PER_WIN   = 150\n","WIN_OVERLAP       = 0.5\n","STRIDE_SAMPLES    = int(SAMPLES_PER_WIN * (1 - WIN_OVERLAP))  # 75\n","CONTEXT_LEN_WINS  = 100\n","NUM_CLASSES       = 8\n","\n","# Model hyperparameters (must match training script)\n","HIDDEN_UNITS  = 128\n","CONV_CHANNELS = 64\n","KERNEL_SIZE   = 9\n","DROPOUT_P     = 0.5\n","BIDIRECTIONAL = False\n","\n","print(f\"\\nConfig: num_classes={NUM_CLASSES}, num_channels={NUM_CHANNELS}, \"\n","      f\"samples_per_window={SAMPLES_PER_WIN}, sequence_length={CONTEXT_LEN_WINS}\")\n","print(f\"DeepConvContext: conv_channels={CONV_CHANNELS}, hidden_intra={HIDDEN_UNITS}, \"\n","      f\"hidden_inter={HIDDEN_UNITS}, bidirectional={BIDIRECTIONAL}, dropout={DROPOUT_P}\")\n","\n","\n","# ---------------------------\n","# 1) Model definition (exactly as in the Step 10 from-scratch script)\n","# ---------------------------\n","class DeepConvLSTM_Intra(nn.Module):\n","    def __init__(self, in_ch=6, conv_ch=64, kernel_size=9, hidden=128):\n","        super().__init__()\n","        pad = kernel_size // 2\n","        self.conv1 = nn.Conv1d(in_ch,   conv_ch, kernel_size, padding=pad)\n","        self.conv2 = nn.Conv1d(conv_ch, conv_ch, kernel_size, padding=pad)\n","        self.conv3 = nn.Conv1d(conv_ch, conv_ch, kernel_size, padding=pad)\n","        self.conv4 = nn.Conv1d(conv_ch, conv_ch, kernel_size, padding=pad)\n","        self.relu  = nn.ReLU(inplace=True)\n","        self.lstm  = nn.LSTM(input_size=conv_ch, hidden_size=hidden,\n","                             num_layers=1, batch_first=True)\n","\n","    def forward(self, x_win):  # x_win: (N, C, T)\n","        x = self.relu(self.conv1(x_win))\n","        x = self.relu(self.conv2(x))\n","        x = self.relu(self.conv3(x))\n","        x = self.relu(self.conv4(x))\n","        x = x.permute(0, 2, 1)  # (N, T, C)\n","        _, (h_n, _) = self.lstm(x)\n","        return h_n[-1]         # (N, hidden)\n","\n","\n","class DeepConvContext(nn.Module):\n","    def __init__(self,\n","                 num_channels=6,\n","                 num_classes=8,\n","                 conv_channels=64,\n","                 hidden_intra=128,\n","                 hidden_inter=128,\n","                 dropout=0.5,\n","                 bidirectional=False):\n","        super().__init__()\n","        self.intra = DeepConvLSTM_Intra(num_channels, conv_channels, KERNEL_SIZE, hidden_intra)\n","\n","        self.inter = nn.LSTM(input_size=hidden_intra,\n","                             hidden_size=hidden_inter,\n","                             num_layers=1,\n","                             batch_first=True,\n","                             bidirectional=bidirectional)\n","        inter_out = hidden_inter * (2 if bidirectional else 1)\n","\n","        self.dropout = nn.Dropout(dropout)\n","        self.fc      = nn.Linear(inter_out, num_classes)\n","\n","    def forward(self, x):               # x: (B, S, C, T)\n","        B, S, C, T = x.shape\n","        x = x.reshape(B * S, C, T)\n","        feats = self.intra(x)           # (B*S, hidden_intra)\n","        feats = feats.view(B, S, -1)    # (B, S, hidden_intra)\n","        inter_out, _ = self.inter(feats)  # (B, S, inter_out)\n","        inter_out = self.dropout(inter_out)\n","        logits = self.fc(inter_out)     # (B, S, K)\n","        return logits\n","\n","\n","# ---------------------------\n","# 2) Utility: parameter count\n","# ---------------------------\n","def count_parameters(model: nn.Module) -> int:\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","\n","# ---------------------------\n","# 3) Latency measurement on CPU\n","# ---------------------------\n","def measure_latency(\n","    model: nn.Module,\n","    input_shape,\n","    device: torch.device,\n","    n_warmup: int = 20,\n","    n_runs: int = 100,\n","):\n","    \"\"\"\n","    Measure pure forward-pass latency on CPU.\n","    Returns latency stats in milliseconds per sequence (B, S, C, T).\n","    \"\"\"\n","    model = model.to(device)\n","    model.eval()\n","    torch.set_grad_enabled(False)\n","\n","    x = torch.randn(*input_shape, device=device, dtype=torch.float32)\n","\n","    # Warm-up\n","    for _ in range(n_warmup):\n","        _ = model(x)\n","\n","    # Timed runs\n","    times_ms = []\n","    for _ in range(n_runs):\n","        t0 = time.perf_counter()\n","        _ = model(x)\n","        t1 = time.perf_counter()\n","        times_ms.append((t1 - t0) * 1000.0)\n","\n","    times_ms = np.array(times_ms, dtype=float)\n","    stats = {\n","        \"sequence_latency_p50_ms\": float(np.percentile(times_ms, 50)),\n","        \"sequence_latency_p90_ms\": float(np.percentile(times_ms, 90)),\n","        \"sequence_latency_mean_ms\": float(times_ms.mean()),\n","        \"sequence_latency_std_ms\":  float(times_ms.std()),\n","        \"n_runs\": int(n_runs),\n","    }\n","    return stats\n","\n","\n","# ---------------------------\n","# 4) Instantiate model and run benchmark\n","# ---------------------------\n","model = DeepConvContext(\n","    num_channels=NUM_CHANNELS,\n","    num_classes=NUM_CLASSES,\n","    conv_channels=CONV_CHANNELS,\n","    hidden_intra=HIDDEN_UNITS,\n","    hidden_inter=HIDDEN_UNITS,\n","    dropout=DROPOUT_P,\n","    bidirectional=BIDIRECTIONAL,\n",")\n","\n","n_params = count_parameters(model)\n","print(f\"\\nNumber of trainable parameters: {n_params:,}\")\n","\n","BATCH_SIZE = 1   # one sequence per batch\n","input_shape = (BATCH_SIZE, CONTEXT_LEN_WINS, NUM_CHANNELS, SAMPLES_PER_WIN)  # (B, S, C, T)\n","\n","print(f\"\\nMeasuring CPU latency with input shape: {input_shape} (B, S, C, T)\")\n","\n","stats = measure_latency(\n","    model,\n","    input_shape=input_shape,\n","    device=device,\n","    n_warmup=20,\n","    n_runs=100,\n",")\n","\n","print(\"\\nCPU latency stats for DeepConvContext (from-scratch) forward() \"\n","      \"(per sequence of 100 windows):\")\n","for k, v in stats.items():\n","    if k.endswith(\"_ms\"):\n","        print(f\"  {k}: {v:.4f}\")\n","    else:\n","        print(f\"  {k}: {v}\")\n","\n","# Convert sequence latency → per-window latency (divide by S=100)\n","per_window_p50  = stats[\"sequence_latency_p50_ms\"]  / CONTEXT_LEN_WINS\n","per_window_p90  = stats[\"sequence_latency_p90_ms\"]  / CONTEXT_LEN_WINS\n","per_window_mean = stats[\"sequence_latency_mean_ms\"] / CONTEXT_LEN_WINS\n","\n","print(\"\\nApproximate CPU latency per window (3 s HAR window):\")\n","print(f\"  window_latency_p50_ms  ≈ {per_window_p50:.4f}\")\n","print(f\"  window_latency_p90_ms  ≈ {per_window_p90:.4f}\")\n","print(f\"  window_latency_mean_ms ≈ {per_window_mean:.4f}\")\n","\n","print(\"\\n[DeepConvContext (from-scratch) CPU inference latency benchmark completed]\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zigb2b5rQyDq","executionInfo":{"status":"ok","timestamp":1763457616853,"user_tz":0,"elapsed":24389,"user":{"displayName":"yu Wu","userId":"12692660435918028293"}},"outputId":"46848b6a-ec46-4e45-c8ed-55816f94f502"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","[DeepConvContext (from-scratch) CPU Inference Latency Benchmark]\n","Using device: cpu\n","torch.get_num_threads() = 1\n","\n","Config: num_classes=8, num_channels=6, samples_per_window=150, sequence_length=100\n","DeepConvContext: conv_channels=64, hidden_intra=128, hidden_inter=128, bidirectional=False, dropout=0.5\n","\n","Number of trainable parameters: 346,760\n","\n","Measuring CPU latency with input shape: (1, 100, 6, 150) (B, S, C, T)\n","\n","CPU latency stats for DeepConvContext (from-scratch) forward() (per sequence of 100 windows):\n","  sequence_latency_p50_ms: 201.0896\n","  sequence_latency_p90_ms: 205.5973\n","  sequence_latency_mean_ms: 201.9558\n","  sequence_latency_std_ms: 3.1175\n","  n_runs: 100\n","\n","Approximate CPU latency per window (3 s HAR window):\n","  window_latency_p50_ms  ≈ 2.0109\n","  window_latency_p90_ms  ≈ 2.0560\n","  window_latency_mean_ms ≈ 2.0196\n","\n","[DeepConvContext (from-scratch) CPU inference latency benchmark completed]\n"]}]},{"cell_type":"markdown","source":["13. DeepConvContext Bi‑Attention"],"metadata":{"id":"ZwKRcg0mRMP7"}},{"cell_type":"code","source":["# ================ DeepConvContext Bi-Attention CPU Inference Latency Benchmark (Standalone) ================\n","import os\n","os.environ.setdefault(\"OMP_NUM_THREADS\", \"1\")\n","os.environ.setdefault(\"MKL_NUM_THREADS\", \"1\")\n","os.environ.setdefault(\"OPENBLAS_NUM_THREADS\", \"1\")\n","\n","import time\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","\n","print(\"\\n[DeepConvContext Bi-Attention CPU Inference Latency Benchmark]\")\n","\n","# ---------------------------\n","# 0) Basic configuration (CPU, single-thread)\n","# ---------------------------\n","SEED = 1\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","\n","device = torch.device(\"cpu\")\n","torch.set_num_threads(1)\n","\n","print(f\"Using device: {device}\")\n","print(f\"torch.get_num_threads() = {torch.get_num_threads()}\")\n","\n","# Window settings: 3 s @ 50 Hz = 150 samples; 50% overlap → stride = 75\n","NUM_CHANNELS     = 6\n","SAMPLES_PER_WIN  = 150\n","WIN_OVERLAP      = 0.5\n","STRIDE_SAMPLES   = int(SAMPLES_PER_WIN * (1 - WIN_OVERLAP))  # 75\n","\n","# Context length per batch (paper uses batch as context, batch_size=100)\n","CONTEXT_LEN_WINS = 100   # number of windows per context (batch size during training/testing)\n","\n","# Model hyperparameters (must match training script)\n","NUM_CLASSES     = 8\n","DROPOUT_P       = 0.5\n","HIDDEN_UNITS    = 128\n","CONV_CHANNELS   = 64\n","KERNEL_SIZE     = 9\n","PROJECTION_DIM  = 128\n","ATTN_HEADS      = 4\n","ATTN_LAYERS     = 3\n","MAX_CONTEXT_WINS= 200    # for positional encoding\n","BIDIRECTIONAL   = True   # Bi-Attention variant\n","\n","print(f\"\\nConfig: num_classes={NUM_CLASSES}, num_channels={NUM_CHANNELS}, \"\n","      f\"samples_per_window={SAMPLES_PER_WIN}, context_len_windows={CONTEXT_LEN_WINS}\")\n","print(f\"DeepConvContext Bi-Attention: conv_channels={CONV_CHANNELS}, hidden={HIDDEN_UNITS}, \"\n","      f\"proj_dim={PROJECTION_DIM}, attn_heads={ATTN_HEADS}, attn_layers={ATTN_LAYERS}, \"\n","      f\"dropout={DROPOUT_P}, bidirectional={BIDIRECTIONAL}\")\n","\n","\n","# ---------------------------\n","# 1) Model definition (exactly as in the paper-aligned script)\n","# ---------------------------\n","class DeepConvLSTM_Intra(nn.Module):\n","    \"\"\"\n","    Intra-window branch:\n","    4×Conv1d(64, k=9) + ReLU → 1-layer LSTM(128)\n","    \"\"\"\n","    def __init__(self, in_ch: int = 6, conv_ch: int = 64, kernel_size: int = 9, hidden: int = 128):\n","        super().__init__()\n","        pad = kernel_size // 2\n","        self.conv1 = nn.Conv1d(in_ch,   conv_ch, kernel_size, padding=pad)\n","        self.conv2 = nn.Conv1d(conv_ch, conv_ch, kernel_size, padding=pad)\n","        self.conv3 = nn.Conv1d(conv_ch, conv_ch, kernel_size, padding=pad)\n","        self.conv4 = nn.Conv1d(conv_ch, conv_ch, kernel_size, padding=pad)\n","        self.relu  = nn.ReLU(inplace=True)\n","        self.lstm  = nn.LSTM(\n","            input_size=conv_ch,\n","            hidden_size=hidden,\n","            num_layers=1,\n","            batch_first=True\n","        )\n","\n","    def forward(self, x_win: torch.Tensor) -> torch.Tensor:\n","        # x_win: (B, C, T)\n","        x = self.relu(self.conv1(x_win))\n","        x = self.relu(self.conv2(x))\n","        x = self.relu(self.conv3(x))\n","        x = self.relu(self.conv4(x))        # (B, conv_ch, T)\n","        x = x.permute(0, 2, 1)              # (B, T, conv_ch)\n","        _, (h_n, _) = self.lstm(x)          # h_n: (1, B, hidden)\n","        return h_n[-1]                      # (B, hidden)\n","\n","\n","class PositionalEncoding1D(nn.Module):\n","    \"\"\"\n","    Learnable positional encoding over the context window index.\n","    \"\"\"\n","    def __init__(self, d_model: int, max_len: int = 200):\n","        super().__init__()\n","        self.pos_embedding = nn.Embedding(max_len, d_model)\n","\n","    def forward(self, x: torch.Tensor) -> torch.Tensor:\n","        # x: (B_seq, S, D)\n","        seq_len = x.size(1)\n","        positions = torch.arange(seq_len, device=x.device).unsqueeze(0)  # (1, S)\n","        pos = self.pos_embedding(positions)                              # (1, S, D)\n","        return x + pos\n","\n","\n","class MultiHeadSelfAttentionBlock(nn.Module):\n","    \"\"\"\n","    Self-attention block: MHA + residual + LayerNorm (no dropout inside attention to match paper).\n","    \"\"\"\n","    def __init__(self, dim: int, num_heads: int):\n","        super().__init__()\n","        self.mha  = nn.MultiheadAttention(\n","            embed_dim=dim,\n","            num_heads=num_heads,\n","            dropout=0.0,\n","            batch_first=True\n","        )\n","        self.norm = nn.LayerNorm(dim)\n","\n","    def forward(self, x: torch.Tensor, attn_mask: torch.Tensor | None = None) -> torch.Tensor:\n","        # x: (B_seq, S, D)\n","        attn_out, _ = self.mha(x, x, x, attn_mask=attn_mask, need_weights=False)\n","        return self.norm(x + attn_out)\n","\n","\n","class DeepConvContext_BiAttention(nn.Module):\n","    \"\"\"\n","    DeepConvContext attention variant (paper-aligned RWHAR):\n","      Intra : Conv×4 + 1-Layer LSTM(128)\n","      Proj  : FC(128→128)\n","      Inter : stack of 3×(4-head Multi-Head Self-Attention) blocks\n","              (batch dimension is treated as context sequence)\n","      Positional encoding added before attention\n","      Dropout(0.5) → FC(num_classes)\n","    \"\"\"\n","    def __init__(self,\n","                 num_channels: int = 6,\n","                 num_classes: int = 8,\n","                 conv_channels: int = 64,\n","                 hidden_intra: int = 128,\n","                 projection_dim: int = 128,\n","                 attn_heads: int = 4,\n","                 num_attn_layers: int = 3,\n","                 max_context_len: int = 200,\n","                 dropout: float = 0.5,\n","                 bidirectional: bool = True):\n","        super().__init__()\n","\n","        self.intra = DeepConvLSTM_Intra(\n","            in_ch=num_channels,\n","            conv_ch=conv_channels,\n","            kernel_size=KERNEL_SIZE,\n","            hidden=hidden_intra\n","        )\n","\n","        self.proj = nn.Linear(hidden_intra, projection_dim)\n","        self.pos_enc = PositionalEncoding1D(projection_dim, max_len=max_context_len)\n","\n","        self.bidirectional = bidirectional\n","        self.attn_layers = nn.ModuleList([\n","            MultiHeadSelfAttentionBlock(projection_dim, attn_heads)\n","            for _ in range(num_attn_layers)\n","        ])\n","\n","        self.dropout = nn.Dropout(dropout)\n","        self.fc      = nn.Linear(projection_dim, num_classes)\n","\n","    def forward(self, x: torch.Tensor) -> torch.Tensor:\n","        \"\"\"\n","        x: (B, C, T) — B time-ordered windows, batch is treated as context\n","        return: (B, num_classes)\n","        \"\"\"\n","        B, C, T = x.shape\n","\n","        feats = self.intra(x)          # (B, hidden_intra)\n","        proj  = self.proj(feats)       # (B, D)\n","\n","        # Batch-as-context: interpret B as sequence length\n","        seq = proj.unsqueeze(0)        # (1, B, D)\n","        seq = self.pos_enc(seq)        # (1, B, D)\n","\n","        attn_mask = None\n","        if not self.bidirectional:\n","            S_len = B\n","            attn_mask = torch.ones(\n","                S_len, S_len,\n","                device=x.device,\n","                dtype=torch.bool\n","            ).triu(diagonal=1)\n","\n","        for layer in self.attn_layers:\n","            seq = layer(seq, attn_mask=attn_mask)   # (1, B, D)\n","\n","        seq = self.dropout(seq)\n","        logits = self.fc(seq)         # (1, B, num_classes)\n","        return logits.squeeze(0)      # (B, num_classes)\n","\n","\n","# ---------------------------\n","# 2) Utility: parameter count\n","# ---------------------------\n","def count_parameters(model: nn.Module) -> int:\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","\n","# ---------------------------\n","# 3) Latency measurement on CPU\n","# ---------------------------\n","def measure_latency(\n","    model: nn.Module,\n","    input_shape,\n","    device: torch.device,\n","    n_warmup: int = 20,\n","    n_runs: int = 100,\n","):\n","    \"\"\"\n","    Measure pure forward-pass latency on CPU.\n","    Returns latency stats in milliseconds per batch (i.e., per context of 100 windows).\n","    \"\"\"\n","    model = model.to(device)\n","    model.eval()\n","    torch.set_grad_enabled(False)\n","\n","    x = torch.randn(*input_shape, device=device, dtype=torch.float32)\n","\n","    # Warm-up\n","    for _ in range(n_warmup):\n","        _ = model(x)\n","\n","    # Timed runs\n","    times_ms = []\n","    for _ in range(n_runs):\n","        t0 = time.perf_counter()\n","        _ = model(x)\n","        t1 = time.perf_counter()\n","        times_ms.append((t1 - t0) * 1000.0)\n","\n","    times_ms = np.array(times_ms, dtype=float)\n","    stats = {\n","        \"context_latency_p50_ms\": float(np.percentile(times_ms, 50)),\n","        \"context_latency_p90_ms\": float(np.percentile(times_ms, 90)),\n","        \"context_latency_mean_ms\": float(times_ms.mean()),\n","        \"context_latency_std_ms\":  float(times_ms.std()),\n","        \"n_runs\": int(n_runs),\n","    }\n","    return stats\n","\n","\n","# ---------------------------\n","# 4) Instantiate model and run benchmark\n","# ---------------------------\n","model = DeepConvContext_BiAttention(\n","    num_channels=NUM_CHANNELS,\n","    num_classes=NUM_CLASSES,\n","    conv_channels=CONV_CHANNELS,\n","    hidden_intra=HIDDEN_UNITS,\n","    projection_dim=PROJECTION_DIM,\n","    attn_heads=ATTN_HEADS,\n","    num_attn_layers=ATTN_LAYERS,\n","    max_context_len=MAX_CONTEXT_WINS,\n","    dropout=DROPOUT_P,\n","    bidirectional=BIDIRECTIONAL,   # Bi-Attention variant\n",")\n","\n","n_params = count_parameters(model)\n","print(f\"\\nNumber of trainable parameters: {n_params:,}\")\n","\n","# Here, each batch = one context of 100 windows (B=100, C=6, T=150)\n","BATCH_CONTEXT = CONTEXT_LEN_WINS\n","input_shape = (BATCH_CONTEXT, NUM_CHANNELS, SAMPLES_PER_WIN)  # (B, C, T)\n","\n","print(f\"\\nMeasuring CPU latency with input shape: {input_shape} (B=context_len, C, T)\")\n","\n","stats = measure_latency(\n","    model,\n","    input_shape=input_shape,\n","    device=device,\n","    n_warmup=20,\n","    n_runs=100,\n",")\n","\n","print(\"\\nCPU latency stats for DeepConvContext Bi-Attention forward() \"\n","      \"(per context of 100 windows):\")\n","for k, v in stats.items():\n","    if k.endswith(\"_ms\"):\n","        print(f\"  {k}: {v:.4f}\")\n","    else:\n","        print(f\"  {k}: {v}\")\n","\n","# Convert context latency → per-window latency (divide by context length = 100)\n","per_window_p50  = stats[\"context_latency_p50_ms\"]  / BATCH_CONTEXT\n","per_window_p90  = stats[\"context_latency_p90_ms\"]  / BATCH_CONTEXT\n","per_window_mean = stats[\"context_latency_mean_ms\"] / BATCH_CONTEXT\n","\n","print(\"\\nApproximate CPU latency per window (3 s HAR window):\")\n","print(f\"  window_latency_p50_ms  ≈ {per_window_p50:.4f}\")\n","print(f\"  window_latency_p90_ms  ≈ {per_window_p90:.4f}\")\n","print(f\"  window_latency_mean_ms ≈ {per_window_mean:.4f}\")\n","\n","print(\"\\n[DeepConvContext Bi-Attention CPU inference latency benchmark completed]\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XC0NoBgwRqyH","executionInfo":{"status":"ok","timestamp":1763457885247,"user_tz":0,"elapsed":24708,"user":{"displayName":"yu Wu","userId":"12692660435918028293"}},"outputId":"2232d131-f22c-4769-a427-0af8f5941e40"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","[DeepConvContext Bi-Attention CPU Inference Latency Benchmark]\n","Using device: cpu\n","torch.get_num_threads() = 1\n","\n","Config: num_classes=8, num_channels=6, samples_per_window=150, context_len_windows=100\n","DeepConvContext Bi-Attention: conv_channels=64, hidden=128, proj_dim=128, attn_heads=4, attn_layers=3, dropout=0.5, bidirectional=True\n","\n","Number of trainable parameters: 455,688\n","\n","Measuring CPU latency with input shape: (100, 6, 150) (B=context_len, C, T)\n","\n","CPU latency stats for DeepConvContext Bi-Attention forward() (per context of 100 windows):\n","  context_latency_p50_ms: 202.3500\n","  context_latency_p90_ms: 208.1371\n","  context_latency_mean_ms: 203.6163\n","  context_latency_std_ms: 4.0729\n","  n_runs: 100\n","\n","Approximate CPU latency per window (3 s HAR window):\n","  window_latency_p50_ms  ≈ 2.0235\n","  window_latency_p90_ms  ≈ 2.0814\n","  window_latency_mean_ms ≈ 2.0362\n","\n","[DeepConvContext Bi-Attention CPU inference latency benchmark completed]\n"]}]}]}