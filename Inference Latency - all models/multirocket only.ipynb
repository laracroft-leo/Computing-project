{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyN0NO+zKKeHedyEnIvuM5Xs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pH0ysIgaTbHy","executionInfo":{"status":"ok","timestamp":1763461044386,"user_tz":0,"elapsed":2764086,"user":{"displayName":"yu Wu","userId":"12692660435918028293"}},"outputId":"3db0c537-07b8-49f1-fc0b-2da1b028721a"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.3/37.3 MB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\n","[MultiRocket CPU Inference Latency Benchmark for HAR Windows (aeon)]\n","Using device: cpu\n","torch.get_num_threads()      = 1\n","Numba effective num_threads  = 1\n","Platform : Linux 6.6.105+\n","CPU      : x86_64\n","N_CHANNELS=6, WINDOW_SAMPLES=150, N_CLASSES=8\n","N_TRAIN=20000, N_WARMUP=20, N_RUNS=100, BATCH_SIZE=1\n","N_KERNELS (MultiRocket)          = 10000\n","MAX_DILATIONS_PER_KERNEL         = 32\n","N_FEATURES_PER_KERNEL            = 4\n","Assumed sampling rate = 50.0 Hz → window length ≈ 3.000 s\n","\n","X_train_np shape: (20000, 6, 150), y_train shape: (20000,)\n","\n","MultiRocket fit + linear head fit time: 2737552.053 ms\n","MultiRocket transformed feature dimension: 79968\n","Approximate number of linear head parameters: 639,752\n","\n","Query batch array shape: (1, 6, 150)\n","\n","CPU latency stats for MultiRocket + linear head (per batch):\n","  batch_latency_p50_ms: 28.2411\n","  batch_latency_p90_ms: 28.6361\n","  batch_latency_mean_ms: 28.3152\n","  batch_latency_std_ms: 0.6243\n","  n_runs: 100\n","  batch_size: 1\n","\n","Approximate CPU latency per window (HAR sample):\n","  window_latency_p50_ms  ≈ 28.2411\n","  window_latency_p90_ms  ≈ 28.6361\n","  window_latency_mean_ms ≈ 28.3152\n","\n","Real-time factor (MultiRocket, CPU):\n","  p50  RTF ≈ 0.0094 (CPU time / wall-clock window length)\n","  mean RTF ≈ 0.0094\n","\n","[MultiRocket CPU inference latency benchmark (aeon, single-core) completed]\n"]}],"source":["# ================ MultiRocket CPU Inference Latency Benchmark for HAR Windows (Standalone, aeon) ================\n","# IMPORTANT:\n","#   - Run this cell in a *fresh* Colab runtime, before importing numba / aeon / torch anywhere else.\n","#   - The script is designed to be directly comparable to your MiniRocket CPU benchmark:\n","#       * 6 channels, 150 time steps (~3 s @ 50 Hz), 8 classes\n","#       * N_TRAIN = 20,000 synthetic windows\n","#       * N_WARMUP = 20, N_RUNS = 100, BATCH_SIZE = 1\n","#       * Single-core intent: all thread-related env vars set to 1, n_jobs=1 in MultiRocket\n","#   - Latency = MultiRocket.transform() + RidgeClassifier.predict() on CPU.\n","\n","!pip -q install aeon scikit-learn\n","\n","import os\n","import time\n","import random\n","import warnings\n","import platform\n","\n","warnings.filterwarnings(\"ignore\")\n","\n","# ----------------------------------------------------------------------\n","# 0) Environment: fix thread-related env vars BEFORE importing numba/aeon\n","# ----------------------------------------------------------------------\n","# We fix all relevant BLAS / OpenMP / Numba thread counts to 1 to emulate\n","# a single-core CPU setting. This MUST be done before importing numba.\n","for var in [\"OMP_NUM_THREADS\", \"MKL_NUM_THREADS\", \"OPENBLAS_NUM_THREADS\", \"NUMBA_NUM_THREADS\"]:\n","    os.environ[var] = \"1\"\n","\n","import numpy as np\n","import torch\n","from sklearn.linear_model import RidgeClassifier\n","import numba\n","from aeon.transformations.collection.convolution_based import MultiRocket\n","\n","print(\"\\n[MultiRocket CPU Inference Latency Benchmark for HAR Windows (aeon)]\")\n","\n","# ----------------------------------------------------------------------\n","# 1) Basic configuration\n","# ----------------------------------------------------------------------\n","SEED = 42\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","\n","# Make PyTorch single-threaded (for consistency with env vars)\n","torch.set_num_threads(1)\n","\n","# Numba should already respect NUMBA_NUM_THREADS=1 from the env\n","numba_threads = numba.get_num_threads()\n","\n","device = \"cpu\"\n","print(f\"Using device: {device}\")\n","print(f\"torch.get_num_threads()      = {torch.get_num_threads()}\")\n","print(f\"Numba effective num_threads  = {numba_threads}\")\n","\n","print(\"Platform :\", platform.system(), platform.release())\n","print(\"CPU      :\", platform.processor())\n","\n","# HAR-like window settings (aligned with the MiniRocket benchmark)\n","N_CHANNELS      = 6\n","WINDOW_SAMPLES  = 150   # ~3 s @ 50 Hz\n","N_CLASSES       = 8\n","\n","print(f\"N_CHANNELS={N_CHANNELS}, WINDOW_SAMPLES={WINDOW_SAMPLES}, N_CLASSES={N_CLASSES}\")\n","\n","# Training set size (aligned with other baselines)\n","N_TRAIN   = 20000\n","\n","# Latency measurement settings\n","N_WARMUP   = 20\n","N_RUNS     = 100\n","BATCH_SIZE = 1      # number of query windows per call\n","\n","print(f\"N_TRAIN={N_TRAIN}, N_WARMUP={N_WARMUP}, N_RUNS={N_RUNS}, BATCH_SIZE={BATCH_SIZE}\")\n","\n","# MultiRocket configuration (standard, literature-aligned)\n","N_KERNELS                = 10000   # number of convolutional kernels\n","MAX_DILATIONS_PER_KERNEL = 32\n","N_FEATURES_PER_KERNEL    = 4\n","\n","print(f\"N_KERNELS (MultiRocket)          = {N_KERNELS}\")\n","print(f\"MAX_DILATIONS_PER_KERNEL         = {MAX_DILATIONS_PER_KERNEL}\")\n","print(f\"N_FEATURES_PER_KERNEL            = {N_FEATURES_PER_KERNEL}\")\n","\n","SAMPLE_RATE_HZ = 50.0\n","WINDOW_SECONDS = WINDOW_SAMPLES / SAMPLE_RATE_HZ\n","print(f\"Assumed sampling rate = {SAMPLE_RATE_HZ} Hz → window length ≈ {WINDOW_SECONDS:.3f} s\")\n","\n","# ----------------------------------------------------------------------\n","# 2) Create synthetic HAR-like training dataset (3D numpy)\n","# ----------------------------------------------------------------------\n","# Shape: (n_instances, n_channels, n_timepoints)\n","X_train_np = np.random.randn(N_TRAIN, N_CHANNELS, WINDOW_SAMPLES).astype(np.float32)\n","y_train    = np.random.randint(0, N_CLASSES, size=(N_TRAIN,), dtype=np.int32)\n","\n","print(f\"\\nX_train_np shape: {X_train_np.shape}, y_train shape: {y_train.shape}\")\n","\n","# ----------------------------------------------------------------------\n","# 3) Define MultiRocket + linear classifier (Ridge)\n","# ----------------------------------------------------------------------\n","multirocket = MultiRocket(\n","    n_kernels=N_KERNELS,\n","    max_dilations_per_kernel=MAX_DILATIONS_PER_KERNEL,\n","    n_features_per_kernel=N_FEATURES_PER_KERNEL,\n","    normalise=False,\n","    n_jobs=1,           # do not use joblib parallelism; keep it single-process\n","    random_state=SEED,\n",")\n","\n","clf = RidgeClassifier(\n","    alpha=1.0,\n","    fit_intercept=True\n",")\n","\n","# ----------------------------------------------------------------------\n","# 4) Fit MultiRocket feature extractor + linear classifier\n","# ----------------------------------------------------------------------\n","t0_fit = time.perf_counter()\n","multirocket.fit(X_train_np, y_train)\n","X_train_trans = multirocket.transform(X_train_np)\n","clf.fit(X_train_trans, y_train)\n","t1_fit = time.perf_counter()\n","fit_time_ms = (t1_fit - t0_fit) * 1000.0\n","\n","n_features_rocket = X_train_trans.shape[1]\n","n_linear_params = clf.coef_.size + clf.intercept_.size\n","\n","print(f\"\\nMultiRocket fit + linear head fit time: {fit_time_ms:.3f} ms\")\n","print(f\"MultiRocket transformed feature dimension: {n_features_rocket}\")\n","print(f\"Approximate number of linear head parameters: {n_linear_params:,}\")\n","\n","# ----------------------------------------------------------------------\n","# 5) Utility: latency measurement for MultiRocket + linear head\n","# ----------------------------------------------------------------------\n","def measure_multirocket_latency(\n","    transformer: MultiRocket,\n","    classifier,\n","    X_query: np.ndarray,\n","    batch_size: int,\n","    n_warmup: int = 20,\n","    n_runs: int = 100,\n","):\n","    \"\"\"\n","    Measure MultiRocket.transform() + linear classifier.predict() latency on CPU.\n","    X_query: np.ndarray with shape (batch_size, n_channels, n_timepoints).\n","    Returns latency stats in milliseconds per batch.\n","    \"\"\"\n","    # Warm-up runs (excluded from stats)\n","    for _ in range(n_warmup):\n","        X_feat = transformer.transform(X_query)\n","        _ = classifier.predict(X_feat)\n","\n","    # Timed runs\n","    times_ms = []\n","    for _ in range(n_runs):\n","        t0 = time.perf_counter()\n","        X_feat = transformer.transform(X_query)\n","        _ = classifier.predict(X_feat)\n","        t1 = time.perf_counter()\n","        times_ms.append((t1 - t0) * 1000.0)\n","\n","    times_ms = np.array(times_ms, dtype=float)\n","    stats = {\n","        \"batch_latency_p50_ms\": float(np.percentile(times_ms, 50)),\n","        \"batch_latency_p90_ms\": float(np.percentile(times_ms, 90)),\n","        \"batch_latency_mean_ms\": float(times_ms.mean()),\n","        \"batch_latency_std_ms\":  float(times_ms.std()),\n","        \"n_runs\": int(n_runs),\n","        \"batch_size\": int(batch_size),\n","    }\n","    return stats\n","\n","# ----------------------------------------------------------------------\n","# 6) Build a synthetic query batch and run the benchmark\n","# ----------------------------------------------------------------------\n","X_query_np = np.random.randn(BATCH_SIZE, N_CHANNELS, WINDOW_SAMPLES).astype(np.float32)\n","print(f\"\\nQuery batch array shape: {X_query_np.shape}\")\n","\n","stats = measure_multirocket_latency(\n","    multirocket,\n","    clf,\n","    X_query=X_query_np,\n","    batch_size=BATCH_SIZE,\n","    n_warmup=N_WARMUP,\n","    n_runs=N_RUNS,\n",")\n","\n","print(\"\\nCPU latency stats for MultiRocket + linear head (per batch):\")\n","for k, v in stats.items():\n","    if k.endswith(\"_ms\"):\n","        print(f\"  {k}: {v:.4f}\")\n","    else:\n","        print(f\"  {k}: {v}\")\n","\n","# Each sample corresponds to one HAR window, so per-window latency = per-batch / batch_size\n","per_window_p50  = stats[\"batch_latency_p50_ms\"]  / stats[\"batch_size\"]\n","per_window_p90  = stats[\"batch_latency_p90_ms\"]  / stats[\"batch_size\"]\n","per_window_mean = stats[\"batch_latency_mean_ms\"] / stats[\"batch_size\"]\n","\n","print(\"\\nApproximate CPU latency per window (HAR sample):\")\n","print(f\"  window_latency_p50_ms  ≈ {per_window_p50:.4f}\")\n","print(f\"  window_latency_p90_ms  ≈ {per_window_p90:.4f}\")\n","print(f\"  window_latency_mean_ms ≈ {per_window_mean:.4f}\")\n","\n","# Optional: real-time factor relative to window length\n","rt_factor_p50  = per_window_p50  / (WINDOW_SECONDS * 1000.0)\n","rt_factor_mean = per_window_mean / (WINDOW_SECONDS * 1000.0)\n","\n","print(\"\\nReal-time factor (MultiRocket, CPU):\")\n","print(f\"  p50  RTF ≈ {rt_factor_p50:.4f} (CPU time / wall-clock window length)\")\n","print(f\"  mean RTF ≈ {rt_factor_mean:.4f}\")\n","\n","print(\"\\n[MultiRocket CPU inference latency benchmark (aeon, single-core) completed]\")"]}]}