{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyPVVeoT7tpKZcaVRVkrl7OS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Test sequence:\n","1. minirocket (sktime)\n","2. multirocket (sktime)\n","3. multirocket (aeon)"],"metadata":{"id":"6NGVP88ES7ZZ"}},{"cell_type":"markdown","source":["1. minirocket (sktime)"],"metadata":{"id":"OBEhesSrTGxn"}},{"cell_type":"code","source":["\n","# ================ MiniRocket CPU Inference Latency Benchmark for HAR Windows (Standalone) ================\n","!pip -q install sktime\n","\n","import os\n","os.environ.setdefault(\"OMP_NUM_THREADS\", \"1\")\n","os.environ.setdefault(\"MKL_NUM_THREADS\", \"1\")\n","os.environ.setdefault(\"OPENBLAS_NUM_THREADS\", \"1\")\n","os.environ.setdefault(\"NUMBA_NUM_THREADS\", \"1\")\n","os.environ.setdefault(\"NUMBA_DEFAULT_NUM_THREADS\", \"1\")\n","\n","import time\n","import random\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","import numpy as np\n","import pandas as pd\n","import torch\n","import numba\n","from sklearn.linear_model import RidgeClassifier\n","from sktime.transformations.panel.rocket import MiniRocketMultivariate\n","\n","print(\"\\n[MiniRocket CPU Inference Latency Benchmark for HAR Windows]\")\n","\n","# ---------------------------\n","# 0) Basic configuration\n","# ---------------------------\n","SEED = 42\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","\n","# Single-core CPU\n","device = \"cpu\"\n","torch.set_num_threads(1)\n","numba.set_num_threads(1)\n","\n","print(f\"Using device: {device}\")\n","print(f\"torch.get_num_threads() = {torch.get_num_threads()}\")\n","print(f\"NUMBA threads = {numba.get_num_threads()}\")\n","\n","# HAR-like window settings: 6 channels, 150 time steps (e.g., 3 s @ 50 Hz)\n","N_CHANNELS      = 6\n","WINDOW_SAMPLES  = 150\n","N_CLASSES       = 8\n","\n","print(f\"N_CHANNELS={N_CHANNELS}, WINDOW_SAMPLES={WINDOW_SAMPLES}, N_CLASSES={N_CLASSES}\")\n","\n","# Training set size for MiniRocket + linear head (aligned with KNN/RF)\n","N_TRAIN   = 20000   # number of training windows\n","\n","# Latency measurement settings\n","N_WARMUP   = 20\n","N_RUNS     = 100\n","BATCH_SIZE = 1      # number of query windows per call\n","\n","print(f\"N_TRAIN={N_TRAIN}, N_WARMUP={N_WARMUP}, N_RUNS={N_RUNS}, BATCH_SIZE={BATCH_SIZE}\")\n","\n","\n","# ---------------------------\n","# 1) Helper: convert 3D numpy to sktime nested DataFrame\n","#    X_np: (n_instances, n_channels, n_timepoints)\n","# ---------------------------\n","def to_nested_dataframe(X_np: np.ndarray) -> pd.DataFrame:\n","    n_instances, n_channels, n_timepoints = X_np.shape\n","    data = {}\n","    for c in range(n_channels):\n","        data[f\"dim_{c}\"] = [pd.Series(X_np[i, c, :]) for i in range(n_instances)]\n","    return pd.DataFrame(data)\n","\n","\n","# ---------------------------\n","# 2) Create synthetic HAR-like training dataset\n","# ---------------------------\n","# Each sample: one window [channels, time] with Gaussian noise\n","X_train_np = np.random.randn(N_TRAIN, N_CHANNELS, WINDOW_SAMPLES).astype(np.float32)\n","y_train    = np.random.randint(0, N_CLASSES, size=(N_TRAIN,), dtype=np.int32)\n","\n","print(f\"X_train_np shape: {X_train_np.shape}, y_train shape: {y_train.shape}\")\n","\n","X_train = to_nested_dataframe(X_train_np)\n","print(f\"X_train nested DataFrame shape: {X_train.shape}\")\n","\n","\n","# ---------------------------\n","# 3) Define MiniRocket + linear classifier\n","# ---------------------------\n","minirocket = MiniRocketMultivariate(\n","    num_kernels=10000,             # standard MiniRocket setting\n","    max_dilations_per_kernel=32,\n","    n_jobs=1,                      # single-core for fair comparison\n","    random_state=SEED,\n",")\n","\n","clf = RidgeClassifier(\n","    alpha=1.0,\n","    fit_intercept=True\n",")\n","\n","# ---------------------------\n","# 4) Fit MiniRocket feature extractor + linear classifier\n","# ---------------------------\n","t0_fit = time.perf_counter()\n","minirocket.fit(X_train, y_train)\n","X_train_trans = minirocket.transform(X_train)\n","clf.fit(X_train_trans, y_train)\n","t1_fit = time.perf_counter()\n","fit_time_ms = (t1_fit - t0_fit) * 1000.0\n","\n","n_features_rocket = X_train_trans.shape[1]\n","n_linear_params = clf.coef_.size + clf.intercept_.size\n","\n","print(f\"\\nMiniRocket fit + linear head fit time: {fit_time_ms:.3f} ms\")\n","print(f\"MiniRocket transformed feature dimension: {n_features_rocket}\")\n","print(f\"Approximate number of linear head parameters: {n_linear_params:,}\")\n","\n","\n","# ---------------------------\n","# 5) Utility: latency measurement for MiniRocket + linear head\n","# ---------------------------\n","def measure_minirocket_latency(\n","    transformer: MiniRocketMultivariate,\n","    classifier,\n","    X_query_nested: pd.DataFrame,\n","    batch_size: int,\n","    n_warmup: int = 20,\n","    n_runs: int = 100,\n","):\n","    \"\"\"\n","    Measure MiniRocket.transform() + linear classifier.predict() latency on CPU.\n","    X_query_nested: nested DataFrame with shape (batch_size, n_channels).\n","    Returns latency stats in milliseconds per batch.\n","    \"\"\"\n","    # Warm-up\n","    for _ in range(n_warmup):\n","        X_feat = transformer.transform(X_query_nested)\n","        _ = classifier.predict(X_feat)\n","\n","    # Timed runs\n","    times_ms = []\n","    for _ in range(n_runs):\n","        t0 = time.perf_counter()\n","        X_feat = transformer.transform(X_query_nested)\n","        _ = classifier.predict(X_feat)\n","        t1 = time.perf_counter()\n","        times_ms.append((t1 - t0) * 1000.0)\n","\n","    times_ms = np.array(times_ms, dtype=float)\n","    stats = {\n","        \"batch_latency_p50_ms\": float(np.percentile(times_ms, 50)),\n","        \"batch_latency_p90_ms\": float(np.percentile(times_ms, 90)),\n","        \"batch_latency_mean_ms\": float(times_ms.mean()),\n","        \"batch_latency_std_ms\":  float(times_ms.std()),\n","        \"n_runs\": int(n_runs),\n","        \"batch_size\": int(batch_size),\n","    }\n","    return stats\n","\n","\n","# ---------------------------\n","# 6) Build a synthetic query batch and run the benchmark\n","# ---------------------------\n","X_query_np = np.random.randn(BATCH_SIZE, N_CHANNELS, WINDOW_SAMPLES).astype(np.float32)\n","X_query = to_nested_dataframe(X_query_np)\n","\n","print(f\"\\nQuery batch nested DataFrame shape: {X_query.shape}\")\n","\n","stats = measure_minirocket_latency(\n","    minirocket,\n","    clf,\n","    X_query_nested=X_query,\n","    batch_size=BATCH_SIZE,\n","    n_warmup=N_WARMUP,\n","    n_runs=N_RUNS,\n",")\n","\n","print(\"\\nCPU latency stats for MiniRocket + linear head (per batch):\")\n","for k, v in stats.items():\n","    if k.endswith(\"_ms\"):\n","        print(f\"  {k}: {v:.4f}\")\n","    else:\n","        print(f\"  {k}: {v}\")\n","\n","# Each sample corresponds to one HAR window, so per-window latency = per-batch / batch_size\n","per_window_p50  = stats[\"batch_latency_p50_ms\"]  / stats[\"batch_size\"]\n","per_window_p90  = stats[\"batch_latency_p90_ms\"]  / stats[\"batch_size\"]\n","per_window_mean = stats[\"batch_latency_mean_ms\"] / stats[\"batch_size\"]\n","\n","print(\"\\nApproximate CPU latency per window (HAR sample):\")\n","print(f\"  window_latency_p50_ms  ≈ {per_window_p50:.4f}\")\n","print(f\"  window_latency_p90_ms  ≈ {per_window_p90:.4f}\")\n","print(f\"  window_latency_mean_ms ≈ {per_window_mean:.4f}\")\n","\n","print(\"\\n[MiniRocket CPU inference latency benchmark completed]\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"keBHTxRjS3jK","executionInfo":{"status":"ok","timestamp":1763474955265,"user_tz":0,"elapsed":56359,"user":{"displayName":"yu Wu","userId":"12692660435918028293"}},"outputId":"bef4d59e-c358-4877-8560-37dda9be5a0c"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","[MiniRocket CPU Inference Latency Benchmark for HAR Windows]\n","Using device: cpu\n","torch.get_num_threads() = 1\n","NUMBA threads = 1\n","N_CHANNELS=6, WINDOW_SAMPLES=150, N_CLASSES=8\n","N_TRAIN=20000, N_WARMUP=20, N_RUNS=100, BATCH_SIZE=1\n","X_train_np shape: (20000, 6, 150), y_train shape: (20000,)\n","X_train nested DataFrame shape: (20000, 6)\n","\n","MiniRocket fit + linear head fit time: 43968.084 ms\n","MiniRocket transformed feature dimension: 9996\n","Approximate number of linear head parameters: 79,976\n","\n","Query batch nested DataFrame shape: (1, 6)\n","\n","CPU latency stats for MiniRocket + linear head (per batch):\n","  batch_latency_p50_ms: 31.7074\n","  batch_latency_p90_ms: 92.0187\n","  batch_latency_mean_ms: 40.9640\n","  batch_latency_std_ms: 22.8331\n","  n_runs: 100\n","  batch_size: 1\n","\n","Approximate CPU latency per window (HAR sample):\n","  window_latency_p50_ms  ≈ 31.7074\n","  window_latency_p90_ms  ≈ 92.0187\n","  window_latency_mean_ms ≈ 40.9640\n","\n","[MiniRocket CPU inference latency benchmark completed]\n"]}]},{"cell_type":"markdown","source":["2. multirocket (sktime)"],"metadata":{"id":"7b8IuQibTJWK"}},{"cell_type":"code","source":["# ================ MultiRocket CPU Inference Latency Benchmark for HAR Windows (Single-Core Baseline) ================\n","import os\n","os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n","os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n","os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n","os.environ[\"NUMBA_NUM_THREADS\"] = \"1\"\n","os.environ[\"NUMBA_DEFAULT_NUM_THREADS\"] = \"1\"\n","\n","import time\n","import random\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","import numpy as np\n","import torch\n","import numba\n","from sklearn.linear_model import RidgeClassifier\n","from sktime.transformations.panel.rocket import MultiRocketMultivariate\n","\n","print(\"\\n[MultiRocket CPU Inference Latency Benchmark for HAR Windows]\")\n","\n","# ---------------------------\n","# 1) Basic configuration (single-core CPU)\n","# ---------------------------\n","SEED = 42\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","\n","device = \"cpu\"\n","torch.set_num_threads(1)\n","numba.set_num_threads(1)\n","\n","print(f\"Using device: {device}\")\n","print(f\"torch.get_num_threads() = {torch.get_num_threads()}\")\n","print(f\"NUMBA threads = {numba.get_num_threads()}\")\n","\n","# HAR-like window settings: 6 channels, 150 time steps (3 s @ 50 Hz)\n","N_CHANNELS      = 6\n","WINDOW_SAMPLES  = 150\n","N_CLASSES       = 8\n","\n","print(f\"\\nN_CHANNELS={N_CHANNELS}, WINDOW_SAMPLES={WINDOW_SAMPLES}, N_CLASSES={N_CLASSES}\")\n","\n","# Training set size (aligned with other baselines)\n","N_TRAIN   = 20000\n","\n","# Latency measurement settings\n","N_WARMUP   = 20\n","N_RUNS     = 100\n","BATCH_SIZE = 1   # per-window latency\n","\n","print(f\"N_TRAIN={N_TRAIN}, N_WARMUP={N_WARMUP}, N_RUNS={N_RUNS}, BATCH_SIZE={BATCH_SIZE}\")\n","\n","# MultiRocket configuration (canonical setting: ~6,250 kernels)\n","NUM_KERNELS = 6250     # MultiRocket will internally round down to multiple of 84\n","MAX_DILATIONS_PER_KERNEL = 32\n","N_FEATURES_PER_KERNEL    = 4\n","\n","print(f\"\\nMultiRocket config: num_kernels={NUM_KERNELS}, \"\n","      f\"max_dilations_per_kernel={MAX_DILATIONS_PER_KERNEL}, \"\n","      f\"n_features_per_kernel={N_FEATURES_PER_KERNEL}\")\n","\n","# ---------------------------\n","# 2) Create synthetic HAR-like training dataset (3D numpy: [N, C, T])\n","# ---------------------------\n","X_train = np.random.randn(N_TRAIN, N_CHANNELS, WINDOW_SAMPLES).astype(np.float64)\n","y_train = np.random.randint(0, N_CLASSES, size=(N_TRAIN,), dtype=np.int32)\n","\n","print(f\"\\nX_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n","\n","# ---------------------------\n","# 3) Define MultiRocket + linear classifier\n","# ---------------------------\n","multirocket = MultiRocketMultivariate(\n","    num_kernels=NUM_KERNELS,\n","    max_dilations_per_kernel=MAX_DILATIONS_PER_KERNEL,\n","    n_features_per_kernel=N_FEATURES_PER_KERNEL,\n","    n_jobs=1,             # single-core for fair comparison\n","    random_state=SEED,\n",")\n","\n","clf = RidgeClassifier(\n","    alpha=1.0,\n","    fit_intercept=True,\n","    solver=\"lsqr\",\n",")\n","\n","# ---------------------------\n","# 4) Fit MultiRocket feature extractor + linear classifier\n","# ---------------------------\n","t0_fit = time.perf_counter()\n","multirocket.fit(X_train, y_train)\n","X_train_trans = multirocket.transform(X_train)\n","if hasattr(X_train_trans, \"values\"):\n","    X_train_trans = X_train_trans.values\n","clf.fit(X_train_trans, y_train)\n","t1_fit = time.perf_counter()\n","fit_time_ms = (t1_fit - t0_fit) * 1000.0\n","\n","n_features_rocket = X_train_trans.shape[1]\n","n_linear_params = clf.coef_.size + clf.intercept_.size\n","\n","print(f\"\\nMultiRocket fit + linear head fit time: {fit_time_ms:.3f} ms\")\n","print(f\"MultiRocket transformed feature dimension: {n_features_rocket}\")\n","print(f\"Approximate number of linear head parameters: {n_linear_params:,}\")\n","\n","# ---------------------------\n","# 5) Utility: latency measurement for MultiRocket + linear head\n","# ---------------------------\n","def measure_multirocket_latency(\n","    transformer,\n","    classifier,\n","    X_query,\n","    batch_size: int,\n","    n_warmup: int = 20,\n","    n_runs: int = 100,\n","):\n","    \"\"\"\n","    Measure MultiRocket.transform() + RidgeClassifier.predict() latency on CPU.\n","    X_query: numpy array with shape (batch_size, n_channels, n_timepoints).\n","    Returns latency stats in milliseconds per batch.\n","    \"\"\"\n","    assert X_query.shape[0] == batch_size\n","\n","    # Warm-up (excluded from statistics)\n","    for _ in range(n_warmup):\n","        feats = transformer.transform(X_query)\n","        if hasattr(feats, \"values\"):\n","            feats = feats.values\n","        _ = classifier.predict(feats)\n","\n","    # Timed runs\n","    times_ms = []\n","    for _ in range(n_runs):\n","        t0 = time.perf_counter()\n","        feats = transformer.transform(X_query)\n","        if hasattr(feats, \"values\"):\n","            feats = feats.values\n","        _ = classifier.predict(feats)\n","        t1 = time.perf_counter()\n","        times_ms.append((t1 - t0) * 1000.0)\n","\n","    times_ms = np.array(times_ms, dtype=float)\n","    stats = {\n","        \"batch_latency_p50_ms\": float(np.percentile(times_ms, 50)),\n","        \"batch_latency_p90_ms\": float(np.percentile(times_ms, 90)),\n","        \"batch_latency_mean_ms\": float(times_ms.mean()),\n","        \"batch_latency_std_ms\":  float(times_ms.std()),\n","        \"n_runs\": int(n_runs),\n","        \"batch_size\": int(batch_size),\n","    }\n","    return stats\n","\n","# ---------------------------\n","# 6) Build a synthetic query batch and run the benchmark\n","# ---------------------------\n","X_query = np.random.randn(BATCH_SIZE, N_CHANNELS, WINDOW_SAMPLES).astype(np.float64)\n","print(f\"\\nX_query shape: {X_query.shape}\")\n","\n","stats = measure_multirocket_latency(\n","    multirocket,\n","    clf,\n","    X_query=X_query,\n","    batch_size=BATCH_SIZE,\n","    n_warmup=N_WARMUP,\n","    n_runs=N_RUNS,\n",")\n","\n","print(\"\\nCPU latency stats for MultiRocket + Ridge (per batch):\")\n","for k, v in stats.items():\n","    if k.endswith(\"_ms\"):\n","        print(f\"  {k}: {v:.4f}\")\n","    else:\n","        print(f\"  {k}: {v}\")\n","\n","# Each batch element = one HAR window, so per-window latency = per-batch / batch_size\n","per_window_p50  = stats[\"batch_latency_p50_ms\"]  / stats[\"batch_size\"]\n","per_window_p90  = stats[\"batch_latency_p90_ms\"]  / stats[\"batch_size\"]\n","per_window_mean = stats[\"batch_latency_mean_ms\"] / stats[\"batch_size\"]\n","\n","print(\"\\nApproximate CPU latency per window (HAR sample):\")\n","print(f\"  window_latency_p50_ms  ≈ {per_window_p50:.4f}\")\n","print(f\"  window_latency_p90_ms  ≈ {per_window_p90:.4f}\")\n","print(f\"  window_latency_mean_ms ≈ {per_window_mean:.4f}\")\n","\n","print(\"\\n[MultiRocket CPU inference latency benchmark completed]\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wK6jPtQcAfqg","executionInfo":{"status":"ok","timestamp":1763470704390,"user_tz":0,"elapsed":531155,"user":{"displayName":"yu Wu","userId":"12692660435918028293"}},"outputId":"eaad7bac-2fc4-4d88-9eda-b90a4b70d2e4"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","[MultiRocket CPU Inference Latency Benchmark for HAR Windows]\n","Using device: cpu\n","torch.get_num_threads() = 1\n","NUMBA threads = 1\n","\n","N_CHANNELS=6, WINDOW_SAMPLES=150, N_CLASSES=8\n","N_TRAIN=20000, N_WARMUP=20, N_RUNS=100, BATCH_SIZE=1\n","\n","MultiRocket config: num_kernels=6250, max_dilations_per_kernel=32, n_features_per_kernel=4\n","\n","X_train shape: (20000, 6, 150), y_train shape: (20000,)\n","\n","MultiRocket fit + linear head fit time: 524059.676 ms\n","MultiRocket transformed feature dimension: 49728\n","Approximate number of linear head parameters: 397,832\n","\n","X_query shape: (1, 6, 150)\n","\n","CPU latency stats for MultiRocket + Ridge (per batch):\n","  batch_latency_p50_ms: 10.2868\n","  batch_latency_p90_ms: 10.5759\n","  batch_latency_mean_ms: 10.3077\n","  batch_latency_std_ms: 0.2091\n","  n_runs: 100\n","  batch_size: 1\n","\n","Approximate CPU latency per window (HAR sample):\n","  window_latency_p50_ms  ≈ 10.2868\n","  window_latency_p90_ms  ≈ 10.5759\n","  window_latency_mean_ms ≈ 10.3077\n","\n","[MultiRocket CPU inference latency benchmark completed]\n"]}]},{"cell_type":"markdown","source":["3. multirocket (aeon)"],"metadata":{"id":"ihQv3VCPTPBB"}},{"cell_type":"code","source":["# ================ MultiRocket CPU Inference Latency Benchmark for HAR Windows (Standalone, aeon) ================\n","# IMPORTANT:\n","#   - Run this cell in a *fresh* Colab runtime, before importing numba / aeon / torch anywhere else.\n","#   - The script is designed to be directly comparable to your MiniRocket CPU benchmark:\n","#       * 6 channels, 150 time steps (~3 s @ 50 Hz), 8 classes\n","#       * N_TRAIN = 20,000 synthetic windows\n","#       * N_WARMUP = 20, N_RUNS = 100, BATCH_SIZE = 1\n","#       * Single-core intent: all thread-related env vars set to 1, n_jobs=1 in MultiRocket\n","#   - Latency = MultiRocket.transform() + RidgeClassifier.predict() on CPU.\n","\n","!pip -q install aeon scikit-learn\n","\n","import os\n","import time\n","import random\n","import warnings\n","import platform\n","\n","warnings.filterwarnings(\"ignore\")\n","\n","# ----------------------------------------------------------------------\n","# 0) Environment: fix thread-related env vars BEFORE importing numba/aeon\n","# ----------------------------------------------------------------------\n","# We fix all relevant BLAS / OpenMP / Numba thread counts to 1 to emulate\n","# a single-core CPU setting. This MUST be done before importing numba.\n","for var in [\"OMP_NUM_THREADS\", \"MKL_NUM_THREADS\", \"OPENBLAS_NUM_THREADS\", \"NUMBA_NUM_THREADS\"]:\n","    os.environ[var] = \"1\"\n","\n","import numpy as np\n","import torch\n","from sklearn.linear_model import RidgeClassifier\n","import numba\n","from aeon.transformations.collection.convolution_based import MultiRocket\n","\n","print(\"\\n[MultiRocket CPU Inference Latency Benchmark for HAR Windows (aeon)]\")\n","\n","# ----------------------------------------------------------------------\n","# 1) Basic configuration\n","# ----------------------------------------------------------------------\n","SEED = 42\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","\n","# Make PyTorch single-threaded (for consistency with env vars)\n","torch.set_num_threads(1)\n","\n","# Numba should already respect NUMBA_NUM_THREADS=1 from the env\n","numba_threads = numba.get_num_threads()\n","\n","device = \"cpu\"\n","print(f\"Using device: {device}\")\n","print(f\"torch.get_num_threads()      = {torch.get_num_threads()}\")\n","print(f\"Numba effective num_threads  = {numba_threads}\")\n","\n","print(\"Platform :\", platform.system(), platform.release())\n","print(\"CPU      :\", platform.processor())\n","\n","# HAR-like window settings (aligned with the MiniRocket benchmark)\n","N_CHANNELS      = 6\n","WINDOW_SAMPLES  = 150   # ~3 s @ 50 Hz\n","N_CLASSES       = 8\n","\n","print(f\"N_CHANNELS={N_CHANNELS}, WINDOW_SAMPLES={WINDOW_SAMPLES}, N_CLASSES={N_CLASSES}\")\n","\n","# Training set size (aligned with other baselines)\n","N_TRAIN   = 20000\n","\n","# Latency measurement settings\n","N_WARMUP   = 20\n","N_RUNS     = 100\n","BATCH_SIZE = 1      # number of query windows per call\n","\n","print(f\"N_TRAIN={N_TRAIN}, N_WARMUP={N_WARMUP}, N_RUNS={N_RUNS}, BATCH_SIZE={BATCH_SIZE}\")\n","\n","# MultiRocket configuration (standard, literature-aligned)\n","N_KERNELS                = 10000   # number of convolutional kernels\n","MAX_DILATIONS_PER_KERNEL = 32\n","N_FEATURES_PER_KERNEL    = 4\n","\n","print(f\"N_KERNELS (MultiRocket)          = {N_KERNELS}\")\n","print(f\"MAX_DILATIONS_PER_KERNEL         = {MAX_DILATIONS_PER_KERNEL}\")\n","print(f\"N_FEATURES_PER_KERNEL            = {N_FEATURES_PER_KERNEL}\")\n","\n","SAMPLE_RATE_HZ = 50.0\n","WINDOW_SECONDS = WINDOW_SAMPLES / SAMPLE_RATE_HZ\n","print(f\"Assumed sampling rate = {SAMPLE_RATE_HZ} Hz → window length ≈ {WINDOW_SECONDS:.3f} s\")\n","\n","# ----------------------------------------------------------------------\n","# 2) Create synthetic HAR-like training dataset (3D numpy)\n","# ----------------------------------------------------------------------\n","# Shape: (n_instances, n_channels, n_timepoints)\n","X_train_np = np.random.randn(N_TRAIN, N_CHANNELS, WINDOW_SAMPLES).astype(np.float32)\n","y_train    = np.random.randint(0, N_CLASSES, size=(N_TRAIN,), dtype=np.int32)\n","\n","print(f\"\\nX_train_np shape: {X_train_np.shape}, y_train shape: {y_train.shape}\")\n","\n","# ----------------------------------------------------------------------\n","# 3) Define MultiRocket + linear classifier (Ridge)\n","# ----------------------------------------------------------------------\n","multirocket = MultiRocket(\n","    n_kernels=N_KERNELS,\n","    max_dilations_per_kernel=MAX_DILATIONS_PER_KERNEL,\n","    n_features_per_kernel=N_FEATURES_PER_KERNEL,\n","    normalise=False,\n","    n_jobs=1,           # do not use joblib parallelism; keep it single-process\n","    random_state=SEED,\n",")\n","\n","clf = RidgeClassifier(\n","    alpha=1.0,\n","    fit_intercept=True\n",")\n","\n","# ----------------------------------------------------------------------\n","# 4) Fit MultiRocket feature extractor + linear classifier\n","# ----------------------------------------------------------------------\n","t0_fit = time.perf_counter()\n","multirocket.fit(X_train_np, y_train)\n","X_train_trans = multirocket.transform(X_train_np)\n","clf.fit(X_train_trans, y_train)\n","t1_fit = time.perf_counter()\n","fit_time_ms = (t1_fit - t0_fit) * 1000.0\n","\n","n_features_rocket = X_train_trans.shape[1]\n","n_linear_params = clf.coef_.size + clf.intercept_.size\n","\n","print(f\"\\nMultiRocket fit + linear head fit time: {fit_time_ms:.3f} ms\")\n","print(f\"MultiRocket transformed feature dimension: {n_features_rocket}\")\n","print(f\"Approximate number of linear head parameters: {n_linear_params:,}\")\n","\n","# ----------------------------------------------------------------------\n","# 5) Utility: latency measurement for MultiRocket + linear head\n","# ----------------------------------------------------------------------\n","def measure_multirocket_latency(\n","    transformer: MultiRocket,\n","    classifier,\n","    X_query: np.ndarray,\n","    batch_size: int,\n","    n_warmup: int = 20,\n","    n_runs: int = 100,\n","):\n","    \"\"\"\n","    Measure MultiRocket.transform() + linear classifier.predict() latency on CPU.\n","    X_query: np.ndarray with shape (batch_size, n_channels, n_timepoints).\n","    Returns latency stats in milliseconds per batch.\n","    \"\"\"\n","    # Warm-up runs (excluded from stats)\n","    for _ in range(n_warmup):\n","        X_feat = transformer.transform(X_query)\n","        _ = classifier.predict(X_feat)\n","\n","    # Timed runs\n","    times_ms = []\n","    for _ in range(n_runs):\n","        t0 = time.perf_counter()\n","        X_feat = transformer.transform(X_query)\n","        _ = classifier.predict(X_feat)\n","        t1 = time.perf_counter()\n","        times_ms.append((t1 - t0) * 1000.0)\n","\n","    times_ms = np.array(times_ms, dtype=float)\n","    stats = {\n","        \"batch_latency_p50_ms\": float(np.percentile(times_ms, 50)),\n","        \"batch_latency_p90_ms\": float(np.percentile(times_ms, 90)),\n","        \"batch_latency_mean_ms\": float(times_ms.mean()),\n","        \"batch_latency_std_ms\":  float(times_ms.std()),\n","        \"n_runs\": int(n_runs),\n","        \"batch_size\": int(batch_size),\n","    }\n","    return stats\n","\n","# ----------------------------------------------------------------------\n","# 6) Build a synthetic query batch and run the benchmark\n","# ----------------------------------------------------------------------\n","X_query_np = np.random.randn(BATCH_SIZE, N_CHANNELS, WINDOW_SAMPLES).astype(np.float32)\n","print(f\"\\nQuery batch array shape: {X_query_np.shape}\")\n","\n","stats = measure_multirocket_latency(\n","    multirocket,\n","    clf,\n","    X_query=X_query_np,\n","    batch_size=BATCH_SIZE,\n","    n_warmup=N_WARMUP,\n","    n_runs=N_RUNS,\n",")\n","\n","print(\"\\nCPU latency stats for MultiRocket + linear head (per batch):\")\n","for k, v in stats.items():\n","    if k.endswith(\"_ms\"):\n","        print(f\"  {k}: {v:.4f}\")\n","    else:\n","        print(f\"  {k}: {v}\")\n","\n","# Each sample corresponds to one HAR window, so per-window latency = per-batch / batch_size\n","per_window_p50  = stats[\"batch_latency_p50_ms\"]  / stats[\"batch_size\"]\n","per_window_p90  = stats[\"batch_latency_p90_ms\"]  / stats[\"batch_size\"]\n","per_window_mean = stats[\"batch_latency_mean_ms\"] / stats[\"batch_size\"]\n","\n","print(\"\\nApproximate CPU latency per window (HAR sample):\")\n","print(f\"  window_latency_p50_ms  ≈ {per_window_p50:.4f}\")\n","print(f\"  window_latency_p90_ms  ≈ {per_window_p90:.4f}\")\n","print(f\"  window_latency_mean_ms ≈ {per_window_mean:.4f}\")\n","\n","# Optional: real-time factor relative to window length\n","rt_factor_p50  = per_window_p50  / (WINDOW_SECONDS * 1000.0)\n","rt_factor_mean = per_window_mean / (WINDOW_SECONDS * 1000.0)\n","\n","print(\"\\nReal-time factor (MultiRocket, CPU):\")\n","print(f\"  p50  RTF ≈ {rt_factor_p50:.4f} (CPU time / wall-clock window length)\")\n","print(f\"  mean RTF ≈ {rt_factor_mean:.4f}\")\n","\n","print(\"\\n[MultiRocket CPU inference latency benchmark (aeon, single-core) completed]\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_Xt44osFLKmj","executionInfo":{"status":"ok","timestamp":1763474343222,"user_tz":0,"elapsed":1463895,"user":{"displayName":"yu Wu","userId":"12692660435918028293"}},"outputId":"d9e6d740-249c-4897-a5cc-3c76d5b46735"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.3/37.3 MB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n","mizani 0.13.5 requires pandas>=2.2.0, but you have pandas 2.1.4 which is incompatible.\n","umap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.4.2 which is incompatible.\n","plotnine 0.14.5 requires pandas>=2.2.0, but you have pandas 2.1.4 which is incompatible.\n","cuml-cu12 25.10.0 requires numba<0.62.0a0,>=0.60.0, but you have numba 0.59.1 which is incompatible.\n","jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n","jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n","pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m\n","[MultiRocket CPU Inference Latency Benchmark for HAR Windows (aeon)]\n","Using device: cpu\n","torch.get_num_threads()      = 1\n","Numba effective num_threads  = 1\n","Platform : Linux 6.6.105+\n","CPU      : x86_64\n","N_CHANNELS=6, WINDOW_SAMPLES=150, N_CLASSES=8\n","N_TRAIN=20000, N_WARMUP=20, N_RUNS=100, BATCH_SIZE=1\n","N_KERNELS (MultiRocket)          = 10000\n","MAX_DILATIONS_PER_KERNEL         = 32\n","N_FEATURES_PER_KERNEL            = 4\n","Assumed sampling rate = 50.0 Hz → window length ≈ 3.000 s\n","\n","X_train_np shape: (20000, 6, 150), y_train shape: (20000,)\n","\n","MultiRocket fit + linear head fit time: 1451437.607 ms\n","MultiRocket transformed feature dimension: 79968\n","Approximate number of linear head parameters: 639,752\n","\n","Query batch array shape: (1, 6, 150)\n","\n","CPU latency stats for MultiRocket + linear head (per batch):\n","  batch_latency_p50_ms: 16.0703\n","  batch_latency_p90_ms: 16.5054\n","  batch_latency_mean_ms: 16.2110\n","  batch_latency_std_ms: 0.8237\n","  n_runs: 100\n","  batch_size: 1\n","\n","Approximate CPU latency per window (HAR sample):\n","  window_latency_p50_ms  ≈ 16.0703\n","  window_latency_p90_ms  ≈ 16.5054\n","  window_latency_mean_ms ≈ 16.2110\n","\n","Real-time factor (MultiRocket, CPU):\n","  p50  RTF ≈ 0.0054 (CPU time / wall-clock window length)\n","  mean RTF ≈ 0.0054\n","\n","[MultiRocket CPU inference latency benchmark (aeon, single-core) completed]\n"]}]}]}