All models are evaluated for inference latency within the same Google Colab session, using the high-RAM (51 GB) CPU and 3-second windows.
